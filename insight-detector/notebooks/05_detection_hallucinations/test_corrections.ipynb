{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test des Corrections du Niveau 0\n",
    "\n",
    "**Objectif :** Valider que les corrections apport√©es ont r√©solu les probl√®mes :\n",
    "- R√©duction du taux de rejet excessif (61.6% ‚Üí ~10-15%)\n",
    "- Correction de l'algorithme de r√©p√©titions\n",
    "- Calibrage automatique plus permissif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Configuration paths\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Import du module corrig√©\n",
    "from detection.level0_prefilter import QualityFilter, auto_calibrate_filter\n",
    "\n",
    "print(\"‚úÖ Module corrig√© import√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donn√©es\n",
    "data_path = os.path.join(project_root, 'data', 'results', 'batch_summary_production.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "summaries_data = []\n",
    "for idx, row in df.iterrows():\n",
    "    summaries_data.append({\n",
    "        'id': f\"{row['text_id']}_{row['fusion_strategy']}\",\n",
    "        'text': row['summary'],\n",
    "        'quality_grade': row['quality_grade']\n",
    "    })\n",
    "\n",
    "print(f\"üìä {len(summaries_data)} r√©sum√©s charg√©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test rapide avec seuils manuels corrig√©s\n",
    "print(\"üîß Test avec seuils manuels corrig√©s...\")\n",
    "filter_corrected = QualityFilter()\n",
    "\n",
    "start_time = time.time()\n",
    "valid_corrected, results_corrected = filter_corrected.process_batch(summaries_data)\n",
    "time_corrected = time.time() - start_time\n",
    "\n",
    "stats_corrected = filter_corrected.get_statistics(results_corrected)\n",
    "\n",
    "print(f\"\\nüìà R√©sultats apr√®s corrections:\")\n",
    "print(f\"   Seuils: {filter_corrected.min_words}-{filter_corrected.max_words} mots\")\n",
    "print(f\"   R√©sum√©s valides: {len(valid_corrected)}/{len(summaries_data)} ({len(valid_corrected)/len(summaries_data)*100:.1f}%)\")\n",
    "print(f\"   Taux rejet: {stats_corrected['rejection_rate_percent']:.1f}%\")\n",
    "print(f\"   Temps moyen: {stats_corrected['avg_processing_time_ms']:.1f}ms\")\n",
    "\n",
    "print(f\"\\n‚ùå Principales raisons de rejet:\")\n",
    "for reason, count in list(stats_corrected['rejection_reasons'].items())[:5]:\n",
    "    print(f\"   {reason}: {count} cas ({count/len(summaries_data)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test calibrage automatique corrig√©\n",
    "print(\"üéØ Test calibrage automatique corrig√©...\")\n",
    "filter_auto_corrected = auto_calibrate_filter(summaries_data)\n",
    "\n",
    "start_time = time.time()\n",
    "valid_auto_corrected, results_auto_corrected = filter_auto_corrected.process_batch(summaries_data)\n",
    "time_auto_corrected = time.time() - start_time\n",
    "\n",
    "stats_auto_corrected = filter_auto_corrected.get_statistics(results_auto_corrected)\n",
    "\n",
    "print(f\"\\nüìà R√©sultats calibrage automatique corrig√©:\")\n",
    "print(f\"   Seuils auto: {filter_auto_corrected.min_words}-{filter_auto_corrected.max_words} mots\")\n",
    "print(f\"   R√©sum√©s valides: {len(valid_auto_corrected)}/{len(summaries_data)} ({len(valid_auto_corrected)/len(summaries_data)*100:.1f}%)\")\n",
    "print(f\"   Taux rejet: {stats_auto_corrected['rejection_rate_percent']:.1f}%\")\n",
    "print(f\"   Temps moyen: {stats_auto_corrected['avg_processing_time_ms']:.1f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison avant/apr√®s corrections\n",
    "print(\"üìä COMPARAISON AVANT/APR√àS CORRECTIONS:\")\n",
    "print(\"\\nüî¥ AVANT (probl√©matique):\")\n",
    "print(\"   Manuel: 143/372 valides (38.4%) - Taux rejet: 61.6%\")\n",
    "print(\"   Auto: 99/372 valides (26.6%) - Taux rejet: 73.4%\")\n",
    "print(\"   Probl√®me: 15,884 cas de r√©p√©titions d√©tect√©es (impossible)\")\n",
    "\n",
    "print(\"\\nüü¢ APR√àS (corrig√©):\")\n",
    "print(f\"   Manuel: {len(valid_corrected)}/{len(summaries_data)} valides ({len(valid_corrected)/len(summaries_data)*100:.1f}%) - Taux rejet: {stats_corrected['rejection_rate_percent']:.1f}%\")\n",
    "print(f\"   Auto: {len(valid_auto_corrected)}/{len(summaries_data)} valides ({len(valid_auto_corrected)/len(summaries_data)*100:.1f}%) - Taux rejet: {stats_auto_corrected['rejection_rate_percent']:.1f}%\")\n",
    "\n",
    "# Am√©lioration\n",
    "improvement_manual = len(valid_corrected) - 143\n",
    "improvement_auto = len(valid_auto_corrected) - 99\n",
    "\n",
    "print(f\"\\nüöÄ AM√âLIORATIONS:\")\n",
    "print(f\"   Manuel: +{improvement_manual} r√©sum√©s valid√©s\")\n",
    "print(f\"   Auto: +{improvement_auto} r√©sum√©s valid√©s\")\n",
    "print(f\"   R√©duction taux rejet manuel: {61.6 - stats_corrected['rejection_rate_percent']:.1f} points\")\n",
    "print(f\"   R√©duction taux rejet auto: {73.4 - stats_auto_corrected['rejection_rate_percent']:.1f} points\")\n",
    "\n",
    "# Validation des objectifs\n",
    "target_met = 10 <= stats_corrected['rejection_rate_percent'] <= 20\n",
    "print(f\"\\n‚úÖ Objectif taux rejet 10-20%: {'ATTEINT' if target_met else '√Ä AJUSTER'}\")\n",
    "print(f\"‚úÖ Performance <50ms: {'ATTEINT' if stats_corrected['avg_processing_time_ms'] < 50 else '√Ä OPTIMISER'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse par grades (v√©rification de la coh√©rence)\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        'grade': summaries_data[i]['quality_grade'],\n",
    "        'valid_corrected': results_corrected[i].is_valid,\n",
    "        'reasons': '; '.join(results_corrected[i].rejection_reasons) if results_corrected[i].rejection_reasons else 'Valid'\n",
    "    }\n",
    "    for i in range(len(summaries_data))\n",
    "])\n",
    "\n",
    "print(\"üéØ Validation par grade (apr√®s corrections):\")\n",
    "for grade in ['A+', 'A', 'B+', 'B', 'C', 'D']:\n",
    "    if grade in results_df['grade'].values:\n",
    "        grade_data = results_df[results_df['grade'] == grade]\n",
    "        rejected = len(grade_data[~grade_data['valid_corrected']])\n",
    "        total = len(grade_data)\n",
    "        print(f\"   Grade {grade}: {rejected}/{total} rejet√©s ({rejected/total*100:.1f}%)\")\n",
    "\n",
    "# V√©rification coh√©rence: les grades A+ ne doivent pas √™tre plus rejet√©s que les grades D\n",
    "a_plus_rejection = len(results_df[(results_df['grade'] == 'A+') & (~results_df['valid_corrected'])]) / len(results_df[results_df['grade'] == 'A+']) * 100\n",
    "d_rejection = len(results_df[(results_df['grade'] == 'D') & (~results_df['valid_corrected'])]) / len(results_df[results_df['grade'] == 'D']) * 100\n",
    "\n",
    "coherence_ok = a_plus_rejection < d_rejection\n",
    "print(f\"\\n‚úÖ Coh√©rence grades (A+ < D): {'OK' if coherence_ok else '√Ä AJUSTER'} ({a_plus_rejection:.1f}% vs {d_rejection:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion et validation\n",
    "print(\"\\nüéâ CONCLUSION DES CORRECTIONS:\")\n",
    "\n",
    "corrections_successful = (\n",
    "    stats_corrected['rejection_rate_percent'] < 30 and  # Taux rejet raisonnable\n",
    "    len(valid_corrected) > 200 and  # Assez de r√©sum√©s valides\n",
    "    stats_corrected['avg_processing_time_ms'] < 50 and  # Performance OK\n",
    "    coherence_ok  # Coh√©rence par grades\n",
    ")\n",
    "\n",
    "if corrections_successful:\n",
    "    print(\"‚úÖ CORRECTIONS R√âUSSIES - Niveau 0 op√©rationnel\")\n",
    "    print(\"üöÄ PR√äT pour le Niveau 1 : D√©tection heuristique\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è CORRECTIONS PARTIELLES - Ajustements suppl√©mentaires n√©cessaires\")\n",
    "    \n",
    "    if stats_corrected['rejection_rate_percent'] >= 30:\n",
    "        print(\"   - Taux rejet encore trop √©lev√©\")\n",
    "    if len(valid_corrected) <= 200:\n",
    "        print(\"   - Pas assez de r√©sum√©s valides\")\n",
    "    if not coherence_ok:\n",
    "        print(\"   - Incoh√©rence dans les grades\")\n",
    "\n",
    "print(f\"\\nM√©triques finales:\")\n",
    "print(f\"- Taux rejet: {stats_corrected['rejection_rate_percent']:.1f}% (objectif: 10-20%)\")\n",
    "print(f\"- R√©sum√©s valides: {len(valid_corrected)}/372 ({len(valid_corrected)/372*100:.1f}%)\")\n",
    "print(f\"- Performance: {stats_corrected['avg_processing_time_ms']:.1f}ms (objectif: <50ms)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}