{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Niveau 3 Corrig√© - Test des Am√©liorations\n",
    "\n",
    "Ce notebook teste les corrections apport√©es au Level 3:\n",
    "- Configuration assouplies (seuils d'acceptation)\n",
    "- Mapping am√©lior√© articles ‚Üí source_id\n",
    "- Crit√®res de re-summarize moins restrictifs\n",
    "- Nouveaux garde-fous pour tier CRITICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json, pandas as pd\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Setup paths\n",
    "def find_project_root():\n",
    "    p = Path.cwd().resolve()\n",
    "    for parent in [p, *p.parents]:\n",
    "        if (parent / \"src\").exists() and (parent / \"outputs\").exists():\n",
    "            return parent\n",
    "    return Path.cwd()\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "sys.path.append(str(PROJECT_ROOT / \"src\" / \"detection\" / \"level3_improvement\"))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Level3 utils with corrections\n",
    "from level3_utils import (\n",
    "    sha1_text, read_jsonl, write_jsonl, detect_lang, \n",
    "    choose_mode, accept_after, l2_like_evaluate\n",
    ")\n",
    "import yaml\n",
    "\n",
    "# Load corrected config\n",
    "config_file = PROJECT_ROOT / \"src\" / \"detection\" / \"level3_improvement\" / \"config\" / \"level3.yaml\"\n",
    "with open(config_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    CFG = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration corrig√©e charg√©e:\")\n",
    "print(f\"- priority_threshold: {CFG['priority_threshold']}\")\n",
    "print(f\"- min_text_chars_for_resummarize: {CFG['min_text_chars_for_resummarize']}\")\n",
    "print(f\"- accepted_tiers: {CFG['acceptance']['accepted_tiers']}\")\n",
    "print(f\"- topic overlap min: {CFG.get('acceptance_topic', {}).get('after_text_min', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test du mapping am√©lior√©\n",
    "outputs_dir = PROJECT_ROOT / \"outputs\"\n",
    "\n",
    "# Charger le mapping am√©lior√©\n",
    "enhanced_mapping = pd.read_csv(outputs_dir / \"level3_enhanced_mapping.csv\")\n",
    "text_mapping = pd.read_csv(outputs_dir / \"level3_text_mapping.csv\")\n",
    "\n",
    "print(f\"Mapping am√©lior√©: {len(enhanced_mapping)} entr√©es\")\n",
    "print(f\"Avec texte: {enhanced_mapping['has_text'].sum()} ({enhanced_mapping['has_text'].mean()*100:.1f}%)\")\n",
    "print(f\"Texte suffisant: {enhanced_mapping['enough_length'].sum()} ({enhanced_mapping['enough_length'].mean()*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nMapping texte pour Level3: {len(text_mapping)} entr√©es\")\n",
    "print(f\"Longueur moyenne des textes: {text_mapping['text_length'].mean():.0f} caract√®res\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de la s√©lection des candidats avec nouveaux seuils\n",
    "level2_results = pd.read_csv(outputs_dir / \"level2_simplified_results_with_ids.csv\")\n",
    "\n",
    "# S√©lection avec seuil abaiss√©\n",
    "candidates_new = level2_results[\n",
    "    (level2_results[\"tier\"] == \"CRITICAL\") | \n",
    "    (level2_results[\"level3_priority_final\"] >= CFG[\"priority_threshold\"])\n",
    "].copy()\n",
    "\n",
    "print(f\"Candidats avec nouveaux seuils: {len(candidates_new)}\")\n",
    "print(f\"Distribution par tier:\")\n",
    "print(candidates_new[\"tier\"].value_counts())\n",
    "print(f\"\\nDistribution par strat√©gie:\")\n",
    "print(candidates_new[\"strategy\"].value_counts() if \"strategy\" in candidates_new.columns else \"Strat√©gie non trouv√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de choose_mode avec crit√®res assouplies\n",
    "sample_candidates = candidates_new.head(20).copy()\n",
    "\n",
    "# Ajouter les informations de texte depuis le mapping am√©lior√©\n",
    "sample_with_text = sample_candidates.merge(\n",
    "    enhanced_mapping[['level2_id', 'has_text', 'enough_length', 'text_length', 'text']], \n",
    "    left_on='summary_id', \n",
    "    right_on='level2_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Test des modes\n",
    "mode_results = []\n",
    "for _, row in sample_with_text.iterrows():\n",
    "    mode, reason, flags = choose_mode(row.to_dict(), CFG)\n",
    "    mode_results.append({\n",
    "        'summary_id': row['summary_id'],\n",
    "        'tier': row['tier'],\n",
    "        'strategy': row.get('strategy', 'unknown'),\n",
    "        'has_text': flags['has_text'],\n",
    "        'enough_length': flags['enough_length'],\n",
    "        'text_length': row.get('text_length', 0),\n",
    "        'mode': mode,\n",
    "        'reason': reason\n",
    "    })\n",
    "\n",
    "mode_df = pd.DataFrame(mode_results)\n",
    "print(\"Test des modes avec crit√®res assouplies:\")\n",
    "print(mode_df[['summary_id', 'tier', 'strategy', 'has_text', 'enough_length', 'mode', 'reason']])\n",
    "print(f\"\\nDistribution des modes:\")\n",
    "print(mode_df['mode'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test des crit√®res d'acceptation assouplies\n",
    "print(\"Test des nouveaux crit√®res d'acceptation:\")\n",
    "\n",
    "# Simuler des cas avant/apr√®s pour tester accept_after\n",
    "test_cases = [\n",
    "    {\n",
    "        'name': 'CRITICAL avec am√©lioration factualit√©',\n",
    "        'before': {'tier': 'CRITICAL', 'factuality_score': 0.65, 'coherence_score': 0.70},\n",
    "        'after': {'tier': 'CRITICAL', 'factuality_score': 0.82, 'coherence_score': 0.72, 'issues_count': 5}\n",
    "    },\n",
    "    {\n",
    "        'name': 'MODERATE assouplies',\n",
    "        'before': {'tier': 'CRITICAL', 'factuality_score': 0.70, 'coherence_score': 0.65},\n",
    "        'after': {'tier': 'MODERATE', 'factuality_score': 0.82, 'coherence_score': 0.72, 'issues_count': 3}\n",
    "    },\n",
    "    {\n",
    "        'name': 'GOOD (accept√©)',\n",
    "        'before': {'tier': 'CRITICAL', 'factuality_score': 0.70, 'coherence_score': 0.65},\n",
    "        'after': {'tier': 'GOOD', 'factuality_score': 0.85, 'coherence_score': 0.75, 'issues_count': 2}\n",
    "    }\n",
    "]\n",
    "\n",
    "for test_case in test_cases:\n",
    "    accepted, reason = accept_after(test_case['before'], test_case['after'], CFG)\n",
    "    print(f\"\\n{test_case['name']}: {'‚úÖ ACCEPT√â' if accepted else '‚ùå REJET√â'} - {reason}\")\n",
    "    print(f\"  Avant: {test_case['before']}\")\n",
    "    print(f\"  Apr√®s: {test_case['after']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation finale: comparaison ancien vs nouveau syst√®me\n",
    "print(\"=== COMPARAISON ANCIEN vs NOUVEAU SYST√àME ===\")\n",
    "\n",
    "# Anciens seuils (pour comparaison)\n",
    "old_priority_threshold = 0.85\n",
    "old_min_chars = 800\n",
    "old_topic_threshold = 0.12\n",
    "\n",
    "# Nouveaux seuils\n",
    "new_priority_threshold = CFG['priority_threshold']\n",
    "new_min_chars = CFG['min_text_chars_for_resummarize']\n",
    "new_topic_threshold = CFG.get('acceptance_topic', {}).get('after_text_min', 0.05)\n",
    "\n",
    "print(f\"Seuil priorit√©: {old_priority_threshold} ‚Üí {new_priority_threshold}\")\n",
    "print(f\"Caract√®res min: {old_min_chars} ‚Üí {new_min_chars}\")\n",
    "print(f\"Topic overlap: {old_topic_threshold} ‚Üí {new_topic_threshold}\")\n",
    "\n",
    "# Impact sur la s√©lection\n",
    "old_candidates = level2_results[\n",
    "    (level2_results[\"tier\"] == \"CRITICAL\") | \n",
    "    (level2_results[\"level3_priority_final\"] >= old_priority_threshold)\n",
    "]\n",
    "\n",
    "print(f\"\\nCandidats s√©lectionn√©s:\")\n",
    "print(f\"  Ancien syst√®me: {len(old_candidates)}\")\n",
    "print(f\"  Nouveau syst√®me: {len(candidates_new)}\")\n",
    "print(f\"  Gain: +{len(candidates_new) - len(old_candidates)} candidats\")\n",
    "\n",
    "# Impact sur les textes suffisants\n",
    "old_sufficient = enhanced_mapping[enhanced_mapping['text_length'] >= old_min_chars]\n",
    "new_sufficient = enhanced_mapping[enhanced_mapping['text_length'] >= new_min_chars]\n",
    "\n",
    "print(f\"\\nTextes suffisants pour re-summarize:\")\n",
    "print(f\"  Ancien syst√®me: {len(old_sufficient)} ({len(old_sufficient)/len(enhanced_mapping)*100:.1f}%)\")\n",
    "print(f\"  Nouveau syst√®me: {len(new_sufficient)} ({len(new_sufficient)/len(enhanced_mapping)*100:.1f}%)\")\n",
    "print(f\"  Gain: +{len(new_sufficient) - len(old_sufficient)} textes utilisables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©sum√© des am√©liorations\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"R√âSUM√â DES CORRECTIONS LEVEL 3\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n‚úÖ CORRECTIONS APPLIQU√âES:\")\n",
    "print(\"1. Configuration assouplies:\")\n",
    "print(f\"   - Seuil priorit√©: 0.85 ‚Üí {CFG['priority_threshold']}\")\n",
    "print(f\"   - Texte min: 800 ‚Üí {CFG['min_text_chars_for_resummarize']} caract√®res\")\n",
    "print(f\"   - Tiers accept√©s: {CFG['acceptance']['accepted_tiers']}\")\n",
    "print(f\"   - Topic overlap: 0.12 ‚Üí {CFG.get('acceptance_topic', {}).get('after_text_min', 0.05)}\")\n",
    "\n",
    "print(\"\\n2. Mapping am√©lior√©:\")\n",
    "print(f\"   - {len(enhanced_mapping)} entr√©es avec correspondance parfaite\")\n",
    "print(f\"   - {enhanced_mapping['has_text'].mean()*100:.1f}% avec texte\")\n",
    "print(f\"   - {enhanced_mapping['enough_length'].mean()*100:.1f}% avec texte suffisant\")\n",
    "\n",
    "print(\"\\n3. Crit√®res assouplies:\")\n",
    "print(\"   - MODERATE accept√© avec garde-fous\")\n",
    "print(\"   - CRITICAL accept√© si am√©lioration significative\")\n",
    "print(\"   - Re-summarize moins restrictif\")\n",
    "\n",
    "print(\"\\nüìà IMPACT ATTENDU:\")\n",
    "print(f\"   - +{len(candidates_new) - len(old_candidates)} candidats trait√©s\")\n",
    "print(f\"   - +{len(new_sufficient) - len(old_sufficient)} textes utilisables pour re-summarize\")\n",
    "print(\"   - Taux d'acceptation am√©lior√© (√† valider)\")\n",
    "\n",
    "print(\"\\nüéØ PR√äT POUR TESTS:\")\n",
    "print(\"   - Fichiers: level3_enhanced_mapping.csv, level3_text_mapping.csv\")\n",
    "print(\"   - Config: level3.yaml (mise √† jour)\")\n",
    "print(\"   - Utils: level3_utils.py (fonctions corrig√©es)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}