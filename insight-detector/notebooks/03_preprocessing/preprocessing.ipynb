{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22379de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Auto-reload pour développement interactif\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports standards\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLP avancé\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Détection de langue\n",
    "from langdetect import detect, detect_langs\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "# Preprocessing texte\n",
    "import unicodedata\n",
    "import ftfy  # Pour corriger les encodages\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Similarité et déduplication\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033442b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration optimisée pour ressources limitées:\n",
      "   SpaCy: fr_core_news_sm (modèle léger)\n",
      "   Embeddings: all-MiniLM-L6-v2 (80MB au lieu de 420MB)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuration\n",
    "BASE_DIR = Path().resolve().parent.parent\n",
    "sys.path.append(str(BASE_DIR / \"src\"))\n",
    "\n",
    "# Répertoires\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "EXPORTS_DIR = DATA_DIR / \"exports\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "PROCESSED_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Configuration des modèles\n",
    "NLP_MODEL = \"fr_core_news_sm\"  # Modèle spaCy français LÉGER\n",
    "EMBEDDINGS_MODEL = \"all-MiniLM-L6-v2\"  # Modèle plus léger (~80MB vs 420MB)\n",
    "SIMILARITY_THRESHOLD = 0.85  # Seuil de similarité pour déduplication\n",
    "\n",
    "print(f\"Configuration optimisée pour ressources limitées:\")\n",
    "print(f\"   SpaCy: {NLP_MODEL} (modèle léger)\")\n",
    "print(f\"   Embeddings: {EMBEDDINGS_MODEL} (80MB au lieu de 420MB)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b185b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du fichier JSON enrichi (priorité) ou brut (fallback)\n",
    "enriched_file = EXPORTS_DIR / \"enriched_article.json\"  # MODIFIÉ: sans \"s\"\n",
    "enriched_files_alt = EXPORTS_DIR / \"enriched_articles.json\"  # Alternative\n",
    "raw_file = EXPORTS_DIR / \"raw_articles.json\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09529af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FICHIER ENRICHI ALTERNATIF DÉTECTÉ: C:\\Users\\beedi.goua_square-ma\\Desktop\\Gheb\\projet perso\\InsightDetector\\insight-detector\\data\\exports\\enriched_articles.json\n",
      "   Mode: Preprocessing avancé sur données pré-enrichies\n"
     ]
    }
   ],
   "source": [
    "# Détection automatique du fichier source\n",
    "if enriched_file.exists():\n",
    "    source_file = enriched_file\n",
    "    print(f\"FICHIER ENRICHI DÉTECTÉ: {enriched_file}\")\n",
    "    print(\"   Mode: Preprocessing avancé sur données pré-enrichies\")\n",
    "elif enriched_files_alt.exists():\n",
    "    source_file = enriched_files_alt\n",
    "    print(f\"FICHIER ENRICHI ALTERNATIF DÉTECTÉ: {enriched_files_alt}\")\n",
    "    print(\"   Mode: Preprocessing avancé sur données pré-enrichies\")\n",
    "elif raw_file.exists():\n",
    "    source_file = raw_file\n",
    "    print(f\"FICHIER BRUT DÉTECTÉ: {raw_file}\")\n",
    "    print(\"   → Mode: Preprocessing complet depuis zéro\")\n",
    "else:\n",
    "    print(f\"ERREUR: Aucun fichier source trouvé!\")\n",
    "    print(f\"   Recherche: {enriched_file} OU {raw_file}\")\n",
    "    print(\"   Solution: Exécutez d'abord collect_articles.ipynb ou enrich_articles.ipynb\")\n",
    "    exit(1)\n",
    "\n",
    "with open(source_file, 'r', encoding='utf-8') as f:\n",
    "    articles_data = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "987311e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 articles chargés depuis enriched_articles.json\n"
     ]
    }
   ],
   "source": [
    "# Mode adaptatif selon la source\n",
    "ENRICHED_MODE = \"enriched_article\" in str(source_file)  # Compatible avec les deux formats\n",
    "\n",
    "print(f\"{len(articles_data)} articles chargés depuis {source_file.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c17eb298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion en DataFrame pour manipulation\n",
    "df = pd.DataFrame(articles_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "240fd347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "summary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "published",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cleaned_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "language",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "entities",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "embedding",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "quality_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "96fa60a3-6d8a-48fb-a633-9d96fe0377fb",
       "rows": [
        [
         "0",
         "26",
         "Top 10 AI Content Generator & Writer Tools in 2022",
         "Are you looking for a way to create content that is both effective and efficient? If so, then you should consider using an AI content generator. AI content generators are a great way to create content that is both engaging and relevant to your audience. There are a number of different AI content generator tools available on the market, and it can be difficult to know which one is right for you. To help you make the best decision, we have compiled a list of the top 10 AI content generator tools that you should use in 2022. So, without further ado, let’s get started! 1. Jasper Ai (Formerly known as Jarvis) Jasper is a content writing and content generation tool that uses artificial intelligence to identify the best words and sentences for your writing style and medium in the most efficient, quick, and accessible way. Features It's trusted by 50,000+ marketers for creating engaging marketing campaigns, ad copy, blog posts, and articles within minutes which would traditionally take hours or days. Special Features: Blog posts have been optimized for search engines and rank high on Google and other search engines. This is a huge plus for online businesses that want to generate traffic to their website through content marketing. 99.9% Original Content and guarantees that all content it generates will be original, so businesses can focus on their online reputation rather than worrying about penalties from Google for duplicate content. Long-Form Article Writing – Jasper.ai is also useful for long-form writing, allowing users to create articles of up to 10,000 words without any difficulty. This is ideal for businesses that want to produce in-depth content that will capture their audience’s attention. Pros User-friendly interface Generates a wide variety of content types Guarantees 100% unique and free-plagiarism content SEO friendly Create articles of up to 10k words Cons Not the cheapest AI writer on the market Pricing Jasper.ai offers a free trial Starter Plan: $29/Month Features: 50 AI copywriting skills Unlimited projects, Up to 5 user logins The cheapest option covers up to 20,000 words generated each month. Boss Mode: $99/Month Features: Up to 100k words are generated each month and can go up to over 300k. Wait! I've got a pretty sweet deal for you. Sign up through the link below, and you'll get ( 10k Free Credits ) 2. Copy Ai Copy.ai is a content writing tool that enables its users to create marketing copy, social media posts, Facebook Ads, and many more formats by using more than 90 templates such as Bullet Points to Blogs, General Ads, Hook Text, etc. The utility of this service can be used for short-term or format business purposes such as product descriptions, website copy, market copy, and sales reports. Key Features: Provides a large set of templates where you can input the data and the AI will generate Templates with around 10 or more options to make it easy for the user to choose. Smooth and efficient user experience with chrome extension where one can easily transfer information from Copy.ai to a content management forum, Google docs, etc without having to switch tabs. Generates content in 25 languages where your input and output language may differ if you are not a native English speaker. Pros The best option for short-length content generation such as market copy, sales reports, blogs, etc. Facebook community and email support for users to understand the AI better and to interact with other users. Beginner-friendly user experience with various templates to help the process of content generation. Free plan and no credit card required. Cons The free plan from Copy AI is a welcome sight, however, it is just suitable for testing the software. Pricing Free Trial – 7 days with 24/7 email support and 100 runs per day. Pro Plan: $49 and yearly, it will cost you $420 i.e. $35 per month. Wait! I've got a pretty sweet deal for you. Sign up through the link below, and you'll get ( 7,000 Free Words Plus 40% OFF ) if you upgrade to the paid plan within four days. Claim Your 7,000 Free Words With This Special Link - No Credit Card Required 3. Frase Ai Just like Outranking, Frase is an AI that helps you research, create and optimize your content to make it high quality within seconds. Frase works on SEO optimization where the content is made to the liking of search engines by optimizing keywords and keywords. Features: Generate full-length, optimized content briefs in seconds and review the main keywords, headers, and concepts in your SEO competitors’ content in one intuitive research panel. Write high-converting, SEO-optimized copy and make writer’s block a thing of the past with automated outlines, blog introductions, product descriptions, FAQs, and more. An intuitive text editor that uses a topic model to score your content Optimization against your competitors. A dashboard that automatically identifies and categorizes your best content opportunities. Frase uses your Google Search Console data to serve up actionable insights about what you should work on next. Pros Unlike Outranking, the interface to Frase is very user-friendly and accessible. Users who are content writers and have to research get a lot of time to write and ideate instead of juggling from one website to another as data can be easily accessed on Frase for research on a topic. Optimizing content with keyword analysis and SEO optimization has been made easier with Frase's Content Optimization. Reports on competitors' websites help in optimizing our own articles and websites. Content briefs make research very easy and efficient. Cons The paid plans are a bit pricey because they include many tools for content optimization. Pricing Frase provides two plans for all users and a customizable plan for an enterprise or business. Solo Plan: $14.99/Month and $12/Month if billed yearly with 4 Document Credits for 1 user seat. Basic Plan: $44.99/month and $39.99/month if billed yearly with 30 Document Credits for 1 user seat. Team Plan: $114.99/month and $99.99/month if billed yearly for unlimited document credits for 3 users. *SEO Add-ons and other premium features for $35/month irrespective of the plan. 4. Article Forge — Popular Blog Writing Software for Efficiency and Affordability Article Forge is another content generator that operates quite differently from the others on this list. Unlike Jasper.ai, which requires you to provide a brief and some information on what you want it to write this tool only asks for a keyword. From there, it’ll generate a complete article for you. Features Article Forge integrates with several other software, including WordAi, RankerX, SEnuke TNG, and SEO Autopilot. The software takes information from high-ranking websites and then creates more credible articles to rank well in search engines. If you want to generate content regularly, Article Forge can help. You can set it up to automatically generate articles based on your specific keyword or topic. Or, if you need a lot of content quickly, you can use the bulk content feature to get many articles in a short period. Pros Excellent for engaging with readers on multiple CMS platforms No spinner content. Create multiple unique articles Extremely quick and efficient One of the cheapest options online Cons You need to pay attention to the content since it’s not always on point Only ideal for decent-quality articles – if you’re lucky Pricing What’s excellent about Article Forge is they provide a 30-day money-back guarantee. You can choose between a monthly or yearly subscription. Unfortunately, they offer a free trial and no free plan: Basic Plan: $27/Month Features: This plan allows users to produce up to 25k words each month. This is excellent for smaller blogs or those who are just starting. Standard Plan: $57/month) Features: This plan allows users to produce up to 250k words each month. This is excellent for smaller blogs or those who are just starting. Unlimited Plan: $117/month Features: If you’re looking for an unlimited amount of content, this is the plan for you. You can create as many articles as you want, and there’s no word limit. It’s important to note that Article Forge guarantees that all content generated through the platform passes Copyscape. 5. Rytr — Superb AI Content Writing Assistant Rytr.me is a free AI content generator perfect for small businesses, bloggers, and students. The software is easy to use and can generate SEO-friendly blog posts, articles, and school papers in minutes. Features Rytr can be used for various purposes, from writing blog posts to creating school papers. You can also generate captions for social media, product descriptions, and meta descriptions. Rytr supports writing for over 30 languages, so you can easily create content in your native language. The AI helps you write content in over 30 tones to find the perfect tone for your brand or project. Rytr has a built-in plagiarism checker that ensures all your content is original and plagiarism free. Pros Easy to use Creates unique content It supports over 30 languages Multi-tone writing capabilities Cons It can be slow at times Grammar and flow could use improvement Pricing Rytr offers a free plan that comes with limited features. It covers up to 5,000 characters generated each month and has access to the built-in plagiarism checker. If you want to use all the features of the software, you can purchase one of the following plans: Saver Plan: $9/month, $90/year Features: Generate 100k characters per month Access 40+ use-cases Write in 30+ languages Access 20+ tones Built-in plagiarism checker Generate up to 20 images per month with AI Access to premium community Create your own custom use-case Unlimited Plan: $29/month, $290/year Features: Generate UNLIMITED* characters per month Access 40+ use-cases Write in 30+ languages Access 20+ tones Built-in plagiarism checker Generate up to 100 images per month with AI Access to premium community Create your own custom use-case Dedicated account manager Priority email & chat support 6. Writesonic — Best AI Article Writing Software with a Grammar and Plagiarism Checker Writesonic is a free, easy-to-use AI content generator. The software is designed to help you create copy for marketing content, websites, and blogs. It's also helpful for small businesses or solopreneurs who need to produce content on a budget. Features The tone checker, is a great feature that helps you ensure that your content is consistent with your brand’s voice. This is excellent for crafting cohesive and on-brand content. The grammar checker is another valuable tool that helps you produce error-free content. The plagiarism checker is a great way to ensure that your content is original. Pricing Writesonic is free with limited features. The free plan is more like a free trial, providing ten credits. After that, you’d need to upgrade to a paid plan. Here are your options: Short-form: $15/month Features : Access to all the short-form content templates like Facebook ads, product descriptions, paragraphs, and more. Long-Form: $19/month Features: Awesome tools to help you write short and long-form content like blog posts, ebooks, and more. 7. CopySmith — Produces Quality Content in Seconds CopySmith is an AI content generator that can be used to create personal and professional documents, blogs, and presentations. It offers a wide range of features including the ability to easily create documents and presentations. CopySmith also has several templates that you can use to get started quickly. Features This software allows you to create product descriptions, landing pages, and more in minutes. Offers rewritten content that is both unique and plagiarism free. This feature helps you create product descriptions for your Shopify store that are SEO-friendly and attractive to customers. This is an excellent tool for new content ideas. Pros Excellent for generating eCommerce-ready content No credit card is required for the free trial SEO-ready content Cons The blog content isn’t the best Better suited for short copy Pricing CopySmith offers a free trial with no credit card required. After the free trial, the paid plans are as follows: Starter Plan: $19/month Features: Get 50 credits monthly with up to 20 plagiarism checks. Professional Plan: $59/month Features: Upgrade to 400 credits per month with up to 100 plagiarism checks. Enterprise – Create a custom-tailored plan by contacting the sales team. 8. Hypotenuse.ai — Best AI Writing Software for E-Commerce and Product Descriptions Hypotenuse.ai is a free online tool that can help you create AI content. It's great for beginners because it allows you to create videos, articles, and infographics with ease. The software has a simple and easy-to-use interface that makes it perfect for new people looking for AI content generation. Special Features You can create custom-tailored copy specific to your audience’s needs. This is impressive since most free AI content generators do not offer this feature. Hypotenuse takes data from social media sites, websites, and more sources to provide accurate information for your content. If you’re selling a product online, you can use Hypotenuse to create automated product descriptions that are of high quality and will help you sell more products. Pros Excellent research capabilities Custom-tailored copy Automated product descriptions Cons No free plan Pricing Hypotenuse doesn’t offer a free plan. Instead, it offers a free trial period where you can take the software for a run before deciding whether it’s the right choice for you or not. Other than that, here are its paid options: Starter Plan: $29/month Features: This plan comes with 100 credits/month with 25k Words with one user seat. It’s an excellent option for individuals or small businesses. Growth Plan: $59/month Features: This plan comes with 350 credits/month with 87.5k words and 1 user seat. It’s perfect for larger businesses or agencies. Enterprise – pricing is custom, so don’t hesitate to contact the company for more information. 9. Kafkai — Leading AI Writing Tool for SEOs and Marketers Kafkai is an AI content generator and writing software that produces niche-specific content on a wide variety of topics. It offers a user-friendly interface, as well as a high degree of personalization. Features Kafkai offers a host of features that make it SEO-ready, including the ability to add keywords and tags to your content. Kafkai is designed explicitly for creating niche-specific content, which can be a significant advantage for businesses or bloggers looking to target a specific audience. Kafkai produces high-quality content, a significant advantage for businesses or bloggers looking to set themselves apart from the competition. Kafkai offers a unique feature that allows you to seed content from other sources, which can be a significant time-saver when creating content. Pros Quick results with high efficiency You can add seed content and phrases It can be used to craft complete articles Cons Its long-form-content generator isn’t very high quality Pricing Kafkai comes with a free trial to help you understand whether it’s the right choice for you or not. Additionally, you can also take a look at its paid plans: Writer Plan: $29/month Create 100 articles per month. $0.29/article Newsroom Plan $49/month – Generate 250 articles a month at $0.20 per article. Printing Press Plan: $129 /month Create up to 1000 articles a month at roughly $0.13/article. Industrial Printer Plan: ($199 a month) – Generate 2500 articles each month for $0.08/article. 10. Peppertype.ai — Best AI Content Writing Software for Blogging Peppertype.ai is an online AI content generator that’s easy to use and best for small business owners looking for a powerful copy and content writing tool to help them craft and generate various content for many purposes. Features You can choose from various pre-trained templates to create your content. This can save you a lot of time since you don’t have to spend time designing your templates or starting entirely from scratch. Peppertype offers various copywriting frameworks to help you write better content. Peppertype is lightweight and easy to use. This makes it perfect for beginners who want to get started with AI content generation. Peppertype’s autocorrect feature automatically corrects your grammar and spelling mistakes as you type. This ensures that your content is free of errors. Peppertype tracks user engagement data to help you create content that resonates with your audience. Pros It doesn’t have a steep learning curve It helps users to create entirely original content The basic plan comes with access to all of their frameworks and templates Built-in style editor Cons More hits than misses on content generated Tons of typos and grammatical errors Pricing Unfortunately, Peppertype.ai isn’t free. However, it does have a free trial to try out the software before deciding whether it’s the right choice for you. Here are its paid plans: personal Plan:$35/Month Features: 50,000 words included 40+ content types Notes and Text Editor Access to templates Unlimited projects Active customer support Team Plan: $199/month Features: Everything included in the Personal Collaborate & share results Access control Export results Request custom content types Enterprise – pricing is custom, so please contact the company for more information. Final thoughts: It is no longer a secret that humans are getting overwhelmed with the daily task of creating content. Our lives are busy, and the process of writing blog posts, video scripts, or other types of content is not our day job. In comparison, AI writers are not only cheaper to hire, but also perform tasks at a high level of excellence. This article explores 10 writing tools that used AI to create better content choose the one which meets your requirements and budget but in my opinion Jasper ai is one of the best tools to use to make high-quality content. If you have any questions ask in the comments section Note: Don't post links in your comments Note: This article contains affiliate links which means we make a small commission if you buy any premium plan from our link.",
         "Top 10 AI Content Generator & Writer Tools in 2022\n\n\n\n\n\nAre you looking for a way to create content that is both effective and efficient? If so, then you should consider using an AI content generator. AI content generators are a great way to create content that is both engaging and relevant to your audience.\n\nThere are a number of different AI content generator tools available on the market, and it can be difficult to know which one is right for you. To help you make the best decision, we have compiled a list of the top 10 AI content generator tools that you should use in 2022.\n\nSo, without further ado, let’s get started!\n\n\n\n\n\n\n\n\n\n\n\n\n\nJasper is a content writing and content generation tool that uses artificial intelligence to identify the best words and sentences for your writing style and medium in the most efficient, quick, and accessible way.\n\nFeatures\n\nIt's trusted by 50,000+ marketers for creating engaging marketing campaigns, ad copy, blog posts, and articles within minutes which would traditionally take hours or days. Special Features:\n\nBlog posts have been optimized for search engines and rank high on Google and other search engines. This is a huge plus for online businesses that want to generate traffic to their website through content marketing.\n\n99.9% Original Content and guarantees that all content it generates will be original, so businesses can focus on their online reputation rather than worrying about penalties from Google for duplicate content.\n\nLong-Form Article Writing – Jasper.ai is also useful for long-form writing, allowing users to create articles of up to 10,000 words without any difficulty. This is ideal for businesses that want to produce in-depth content that will capture their audience’s attention.\n\nPros\n\nUser-friendly interface\n\nGenerates a wide variety of content types\n\nGuarantees 100% unique and free-plagiarism content\n\nSEO friendly\n\nCreate articles of up to 10k words\n\nCons\n\nNot the cheapest AI writer on the market\n\nPricing\n\nJasper.ai offers a free trial\n\nStarter Plan: $29/Month\n\nFeatures:\n\n50 AI copywriting skills\n\nUnlimited projects,\n\nUp to 5 user logins\n\nThe cheapest option covers up to 20,000 words generated each month.\n\nBoss Mode: $99/Month\n\nFeatures:\n\nUp to 100k words are generated each month and can go up to over 300k.\n\nWait! I've got a pretty sweet deal for you. Sign up through the link below, and you'll get ( 10k Free Credits\n\n\n\n\n\n\n\n\n\nCopy.ai is a content writing tool that enables its users to create marketing copy, social media posts, Facebook Ads, and many more formats by using more than 90 templates such as Bullet Points to Blogs, General Ads, Hook Text, etc.\n\nThe utility of this service can be used for short-term or format business purposes such as product descriptions, website copy, market copy, and sales reports.\n\nKey Features:\n\nProvides a large set of templates where you can input the data and the AI will generate Templates with around 10 or more options to make it easy for the user to choose.\n\nSmooth and efficient user experience with chrome extension where one can easily transfer information from Copy.ai to a content management forum, Google docs, etc without having to switch tabs.\n\nGenerates content in 25 languages where your input and output language may differ if you are not a native English speaker.\n\nPros\n\nThe best option for short-length content generation such as market copy, sales reports, blogs, etc.\n\nFacebook community and email support for users to understand the AI better and to interact with other users.\n\nBeginner-friendly user experience with various templates to help the process of content generation.\n\nFree plan and no credit card required.\n\nCons\n\nThe free plan from Copy AI is a welcome sight, however, it is just suitable for testing the software.\n\nPricing\n\nFree Trial – 7 days with 24/7 email support and 100 runs per day.\n\nPro Plan: $49 and yearly, it will cost you $420 i.e. $35 per month.\n\nWait! I've got a pretty sweet deal for you. Sign up through the link below, and you'll get (7,000 Free Words Plus 40% OFF) if you upgrade to the paid plan within four days.\n\nClaim Your 7,000 Free Words With This Special Link - No Credit Card Required\n\n\n\n\n\n\n\n\n\n\n\n\n\nJust like Outranking, Frase is an AI that helps you research, create and optimize your content to make it high quality within seconds. Frase works on SEO optimization where the content is made to the liking of search engines by optimizing keywords and keywords.\n\nFeatures:\n\nGenerate full-length, optimized content briefs in seconds and review the main keywords, headers, and concepts in your SEO competitors’ content in one intuitive research panel.\n\nWrite high-converting, SEO-optimized copy and make writer’s block a thing of the past with automated outlines, blog introductions, product descriptions, FAQs, and more.\n\nAn intuitive text editor that uses a topic model to score your content Optimization against your competitors.\n\nA dashboard that automatically identifies and categorizes your best content opportunities. Frase uses your Google Search Console data to serve up actionable insights about what you should work on next.\n\nPros\n\nUnlike Outranking, the interface to Frase is very user-friendly and accessible.\n\nUsers who are content writers and have to research get a lot of time to write and ideate instead of juggling from one website to another as data can be easily accessed on Frase for research on a topic.\n\nOptimizing content with keyword analysis and SEO optimization has been made easier with Frase's Content Optimization.\n\nReports on competitors' websites help in optimizing our own articles and websites.\n\nContent briefs make research very easy and efficient.\n\nCons\n\nThe paid plans are a bit pricey because they include many tools for content optimization.\n\nPricing\n\nFrase provides two plans for all users and a customizable plan for an enterprise or business.\n\nSolo Plan: $14.99/Month and $12/Month if billed yearly with 4 Document Credits for 1 user seat.\n\nBasic Plan: $44.99/month and $39.99/month if billed yearly with 30 Document Credits for 1 user seat.\n\nTeam Plan: $114.99/month and $99.99/month if billed yearly for unlimited document credits for 3 users.\n\n*SEO Add-ons and other premium features for $35/month irrespective of the plan.\n\n\n\n\n\n4. Article Forge — Popular Blog Writing Software for Efficiency and Affordability\n\n\n\n\n\n\n\n\n\nArticle Forge is another content generator that operates quite differently from the others on this list. Unlike Jasper.ai, which requires you to provide a brief and some information on what you want it to write this tool only asks for a keyword. From there, it’ll generate a complete article for you.\n\nFeatures\n\nArticle Forge integrates with several other software, including WordAi, RankerX, SEnuke TNG, and SEO Autopilot.\n\nThe software takes information from high-ranking websites and then creates more credible articles to rank well in search engines.\n\nIf you want to generate content regularly, Article Forge can help. You can set it up to automatically generate articles based on your specific keyword or topic. Or, if you need a lot of content quickly, you can use the bulk content feature to get many articles in a short period.\n\nPros\n\nExcellent for engaging with readers on multiple CMS platforms\n\nNo spinner content. Create multiple unique articles\n\nExtremely quick and efficient\n\nOne of the cheapest options online\n\nCons\n\nYou need to pay attention to the content since it’s not always on point\n\nOnly ideal for decent-quality articles – if you’re lucky\n\nPricing\n\nWhat’s excellent about Article Forge is they provide a 30-day money-back guarantee. You can choose between a monthly or yearly subscription. Unfortunately, they offer a free trial and no free plan:\n\nBasic Plan: $27/Month\n\nFeatures:\n\nThis plan allows users to produce up to 25k words each month. This is excellent for smaller blogs or those who are just starting.\n\nStandard Plan: $57/month)\n\nFeatures:\n\nThis plan allows users to produce up to 250k words each month. This is excellent for smaller blogs or those who are just starting.\n\nUnlimited Plan: $117/month\n\nFeatures:\n\nIf you’re looking for an unlimited amount of content, this is the plan for you. You can create as many articles as you want, and there’s no word limit.\n\nIt’s important to note that Article Forge guarantees that all content generated through the platform passes Copyscape.\n\n\n\n\n\n5. Rytr — Superb AI Content Writing Assistant\n\n\n\n\n\n\n\n\n\nRytr.me is a free AI content generator perfect for small businesses, bloggers, and students. The software is easy to use and can generate SEO-friendly blog posts, articles, and school papers in minutes.\n\nFeatures\n\nRytr can be used for various purposes, from writing blog posts to creating school papers. You can also generate captions for social media, product descriptions, and meta descriptions.\n\nRytr supports writing for over 30 languages, so you can easily create content in your native language.\n\nThe AI helps you write content in over 30 tones to find the perfect tone for your brand or project.\n\nRytr has a built-in plagiarism checker that ensures all your content is original and plagiarism free.\n\nPros\n\nEasy to use\n\nCreates unique content\n\nIt supports over 30 languages\n\nMulti-tone writing capabilities\n\nCons\n\nIt can be slow at times\n\nGrammar and flow could use improvement\n\nPricing\n\nRytr offers a free plan that comes with limited features. It covers up to 5,000 characters generated each month and has access to the built-in plagiarism checker. If you want to use all the features of the software, you can purchase one of the following plans:\n\n\n\n\n\nSaver Plan: $9/month, $90/year\n\nFeatures:\n\nGenerate 100k characters per month\n\nAccess 40+ use-cases\n\nWrite in 30+ languages\n\nAccess 20+ tones\n\nBuilt-in plagiarism checker\n\nGenerate up to 20 images per month with AI\n\nAccess to premium community\n\nCreate your own custom use-case\n\nUnlimited Plan: $29/month, $290/year\n\nFeatures:\n\nGenerate UNLIMITED* characters per month\n\nAccess 40+ use-cases\n\nWrite in 30+ languages\n\nAccess 20+ tones\n\nBuilt-in plagiarism checker\n\nGenerate up to 100 images per month with AI\n\nAccess to premium community\n\nCreate your own custom use-case\n\nDedicated account manager\n\nPriority email & chat support\n\n\n\n\n\n6. Writesonic — Best AI Article Writing Software with a Grammar and Plagiarism Checker\n\n\n\n\n\n\n\n\n\nWritesonic is a free, easy-to-use AI content generator. The software is designed to help you create copy for marketing content, websites, and blogs. It's also helpful for small businesses or solopreneurs who need to produce content on a budget.\n\nFeatures\n\nThe tone checker, is a great feature that helps you ensure that your content is consistent with your brand’s voice. This is excellent for crafting cohesive and on-brand content.\n\nThe grammar checker is another valuable tool that helps you produce error-free content.\n\nThe plagiarism checker is a great way to ensure that your content is original.\n\nPricing\n\nWritesonic is free with limited features. The free plan is more like a free trial, providing ten credits. After that, you’d need to upgrade to a paid plan. Here are your options:\n\nShort-form: $15/month\n\nFeatures:\n\nAccess to all the short-form content templates like Facebook ads, product descriptions, paragraphs, and more.\n\nLong-Form: $19/month\n\nFeatures:\n\nAwesome tools to help you write short and long-form content like blog posts, ebooks, and more.\n\n\n\n\n\n7. CopySmith — Produces Quality Content in Seconds\n\n\n\n\n\n\n\n\n\nCopySmith is an AI content generator that can be used to create personal and professional documents, blogs, and presentations. It offers a wide range of features including the ability to easily create documents and presentations.\n\nCopySmith also has several templates that you can use to get started quickly.\n\nFeatures\n\nThis software allows you to create product descriptions, landing pages, and more in minutes.\n\nOffers rewritten content that is both unique and plagiarism free.\n\nThis feature helps you create product descriptions for your Shopify store that are SEO-friendly and attractive to customers.\n\nThis is an excellent tool for new content ideas.\n\nPros\n\nExcellent for generating eCommerce-ready content\n\nNo credit card is required for the free trial\n\nSEO-ready content\n\nCons\n\nThe blog content isn’t the best\n\nBetter suited for short copy\n\nPricing\n\nCopySmith offers a free trial with no credit card required. After the free trial, the paid plans are as follows:\n\nStarter Plan: $19/month\n\nFeatures:\n\nGet 50 credits monthly with up to 20 plagiarism checks.\n\nProfessional Plan: $59/month\n\nFeatures:\n\nUpgrade to 400 credits per month with up to 100 plagiarism checks.\n\nEnterprise – Create a custom-tailored plan by contacting the sales team.\n\n\n\n\n\n8. Hypotenuse.ai — Best AI Writing Software for E-Commerce and Product Descriptions\n\n\n\n\n\n\n\n\n\nHypotenuse.ai is a free online tool that can help you create AI content. It's great for beginners because it allows you to create videos, articles, and infographics with ease. The software has a simple and easy-to-use interface that makes it perfect for new people looking for AI content generation.\n\nSpecial Features\n\nYou can create custom-tailored copy specific to your audience’s needs. This is impressive since most free AI content generators do not offer this feature.\n\nHypotenuse takes data from social media sites, websites, and more sources to provide accurate information for your content.\n\nIf you’re selling a product online, you can use Hypotenuse to create automated product descriptions that are of high quality and will help you sell more products.\n\nPros\n\nExcellent research capabilities\n\nCustom-tailored copy\n\nAutomated product descriptions\n\nCons\n\nNo free plan\n\nPricing\n\nHypotenuse doesn’t offer a free plan. Instead, it offers a free trial period where you can take the software for a run before deciding whether it’s the right choice for you or not. Other than that, here are its paid options:\n\nStarter Plan: $29/month\n\nFeatures:\n\nThis plan comes with 100 credits/month with 25k Words with one user seat. It’s an excellent option for individuals or small businesses.\n\nGrowth Plan: $59/month\n\nFeatures:\n\nThis plan comes with 350 credits/month with 87.5k words and 1 user seat. It’s perfect for larger businesses or agencies.\n\nEnterprise – pricing is custom, so don’t hesitate to contact the company for more information.\n\n\n\n\n\n9. Kafkai — Leading AI Writing Tool for SEOs and Marketers\n\n\n\n\n\nKafkai is an AI content generator and writing software that produces niche-specific content on a wide variety of topics. It offers a user-friendly interface, as well as a high degree of personalization.\n\nFeatures\n\nKafkai offers a host of features that make it SEO-ready, including the ability to add keywords and tags to your content.\n\nKafkai is designed explicitly for creating niche-specific content, which can be a significant advantage for businesses or bloggers looking to target a specific audience.\n\nKafkai produces high-quality content, a significant advantage for businesses or bloggers looking to set themselves apart from the competition.\n\nKafkai offers a unique feature that allows you to seed content from other sources, which can be a significant time-saver when creating content.\n\nPros\n\nQuick results with high efficiency\n\nYou can add seed content and phrases\n\nIt can be used to craft complete articles\n\nCons\n\nIts long-form-content generator isn’t very high quality\n\nPricing\n\nKafkai comes with a free trial to help you understand whether it’s the right choice for you or not. Additionally, you can also take a look at its paid plans:\n\nWriter Plan: $29/month Create 100 articles per month. $0.29/article\n\nNewsroom Plan $49/month – Generate 250 articles a month at $0.20 per article.\n\nPrinting Press Plan: $129 /month Create up to 1000 articles a month at roughly $0.13/article.\n\nIndustrial Printer Plan: ($199 a month) – Generate 2500 articles each month for $0.08/article.\n\n\n\n\n\n10. Peppertype.ai — Best AI Content Writing Software for Blogging\n\n\n\n\n\n\n\n\n\nPeppertype.ai is an online AI content generator that’s easy to use and best for small business owners looking for a powerful copy and content writing tool to help them craft and generate various content for many purposes.\n\nFeatures\n\nYou can choose from various pre-trained templates to create your content. This can save you a lot of time since you don’t have to spend time designing your templates or starting entirely from scratch.\n\nPeppertype offers various copywriting frameworks to help you write better content.\n\nPeppertype is lightweight and easy to use. This makes it perfect for beginners who want to get started with AI content generation.\n\nPeppertype’s autocorrect feature automatically corrects your grammar and spelling mistakes as you type. This ensures that your content is free of errors.\n\nPeppertype tracks user engagement data to help you create content that resonates with your audience.\n\nPros\n\nIt doesn’t have a steep learning curve\n\nIt helps users to create entirely original content\n\nThe basic plan comes with access to all of their frameworks and templates\n\nBuilt-in style editor\n\nCons\n\nMore hits than misses on content generated\n\nTons of typos and grammatical errors\n\nPricing\n\nUnfortunately, Peppertype.ai isn’t free. However, it does have a free trial to try out the software before deciding whether it’s the right choice for you. Here are its paid plans:\n\npersonal Plan:$35/Month\n\nFeatures:\n\n50,000 words included\n\n40+ content types\n\nNotes and Text Editor\n\nAccess to templates\n\nUnlimited projects\n\nActive customer support\n\nTeam Plan: $199/month\n\nFeatures:\n\nEverything included in the Personal\n\nCollaborate & share results\n\nAccess control\n\nExport results\n\nRequest custom content types\n\nEnterprise – pricing is custom, so please contact the company for more information.\n\nFinal thoughts:\n\nIt is no longer a secret that humans are getting overwhelmed with the daily task of creating content. Our lives are busy, and the process of writing blog posts, video scripts, or other types of content is not our day job. In comparison, AI writers are not only cheaper to hire, but also perform tasks at a high level of excellence. This article explores 10 writing tools that used AI to create better content choose the one which meets your requirements and budget but in my opinion Jasper ai is one of the best tools to use to make high-quality content.\n\nIf you have any questions ask in the comments section\n\nNote: Don't post links in your comments\n\nNote: This article contains affiliate links which means we make a small commission if you buy any premium plan from our link.",
         "2022-11-15T08:58:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/11/top-10-ai-content-generator-writer.html",
         "2025-07-26T05:41:35.784294",
         "Top 10 AI Content Generator & Writer Tools in 2022 Are you looking for a way to create content that is both effective and efficient? If so, then you should consider using an AI content generator. AI content generators are a great way to create content that is both engaging and relevant to your audience. There are a number of different AI content generator tools available on the market, and it can be difficult to know which one is right for you. To help you make the best decision, we have compiled a list of the top 10 AI content generator tools that you should use in 2022. So, without further ado, let’s get started! Jasper is a content writing and content generation tool that uses artificial intelligence to identify the best words and sentences for your writing style and medium in the most efficient, quick, and accessible way. Features It's trusted by 50,000+ marketers for creating engaging marketing campaigns, ad copy, blog posts, and articles within minutes which would traditionally take hours or days. Special Features: Blog posts have been optimized for search engines and rank high on Google and other search engines. This is a huge plus for online businesses that want to generate traffic to their website through content marketing. 99.9% Original Content and guarantees that all content it generates will be original, so businesses can focus on their online reputation rather than worrying about penalties from Google for duplicate content. Long-Form Article Writing – Jasper.ai is also useful for long-form writing, allowing users to create articles of up to 10,000 words without any difficulty. This is ideal for businesses that want to produce in-depth content that will capture their audience’s attention. Pros User-friendly interface Generates a wide variety of content types Guarantees 100% unique and free-plagiarism content SEO friendly Create articles of up to 10k words Cons Not the cheapest AI writer on the market Pricing Jasper.ai offers a free trial Starter Plan: $29/Month Features: 50 AI copywriting skills Unlimited projects, Up to 5 user logins The cheapest option covers up to 20,000 words generated each month. Boss Mode: $99/Month Features: Up to 100k words are generated each month and can go up to over 300k. Wait! I've got a pretty sweet deal for you. Sign up through the link below, and you'll get ( 10k Free Credits Copy.ai is a content writing tool that enables its users to create marketing copy, social media posts, Facebook Ads, and many more formats by using more than 90 templates such as Bullet Points to Blogs, General Ads, Hook Text, etc. The utility of this service can be used for short-term or format business purposes such as product descriptions, website copy, market copy, and sales reports. Key Features: Provides a large set of templates where you can input the data and the AI will generate Templates with around 10 or more options to make it easy for the user to choose. Smooth and efficient user experience with chrome extension where one can easily transfer information from Copy.ai to a content management forum, Google docs, etc without having to switch tabs. Generates content in 25 languages where your input and output language may differ if you are not a native English speaker. Pros The best option for short-length content generation such as market copy, sales reports, blogs, etc. Facebook community and email support for users to understand the AI better and to interact with other users. Beginner-friendly user experience with various templates to help the process of content generation. Free plan and no credit card required. Cons The free plan from Copy AI is a welcome sight, however, it is just suitable for testing the software. Pricing Free Trial – 7 days with 24/7 email support and 100 runs per day. Pro Plan: $49 and yearly, it will cost you $420 i.e. $35 per month. Wait! I've got a pretty sweet deal for you. Sign up through the link below, and you'll get (7,000 Free Words Plus 40% OFF) if you upgrade to the paid plan within four days. Claim Your 7,000 Free Words With This Special Link - No Credit Card Required Just like Outranking, Frase is an AI that helps you research, create and optimize your content to make it high quality within seconds. Frase works on SEO optimization where the content is made to the liking of search engines by optimizing keywords and keywords. Features: Generate full-length, optimized content briefs in seconds and review the main keywords, headers, and concepts in your SEO competitors’ content in one intuitive research panel. Write high-converting, SEO-optimized copy and make writer’s block a thing of the past with automated outlines, blog introductions, product descriptions, FAQs, and more. An intuitive text editor that uses a topic model to score your content Optimization against your competitors. A dashboard that automatically identifies and categorizes your best content opportunities. Frase uses your Google Search Console data to serve up actionable insights about what you should work on next. Pros Unlike Outranking, the interface to Frase is very user-friendly and accessible. Users who are content writers and have to research get a lot of time to write and ideate instead of juggling from one website to another as data can be easily accessed on Frase for research on a topic. Optimizing content with keyword analysis and SEO optimization has been made easier with Frase's Content Optimization. Reports on competitors' websites help in optimizing our own articles and websites. Content briefs make research very easy and efficient. Cons The paid plans are a bit pricey because they include many tools for content optimization. Pricing Frase provides two plans for all users and a customizable plan for an enterprise or business. Solo Plan: $14.99/Month and $12/Month if billed yearly with 4 Document Credits for 1 user seat. Basic Plan: $44.99/month and $39.99/month if billed yearly with 30 Document Credits for 1 user seat. Team Plan: $114.99/month and $99.99/month if billed yearly for unlimited document credits for 3 users. *SEO Add-ons and other premium features for $35/month irrespective of the plan. 4. Article Forge — Popular Blog Writing Software for Efficiency and Affordability Article Forge is another content generator that operates quite differently from the others on this list. Unlike Jasper.ai, which requires you to provide a brief and some information on what you want it to write this tool only asks for a keyword. From there, it’ll generate a complete article for you. Features Article Forge integrates with several other software, including WordAi, RankerX, SEnuke TNG, and SEO Autopilot. The software takes information from high-ranking websites and then creates more credible articles to rank well in search engines. If you want to generate content regularly, Article Forge can help. You can set it up to automatically generate articles based on your specific keyword or topic. Or, if you need a lot of content quickly, you can use the bulk content feature to get many articles in a short period. Pros Excellent for engaging with readers on multiple CMS platforms No spinner content. Create multiple unique articles Extremely quick and efficient One of the cheapest options online Cons You need to pay attention to the content since it’s not always on point Only ideal for decent-quality articles – if you’re lucky Pricing What’s excellent about Article Forge is they provide a 30-day money-back guarantee. You can choose between a monthly or yearly subscription. Unfortunately, they offer a free trial and no free plan: Basic Plan: $27/Month Features: This plan allows users to produce up to 25k words each month. This is excellent for smaller blogs or those who are just starting. Standard Plan: $57/month) Features: This plan allows users to produce up to 250k words each month. This is excellent for smaller blogs or those who are just starting. Unlimited Plan: $117/month Features: If you’re looking for an unlimited amount of content, this is the plan for you. You can create as many articles as you want, and there’s no word limit. It’s important to note that Article Forge guarantees that all content generated through the platform passes Copyscape. 5. Rytr — Superb AI Content Writing Assistant Rytr.me is a free AI content generator perfect for small businesses, bloggers, and students. The software is easy to use and can generate SEO-friendly blog posts, articles, and school papers in minutes. Features Rytr can be used for various purposes, from writing blog posts to creating school papers. You can also generate captions for social media, product descriptions, and meta descriptions. Rytr supports writing for over 30 languages, so you can easily create content in your native language. The AI helps you write content in over 30 tones to find the perfect tone for your brand or project. Rytr has a built-in plagiarism checker that ensures all your content is original and plagiarism free. Pros Easy to use Creates unique content It supports over 30 languages Multi-tone writing capabilities Cons It can be slow at times Grammar and flow could use improvement Pricing Rytr offers a free plan that comes with limited features. It covers up to 5,000 characters generated each month and has access to the built-in plagiarism checker. If you want to use all the features of the software, you can purchase one of the following plans: Saver Plan: $9/month, $90/year Features: Generate 100k characters per month Access 40+ use-cases Write in 30+ languages Access 20+ tones Built-in plagiarism checker Generate up to 20 images per month with AI Access to premium community Create your own custom use-case Unlimited Plan: $29/month, $290/year Features: Generate UNLIMITED* characters per month Access 40+ use-cases Write in 30+ languages Access 20+ tones Built-in plagiarism checker Generate up to 100 images per month with AI Access to premium community Create your own custom use-case Dedicated account manager Priority email & chat support 6. Writesonic — Best AI Article Writing Software with a Grammar and Plagiarism Checker Writesonic is a free, easy-to-use AI content generator. The software is designed to help you create copy for marketing content, websites, and blogs. It's also helpful for small businesses or solopreneurs who need to produce content on a budget. Features The tone checker, is a great feature that helps you ensure that your content is consistent with your brand’s voice. This is excellent for crafting cohesive and on-brand content. The grammar checker is another valuable tool that helps you produce error-free content. The plagiarism checker is a great way to ensure that your content is original. Pricing Writesonic is free with limited features. The free plan is more like a free trial, providing ten credits. After that, you’d need to upgrade to a paid plan. Here are your options: Short-form: $15/month Features: Access to all the short-form content templates like Facebook ads, product descriptions, paragraphs, and more. Long-Form: $19/month Features: Awesome tools to help you write short and long-form content like blog posts, ebooks, and more. 7. CopySmith — Produces Quality Content in Seconds CopySmith is an AI content generator that can be used to create personal and professional documents, blogs, and presentations. It offers a wide range of features including the ability to easily create documents and presentations. CopySmith also has several templates that you can use to get started quickly. Features This software allows you to create product descriptions, landing pages, and more in minutes. Offers rewritten content that is both unique and plagiarism free. This feature helps you create product descriptions for your Shopify store that are SEO-friendly and attractive to customers. This is an excellent tool for new content ideas. Pros Excellent for generating eCommerce-ready content No credit card is required for the free trial SEO-ready content Cons The blog content isn’t the best Better suited for short copy Pricing CopySmith offers a free trial with no credit card required. After the free trial, the paid plans are as follows: Starter Plan: $19/month Features: Get 50 credits monthly with up to 20 plagiarism checks. Professional Plan: $59/month Features: Upgrade to 400 credits per month with up to 100 plagiarism checks. Enterprise – Create a custom-tailored plan by contacting the sales team. 8. Hypotenuse.ai — Best AI Writing Software for E-Commerce and Product Descriptions Hypotenuse.ai is a free online tool that can help you create AI content. It's great for beginners because it allows you to create videos, articles, and infographics with ease. The software has a simple and easy-to-use interface that makes it perfect for new people looking for AI content generation. Special Features You can create custom-tailored copy specific to your audience’s needs. This is impressive since most free AI content generators do not offer this feature. Hypotenuse takes data from social media sites, websites, and more sources to provide accurate information for your content. If you’re selling a product online, you can use Hypotenuse to create automated product descriptions that are of high quality and will help you sell more products. Pros Excellent research capabilities Custom-tailored copy Automated product descriptions Cons No free plan Pricing Hypotenuse doesn’t offer a free plan. Instead, it offers a free trial period where you can take the software for a run before deciding whether it’s the right choice for you or not. Other than that, here are its paid options: Starter Plan: $29/month Features: This plan comes with 100 credits/month with 25k Words with one user seat. It’s an excellent option for individuals or small businesses. Growth Plan: $59/month Features: This plan comes with 350 credits/month with 87.5k words and 1 user seat. It’s perfect for larger businesses or agencies. Enterprise – pricing is custom, so don’t hesitate to contact the company for more information. 9. Kafkai — Leading AI Writing Tool for SEOs and Marketers Kafkai is an AI content generator and writing software that produces niche-specific content on a wide variety of topics. It offers a user-friendly interface, as well as a high degree of personalization. Features Kafkai offers a host of features that make it SEO-ready, including the ability to add keywords and tags to your content. Kafkai is designed explicitly for creating niche-specific content, which can be a significant advantage for businesses or bloggers looking to target a specific audience. Kafkai produces high-quality content, a significant advantage for businesses or bloggers looking to set themselves apart from the competition. Kafkai offers a unique feature that allows you to seed content from other sources, which can be a significant time-saver when creating content. Pros Quick results with high efficiency You can add seed content and phrases It can be used to craft complete articles Cons Its long-form-content generator isn’t very high quality Pricing Kafkai comes with a free trial to help you understand whether it’s the right choice for you or not. Additionally, you can also take a look at its paid plans: Writer Plan: $29/month Create 100 articles per month. $0.29/article Newsroom Plan $49/month – Generate 250 articles a month at $0.20 per article. Printing Press Plan: $129 /month Create up to 1000 articles a month at roughly $0.13/article. Industrial Printer Plan: ($199 a month) – Generate 2500 articles each month for $0.08/article. 10. Peppertype.ai — Best AI Content Writing Software for Blogging Peppertype.ai is an online AI content generator that’s easy to use and best for small business owners looking for a powerful copy and content writing tool to help them craft and generate various content for many purposes. Features You can choose from various pre-trained templates to create your content. This can save you a lot of time since you don’t have to spend time designing your templates or starting entirely from scratch. Peppertype offers various copywriting frameworks to help you write better content. Peppertype is lightweight and easy to use. This makes it perfect for beginners who want to get started with AI content generation. Peppertype’s autocorrect feature automatically corrects your grammar and spelling mistakes as you type. This ensures that your content is free of errors. Peppertype tracks user engagement data to help you create content that resonates with your audience. Pros It doesn’t have a steep learning curve It helps users to create entirely original content The basic plan comes with access to all of their frameworks and templates Built-in style editor Cons More hits than misses on content generated Tons of typos and grammatical errors Pricing Unfortunately, Peppertype.ai isn’t free. However, it does have a free trial to try out the software before deciding whether it’s the right choice for you. Here are its paid plans: personal Plan:$35/Month Features: 50,000 words included 40+ content types Notes and Text Editor Access to templates Unlimited projects Active customer support Team Plan: $199/month Features: Everything included in the Personal Collaborate & share results Access control Export results Request custom content types Enterprise – pricing is custom, so please contact the company for more information. Final thoughts: It is no longer a secret that humans are getting overwhelmed with the daily task of creating content. Our lives are busy, and the process of writing blog posts, video scripts, or other types of content is not our day job. In comparison, AI writers are not only cheaper to hire, but also perform tasks at a high level of excellence. This article explores 10 writing tools that used AI to create better content choose the one which meets your requirements and budget but in my opinion Jasper ai is one of the best tools to use to make high-quality content. If you have any questions ask in the comments section Note: Don't post links in your comments Note: This article contains affiliate links which means we make a small commission if you buy any premium plan from our link.",
         "en",
         "{'MISC': ['10 writing tools that used AI to create better content choose the one which meets your requirements and budget but in my', 'AI content generator', 'AI writers are not only cheaper to hire', 'Access 20+ tones Built', 'After the free trial', 'Article Forge can', 'Awesome tools to help you write short and long', 'Basic Plan', 'Best AI Article Writing Software with', 'Best AI Content Writing Software for Blogging Peppertype.ai is an online AI content generator that’s easy to use and best for small', 'Best AI Writing Software for E-Commerce and', 'Better suited for short', 'Blog posts have been optimized for search engines and rank high on', 'Bullet Points to Blogs', 'Claim Your 7,000 Free Words With This Special Link', 'Cons', 'Cons More hits than misses on content generated Tons of typos and grammatical errors Pricing Unfortunately', 'Cons No free plan Pricing Hypotenuse', 'Copy.ai to a content management forum', 'CopySmith also has several', 'Create', 'Credits for 1', 'Enterprise', 'Everything', 'Extremely quick and', 'Facebook Ads', 'Facebook community and email', \"Features It'\", 'Features: Access to all the short-form content templates like Facebook ads', 'Frase works on SEO optimization where the content is made to the liking of search engines by optimizing', 'Free Credits Copy.ai is', 'Free Words', 'Free plan and no credit card required', 'From there', 'General Ads', 'Generate', 'Generate full-length', 'Generates a wide', 'Get 50 credits monthly with up to 20 plagiarism checks', 'Google Search Console data to', 'Google and other search engines', 'Google docs', 'Google for duplicate content', 'Grammar and Plagiarism Checker Writesonic is a free', 'Grammar and flow could', 'Guarantees', 'Here are its paid plans', 'Here are your options', 'Hypotenuse to create automated product descriptions that are of high quality and will help you sell more products', 'Hypotenuse.ai', 'If so', 'If you have any questions ask in the comments', 'If you want to generate content regularly', 'If you’re selling', 'It', 'It can be used to craft', 'It covers up to 5,000 characters generated each month and has access to the built-in plagiarism checker', 'It supports', \"It's also helpful for small businesses or solopreneurs\", \"It's great for beginners because it allows you to create videos\", 'It’', 'It’s perfect for larger businesses or', 'Jasper ai is one of the best tools to use to make high-quality content', 'Jasper is a content writing and content generation tool', 'Kafkai comes with a free trial to help you understand whether it’s the right choice for you or not', 'Kafkai is designed explicitly', 'Leading AI Writing Tool for SEOs and Marketers Kafkai is an AI content generator and writing software that produces niche', \"Note: Don't post links in\", 'Notes and Text Editor Access to templates', 'Offers rewritten content that is both unique and plagiarism free', 'One of the cheapest options', 'Only ideal for decent-quality', 'Optimization against your', \"Optimizing content with keyword analysis and SEO optimization has been made easier with Frase's\", 'Original Content and guarantees that all content it generates will be', 'Other than that', 'Our lives are busy, and the process of writing blog posts', 'Peppertype', 'Peppertype is lightweight and easy to', 'Peppertype.ai isn’t free', 'Plan', 'Plan:$35', 'Pricing', 'Pricing Frase', 'Pricing Free Trial', 'Pricing Jasper.ai', 'Printing Press Plan', 'Priority email & chat', 'Pro Plan', 'Pros Easy to use Creates', 'Pros Excellent for generating eCommerce-ready content No credit card is required for the free trial SEO-ready content', 'Reports', 'SEO Add-ons and other premium features for', 'SEnuke TNG', 'Saver Plan', 'Short-form', \"Sign up through the link below, and you'll get\", 'Smooth and', 'So', 'Standard', 'Starter Plan', 'Superb AI Content Writing Assistant Rytr.me is a free AI', 'Team', 'The AI helps you write content in over 30 tones to find the perfect tone for your brand or project', 'The basic', 'The cheapest option covers up to 20,000 words generated each month', 'The free plan is more like a free trial', 'The grammar checker is another valuable tool that helps you', 'The plagiarism checker is a great way to ensure that your content is', 'The software has', 'The software is designed to help you create copy for marketing content', 'The software is easy to use and can generate SEO-friendly blog posts', 'The utility of this service can be used for short-term or format business purposes such as product descriptions', 'There are a number of different', 'This is a huge plus for online businesses that want to generate traffic to their website through content marketing', 'This is excellent for crafting cohesive and on-brand content', 'This is excellent for smaller blogs or those who are just starting', 'This makes it perfect for beginners who want to get started with AI', 'To help you make the best decision', 'Top 10 AI Content Generator & Writer Tools in 2022 Are you looking for a way to create content that is', 'Unlimited Plan', 'Unlimited projects', 'Up to 5', 'Users who are content writers and have to research get', 'Wait!', 'Words with one', 'Write high-converting', 'Write in', 'Writer Plan', 'Writesonic —', 'You can also generate captions for social media', 'You can choose between a monthly or yearly', 'You can create as many', 'You can set it up to automatically generate', 'and categorizes your best content', 'and concepts in your SEO', 'and infographics with ease', 'as well as', 'but also perform tasks at a high level of excellence', 'easy-to-use', 'experience with chrome', 'experience with various templates to help the process of content generation', 'for users to understand the AI better and to interact with other users', 'generator isn’t very high', 'help in optimizing our own articles and websites', 'high degree of personalization', 'including WordAi', 'let’s get started!', 'looking for', 'make research very easy and', 'many tools for content', 'providing ten credits', 'seat', 'that your content', 'the best words and sentences for your writing style and medium in the most', 'the paid plans are as follows', 'this is the plan for you', 'using an AI content generator', 'video scripts', 'we have compiled a list of the top 10', 'you can also take', 'you can purchase one of the following plans', 'you can use', 'you can use the bulk', 'you’d need to upgrade to a paid plan'], 'PER': ['CopySmith —', 'Generate', 'Hypotenuse', 'Kafkai', 'Peppertype’', 'Pricing Writesonic is free with', 'Rytr', 'paragraphs', 'since you don’t have to', 'then you should'], 'ORG': ['After that', 'Automated', 'Cons The paid plans are', 'Custom', 'English', 'FAQs', 'Features', 'Features You can', 'Frase for research', 'Generate UNLIMITED', 'Growth', 'Hook Text', 'Industrial Printer', 'Instead', 'Key Features', 'Month Features', 'Pros', 'Pros Excellent for engaging with readers on multiple CMS', 'Pros It doesn’t have', 'Pros Unlike', 'Special Features', 'Special Features You can create custom-tailored copy specific to your audience’', 'create and optimize your content to make it high quality within seconds'], 'LOC': ['Frase', 'Kafkai', 'Month if billed yearly with 4 Document Credits for 1', 'Provides', 'RankerX']}",
         "[-0.11071627587080002, -0.041722897440195084, -0.0631210207939148, 0.047121964395046234, -0.0032670656219124794, 0.052079807966947556, -0.04616987332701683, -0.004802931100130081, -0.01846797950565815, -0.0205438993871212, -0.04798510670661926, 0.05100017040967941, 0.0486467070877552, -0.014857253059744835, 0.03582289069890976, 0.007263002917170525, 0.12604142725467682, 0.0309812780469656, -0.023017924278974533, -0.08032941073179245, 0.04048541188240051, 0.07445570081472397, 0.06870409101247787, -0.06713251769542694, 0.016649266704916954, 0.05518264323472977, -0.01464046724140644, -0.023569900542497635, 0.04393316060304642, -0.06612188369035721, 0.049958016723394394, 0.02115895040333271, 0.033997271209955215, 0.005822618026286364, -0.09097100049257278, 0.055859655141830444, -0.015369519591331482, -0.03645865246653557, 0.12071814388036728, 0.006371543742716312, -0.0405849851667881, -0.09211806207895279, -0.06770909577608109, -0.01607075147330761, 0.0631723627448082, -0.03642459586262703, -0.06220846250653267, 0.003575811395421624, -0.01891658641397953, 0.07423728704452515, -0.18422473967075348, -0.02566397376358509, -0.004514917265623808, -0.08091839402914047, -0.04601756110787392, -0.022201325744390488, -0.02528165839612484, 0.0031137261539697647, -0.03900992497801781, -0.0676165446639061, 0.02081390656530857, -0.053147897124290466, -0.0003120873880106956, 0.011515987105667591, 0.028210289776325226, -0.06460316479206085, -0.05265067145228386, 0.05265916511416435, -0.02568204328417778, -0.04177086800336838, -0.040554922074079514, 0.04111318290233612, -0.018503375351428986, 0.04402310401201248, -0.015628905966877937, 0.08879399299621582, 0.06325055658817291, -0.05049046874046326, 0.028508812189102173, -0.08116155862808228, 0.03957199305295944, -0.010811430402100086, 0.006580763030797243, 0.06304993480443954, -0.08600657433271408, -0.03851945325732231, 0.08897385746240616, 0.06820784509181976, 0.014219478704035282, 0.08785682171583176, 0.050020717084407806, -0.023821085691452026, 0.06100946664810181, -0.005452078767120838, -0.047485366463661194, 0.051314108073711395, -0.03957405686378479, -0.04890195652842522, 0.01000671274960041, 0.004233063664287329, -0.009700817987322807, 0.08604893833398819, 0.06671717762947083, -0.020760787650942802, -0.024212773889303207, -0.07318559288978577, 0.08250700682401657, 0.044997718185186386, 0.00585174048319459, -0.03644277900457382, 0.0939754918217659, 0.010112744756042957, -0.07447154074907303, -0.10059251636266708, 0.08768744021654129, -0.018745189532637596, 0.006655464880168438, -0.01645476743578911, 0.07830830663442612, 0.06390169262886047, -0.001334881060756743, 0.08396697789430618, -0.06071477383375168, 0.041115254163742065, 0.0012488769134506583, 0.037323396652936935, -0.04920116066932678, 3.4627154226706305e-33, 0.011529172770678997, 0.1272483915090561, -0.03903208673000336, 0.07923377305269241, -0.03335242718458176, 0.018424253910779953, -0.06364674121141434, -0.016059614717960358, -0.055722761899232864, -0.030033068731427193, -0.024626625701785088, 0.07750341296195984, -0.05981095880270004, 0.09295324236154556, 0.06490319222211838, -0.09767219424247742, -0.0066063422709703445, 0.003983993083238602, 0.004247067961841822, 0.0211191289126873, 0.08314075320959091, -0.06893076747655869, 0.013308820314705372, 0.012022075243294239, 0.018127337098121643, 0.038519639521837234, 0.0660083144903183, -0.08919531106948853, -0.09619708359241486, -0.021549057215452194, 0.01383998617529869, -0.04739389568567276, -0.02720416523516178, 0.005466461181640625, -0.03056158497929573, -0.02495579980313778, -0.10710716247558594, -0.013015083968639374, 0.021572666242718697, 0.04400121048092842, -0.10837826877832413, 0.026662709191441536, 0.00624583987519145, 0.03589600697159767, 0.008245849050581455, 0.056359585374593735, -0.021675022318959236, -0.019660621881484985, 0.06306857615709305, -0.02667350508272648, 0.04119075834751129, 0.00030992040410637856, 0.0784311518073082, 0.024432649835944176, 0.06657690554857254, -0.010150662623345852, 0.024923328310251236, -0.018038135021924973, 0.06590922176837921, -0.00850675255060196, 0.018381230533123016, 0.05454216152429581, -0.02703258767724037, 0.01685491017997265, 0.04013115540146828, 0.040522828698158264, 0.09333716332912445, -8.189188520191237e-05, 0.0440356470644474, 0.022481046617031097, 0.0760926678776741, -0.003806592430919409, 0.0409720316529274, -0.03528425842523575, -0.054178498685359955, -0.006325362250208855, 0.016920972615480423, -0.09134366363286972, 0.0031834780238568783, 0.039440352469682693, 0.008100799284875393, 0.0009288075962103903, 0.0033500215504318476, -0.07249150425195694, 0.04029156640172005, -0.08466062694787979, 0.0064531415700912476, -0.030156835913658142, -0.020514924079179764, -0.007826321758329868, 0.028022997081279755, 0.10538537800312042, 0.00389089179225266, 0.03256053104996681, -0.009123023599386215, -3.0753288716342455e-33, -0.014951280318200588, -0.003945976495742798, -0.05409206822514534, 0.06309418380260468, -0.03585105016827583, 0.06164534389972687, -0.019738374277949333, 0.03229992091655731, 0.03939235210418701, -0.020886290818452835, -0.05676267668604851, -0.023068126291036606, 0.04280659556388855, -0.014844609424471855, -0.0035393093712627888, -0.06293462216854095, -0.024590248242020607, -0.060991693288087845, -0.022231172770261765, 0.027542607858777046, -0.011133833788335323, 0.1426534652709961, -0.0796579048037529, 0.016294078901410103, 0.12346090376377106, -0.022544503211975098, -0.05491181090474129, 0.07374360412359238, -0.08749821782112122, -0.027783501893281937, 0.0499952957034111, -0.038880132138729095, 0.03544124960899353, -0.003000616794452071, -0.058631591498851776, 0.01680447719991207, 0.051136408001184464, -0.0052498821169137955, -0.02037896402180195, 0.033237989991903305, 0.044906582683324814, 0.004441854543983936, -0.014949553646147251, 0.020197315141558647, -0.0963369607925415, 0.05995747819542885, -0.07816164195537567, 0.02275032177567482, 0.011140158399939537, 0.08481509983539581, -0.044021714478731155, 0.007561140228062868, -0.11134575307369232, -0.03824688494205475, -0.035234712064266205, -0.05821983516216278, -0.03485332429409027, -0.009690945036709309, -0.07954342663288116, 0.0456937700510025, -0.06539452821016312, 0.06227962672710419, 0.057037342339754105, -0.024073634296655655, 0.033894266933202744, -0.09327869862318039, 0.050556499511003494, 0.035519469529390335, -0.06891989707946777, -0.0039259702898561954, 0.042068347334861755, 0.03478257730603218, 0.037429772317409515, -0.013368583284318447, 0.01642964780330658, 0.090848907828331, 0.029311444610357285, 0.014516266994178295, -0.03984865918755531, -0.08375665545463562, -0.011802731081843376, 0.02316119894385338, -0.024051330983638763, 0.05011383071541786, 0.035696472972631454, 0.04800838977098465, -0.07190049439668655, -0.020284369587898254, -0.04652799665927887, 0.0280651543289423, 0.007776669692248106, -0.01034813467413187, 0.05412362888455391, 0.06270718574523926, -0.07642834633588791, -4.7638845757091985e-08, -0.015013046562671661, -0.029996201395988464, -0.03197498247027397, 0.03352157399058342, 0.06115443632006645, 0.03932841867208481, -0.01751898042857647, -0.02358980104327202, -0.029116760939359665, -0.011351708322763443, 0.01304407324641943, -0.04387371987104416, -0.04053874313831329, 0.04512492194771767, 0.050381626933813095, -0.06040162593126297, 0.014329513534903526, -0.04999294877052307, -0.015179969370365143, -0.0559537410736084, 0.1025676503777504, -0.004277035128325224, -0.04069989547133446, -0.04871055483818054, 0.05167314410209656, -0.018433138728141785, -0.033588606864213943, -0.07943958789110184, -0.0007851066184230149, -0.04207264631986618, -0.009996081702411175, -0.01836099848151207, -0.038053736090660095, 0.04187308996915817, 0.07225681841373444, -0.00795814674347639, 0.04101021587848663, -0.04778455197811127, -0.0673217922449112, 0.0032082076650112867, 0.09566602110862732, 0.026498710736632347, 0.022739598527550697, -0.023238765075802803, -0.000893737596925348, -0.004468942526727915, -0.022400056943297386, -0.1367460936307907, 0.055000752210617065, -0.00918502639979124, -0.0579291395843029, -0.05946303904056549, 0.0474102720618248, -0.024391066282987595, 0.02786252461373806, 0.04964742809534073, 0.018134715035557747, 0.08655610680580139, 0.06935161352157593, 0.05258661136031151, 0.05592106655240059, 0.05883225053548813, 0.02861061692237854, -0.025711342692375183]",
         "0.142"
        ],
        [
         "1",
         "569",
         "How I Fine-Tuned Granite-Vision 2B to Beat a 90B Model — Insights and Lessons Learned",
         "A hands-on journey exploring fine-tuning techniques that unlock the power of small vision models. The post How I Fine-Tuned Granite-Vision 2B to Beat a 90B Model — Insights and Lessons Learned appeared first on Towards Data Science .",
         "or vision-language models is a powerful technique that unlocks their potential on specialized tasks. However, despite their effectiveness, these approaches are often out of reach for many users due to their high computational cost and the need for GPUs with large VRAM — resources that only a small percentage of end users can access.\n\nIn this project, I fine-tuned IBM’s Granite-Vision 2B, a relatively small yet powerful vision-language model, to tackle the challenge of converting images of tables into clean, structured HTML code.\n\nWhat makes this project particularly exciting is that the fine-tuning was performed on a consumer-grade GPU — the NVIDIA RTX 4070 Ti Super — and yet, the resulting 2-billion-parameter model was able to outperform much larger models, including meta-llama/Llama-3.2–90B-Vision, on this image-to-text generation task. This success not only demonstrates the power of parameter-efficient fine-tuning methods like LoRA but also highlights the practical value of building specialized small models tailored to specific problems.\n\nIn this post, I’ll walk you through the motivation behind this work, the model and dataset choices, the custom HTML similarity metric I adapted, the experiments and results, and finally, the key insights and lessons learned throughout the process. Whether you’re interested in vision-language models, fine-tuning techniques, or practical AI applications, I hope this journey offers useful takeaways. The fine-tuning code used for this project was adapted from HuggingFace’s Granite Vision fine-tuning cookbook, authored by Eli Schwartz, who in turn adapted the original code from Sergio Paniego.\n\nMotivation\n\nWhile working on Retrieval-Augmented Generation (RAG) projects, I encountered a major challenge: accurately extracting large and complex tables from PDFs, especially when these tables appeared as images. Despite trying different approaches — including tools like Unstructured and large vision-language models such as Meta’s Llama 90B — the results often fell short of the accuracy needed.\n\nThis led me to consider a different approach: a small, specialized vision-language model focused exclusively on table understanding and extraction. Such a model could serve as a dedicated preprocessing step to significantly improve RAG pipelines that rely on accurate table extraction.\n\nAround the same time, IBM released Granite-Vision 2B — a vision-language model with just the right balance of size and power. It’s capable enough to handle complex tables, yet small enough to be fine-tuned on consumer-grade GPUs with 16 GB of VRAM. This made it an ideal candidate for my project.\n\nThe Task: Image to HTML (Table Extraction)\n\nOne important design choice was the target format: HTML. By converting tables into clean HTML code, we obtain a structured and widely supported representation that can be easily converted into other formats. For example, HTML tables can be readily imported into data analysis tools like Pandas as dataframes, making downstream processing and analysis much more efficient.\n\nThe original plan was to build a custom dataset by extracting HTML table tags, rendering them as images, and pairing each image with its corresponding HTML code. Fortunately, I found a solution: the PubTabNet-HTML dataset, which includes over 568,000 image–HTML pairs, far more than needed for this project.\n\nPubTabNet was developed by IBM and is based on scientific articles from the PubMed Central Open Access Subset (commercial use collection). The tables were extracted by aligning PDF and XML versions of the articles. The annotations (i.e., the HTML labels) are licensed under the Community Data License Agreement – Permissive – Version 1.0, and while IBM does not own the images, they are used in accordance with the PMC Open Access Subset Terms of Use. This makes the dataset suitable for both research and commercial applications, provided the license terms are followed.\n\nCustom Metric: HTML Similarity\n\nStandard text similarity metrics like BLEU or ROUGE are insufficient for evaluating HTML table generation because they primarily focus on surface-level text matching and ignore important structural and stylistic aspects of HTML code.\n\nTo better capture the quality of generated HTML tables, I adapted a custom HTML Similarity metric that combines multiple complementary components, where the most important ones (style and structure) are imported from niteru:\n\nStyle similarity (S): Extracts CSS classes of each html document and calculates the jaccard similarity of the sets of classes.\n\nExtracts CSS classes of each html document and calculates the jaccard similarity of the sets of classes. Structural similarity (T): Uses sequence comparison of the html tags to compute the similarity.\n\nUses sequence comparison of the html tags to compute the similarity. Content similarity (C): Based on normalized edit distance between the extracted plain text content of the tables.\n\nBased on normalized edit distance between the extracted plain text content of the tables. Token overlap similarity (J): The Jaccard similarity between the sets of content tokens.\n\nThe final similarity score M is a weighted sum of these components:\n\nI manually tested the metric on various example outputs, iteratively adjusting the weighting coefficients to better capture meaningful similarities. This process resulted in a balanced evaluation that fairly rewards accurate table structure and style, alongside precise textual content. Python implementation is as follows:\n\nfrom torchmetrics.text import EditDistance from niteru import style_similarity, structural_similarity ed_distance = EditDistance() def extract_table_text(html): \"\"\"Extracts only the text from an HTML table in row-wise space-separated format.\"\"\" soup = BeautifulSoup(html, \"html.parser\") table = soup.find(\"table\") # Find the first table if not table: return \"\" # Extract rows and join cells with spaces return \"\n\n\".join(\" \".join(cell.get_text(strip=True) for cell in row.find_all([\"th\", \"td\"])) for row in table.find_all(\"tr\")) def extract_html_table(html): \"\"\"Extracts html table from text\"\"\" match = re.search(r'<table\\b.*?</table>', html, re.DOTALL | re.IGNORECASE) if match: table_html = match.group() return table_html else: return html def html_similarity(html1, html2): html1 = extract_html_table(html1) html2 = extract_html_table(html2) # Compute individual similarity scores style_sim = style_similarity(html1, html2) # Assume returns [0,1] struct_sim = structural_similarity(html1, html2) # Assume returns [0,1] txt1, txt2 = extract_table_text(html1), extract_table_text(html2) content_sim = 1 - (ed_distance(txt1, txt2) / max(len(txt1), len(txt2) + 1e-10)) # Avoid division by zero jaccard_sim = 1 - (len(set(txt1.split()).intersection(set(txt2.split()))) / len(set(txt1.split()).union(set(txt2.split()))) + 1e-10) # Weighted sum of the similarities final_score = (0.10 * style_sim) + (0.40 * struct_sim) + (0.30 * content_sim) + (0.20 * jaccard_sim) # Ensure final score is in [0,1] final_score = max(0, min(1, final_score)) return final_score\n\nThe metric also includes a regex-based function to extract only the HTML content within <table> tags. This was necessary because one of the reference models only generated incomplete or extra HTML outside of the table structure. By focusing the comparison strictly on the table content, the metric provides a more fair and meaningful evaluation across models.\n\nDeveloping a custom evaluation metric like this is crucial for reliably tracking model improvements and benchmarking performance against reference models.\n\nTraining Setup\n\nTo fine-tune the model efficiently on my NVIDIA RTX 4070 Ti Super, which has 16 GB VRAM, I used LoRA (Low-Rank Adaptation). This allowed me to update only a small number of parameters, significantly reducing GPU memory usage. In fact, during training, the model used only about half of the available VRAM — with enough headroom to play around with longer sequences, but not enough to handle more than one batch. Additionally, LoRA is generally faster to train than approaches like QLoRA.\n\nLoRA Setup\n\nI used the following LoRA configuration:\n\n# Setup LoRA target_modules = [] for layer_type in layers_to_tune: target_modules.extend( name for name, _ in model.named_modules() if (layer_type in name) and '_proj' in name ) peft_config = LoraConfig( r=16, lora_alpha=32, lora_dropout=0.1, target_modules=target_modules, use_dora=True, init_lora_weights=\"gaussian\" )\n\nKey points:\n\nr=16 : This low-rank dimension provides a good balance between model capacity and GPU memory usage.\n\n: This low-rank dimension provides a good balance between model capacity and GPU memory usage. use_dora=True : DoRA (Weight-Decomposed Low Rank Adaptation) improves the learning capacity and stability of LoRA by decomposing the pretrained weights into magnitude and direction components, helping the model better resemble the capacity of full fine-tuning — all without adding inference overhead. Performed slightly better than the default setting.\n\n: DoRA (Weight-Decomposed Low Rank Adaptation) improves the learning capacity and stability of LoRA by decomposing the pretrained weights into magnitude and direction components, helping the model better resemble the capacity of full fine-tuning — all without adding inference overhead. Performed slightly better than the default setting. init_lora_weights=\"gaussian\" : No particular reason, I didn’t want to experiment with this parameter.\n\n: No particular reason, I didn’t want to experiment with this parameter. target_modules : This flexible setup allows selectively targeting vision layers, language layers, or both, depending on the experiment. In practice, vision layers remained unaffected — even with use_dora=False — since DoRA currently supports only embedding, linear, and Conv2d layers. As a result, I fine-tuned only the language layers.\n\nDataset Setup\n\nDuring my initial experiments, I kept running into out-of-memory (OOM) errors — even though there was still plenty of available GPU VRAM after loading model, LoRA layers and optimizer parameters (around 4GB still free). There were no memory spikes during training, but the crashes consistently happened at the same training step.\n\nAfter some investigation, I realized that the problem was caused by large tables, which resulted in extremely long token sequences. To address this, I adjusted the max_seq_length parameter and filtered out samples that exceeded this limit. After experimentation, I found that using max_seq_length = 1024 allowed me to fine-tune the model reliably without triggering OOM errors.\n\nTo filter out oversized tables, I wrote a simple data processing function that:\n\nFilters out samples whose HTML token length exceeds max_seq_length\n\nAutomatically balances the number of training and test samples\n\nUses streaming to avoid loading the entire dataset into memory (PubTabNet-HTML is quite large, around 10 GB on disk)\n\n.\n\ndef load_process_filter_dataset(dataset, max_seq_length, num_train_images, num_test_images, system_message): global processor ds = load_dataset(dataset, split='train', streaming=True) max_html_tokens = max_seq_length - len(processor.tokenizer.tokenize(system_message)) num_total_needed = num_train_images + num_test_images filtered_samples = [] p_bar = tqdm(total=num_total_needed, desc=\"Filtering dataset samples\") for sample in ds: processed = process_and_filter_example(sample, max_html_tokens) if processed: filtered_samples.append(processed) p_bar.update(1) if len(filtered_samples) >= num_total_needed: break p_bar.close() # Convert to in-memory dataset ds_filtered = Dataset.from_list(filtered_samples) # Split into train/test ds_train = ds_filtered.select(range(num_train_images)) ds_test = ds_filtered.select(range(num_train_images, num_total_needed)) return ds_train, ds_test def process_and_filter_example(example, max_html_tokens): global processor extracted_table = extract_html_table(example['html_table']) token_count = len(processor.tokenizer.tokenize(extracted_table)) if token_count < max_html_tokens: example['html_table'] = extracted_table return example return None\n\nThe final configuration included num_train_images=10000 and num_test_images=250 to compute the evaluation loss.\n\nFine-Tuning Configuration\n\nFor training, I used the Transformers SFTTrainer to fine-tune the model:\n\n# Training arguments training_args = SFTConfig( output_dir=f\"src/models/{model_name.split('/')[-1].replace('-', '_', 1).split('-')[0]}/checkpoints/{experiment_name}\", num_train_epochs=1, per_device_train_batch_size=1, per_device_eval_batch_size=1, gradient_accumulation_steps=gradient_accumulation_steps, max_seq_length=max_seq_length, warmup_steps=10, learning_rate=3e-4, weight_decay=0.01, logging_strategy=\"steps\", eval_strategy='steps', logging_steps=25, save_strategy=\"steps\", save_steps=50, save_total_limit=1, greater_is_better=False, load_best_model_at_end=True, optim=\"adamw_torch_fused\", bf16=True, push_to_hub=False, report_to=\"wandb\" if not debug else \"none\", remove_unused_columns=False, gradient_checkpointing=True, dataset_text_field=\"\", dataset_kwargs={\"skip_prepare_dataset\": True}, dataset_num_proc=8 ) # Setup Trainer trainer = SFTTrainer( model=model, args=training_args, train_dataset=train_dataset, eval_dataset=test_dataset, data_collator=collate_fn, peft_config=peft_config, processing_class=processor.tokenizer )\n\nKey points:\n\nnum_train_epochs=1 : The dataset is very large, and to run multiple experiments efficiently, I chose to train for only one full epoch while maximizing learning per sample and number of training samples.\n\n: The dataset is very large, and to run multiple experiments efficiently, I chose to train for only one full epoch while maximizing learning per sample and number of training samples. per_device_train_batch_size=1 : Larger batch sizes would not fit in GPU memory without significantly reducing max_seq_length — which would hurt performance on large tables. Keeping longer sequences was more important for this task.\n\n: Larger batch sizes would not fit in GPU memory without significantly reducing max_seq_length — which would hurt performance on large tables. Keeping longer sequences was more important for this task. gradient_accumulation_steps=8 : Used to effectively simulate a larger batch size and help stabilize the learning process, compensating for the small physical batch. This is the final value, but experimented with gradient_accumulation_steps=4 as well.\n\n: Used to effectively simulate a larger batch size and help stabilize the learning process, compensating for the small physical batch. This is the final value, but experimented with as well. optim=\"adamw_torch_fused\" and bf16=True : These settings leverage modern NVIDIA architectures (Ada Lovelace) to accelerate training and reduce memory usage — as recommended for this hardware.\n\nEvaluation Loss Workaround\n\nAt the time of developing the project, there is a known issue in the Transformers + LoRA integration that causes an error when running evaluation with a validation dataset during training. Fortunately, a community-tested workaround is available (although not yet merged into the main branch), and I successfully used this fix in my experiments.\n\nEvaluation (Inference) Setup\n\nThe evaluation dataset used for final scoring was completely independent from the eval_dataset used during training. It consists of 500 randomly selected images, none of which were included in either the train_dataset or the training eval_dataset .\n\nOnce fine-tuning was complete, I used the best model checkpoint — selected based on the lowest evaluation loss — to run inference on these 500 samples.\n\nInitially, I attempted to perform inference by simply loading the LoRA/DoRA adapter on top of the base model. However, I found that inference with DoRA adapters is extremely slow when not merged into the model weights (as explained in the official PEFT docs). In fact, generating one test random sample took about 90 seconds in this configuration.\n\nTo resolve this, I merged the adapter weights into the base model — which is the recommended practice — and after merging, inference speed improved dramatically: down to ~20 seconds for the same sample, making full evaluation runs much more practical.\n\nThe reference models used for comparison with my fine-tuned models are:\n\nmeta-llama/Llama-3.2–90B-Vision: Meta’s massive 90-billion parameter model — the main baseline I aimed to surpass through specialization and parameter-efficient fine-tuning of a much smaller VLM.\n\nmodel — the main baseline I aimed to surpass through specialization and parameter-efficient fine-tuning of a much smaller VLM. KennethTM/pix2struct-base-table2html: A much smaller model fine-tuned from Google’s pix2struct-base, highly specialized for exactly the same dataset I used in this project. Thanks to its smaller size, the developer(s) was able to train it for many more samples and over longer training runs — demonstrating the key advantage of using smaller, targeted models for specific tasks.\n\nThese two baselines allowed me to benchmark both scaling-based performance (vs the 90B model) and specialization efficiency (vs the smaller, dedicated Pix2Struct model).\n\nExperiments & Results\n\nA total of 9 experiments were conducted, iteratively modifying one or two components at a time. The goal was to understand the effect of each change on model performance, gradually refining the setup to achieve the best possible HTML Similarity score compared to reference models.\n\nThe experimental process was incremental: whenever a change improved the results, it was incorporated into the next round of experiments and continued exploring new variations.\n\nThe experiments focused on adjusting the following components:\n\nVision vs. Language Layers\n\n1.1 lang_only\n\n1.2 vision_only\n\n1.3 lang_vision\n\n2. Ground Truth Output Format\n\n2.1 lang_table_only\n\n3. Training Framework\n\n3.1 lang_table_unsloth\n\n3.2 vision_table_unsloth\n\n4. Gradient Accumulation\n\n4.1 lang_table_only_2\n\n5. Prompt Format\n\n5.1 lang_table_only_3\n\n6. Gradient Accumulation & Dataset Size\n\n6.1 lang_table_only_4\n\nBoth the evaluation loss and the HTML Similarity metric were used to assess model performance, and I found them to be well correlated — confirming that HTML Similarity is a good proxy for how well the model is learning the task.\n\nBefore diving into the results of each experiment, let’s first look at GPU memory utilization during training, which is often the most critical factor in determining whether a model can be fine-tuned on consumer hardware.\n\nGPU Memory Utilization During Training | Image by author from wandb.ai\n\nAs shown in the graph, GPU utilization remained stable throughout training — averaging around 75% VRAM usage, or roughly 12 GB on my GPU. Most of VRAM usage (~5.5 GB) is the frozen model weights. LoRA gradients + optimizer states take very little (<< 1 GB). Activations + overhead should fill the rest (~5–6 GB), which depends on batch_size and max_seq_length .\n\nFirst Run: lang_only\n\nThis experiment uses the following initial components/parameters:\n\nThese were the starting values for the first experiment. In subsequent runs, I modified many of them as I refined the approach. This first experiment focused only on tuning language layers, while training the model to predict the full raw HTML output — including everything inside and around the <table> tags.\n\nSince this was the first run, I’ll include the training loss curve here to illustrate how it behaves. For later experiments, I’ll omit this graph — as the behavior was similar across runs, with minor variations. In practice, evaluation loss is more useful for comparing performance across experiments.\n\nTraining Loss | Image by author from wandb.ai\n\nOne important note about the logging configuration: logging_steps=25 means that the training loss is only logged after every 25 steps, where each logged value is the average over gradient_accumulation_steps=4 . As a result, the largest drop in loss appears at the second log point — where most of the initial learning happens. After that, the model continues learning more gradually, with a slow decreasing trend, depending on the difficulty of the training samples.\n\nNow, let’s take a look at the evaluation loss:\n\nValidation Loss 1 | Image by author from wandb.ai\n\nSince we are evaluating on the same set of 250 validation samples, the evaluation loss curve gives us a more stable and meaningful view of model learning — and will serve as a baseline for comparisons across future runs.\n\nHere, we observe a clear and consistent downward trend throughout training. The initial loss starts close to 0.03, with a steady improvement as training progresses, eventually stabilizing just below 0.015.\n\n\n\nThe smooth nature of this curve — compared to the more variable training loss — reflects the regular structure of the validation set and confirms that the model is generalizing well to unseen samples, even with a small batch size and a single epoch of training.\n\nNow, let’s compare the performance of this fine-tuned model against the reference models on the HTML Similarity metric:\n\nAs we can see, this first experiment already delivers strong performance gains — improving the base Granite-Vision 2B model by a large margin (+0.18) and clearly outperforming LLaMA 90B Vision on this specialized task. Only Pix2Struct retains a slight lead at this stage.\n\nSecond Run: vision_only\n\nThere isn’t much to analyze in this run. I tested several variations that could potentially unblock learning in the vision layers — including drastically increasing the learning rate — but without success.\n\n\n\nWhile the base code suggests that fine-tuning vision layers should be possible, in practice I found it was not working in this setup. The following evaluation loss curve confirms that no learning occurred — the loss remained constant throughout training. To avoid wasting compute resources, I stopped the run early:\n\nValidation Loss 2 | Image by author from wandb.ai\n\nAdditionally, training was noticeably faster in this run compared to the previous lang_only experiment — suggesting that the language layers (which contain the bulk of the model’s parameters) remained frozen, and only the small vision layers were being processed:\n\nValidation Samples per Second 1 | Image by author from wandb.ai\n\nThird Run: lang_vision\n\nAt this point, it was clear that only language layers were being effectively trained. In this lang_vision run — where both language and vision layers were selected — I expected results similar to lang_only .\n\nIndeed, the evaluation loss curve confirmed this expectation, showing nearly identical behavior to lang_only :\n\nValidation Loss 3 | Image by author from wandb.ai\n\nOnce this was clear, I again stopped training early to conserve resources, and proceeded to test new approaches.\n\nFourth Run: lang_table_only\n\nThis experiment modified the following component:\n\nThe goal of this run was to train the model to predict only the table content, without any surrounding HTML wrapper code. This approach could help improve learning — by removing unnecessary tokens — and also align the training behavior more closely with Pix2Struct’s model.\n\nAdditionally, by stripping out the wrapper HTML, the target sequences became shorter — which allowed longer and more complex tables to fit within the model’s context window. This change could also improve the model’s ability to generalize to larger or more detailed tables.\n\nLet’s look at the evaluation loss compared to the first run:\n\nValidation Loss 4 | Image by author from wandb.ai\n\nAt first glance, the higher evaluation loss might seem counterintuitive. However, there’s a clear explanation: the wrapper HTML code is trivial for the model to learn — since it tends to be nearly identical across many training samples. These repetitive tokens reduce cross-entropy loss, artificially lowering the average loss in earlier runs. By removing them, the model now focuses entirely on the more challenging and variable table content — resulting in a higher but more meaningful loss value.\n\nNow, let’s see how this change impacted the HTML Similarity metric:\n\nIn this first test, we observe no significant gain or degradation from using this new output format. It is possible that the model would need more epochs or larger training samples to fully adapt to this new format. Another idea is to update the prompt — so that from the very first step the model understands it should focus solely on table content, rather than having to infer this behavior through training alone. This will be explored in the next experiments.\n\nFifth / Sixth Run: lang_table_unsloth , vision_table_unsloth\n\nIn these experiments, I explored the following components:\n\nAt this point, I discovered the promising Unsloth framework — which claims to offer 2x faster training with up to 70% lower memory usage. Of course, I wanted to test whether it could accelerate my workflow.\n\nMy first idea was to leverage the improved memory handling to run longer sequences ( max_seq_length=2048 ), but in my case this quickly led to Out of Memory (OOM) errors — so I reverted to my previous configuration.\n\nThe training speed improvements, however, were undeniable — almost 4x faster than my earlier runs:\n\nValidation Samples per Second 2 | Image by author from wandb.ai\n\nUnfortunately, this came at a clear cost to loss performance:\n\nValidation Loss 5 | Image by author from wandb.ai\n\nGiven this noticeable drop in quality, I paused the experiment to investigate further — particularly to see if Unsloth would allow me to train vision layers, which is one of its advertised advantages. However, I encountered exactly the same behavior as with HuggingFace Transformers — no actual learning in vision layers.\n\nWith these results in mind, I decided to set aside Unsloth for this projectand continue using HuggingFace Transformers, which had shown more reliable learning in earlier runs.\n\nSeventh Run: lang_table_only_2\n\nHere are the new parameters for this run:\n\nGoing back to the previous configuration, I wanted to analyze the impact of a larger virtual batch size (via higher gradient_accumulation_steps ).\n\nThe results were promising — the evaluation loss became smoother and trended closer to the original lang_only run, even though the model was now predicting only the table content:\n\nValidation Loss 6 | Image by author from wandb.ai\n\nBased on this positive result, I decided to keep this gradient_accumulation_steps=8 setting for the final experiment.\n\nEvaluating this model on HTML Similarity resulted in a small but meaningful improvement — finally reaching parity with Pix2Struct:\n\nNaturally, the goal is not just to match Pix2Struct — but to surpass it. Two important levers remained to explore: dataset size and prompt.\n\nEighth Run: lang_table_only_3\n\nThe updated parameters for this run were:\n\nI accidentally reverted gradient_accumulation_steps back to 4 in this run, only realizing it once the training was nearly complete — but this actually gave me an extra-chance to observe its effect on learning.\n\nThe main goal here was to double the training size (to 10K images) and to test the updated, clearer prompt format. Unfortunately, a random CUDA error caused training to halt around 80% completion — but even so, the improvement was clear:\n\nValidation Loss 7 | Image by author from wandb.ai\n\nAs expected, some smoothness was lost due to the smaller virtual batch size, but the new prompt proved very effective — noticeably boosting model learning.\n\nThis set the stage perfectly for the final experiment, using this improved prompt, 10K training samples, and restoring gradient_accumulation_steps to 8.\n\nFinal Run: lang_table_only_4\n\nThe final set of parameters are:\n\nThe evaluation loss for this final run:\n\nValidation Loss 7 | Image by author from wandb.ai\n\nAs expected, restoring the gradient_accumulation_steps to 8 smoothed the loss curve, reducing spikes and achieving slightly lower overall loss values. With a full epoch of training on 10K images, this became the best-performing model across all experiments.\n\nNow, let’s look at the final results on the HTML Similarity metric:\n\nFinal HTML Similarity Results | Image by author from matplotlib\n\nThe goal of this project was achieved — the fine-tuned model now surpasses both reference models on this task. Looking back at the original Granite-Vision 2B, the LoRA fine-tuning improved performance to 0.77, a +21 percentage point gain — all accomplished in under 8 hours on a consumer-grade GPU.\n\nQualitative Results\n\nTo better illustrate how much the model improved through fine-tuning, let’s look at a specific example: Image ID 618932.\n\nPubTabNet Evaluation Sample with ID 618932 | Image from PMC\n\nThis table is particularly tricky — under the Kappa column there are sub-headers ( Present study and King et al. 2001 ). These complex layouts typically challenge generic VLMs, especially when they haven’t been exposed to enough similar examples during training. Models can usually understand these sub-headers and answer questions about them, but generating the full table structure in HTML often requires further prompt tuning and specialized fine-tuning.\n\nLet’s first see how a base, non-fine-tuned Granite-Vision 2B model performs on this task.\n\nBaseline: Raw Granite-Vision 2B\n\nThe model can answer questions based on the table correctly:\n\nprompt='What is the Kappa value for the question \"Do you communicate with this power?\" in the present study?' res = predict(sample['image'], prompt=prompt) print(res)\n\nOut[1]:\n\n74\n\nHowever, when asked to generate the full HTML table, the model struggles:\n\nprompt = \"Convert table to HTML (<table> ... </table>)\" html = predict(sample['image'], prompt=prompt) html = '<table>' + html + '</table>' if '<table>' not in html else html display(HTML(html))\n\nOut[2]:\n\nAnd the HTML Similarity metrics for this attempt:\n\nStyle similarity: 1.0000 Structural similarity: 0.4091 Lev-Edit Distance: 0.1434 Final HTML Similarity Score: 0.3619\n\nFine-Tuned Model: lang_table_only_4\n\nNow, let’s try the exact same test using the fine-tuned model:\n\nfrom src.models.granite_vision.transformers_library import LLM as granite_vision model = granite_vision( model_path, adapter='lang_table_only_4' )\n\nOut[4]:\n\nModel loaded Adapter 'lang_table_only_4' loaded Adapter 'lang_table_only_4' merged Using cuda: NVIDIA GeForce RTX 4070 Ti SUPER\n\nAnd the same prediction prompt:\n\nprompt = \"Convert table to HTML (<table> ... </table>)\" html = model.predict(sample['image'], max_new_tokens=1024, query=prompt) display(HTML(html))\n\nOut[5]:\n\nThe fine-tuned model now produces an output that closely matches the ground truth, correctly capturing the table structure and sub-headers — something the base model struggled with.\n\nFinal HTML Similarity metrics:\n\nStyle similarity: 1.0000 Structural similarity: 0.9231 Lev-Edit Distance: 1.0000 Final HTML Similarity Score: 0.9615\n\nThis example shows a clear quantitative improvement as well: from a score of 0.36 to 0.96 on a complex table structure — confirming that fine-tuning on this specialized task dramatically boosts the model’s capability.\n\nInference Speed\n\nOne major advantage of using a smaller model — aside from the ability to fine-tune on consumer-grade hardware — is inference speed. Even if larger models offer competitive performance, latency and throughput remain key factors, especially in production settings.\n\nLet’s compare the inference speed of the different models:\n\nInference SpeedM | Image by author from matplotlib\n\nAs shown in the plot, Pix2Struct is by far the fastest model. For some use cases — such as batch-processing thousands of documents for table extraction — this speed advantage could translate into significant time savings and lower compute costs.\n\nHowever, the fine-tuned Granite-Vision 2B achieves a good balance when the amount of documents to process is not massive, having a superior accuracy on this specialized task and reasonably fast inference without the need for extremely large compute infrastructure.\n\nConclusions\n\nThis project demonstrated that with LoRA-based fine-tuning and a targeted task (table extraction → HTML), a small vision-language model (Granite-Vision 2B) can outperform much larger models — even Meta’s 90B LLaMA Vision — while requiring only a consumer GPU and less than a day of training.\n\nA few key takeaways:\n\nSmall, specialized models matter — you don’t always need 70B+ models to solve specific problems with high accuracy.\n\n— you don’t always need 70B+ models to solve specific problems with high accuracy. Parameter-efficient fine-tuning (LoRA) is a game-changer: adapting large foundation models becomes accessible for most practitioners.\n\nis a game-changer: adapting large foundation models becomes accessible for most practitioners. Prompt design and training targets have a big influence — small changes (like switching to lang_table_only or refining the prompt) directly impacted performance.\n\nhave a big influence — small changes (like switching to or refining the prompt) directly impacted performance. Having a custom metric (HTML Similarity) was critical to track meaningful progress beyond generic text-based metrics.\n\nwas critical to track meaningful progress beyond generic text-based metrics. Smaller models not only train faster, but also infer faster — ideal for production pipelines with high volume.\n\nFinally — and maybe most importantly — this type of experimentation shows that you can move fast and iterate even with limited hardware. Fine-tuning powerful open models and adapting them to real-world tasks is not reserved to big labs anymore.\n\nI hope this encourages other AI engineers to experiment with small VLMs and fine-tuning techniques for their own projects and solutions — and to see that powerful results are possible even without massive compute budgets!\n\nWhat’s Next?\n\nThere are definitely some interesting follow-up ideas that can be explored next:\n\nPrompt engineering refinements : Final tests (while writing this blog) showed that separating prompts into system message (defining behavior) and user message (providing task instructions) significantly improved the base model’s performance. Applying this strategy during fine-tuning could further enhance the model’s ability to consistently generate accurate HTML. This will be tested in upcoming experiments.\n\n: Final tests (while writing this blog) showed that separating prompts into system message (defining behavior) and user message (providing task instructions) significantly improved the base model’s performance. Applying this strategy during fine-tuning could further enhance the model’s ability to consistently generate accurate HTML. This will be tested in upcoming experiments. Training vision layers : Currently, only the language layers are fine-tuned, as training the vision layers through text-only loss proved ineffective. A more advanced approach could involve adding an auxiliary vision loss — for example, contrastive learning between vision outputs and HTML structure — to better adapt the vision backbone for table extraction tasks.\n\n: Currently, only the language layers are fine-tuned, as training the vision layers through text-only loss proved ineffective. A more advanced approach could involve adding an auxiliary vision loss — for example, contrastive learning between vision outputs and HTML structure — to better adapt the vision backbone for table extraction tasks. Improved generalization: The current model is fine-tuned on a single dataset. Expanding training to include more diverse document layouts, table styles, and noisy OCR scenarios could improve robustness and transferability to real-world data.\n\nLinks\n\nIf you liked this post, feel free to reach out or share your own experiments!",
         "2025-07-25T19:29:01",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/how-i-fine-tuned-granite-vision-2b-to-beat-a-90b-model-insights-and-lessons-learned/",
         "2025-07-26T06:23:31.282901",
         "or vision-language models is a powerful technique that unlocks their potential on specialized tasks. However, despite their effectiveness, these approaches are often out of reach for many users due to their high computational cost and the need for GPUs with large VRAM — resources that only a small percentage of end users can access. In this project, I fine-tuned IBM’s Granite-Vision 2B, a relatively small yet powerful vision-language model, to tackle the challenge of converting images of tables into clean, structured HTML code. What makes this project particularly exciting is that the fine-tuning was performed on a consumer-grade GPU — the NVIDIA RTX 4070 Ti Super — and yet, the resulting 2-billion-parameter model was able to outperform much larger models, including meta-llama/Llama-3.2–90B-Vision, on this image-to-text generation task. This success not only demonstrates the power of parameter-efficient fine-tuning methods like LoRA but also highlights the practical value of building specialized small models tailored to specific problems. In this post, I’ll walk you through the motivation behind this work, the model and dataset choices, the custom HTML similarity metric I adapted, the experiments and results, and finally, the key insights and lessons learned throughout the process. Whether you’re interested in vision-language models, fine-tuning techniques, or practical AI applications, I hope this journey offers useful takeaways. The fine-tuning code used for this project was adapted from HuggingFace’s Granite Vision fine-tuning cookbook, authored by Eli Schwartz, who in turn adapted the original code from Sergio Paniego. Motivation While working on Retrieval-Augmented Generation (RAG) projects, I encountered a major challenge: accurately extracting large and complex tables from PDFs, especially when these tables appeared as images. Despite trying different approaches — including tools like Unstructured and large vision-language models such as Meta’s Llama 90B — the results often fell short of the accuracy needed. This led me to consider a different approach: a small, specialized vision-language model focused exclusively on table understanding and extraction. Such a model could serve as a dedicated preprocessing step to significantly improve RAG pipelines that rely on accurate table extraction. Around the same time, IBM released Granite-Vision 2B — a vision-language model with just the right balance of size and power. It’s capable enough to handle complex tables, yet small enough to be fine-tuned on consumer-grade GPUs with 16 GB of VRAM. This made it an ideal candidate for my project. The Task: Image to HTML (Table Extraction) One important design choice was the target format: HTML. By converting tables into clean HTML code, we obtain a structured and widely supported representation that can be easily converted into other formats. For example, HTML tables can be readily imported into data analysis tools like Pandas as dataframes, making downstream processing and analysis much more efficient. The original plan was to build a custom dataset by extracting HTML table tags, rendering them as images, and pairing each image with its corresponding HTML code. Fortunately, I found a solution: the PubTabNet-HTML dataset, which includes over 568,000 image–HTML pairs, far more than needed for this project. PubTabNet was developed by IBM and is based on scientific articles from the PubMed Central Open Access Subset (commercial use collection). The tables were extracted by aligning PDF and XML versions of the articles. The annotations (i.e., the HTML labels) are licensed under the Community Data License Agreement – Permissive – Version 1.0, and while IBM does not own the images, they are used in accordance with the PMC Open Access Subset Terms of Use. This makes the dataset suitable for both research and commercial applications, provided the license terms are followed. Custom Metric: HTML Similarity Standard text similarity metrics like BLEU or ROUGE are insufficient for evaluating HTML table generation because they primarily focus on surface-level text matching and ignore important structural and stylistic aspects of HTML code. To better capture the quality of generated HTML tables, I adapted a custom HTML Similarity metric that combines multiple complementary components, where the most important ones (style and structure) are imported from niteru: Style similarity (S): Extracts CSS classes of each html document and calculates the jaccard similarity of the sets of classes. Extracts CSS classes of each html document and calculates the jaccard similarity of the sets of classes. Structural similarity (T): Uses sequence comparison of the html tags to compute the similarity. Uses sequence comparison of the html tags to compute the similarity. Content similarity (C): Based on normalized edit distance between the extracted plain text content of the tables. Based on normalized edit distance between the extracted plain text content of the tables. Token overlap similarity (J): The Jaccard similarity between the sets of content tokens. The final similarity score M is a weighted sum of these components: I manually tested the metric on various example outputs, iteratively adjusting the weighting coefficients to better capture meaningful similarities. This process resulted in a balanced evaluation that fairly rewards accurate table structure and style, alongside precise textual content. Python implementation is as follows: from torchmetrics.text import EditDistance from niteru import style_similarity, structural_similarity ed_distance = EditDistance() def extract_table_text(html): \"\"\"Extracts only the text from an HTML table in row-wise space-separated format.\"\"\" soup = BeautifulSoup(html, \"html.parser\") table = soup.find(\"table\") # Find the first table if not table: return \"\" # Extract rows and join cells with spaces return \" \".join(\" \".join(cell.get_text(strip=True) for cell in row.find_all([\"th\", \"td\"])) for row in table.find_all(\"tr\")) def extract_html_table(html): \"\"\"Extracts html table from text\"\"\" match = re.search(r'<table\\b.*?</table>', html, re.DOTALL | re.IGNORECASE) if match: table_html = match.group() return table_html else: return html def html_similarity(html1, html2): html1 = extract_html_table(html1) html2 = extract_html_table(html2) # Compute individual similarity scores style_sim = style_similarity(html1, html2) # Assume returns [0,1] struct_sim = structural_similarity(html1, html2) # Assume returns [0,1] txt1, txt2 = extract_table_text(html1), extract_table_text(html2) content_sim = 1 - (ed_distance(txt1, txt2) / max(len(txt1), len(txt2) + 1e-10)) # Avoid division by zero jaccard_sim = 1 - (len(set(txt1.split()).intersection(set(txt2.split()))) / len(set(txt1.split()).union(set(txt2.split()))) + 1e-10) # Weighted sum of the similarities final_score = (0.10 * style_sim) + (0.40 * struct_sim) + (0.30 * content_sim) + (0.20 * jaccard_sim) # Ensure final score is in [0,1] final_score = max(0, min(1, final_score)) return final_score The metric also includes a regex-based function to extract only the HTML content within <table> tags. This was necessary because one of the reference models only generated incomplete or extra HTML outside of the table structure. By focusing the comparison strictly on the table content, the metric provides a more fair and meaningful evaluation across models. Developing a custom evaluation metric like this is crucial for reliably tracking model improvements and benchmarking performance against reference models. Training Setup To fine-tune the model efficiently on my NVIDIA RTX 4070 Ti Super, which has 16 GB VRAM, I used LoRA (Low-Rank Adaptation). This allowed me to update only a small number of parameters, significantly reducing GPU memory usage. In fact, during training, the model used only about half of the available VRAM — with enough headroom to play around with longer sequences, but not enough to handle more than one batch. Additionally, LoRA is generally faster to train than approaches like QLoRA. LoRA Setup I used the following LoRA configuration: # Setup LoRA target_modules = [] for layer_type in layers_to_tune: target_modules.extend( name for name, _ in model.named_modules() if (layer_type in name) and '_proj' in name ) peft_config = LoraConfig( r=16, lora_alpha=32, lora_dropout=0.1, target_modules=target_modules, use_dora=True, init_lora_weights=\"gaussian\" ) Key points: r=16 : This low-rank dimension provides a good balance between model capacity and GPU memory usage. : This low-rank dimension provides a good balance between model capacity and GPU memory usage. use_dora=True : DoRA (Weight-Decomposed Low Rank Adaptation) improves the learning capacity and stability of LoRA by decomposing the pretrained weights into magnitude and direction components, helping the model better resemble the capacity of full fine-tuning — all without adding inference overhead. Performed slightly better than the default setting. : DoRA (Weight-Decomposed Low Rank Adaptation) improves the learning capacity and stability of LoRA by decomposing the pretrained weights into magnitude and direction components, helping the model better resemble the capacity of full fine-tuning — all without adding inference overhead. Performed slightly better than the default setting. init_lora_weights=\"gaussian\" : No particular reason, I didn’t want to experiment with this parameter. : No particular reason, I didn’t want to experiment with this parameter. target_modules : This flexible setup allows selectively targeting vision layers, language layers, or both, depending on the experiment. In practice, vision layers remained unaffected — even with use_dora=False — since DoRA currently supports only embedding, linear, and Conv2d layers. As a result, I fine-tuned only the language layers. Dataset Setup During my initial experiments, I kept running into out-of-memory (OOM) errors — even though there was still plenty of available GPU VRAM after loading model, LoRA layers and optimizer parameters (around 4GB still free). There were no memory spikes during training, but the crashes consistently happened at the same training step. After some investigation, I realized that the problem was caused by large tables, which resulted in extremely long token sequences. To address this, I adjusted the max_seq_length parameter and filtered out samples that exceeded this limit. After experimentation, I found that using max_seq_length = 1024 allowed me to fine-tune the model reliably without triggering OOM errors. To filter out oversized tables, I wrote a simple data processing function that: Filters out samples whose HTML token length exceeds max_seq_length Automatically balances the number of training and test samples Uses streaming to avoid loading the entire dataset into memory (PubTabNet-HTML is quite large, around 10 GB on disk) . def load_process_filter_dataset(dataset, max_seq_length, num_train_images, num_test_images, system_message): global processor ds = load_dataset(dataset, split='train', streaming=True) max_html_tokens = max_seq_length - len(processor.tokenizer.tokenize(system_message)) num_total_needed = num_train_images + num_test_images filtered_samples = [] p_bar = tqdm(total=num_total_needed, desc=\"Filtering dataset samples\") for sample in ds: processed = process_and_filter_example(sample, max_html_tokens) if processed: filtered_samples.append(processed) p_bar.update(1) if len(filtered_samples) >= num_total_needed: break p_bar.close() # Convert to in-memory dataset ds_filtered = Dataset.from_list(filtered_samples) # Split into train/test ds_train = ds_filtered.select(range(num_train_images)) ds_test = ds_filtered.select(range(num_train_images, num_total_needed)) return ds_train, ds_test def process_and_filter_example(example, max_html_tokens): global processor extracted_table = extract_html_table(example['html_table']) token_count = len(processor.tokenizer.tokenize(extracted_table)) if token_count < max_html_tokens: example['html_table'] = extracted_table return example return None The final configuration included num_train_images=10000 and num_test_images=250 to compute the evaluation loss. Fine-Tuning Configuration For training, I used the Transformers SFTTrainer to fine-tune the model: # Training arguments training_args = SFTConfig( output_dir=f\"src/models/{model_name.split('/')[-1].replace('-', '_', 1).split('-')[0]}/checkpoints/{experiment_name}\", num_train_epochs=1, per_device_train_batch_size=1, per_device_eval_batch_size=1, gradient_accumulation_steps=gradient_accumulation_steps, max_seq_length=max_seq_length, warmup_steps=10, learning_rate=3e-4, weight_decay=0.01, logging_strategy=\"steps\", eval_strategy='steps', logging_steps=25, save_strategy=\"steps\", save_steps=50, save_total_limit=1, greater_is_better=False, load_best_model_at_end=True, optim=\"adamw_torch_fused\", bf16=True, push_to_hub=False, report_to=\"wandb\" if not debug else \"none\", remove_unused_columns=False, gradient_checkpointing=True, dataset_text_field=\"\", dataset_kwargs={\"skip_prepare_dataset\": True}, dataset_num_proc=8 ) # Setup Trainer trainer = SFTTrainer( model=model, args=training_args, train_dataset=train_dataset, eval_dataset=test_dataset, data_collator=collate_fn, peft_config=peft_config, processing_class=processor.tokenizer ) Key points: num_train_epochs=1 : The dataset is very large, and to run multiple experiments efficiently, I chose to train for only one full epoch while maximizing learning per sample and number of training samples. : The dataset is very large, and to run multiple experiments efficiently, I chose to train for only one full epoch while maximizing learning per sample and number of training samples. per_device_train_batch_size=1 : Larger batch sizes would not fit in GPU memory without significantly reducing max_seq_length — which would hurt performance on large tables. Keeping longer sequences was more important for this task. : Larger batch sizes would not fit in GPU memory without significantly reducing max_seq_length — which would hurt performance on large tables. Keeping longer sequences was more important for this task. gradient_accumulation_steps=8 : Used to effectively simulate a larger batch size and help stabilize the learning process, compensating for the small physical batch. This is the final value, but experimented with gradient_accumulation_steps=4 as well. : Used to effectively simulate a larger batch size and help stabilize the learning process, compensating for the small physical batch. This is the final value, but experimented with as well. optim=\"adamw_torch_fused\" and bf16=True : These settings leverage modern NVIDIA architectures (Ada Lovelace) to accelerate training and reduce memory usage — as recommended for this hardware. Evaluation Loss Workaround At the time of developing the project, there is a known issue in the Transformers + LoRA integration that causes an error when running evaluation with a validation dataset during training. Fortunately, a community-tested workaround is available (although not yet merged into the main branch), and I successfully used this fix in my experiments. Evaluation (Inference) Setup The evaluation dataset used for final scoring was completely independent from the eval_dataset used during training. It consists of 500 randomly selected images, none of which were included in either the train_dataset or the training eval_dataset . Once fine-tuning was complete, I used the best model checkpoint — selected based on the lowest evaluation loss — to run inference on these 500 samples. Initially, I attempted to perform inference by simply loading the LoRA/DoRA adapter on top of the base model. However, I found that inference with DoRA adapters is extremely slow when not merged into the model weights (as explained in the official PEFT docs). In fact, generating one test random sample took about 90 seconds in this configuration. To resolve this, I merged the adapter weights into the base model — which is the recommended practice — and after merging, inference speed improved dramatically: down to ~20 seconds for the same sample, making full evaluation runs much more practical. The reference models used for comparison with my fine-tuned models are: meta-llama/Llama-3.2–90B-Vision: Meta’s massive 90-billion parameter model — the main baseline I aimed to surpass through specialization and parameter-efficient fine-tuning of a much smaller VLM. model — the main baseline I aimed to surpass through specialization and parameter-efficient fine-tuning of a much smaller VLM. KennethTM/pix2struct-base-table2html: A much smaller model fine-tuned from Google’s pix2struct-base, highly specialized for exactly the same dataset I used in this project. Thanks to its smaller size, the developer(s) was able to train it for many more samples and over longer training runs — demonstrating the key advantage of using smaller, targeted models for specific tasks. These two baselines allowed me to benchmark both scaling-based performance (vs the 90B model) and specialization efficiency (vs the smaller, dedicated Pix2Struct model). Experiments & Results A total of 9 experiments were conducted, iteratively modifying one or two components at a time. The goal was to understand the effect of each change on model performance, gradually refining the setup to achieve the best possible HTML Similarity score compared to reference models. The experimental process was incremental: whenever a change improved the results, it was incorporated into the next round of experiments and continued exploring new variations. The experiments focused on adjusting the following components: Vision vs. Language Layers 1.1 lang_only 1.2 vision_only 1.3 lang_vision 2. Ground Truth Output Format 2.1 lang_table_only 3. Training Framework 3.1 lang_table_unsloth 3.2 vision_table_unsloth 4. Gradient Accumulation 4.1 lang_table_only_2 5. Prompt Format 5.1 lang_table_only_3 6. Gradient Accumulation & Dataset Size 6.1 lang_table_only_4 Both the evaluation loss and the HTML Similarity metric were used to assess model performance, and I found them to be well correlated — confirming that HTML Similarity is a good proxy for how well the model is learning the task. Before diving into the results of each experiment, let’s first look at GPU memory utilization during training, which is often the most critical factor in determining whether a model can be fine-tuned on consumer hardware. GPU Memory Utilization During Training | Image by author from wandb.ai As shown in the graph, GPU utilization remained stable throughout training — averaging around 75% VRAM usage, or roughly 12 GB on my GPU. Most of VRAM usage (~5.5 GB) is the frozen model weights. LoRA gradients + optimizer states take very little (<< 1 GB). Activations + overhead should fill the rest (~5–6 GB), which depends on batch_size and max_seq_length . First Run: lang_only This experiment uses the following initial components/parameters: These were the starting values for the first experiment. In subsequent runs, I modified many of them as I refined the approach. This first experiment focused only on tuning language layers, while training the model to predict the full raw HTML output — including everything inside and around the <table> tags. Since this was the first run, I’ll include the training loss curve here to illustrate how it behaves. For later experiments, I’ll omit this graph — as the behavior was similar across runs, with minor variations. In practice, evaluation loss is more useful for comparing performance across experiments. Training Loss | Image by author from wandb.ai One important note about the logging configuration: logging_steps=25 means that the training loss is only logged after every 25 steps, where each logged value is the average over gradient_accumulation_steps=4 . As a result, the largest drop in loss appears at the second log point — where most of the initial learning happens. After that, the model continues learning more gradually, with a slow decreasing trend, depending on the difficulty of the training samples. Now, let’s take a look at the evaluation loss: Validation Loss 1 | Image by author from wandb.ai Since we are evaluating on the same set of 250 validation samples, the evaluation loss curve gives us a more stable and meaningful view of model learning — and will serve as a baseline for comparisons across future runs. Here, we observe a clear and consistent downward trend throughout training. The initial loss starts close to 0.03, with a steady improvement as training progresses, eventually stabilizing just below 0.015. The smooth nature of this curve — compared to the more variable training loss — reflects the regular structure of the validation set and confirms that the model is generalizing well to unseen samples, even with a small batch size and a single epoch of training. Now, let’s compare the performance of this fine-tuned model against the reference models on the HTML Similarity metric: As we can see, this first experiment already delivers strong performance gains — improving the base Granite-Vision 2B model by a large margin (+0.18) and clearly outperforming LLaMA 90B Vision on this specialized task. Only Pix2Struct retains a slight lead at this stage. Second Run: vision_only There isn’t much to analyze in this run. I tested several variations that could potentially unblock learning in the vision layers — including drastically increasing the learning rate — but without success. While the base code suggests that fine-tuning vision layers should be possible, in practice I found it was not working in this setup. The following evaluation loss curve confirms that no learning occurred — the loss remained constant throughout training. To avoid wasting compute resources, I stopped the run early: Validation Loss 2 | Image by author from wandb.ai Additionally, training was noticeably faster in this run compared to the previous lang_only experiment — suggesting that the language layers (which contain the bulk of the model’s parameters) remained frozen, and only the small vision layers were being processed: Validation Samples per Second 1 | Image by author from wandb.ai Third Run: lang_vision At this point, it was clear that only language layers were being effectively trained. In this lang_vision run — where both language and vision layers were selected — I expected results similar to lang_only . Indeed, the evaluation loss curve confirmed this expectation, showing nearly identical behavior to lang_only : Validation Loss 3 | Image by author from wandb.ai Once this was clear, I again stopped training early to conserve resources, and proceeded to test new approaches. Fourth Run: lang_table_only This experiment modified the following component: The goal of this run was to train the model to predict only the table content, without any surrounding HTML wrapper code. This approach could help improve learning — by removing unnecessary tokens — and also align the training behavior more closely with Pix2Struct’s model. Additionally, by stripping out the wrapper HTML, the target sequences became shorter — which allowed longer and more complex tables to fit within the model’s context window. This change could also improve the model’s ability to generalize to larger or more detailed tables. Let’s look at the evaluation loss compared to the first run: Validation Loss 4 | Image by author from wandb.ai At first glance, the higher evaluation loss might seem counterintuitive. However, there’s a clear explanation: the wrapper HTML code is trivial for the model to learn — since it tends to be nearly identical across many training samples. These repetitive tokens reduce cross-entropy loss, artificially lowering the average loss in earlier runs. By removing them, the model now focuses entirely on the more challenging and variable table content — resulting in a higher but more meaningful loss value. Now, let’s see how this change impacted the HTML Similarity metric: In this first test, we observe no significant gain or degradation from using this new output format. It is possible that the model would need more epochs or larger training samples to fully adapt to this new format. Another idea is to update the prompt — so that from the very first step the model understands it should focus solely on table content, rather than having to infer this behavior through training alone. This will be explored in the next experiments. Fifth / Sixth Run: lang_table_unsloth , vision_table_unsloth In these experiments, I explored the following components: At this point, I discovered the promising Unsloth framework — which claims to offer 2x faster training with up to 70% lower memory usage. Of course, I wanted to test whether it could accelerate my workflow. My first idea was to leverage the improved memory handling to run longer sequences ( max_seq_length=2048 ), but in my case this quickly led to Out of Memory (OOM) errors — so I reverted to my previous configuration. The training speed improvements, however, were undeniable — almost 4x faster than my earlier runs: Validation Samples per Second 2 | Image by author from wandb.ai Unfortunately, this came at a clear cost to loss performance: Validation Loss 5 | Image by author from wandb.ai Given this noticeable drop in quality, I paused the experiment to investigate further — particularly to see if Unsloth would allow me to train vision layers, which is one of its advertised advantages. However, I encountered exactly the same behavior as with HuggingFace Transformers — no actual learning in vision layers. With these results in mind, I decided to set aside Unsloth for this projectand continue using HuggingFace Transformers, which had shown more reliable learning in earlier runs. Seventh Run: lang_table_only_2 Here are the new parameters for this run: Going back to the previous configuration, I wanted to analyze the impact of a larger virtual batch size (via higher gradient_accumulation_steps ). The results were promising — the evaluation loss became smoother and trended closer to the original lang_only run, even though the model was now predicting only the table content: Validation Loss 6 | Image by author from wandb.ai Based on this positive result, I decided to keep this gradient_accumulation_steps=8 setting for the final experiment. Evaluating this model on HTML Similarity resulted in a small but meaningful improvement — finally reaching parity with Pix2Struct: Naturally, the goal is not just to match Pix2Struct — but to surpass it. Two important levers remained to explore: dataset size and prompt. Eighth Run: lang_table_only_3 The updated parameters for this run were: I accidentally reverted gradient_accumulation_steps back to 4 in this run, only realizing it once the training was nearly complete — but this actually gave me an extra-chance to observe its effect on learning. The main goal here was to double the training size (to 10K images) and to test the updated, clearer prompt format. Unfortunately, a random CUDA error caused training to halt around 80% completion — but even so, the improvement was clear: Validation Loss 7 | Image by author from wandb.ai As expected, some smoothness was lost due to the smaller virtual batch size, but the new prompt proved very effective — noticeably boosting model learning. This set the stage perfectly for the final experiment, using this improved prompt, 10K training samples, and restoring gradient_accumulation_steps to 8. Final Run: lang_table_only_4 The final set of parameters are: The evaluation loss for this final run: Validation Loss 7 | Image by author from wandb.ai As expected, restoring the gradient_accumulation_steps to 8 smoothed the loss curve, reducing spikes and achieving slightly lower overall loss values. With a full epoch of training on 10K images, this became the best-performing model across all experiments. Now, let’s look at the final results on the HTML Similarity metric: Final HTML Similarity Results | Image by author from matplotlib The goal of this project was achieved — the fine-tuned model now surpasses both reference models on this task. Looking back at the original Granite-Vision 2B, the LoRA fine-tuning improved performance to 0.77, a +21 percentage point gain — all accomplished in under 8 hours on a consumer-grade GPU. Qualitative Results To better illustrate how much the model improved through fine-tuning, let’s look at a specific example: Image ID 618932. PubTabNet Evaluation Sample with ID 618932 | Image from PMC This table is particularly tricky — under the Kappa column there are sub-headers ( Present study and King et al. 2001 ). These complex layouts typically challenge generic VLMs, especially when they haven’t been exposed to enough similar examples during training. Models can usually understand these sub-headers and answer questions about them, but generating the full table structure in HTML often requires further prompt tuning and specialized fine-tuning. Let’s first see how a base, non-fine-tuned Granite-Vision 2B model performs on this task. Baseline: Raw Granite-Vision 2B The model can answer questions based on the table correctly: prompt='What is the Kappa value for the question \"Do you communicate with this power?\" in the present study?' res = predict(sample['image'], prompt=prompt) print(res) Out[1]: 74 However, when asked to generate the full HTML table, the model struggles: prompt = \"Convert table to HTML (<table> ... </table>)\" html = predict(sample['image'], prompt=prompt) html = '<table>' + html + '</table>' if '<table>' not in html else html display(HTML(html)) Out[2]: And the HTML Similarity metrics for this attempt: Style similarity: 1.0000 Structural similarity: 0.4091 Lev-Edit Distance: 0.1434 Final HTML Similarity Score: 0.3619 Fine-Tuned Model: lang_table_only_4 Now, let’s try the exact same test using the fine-tuned model: from src.models.granite_vision.transformers_library import LLM as granite_vision model = granite_vision( model_path, adapter='lang_table_only_4' ) Out[4]: Model loaded Adapter 'lang_table_only_4' loaded Adapter 'lang_table_only_4' merged Using cuda: NVIDIA GeForce RTX 4070 Ti SUPER And the same prediction prompt: prompt = \"Convert table to HTML (<table> ... </table>)\" html = model.predict(sample['image'], max_new_tokens=1024, query=prompt) display(HTML(html)) Out[5]: The fine-tuned model now produces an output that closely matches the ground truth, correctly capturing the table structure and sub-headers — something the base model struggled with. Final HTML Similarity metrics: Style similarity: 1.0000 Structural similarity: 0.9231 Lev-Edit Distance: 1.0000 Final HTML Similarity Score: 0.9615 This example shows a clear quantitative improvement as well: from a score of 0.36 to 0.96 on a complex table structure — confirming that fine-tuning on this specialized task dramatically boosts the model’s capability. Inference Speed One major advantage of using a smaller model — aside from the ability to fine-tune on consumer-grade hardware — is inference speed. Even if larger models offer competitive performance, latency and throughput remain key factors, especially in production settings. Let’s compare the inference speed of the different models: Inference SpeedM | Image by author from matplotlib As shown in the plot, Pix2Struct is by far the fastest model. For some use cases — such as batch-processing thousands of documents for table extraction — this speed advantage could translate into significant time savings and lower compute costs. However, the fine-tuned Granite-Vision 2B achieves a good balance when the amount of documents to process is not massive, having a superior accuracy on this specialized task and reasonably fast inference without the need for extremely large compute infrastructure. Conclusions This project demonstrated that with LoRA-based fine-tuning and a targeted task (table extraction → HTML), a small vision-language model (Granite-Vision 2B) can outperform much larger models — even Meta’s 90B LLaMA Vision — while requiring only a consumer GPU and less than a day of training. A few key takeaways: Small, specialized models matter — you don’t always need 70B+ models to solve specific problems with high accuracy. — you don’t always need 70B+ models to solve specific problems with high accuracy. Parameter-efficient fine-tuning (LoRA) is a game-changer: adapting large foundation models becomes accessible for most practitioners. is a game-changer: adapting large foundation models becomes accessible for most practitioners. Prompt design and training targets have a big influence — small changes (like switching to lang_table_only or refining the prompt) directly impacted performance. have a big influence — small changes (like switching to or refining the prompt) directly impacted performance. Having a custom metric (HTML Similarity) was critical to track meaningful progress beyond generic text-based metrics. was critical to track meaningful progress beyond generic text-based metrics. Smaller models not only train faster, but also infer faster — ideal for production pipelines with high volume. Finally — and maybe most importantly — this type of experimentation shows that you can move fast and iterate even with limited hardware. Fine-tuning powerful open models and adapting them to real-world tasks is not reserved to big labs anymore. I hope this encourages other AI engineers to experiment with small VLMs and fine-tuning techniques for their own projects and solutions — and to see that powerful results are possible even without massive compute budgets! What’s Next? There are definitely some interesting follow-up ideas that can be explored next: Prompt engineering refinements : Final tests (while writing this blog) showed that separating prompts into system message (defining behavior) and user message (providing task instructions) significantly improved the base model’s performance. Applying this strategy during fine-tuning could further enhance the model’s ability to consistently generate accurate HTML. This will be tested in upcoming experiments. : Final tests (while writing this blog) showed that separating prompts into system message (defining behavior) and user message (providing task instructions) significantly improved the base model’s performance. Applying this strategy during fine-tuning could further enhance the model’s ability to consistently generate accurate HTML. This will be tested in upcoming experiments. Training vision layers : Currently, only the language layers are fine-tuned, as training the vision layers through text-only loss proved ineffective. A more advanced approach could involve adding an auxiliary vision loss — for example, contrastive learning between vision outputs and HTML structure — to better adapt the vision backbone for table extraction tasks. : Currently, only the language layers are fine-tuned, as training the vision layers through text-only loss proved ineffective. A more advanced approach could involve adding an auxiliary vision loss — for example, contrastive learning between vision outputs and HTML structure — to better adapt the vision backbone for table extraction tasks. Improved generalization: The current model is fine-tuned on a single dataset. Expanding training to include more diverse document layouts, table styles, and noisy OCR scenarios could improve robustness and transferability to real-world data. Links If you liked this post, feel free to reach out or share your own experiments!",
         "en",
         "{'PER': ['Ada Lovelace', 'Despite', 'Eli Schwartz', 'Evaluating', 'However', 'Keeping', 'Sergio Paniego', 'Small', 'Smaller', 'This', 'accurately extracting', 'alongside precise textual content', 'artificially lowering the average loss in earlier runs', 'depending on the difficulty of the training samples', 'downward trend throughout training', 'eventually stabilizing', 'gradually refining the setup to achieve the best', 'however', 'inference speed improved dramatically', 'iteratively adjusting the weighting', 'noticeably boosting model learning', 'save_total_limit=1', 'since DoRA currently', 'some smoothness was lost due to the', 'weight_decay=0.01', 'whenever', 'with', 'yet small enough to be fine-tuned', 'you don’t always need'], 'MISC': ['.join(cell.get_text(strip', '2001', '90B Vision on this specialized task', 'Accumulation', 'Accumulation & Dataset', 'Additionally', 'Additionally, by stripping out the wrapper', 'After experimentation', 'After some investigation', 'After that', 'Another idea is to update the prompt — so that from the very first step the model understands', 'Applying this strategy during fine-tuning could further enhance the model’', 'Around the same time', 'As a result', 'As shown in the graph', 'Based', 'Before diving into the results of each experiment', 'By focusing the', 'By removing them', 'C): Based', 'CSS', 'Content similarity', 'Convert to in-memory dataset', 'Custom Metric', 'DOTALL', 'Dataset Setup During my initial experiments', 'Developing', 'Do you communicate with this power', 'DoRA', 'EditDistance', 'EditDistance from niteru', 'Eighth Run: lang_table_only_3 The updated parameters for this run were: I accidentally reverted gradient_accumulation_steps back to 4 in this run', 'Ensure', 'Evaluation', 'Evaluation Sample with ID', 'Expanding training to', 'Extract rows and join cells with spaces return', 'Extracts', 'Filters out samples whose', 'Final HTML', 'Final HTML Similarity Results | Image by author from matplotlib', 'Final tests', 'Finally — and maybe most importantly', 'Fine-Tuned Model', 'First Run', 'For some', 'Fortunately, I found', 'Fourth', 'GB', 'GPU and less than a day of training', 'Given this noticeable drop in quality', 'Going back to the previous configuration', 'Granite-Vision 2B', 'Ground Truth Output', 'HTML', 'Having', 'Here, we', 'I', 'I adjusted the max_seq_length', 'I chose to train for only one full epoch while maximizing learning per sample and number of training samples', 'I decided to keep this gradient_accumulation_steps=8 setting for the final', 'I decided to set', 'I didn’t want to experiment with this parameter', 'I discovered the promising', 'I encountered', 'I explored', 'I fine-tuned IBM’', 'I found that inference with DoRA adapters is extremely slow when not merged into the model weights', 'I found that using max_seq_length', 'I hope this', 'I kept running into out-of-memory', 'I paused the experiment to investigate further', 'I realized that the problem was', 'I stopped the run early: Validation Loss 2 | Image by author from wandb.ai Additionally', 'I used LoRA', 'I used the', 'I used the best model', 'I wanted to analyze the impact', 'I wanted to test whether it could accelerate my workflow', 'IBM and is based', 'Image ID 618932', 'In these experiments', 'In this post', 'In this project', 'Indeed', 'Inference', 'Inference Speed', 'Inference SpeedM', 'It consists of 500 randomly selected images', 'It is possible that the model would need more epochs or', 'It’', 'I’ll', 'I’ll omit this graph — as the behavior was', 'I’ll walk you through the motivation behind this work', 'J): The Jaccard similarity between the sets of content tokens', 'K', 'K training samples', 'Larger batch sizes would not fit in GPU memory without significantly', 'Larger batch sizes would not fit in GPU memory without significantly reducing max_seq_length — which would hurt performance on large tables', 'Let’', 'Let’s first see how', 'Let’s look at the evaluation loss', 'LoRA', 'LoRA Setup I used the following', 'LoRA is generally faster to train than approaches like QLoRA', 'Looking back at the original', 'LoraConfig', 'Low-Rank Adaptation', 'M is a weighted sum of these components:', 'Meta’', 'Model loaded', 'Models can usually understand these sub-headers and answer questions about them', 'Most of VRAM', 'Motivation While working on Retrieval-Augmented Generation', 'My first idea was to leverage the improved memory handling to run longer sequences', 'NVIDIA GeForce RTX 4070', 'NVIDIA architectures', 'None The final', 'Now', 'OOM', 'Of course', 'Once', 'Once this was clear', 'One', 'Only Pix2Struct', 'Open Access Subset', 'Out[2', 'PDFs', 'Pandas', 'Pix2Struct is by far the fastest model', 'Present study and King', 'Prompt Format', 'PubTabNet-HTML is', 'Python', 'Qualitative Results To better illustrate how much the model improved through fine', 'Raw Granite', 'S):', 'SFTConfig', 'SFTTrainer', 'Second Run: vision_only There isn’t much to analyze in this run', 'Setup LoRA', 'Setup The evaluation dataset used for final scoring was completely', 'Setup Trainer', 'Similarity', 'Since this was the first run', 'Split into', 'Structural similarity', 'Style similarity', 'Style similarity: 1.0000 Structural similarity', 'Style similarity: 1.0000 Structural similarity: 0.9231 Lev', 'T): Uses', 'Table Extraction', 'Thanks to its smaller size', 'The', 'The Task: Image to HTML', 'The dataset is very large', 'The experimental process was incremental', 'The final similarity', 'The following evaluation loss curve confirms that no learning', 'The goal of this run was to train the model to predict only the table content', 'The initial loss starts close to 0.03', 'The main goal here was to double the training size', 'The metric also', 'The results were promising — the evaluation loss became smoother and trended closer to the', 'The training speed improvements', 'There were no memory spikes during training', 'These were the starting values for the first experiment', 'This allowed me to update only a small number of parameters', 'This is the final', 'This led me to consider', 'This project demonstrated that with LoRA-based fine-tuning and a targeted task', 'This set the stage perfectly for the final', 'This success not only demonstrates the power of parameter', 'This will be explored in the next experiments', 'Ti Super', 'Ti Super — and yet', 'To address this', 'To avoid wasting compute resources', 'To better capture the quality of generated HTML', 'To resolve this', 'Token overlap similarity', 'Training Framework 3.1', 'Training Loss | Image by author from wandb.ai One', 'Training Setup To fine-tune', 'True', 'True :', 'True}', 'Two', 'Unsloth for this projectand', 'Unsloth framework', 'Used to effectively simulate', 'Uses', 'VRAM', 'VRAM after loading model', 'Validation Loss 3 | Image by author from wandb.ai', 'Validation Loss 4 | Image by author from wandb.ai At first glance', 'Validation Loss 5', 'Validation Loss 6 | Image by author from wandb.ai Based on this positive result', 'Validation Loss 7', 'Validation Loss 7 | Image by author from wandb.ai As expected, restoring the gradient_accumulation_steps to 8 smoothed the loss curve', 'Validation Samples per Second 2 | Image by author from wandb.ai Unfortunately, this came at a clear cost to loss performance', 'Vision vs', 'Vision — while requiring only', 'Weighted', 'What makes this project particularly exciting is that the fine-tuning was', 'What’s Next?', 'Whether you’re interested in vision', 'While the base', 'With', 'With these results in mind', \"adapter='lang_table_only_4'\", 'all without adding inference overhead', 'and I found them to be well correlated', 'and I successfully used this fix in my experiments', 'and finally', 'and only the small vision layers were being processed: Validation Samples per Second 1 | Image by author from wandb.ai Third Run: lang_vision At this point', 'and pairing each image with its', 'and stylistic aspects of HTML', 'and to run multiple experiments efficiently', 'and while IBM does not own the images', 'aside from the ability to fine-tune', 'batch size', 'batch size and help stabilize the learning process', 'but also infer faster — ideal for production pipelines with high volume', 'but generating the full', 'but the new prompt proved very effective', 'but without success', 'clear and', 'compensating for the small physical batch', 'confirming that', 'content of the tables', 'cookbook', 'cost and the need for GPUs with', 'dataset size and prompt', 'def load_process_filter_dataset(dataset', 'depending on the experiment', 'despite their effectiveness', 'distance between the extracted plain', 'epoch of training', 'even with a small batch size and', 'feel free to reach out or share your own experiments', 'finally reaching parity with Pix2Struct', 'gradient_accumulation_steps=8', 'greater_is_better=False', 'happened at the same training step', 'have a big influence', 'helping the model better resemble the capacity of full fine', 'html', 'html1', 'html2', 'html2):', 'html_similarity(html1', 'impacted performance', 'impacted the HTML Similarity metric: In this first test', 'including tools like', 'iteratively modifying one or two components at a time', 'lang_table_only_4 Now', 'latency and throughput remain', 'let’s first look at GPU memory utilization during training', 'let’s look at the final results on the HTML Similarity metric:', 'let’s see how this', 'let’s take', 'let’s try the exact same test using the fine-tuned model: from src.models.granite_vision.transformers_library', 'like switching to or refining the prompt', 'logging_steps=25 means that the training loss is only logged after every 25 steps', 'look at the evaluation loss: Validation Loss 1 | Image by author from wandb.ai Since we are evaluating on the same set of 250 validation samples', 'making downstream processing and analysis much more', 'many of them as I refined the approach', 'matching and', 'max_new_tokens=1024, query', 'max_seq_length', 'max_seq_length=2048', 'models such as Meta’', 'more fair and meaningful evaluation across models', 'none of which were', 'num_train_images=10000 and num_test_images=250 to compute the evaluation loss', 'only realizing it once the training was nearly complete — but', 'per_device_train_batch_size=1', \"prompt='What is the\", 'provided the license terms are followed', 'reducing spikes and achieving slightly lower overall loss values', 'since it tends to be nearly identical across many training samples', 'structural_similarity(html1', 'structured HTML', 'structured and widely', 'style_similarity(html1', 'targeted models for specific tasks', 'the HTML', 'the custom HTML similarity', 'the developer(s', 'the experiments and results', 'the higher evaluation loss might seem counterintuitive', 'the improvement was clear:', 'the key insights and lessons learned throughout the process', 'the metric provides', 'the model', 'the model and dataset', 'the model now focuses entirely on the more challenging and variable table', 'the model used only about half of the available', 'the training loss curve here to illustrate how it behaves', 'these approaches are often out of reach for many users', 'this became the best-performing model across all experiments', 'to tackle the challenge of converting images of tables into clean', 'txt2', 'unblock learning in the vision layers', 'under the', 'used for this project was', 'using this improved', 'weights into the base model — which is the recommended practice — and after merging', 'which allowed longer and more complex tables to fit within the model’', 'which is often the most critical factor in determining whether', 'which is one of its advertised', 'which resulted in extremely long token sequences', 'while training the model to predict the full raw', 'window'], 'LOC': ['BeautifulSoup(html', 'Dataset.from_list(filtered_samples', 'DoRA', 'Fortunately', 'I', 'Initially', 'Key', 'Llama-3.2–90B-Vision', 'Naturally', 'Out[1', 'Out[4', 'Out[5', 'Such', 'True', 'adapting', 'and Conv2d', 'and max_seq_length', 'dedicated Pix2Struct model', 'having a superior accuracy on this specialized task and reasonably fast inference without the need for extremely large compute infrastructure', 'including meta-llama', 'is', 'learning_rate=3e-4', 'len(txt2', 'load_best_model_at_end', \"loaded Adapter 'lang_table_only_4\", 'logging_steps=25', 'lora_alpha=32', 'lora_dropout=0.1', 'max(0', 'max_seq_length', 'peft_config=peft_config', 'save_steps=50', 'style_sim', 'us', 'warmup_steps=10', 'with'], 'ORG': ['Experiments & Results A total of 9 experiments were conducted', 'Fifth / Sixth Run', 'IBM', 'IGNORECASE', 'Language Layers', 'PEFT', 'PubTabNet', 'RAG', 'Seventh Run', 'The reference', 'These', 'These repetitive tokens reduce cross-entropy loss', 'VLM', 'filtered_samples.append(processed', 'generating one test random', 'let’', 'model’', 'optim=\"adamw_torch_fused', 'process_and_filter_example(sample', 'r=16', 'run', 'there’s']}",
         "[-0.06249945983290672, -0.03206057474017143, -0.024549342691898346, -0.04918352887034416, 0.04511061683297157, -0.02125849947333336, -0.05477359518408775, -0.015969332307577133, 0.007880017161369324, -0.06391793489456177, -0.05154821649193764, -0.06419242918491364, 0.044866327196359634, 0.04436288774013519, -0.00016011000843718648, -4.900270141661167e-05, 0.11170276254415512, 0.030920512974262238, -0.1016397476196289, 0.0038277446292340755, 0.08046336472034454, -0.039741504937410355, 0.0581379160284996, -0.04471360519528389, 0.01285726297646761, 0.09399497509002686, 0.019547220319509506, -0.03397224470973015, 0.05934428796172142, -0.05716091766953468, 0.004564451053738594, 0.051042672246694565, -0.007838769815862179, 0.025593573227524757, -0.03405385464429855, 0.04290442541241646, -0.026162920519709587, -0.02933543175458908, -0.0619564987719059, -0.0766335055232048, -0.03240067511796951, 0.025958281010389328, 0.011420837603509426, 0.05647384747862816, 0.10721816122531891, -0.059816379100084305, -0.032381657510995865, -0.037318769842386246, -0.05728929862380028, -0.03248981386423111, -0.13834820687770844, -0.07267630100250244, -0.06597035378217697, -0.030453190207481384, -0.04176458716392517, 0.031206181272864342, 0.006269651465117931, -0.12182958424091339, 0.041334521025419235, -0.022741122171282768, -0.00014420638035517186, -0.05330754816532135, 0.01609940454363823, 0.04482986032962799, -0.009446567855775356, -0.01662507653236389, 0.020052457228302956, -0.08446066081523895, 0.005047686398029327, -0.004818119574338198, -0.05815600976347923, 0.07066693156957626, 0.014471643604338169, 0.038070861250162125, -0.03874797001481056, 0.041463036090135574, 0.10054446756839752, -0.02763557620346546, 0.0634569376707077, -0.09313797205686569, 0.029357900843024254, -0.020481446757912636, 0.06812626868486404, 0.052004374563694, 0.1074347198009491, 0.015067539177834988, 0.04599960520863533, -0.004519239068031311, 0.048641353845596313, -0.07528603076934814, -0.006096056662499905, -0.029252218082547188, 0.03001723811030388, -0.0423857681453228, 0.0032857332844287157, -0.004123128019273281, 0.06275429576635361, -0.10152608901262283, -0.03569501265883446, 0.06987873464822769, 0.03086557425558567, -0.021813051775097847, 0.06646448373794556, -0.017738688737154007, 0.0062101660296320915, 0.018245816230773926, 0.04353947564959526, 0.10397253930568695, -0.0012473574606701732, -0.050140947103500366, 0.030435554683208466, 0.05607588589191437, -0.06710720807313919, 0.03439398109912872, -0.05910233408212662, -0.020267577841877937, -0.059513628482818604, -0.0813998207449913, 0.0669482871890068, 0.0452253557741642, -0.09772641956806183, -0.0404394306242466, -0.08345334231853485, -0.003366133663803339, -0.01629098691046238, -0.01760280877351761, -0.09267783164978027, 2.0943549586440455e-33, 0.0380389578640461, 0.07063570618629456, 0.0008704349165782332, -0.04519594460725784, 0.09291184693574905, 0.010984436608850956, -0.010306420736014843, 0.009072941727936268, -0.03003162145614624, 0.018256912007927895, -0.06563835591077805, 0.013481753878295422, -0.058961570262908936, 0.15096552670001984, 0.08958378434181213, -0.04503445327281952, -0.07081454992294312, 0.05506438389420509, -0.06973227113485336, 0.0313192754983902, 0.053460728377103806, 0.02714359574019909, 0.056685030460357666, -0.0018702541710808873, -0.036769650876522064, 0.11383509635925293, -0.008797457441687584, 0.001956990920007229, -0.0038745927158743143, 0.02192389778792858, 0.0070720212534070015, -0.023510290309786797, -0.022434398531913757, 0.019824713468551636, 0.024823499843478203, -0.049558863043785095, 0.00493358401581645, -0.07917802780866623, 0.023250969126820564, 0.005541653372347355, 0.015899313613772392, 0.14401164650917053, -0.02677290141582489, -0.10759182274341583, -0.07483172416687012, 0.016208555549383163, 0.06906525045633316, 0.039887163788080215, -0.09110194444656372, -0.0674627423286438, 0.014640336856245995, 0.029245125129818916, -0.09909723699092865, 0.00034454019623808563, -0.04040934890508652, -0.07592704147100449, 0.03526579961180687, 0.021718421950936317, 0.09861848503351212, 0.09417935460805893, 0.020570723339915276, -0.02406281791627407, 0.030786436051130295, 0.04212731122970581, 0.002066932152956724, -0.027429817244410515, 0.030122051015496254, 0.028513548895716667, -0.04425310343503952, -0.0012995842844247818, 0.013383627869188786, 0.00741538917645812, -0.02932370826601982, -0.07353967428207397, 0.032852258533239365, -0.06232431158423424, 0.026731686666607857, -0.08882475644350052, -0.03371424973011017, 0.04549401253461838, -0.04796820133924484, 0.04229419305920601, 0.022645972669124603, -0.0940716564655304, -0.045503877103328705, -0.02757927030324936, 0.046066299080848694, -0.08753372728824615, -0.06345409154891968, -0.026512475684285164, -0.017415732145309448, -0.02479184977710247, 0.009720013476908207, -0.07249636948108673, -0.00038446608232334256, -1.9137779041936258e-33, -0.028926203027367592, -0.004705585539340973, 0.028376245871186256, 0.11264369636774063, -0.0021506298799067736, -0.05646006762981415, 0.062202002853155136, 0.08532582968473434, 0.010766848921775818, -0.050177864730358124, 0.03166500851511955, 0.009524908848106861, -0.017713529989123344, -0.029616838321089745, 0.03497768193483353, -0.061635926365852356, 0.04396485909819603, -0.06652438640594482, -0.05556408688426018, 0.034410931169986725, 0.04022925719618797, 0.07428345829248428, -0.07284002006053925, 0.015257725492119789, -0.05215030536055565, 0.09177204221487045, 0.0020584610756486654, -0.03206183388829231, -0.02514966018497944, 0.03029763139784336, -0.018498657271265984, 0.025798480957746506, -0.0008355817408300936, 0.033428117632865906, 0.012720678932964802, 0.03311226889491081, 0.06533116847276688, -0.018773924559354782, 0.022827059030532837, 0.09789767861366272, 0.05782972276210785, 0.03691452741622925, -0.008926969952881336, 0.03817059472203255, -0.032066699117422104, 0.05050068721175194, -0.06632361561059952, -0.030927838757634163, 0.025460680946707726, -0.01930948905646801, -0.0026432934682816267, -0.03891665115952492, -0.0220927931368351, 0.03407289832830429, -0.03818270191550255, -0.10972456634044647, -0.08167186379432678, -0.009207441471517086, 0.029219701886177063, 0.008137919008731842, -0.03204656392335892, -0.005822055507451296, -0.03044014237821102, -0.07198735326528549, 0.01474089827388525, 0.03641066700220108, -0.058523375540971756, -0.003413656959310174, -0.018513794988393784, 0.06661135703325272, -0.019742172211408615, -0.0478891059756279, -0.017247216776013374, 0.022898541763424873, -0.0949336588382721, -0.011729289777576923, 0.010081841610372066, -0.019299764186143875, 0.08005600422620773, -0.04148847609758377, 0.015990445390343666, 0.005853623151779175, 0.04436584189534187, 0.04592633247375488, 0.08728854358196259, 0.05868421122431755, 0.04112080857157707, 0.03194548934698105, 0.006170917768031359, 0.06612802296876907, -0.06420432031154633, 0.027190733700990677, 0.012742237187922001, 0.10134842246770859, -0.01725161448121071, -5.249088275149916e-08, -0.05466994270682335, -0.015212434343993664, -0.050337642431259155, 0.07528248429298401, -0.04846281558275223, -0.0667000487446785, -0.018604042008519173, 0.022460203617811203, 0.04379464313387871, 0.0037600009236484766, 0.09156133979558945, -0.01826031319797039, -0.05488608032464981, 0.03628787770867348, 0.028696004301309586, 0.06795503944158554, 0.03260926157236099, 0.07155831903219223, 0.01563907228410244, 0.00036659432225860655, -0.033247556537389755, 0.043360624462366104, 0.028358276933431625, -0.01746031455695629, 0.042816050350666046, 0.01642521470785141, -0.08211435377597809, 0.03216558322310448, 0.09295922517776489, -0.024322981014847755, 0.038310181349515915, 0.004641804378479719, 0.04043269902467728, 0.011529496870934963, 0.05120569095015526, -0.02457575686275959, -0.08168913424015045, 0.006629478186368942, 0.038800884038209915, -0.04951044172048569, 0.11536628007888794, 0.03811600059270859, -0.02812276780605316, -0.003643480595201254, 0.07383929938077927, 0.021353639662265778, 0.01579212211072445, -0.12423979490995407, -0.07844268530607224, 0.048020727932453156, -0.023215141147375107, -0.01397490594536066, -0.057092927396297455, 0.044631827622652054, 0.009174439124763012, -0.04597804322838783, 0.025338945910334587, -0.03578487038612366, 0.07338149100542068, 0.0632443055510521, 0.058738935738801956, 0.00841602310538292, -0.03274339810013771, -0.018199127167463303]",
         "0.146"
        ],
        [
         "2",
         "586",
         "When LLMs Try to Reason: Experiments in Text and Vision-Based Abstraction",
         "Can large language models learn to reason abstractly from just a few examples? In this piece, I explore this question by testing both text-based (o3-mini) and image-capable (gpt-4.1) models on abstract grid transformation tasks. These experiments reveal the extent to which current models rely on pattern matching, procedural heuristics, and symbolic shortcuts rather than robust generalization. Even with multimodal inputs, reasoning often breaks down in the face of subtle abstraction. The results offer a window into the current capabilities and limitations of in-context meta-learning with LLMs. The post When LLMs Try to Reason: Experiments in Text and Vision-Based Abstraction appeared first on Towards Data Science .",
         "models learn to reason abstractly from just a few examples? In this piece, I explore this question by testing both text-based (o3-mini) and image-capable (gpt-4.1) models on abstract grid transformation tasks. These experiments reveal the extent to which current models rely on pattern matching, procedural heuristics, and symbolic shortcuts rather than robust generalization. Even with multimodal inputs, reasoning often breaks down in the face of subtle abstraction. The results offer a window into the current capabilities and limitations of in-context meta-learning with LLMs.\n\nIntroduction\n\nMeta-learning, the ability of a system to learn how to learn, has traditionally been explored through gradient-based optimization, memory-augmented networks, or explicit task embeddings. But with the rise of large language models (LLMs), particularly the o3 family with advanced reasoning capabilities, a new question emerges: can we use LLMs themselves as meta-learners in task-based domains like ARC? The Abstraction and Reasoning Corpus (ARC), introduced by François Chollet, is a benchmark explicitly designed to test broad generalization. It provides input-output transformation puzzles with minimal supervision, few examples per task, and often no shared surface-level structure across tasks. In other words: a playground for meta-learning. To get an understanding of typical abstraction and reasoning tasks, the reader can visit the ARC play page.\n\nExample game from the ARC website. From the demonstration grids, it is clear that the task for the test grid is to turn black areas into yellow wherever they are completely enclosed by green boundaries.\n\nData and Setup\n\nTo explore whether LLMs like o3-mini can perform meta-learning on abstract reasoning tasks, I used data from the ARC Prize 2025 Kaggle competition. The dataset repository can be found here (Apache 2.0 license). The dataset consists of input-output grid transformations that challenge models to infer abstract rules from just a few examples.\n\nEach task provides:\n\nA few training examples ( input and output 2D grids)\n\n( and 2D grids) A single test input grid for which the model must predict the corresponding output\n\nA second dataset provides the solution grids for each of the test input grids. Here’s a simplified example of the data format:\n\n# training examples - dictionary of dictionaries. # Here is an extracted task {'train': [{'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]},..., 'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}] } # example of solution to test input grid - dictionary of lists # Here is the extracted solution for the only test input grid above [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]]\n\nEach grid is a 2D array of integers from 0–9, representing colored pixels. Grids have varying sizes and a grid transformation may also carry a size change from the input to the output grid. To visualize the arrays, I used a custom colormap with matplotlib :\n\nfrom matplotlib import colors cmap = colors.ListedColormap([ '#8B00FF', # Violet '#4B0082', # Indigo '#0000FF', # Blue '#FFFF00', # Yellow '#00FF00', # Green '#FF7F00', # Orange '#FF0000', # Red '#964B00', # Golden '#000000', # Black '#FFFFFF', # White ]) norm = colors.Normalize(vmin=0, vmax=9) # Function to visualize an array def visualize_matrix(matrix, title='', cmap=cmap, norm=norm): plt.imshow(matrix, cmap=cmap, norm=norm) plt.title(title) plt.axis('off') # Remove axes plt.show()\n\nFor model interaction, I used OpenAI’s o3-mini model via LangChain. Later on, we will also use gpt-4.1 :\n\nfrom langchain_openai import ChatOpenAI import getpass import os # Prompt for a secret input openai_key = getpass.getpass(\"Enter your OpenAI API key: \") os.environ[\"OPENAI_API_KEY\"] = openai_key AGENT_MODEL = \"o3-mini\" # reasoning model, https://platform.openai.com/docs/models AGENT_LLM = ChatOpenAI(model=AGENT_MODEL) # AGENT_LLM = ChatOpenAI(model=AGENT_MODEL, reasoning_effort='low')\n\nTo handle LLM responses, especially when the model returns a predicted output grid as Python code inside triple backticks, I wrote a utility:\n\nimport re, ast def extract_python_code(response_string): match = re.search(r\"```python\\s*(.*?)```\", response_string, re.DOTALL) if match: return ast.literal_eval(match.group(1).strip()) return None\n\nThis setup allowed me to structure a full reasoning loop: prompt the model with few-shot examples, extract and apply a generated algorithm, assess its performance on new test inputs and finally use the assessment to improve the algorithm.\n\nTesting Reasoning with o3-mini\n\nTo evaluate whether LLMs can “meta-learn” on abstract reasoning tasks, I tested the <a href=\"https://platform.openai.com/docs/models\" rel=\"noreferrer noopener\" target=\"_blank\">o3-mini</a> model using a closed-loop reasoning setup inspired by how humans might approach few-shot tasks. For each ARC challenge, I provided the model with a handful of demonstration input-output grid pairs and asked it to derive a single reusable algorithm.\n\nI defined a sequence of prompts using LangChain’s ChatPromptTemplate to simulate reasoning, application, assessment, and refinement. The process mimics an inner training loop with limited supervision:\n\nPROMPT_REASON : The model is given training examples and asked to infer a general algorithm in pseudocode.\n\n: The model is given training examples and asked to infer a general algorithm in pseudocode. PROMPT_SOLVE : The generated algorithm is applied to new inputs (both training and test).\n\n: The generated algorithm is applied to new inputs (both training and test). PROMPT_ASSESS : When the algorithm fails, the model receives feedback comparing its predicted vs. expected outputs.\n\n: When the algorithm fails, the model receives feedback comparing its predicted vs. expected outputs. PROMPT_SUMMARIZE_FEEDBACK: The model summarizes cumulative feedback from failed attempts to iteratively refine its approach.\n\nfrom langchain_core.prompts import ChatPromptTemplate PROMPT_REASON = ChatPromptTemplate.from_messages( [ ( \"system\", \"You are an expert in solving abstract reasoning tasks. \" \"You will be given several demonstration input-output pairs of 2D arrays. \" \"Your goal is to develop a single algorithm that maps each input array to its corresponding output array.\n\n\n\n\" \"Each input and output is a 2-dimensional array of integers between 0 and 9. \" \"Solving the task involves:\n\n\" \"- Analyzing the demonstration pairs\n\n\" \"- Identifying abstract patterns or transformations\n\n\" \"- Formulating a general rule or algorithm that works across all examples\n\n\" \"- Producing pseudocode that implements the rule\n\n\n\n\" \"If prior attempts were made, you will also receive feedback summarizing what went wrong. \" \"Carefully use this feedback to improve your solution.\n\n\n\n\" \"Return only the updated algorithm as pseudocode. Do not describe or explain it.\n\n\n\n\" \"### Feedback (summary of previous attempts):\n\n{attempt_history}\n\n\n\n\" \"### Demonstration Pairs:\n\n{train_pairs}\n\n\" ), ( \"ai\", \"Answer:\" ) ] ) PROMPT_SOLVE = ChatPromptTemplate.from_messages( [ ( \"system\", \"You are an expert in abstract reasoning. \" \"Previously, you analyzed demonstration input-output pairs and developed an algorithm \" \"to transform input arrays into output arrays.\n\n\n\n\" \"Now, use that algorithm to generate an output array for a new, unseen input array.\n\n\n\n\" \"Only return the output array, formatted as valid Python code within a code block. \" \"For example:\n\n```python\n\n[[2, 3], [5, 6]]\n\n```\n\n\" \"### Developed algorithm:\n\n{reasoning_template}\n\n\n\n\" \"### New input array:\n\n{test_input}\n\n\" ), ( \"ai\", \"Answer:\" ) ] ) PROMPT_ASSESS = ChatPromptTemplate.from_messages( [ ( \"system\", \"You are an expert in abstract reasoning. \" \"A solution array was generated by applying the algorithm to the input array. \" \"Compare the generated solution to the actual target output. \" \"Analyze why the two arrays differ, and provide **clear and concise feedback** on how to improve the algorithm.\n\n\n\n\" \"Only return your feedback-do not repeat the arrays or algorithm.\n\n\n\n\" \"### Algorithm:\n\n{reasoning_template}\n\n\n\n\" \"### Input array:\n\n{test_input}\n\n\n\n\" \"### Solution array (generated by algorithm):\n\n{solved_test_output}\n\n\n\n\" \"### Target output array:\n\n{test_output}\n\n\" ), ( \"ai\", \"Answer:\" ) ] ) PROMPT_SUMMARIZE_FEEDBACK = ChatPromptTemplate.from_messages( [ ( \"system\", \"You are an expert in summarizing feedback on algorithm development. \" \"You will be given a history of past attempts, each containing an algorithm and feedback about its performance.\n\n\n\n\" \"Your goal is to produce a **concise summary** of the most important lessons learned-\" \"focusing on how the algorithm should be improved and what mistakes should be avoided in future versions.\n\n\n\n\" \"Return only the feedback summary. Do not repeat the original attempts or feedback.\n\n\n\n\" \"### Attempt History:\n\n{attempt_history}\n\n\" ), ( \"ai\", \"Answer:\" ) ] )\n\nThese prompts are linked into a simple LangChain pipeline:\n\nreasoning_chain = PROMPT_REASON | AGENT_LLM solve_chain = PROMPT_SOLVE | AGENT_LLM assess_chain = PROMPT_ASSESS | AGENT_LLM summarize_feedback_chain = PROMPT_SUMMARIZE_FEEDBACK | AGENT_LLM\n\nFor each ARC challenge:\n\nThe model receives the demonstration pairs and prior feedback;\n\nThe model generates a new algorithm in pseudocode ( reasoning_template );\n\n); The algorithm is tested on all the demonstrations;\n\nIf it fails, the model: receives detailed feedback on mismatched predictions; summarizes mistakes across attempts; refines the next version of the algorithm;\n\nOnce the model gets all demonstrations correct, I test it on the unseen test input.\n\nThis process repeats for up to a max number of attempts per challenge. A successful algorithm generalizes across the provided examples and applies correctly to the withheld test case. This setup tests whether the model can extract abstract patterns, improve its reasoning over time, and generalize from very few examples.\n\nreasoning_templates = {} for i, id in enumerate(id_train_challenges): print(f\"Training on challenge {i} ID: {id}\") train_pairs = train_challenges[id]['train'] test_input = train_challenges[id]['test'][0]['input'] # only pick the first test input test_output = train_sols[id][0] # only pick the first test output train_pairs_str = '' for i, train_pair in enumerate(train_pairs): train_pairs_str += f\"Demonstration pair {i+1}:\n\ninput grid: {train_pair['input']}\n\noutput grid: {train_pair['output']}\n\n\" train_pairs_str = train_pairs_str.strip() # keep trying until you figure out how to solve the challenge right_wrong = \"incorrect\" # Start with an empty reasoning template, which will be refined over time reasoning_template = '' k = 1 max_attempts = 5 attempt_history = [] attempt_history_summary = '' while right_wrong == \"incorrect\": print(f\"Attempt {k} to solve the challenge...\") # Build the reasoning message with the current reasoning template and attempt history # This message will be used to generate a new reasoning template reason_message = { \"train_pairs\": train_pairs_str, \"attempt_history\": attempt_history_summary, } res = reasoning_chain.invoke(reason_message) reasoning_template = res.content # Assess reasoning template wrong_pairs = [] for train_pair in train_pairs: demo_input = train_pair['input'] demo_output = train_pair['output'] # Test the reasoning template on the demonstration pair test_message = { \"test_input\": demo_input, \"reasoning_template\": reasoning_template, } res = solve_chain.invoke(test_message) solved_demo_output = extract_python_code(res.content) # Compare the output with the demonstration output if solved_demo_output != demo_output: wrong_pairs.append((demo_input, demo_output, solved_demo_output)) if len(wrong_pairs) > 0: right_wrong = 'incorrect' print(f\"Reasoning template failed on {len(wrong_pairs)} demonstration pairs.\") if k >= max_attempts: print(f\"Max attempts reached ({max_attempts}). Stopping for challenge {id}.\") reasoning_templates[id] = '' break print(\"Assessing the reasoning template...\") assessment_res = f'Algorithm failed on {len(wrong_pairs)} demonstration pairs. Here is the feedback:\n\n' for demo_input, demo_output, solved_demo_output in wrong_pairs: assess_chain_message = { \"reasoning_template\": reasoning_template, \"test_input\": demo_input, \"solved_test_output\": solved_demo_output, \"test_output\": demo_output, } res = assess_chain.invoke(assess_chain_message) assessment_res += f\" - From input {demo_input} to output {demo_output}, your solution was {solved_demo_output}: {res.content.strip()}\n\n\" attempt_history.append({ \"attempt\": k, \"reasoning_template\": reasoning_template, \"feedback\": assessment_res }) summary_message = { \"attempt_history\": attempt_history, } summary_res = summarize_feedback_chain.invoke(summary_message) attempt_history_summary = summary_res.content.strip() else: print(\"Solution is correct!\") right_wrong = \"correct\" reasoning_templates[id] = reasoning_template # test it against the test input/ output .... but do not give feedback (this is supposed to be unknown) test_message = { \"test_input\": test_input, \"reasoning_template\": reasoning_template, } res = solve_chain.invoke(test_message) solved_test_output = extract_python_code(res.content) if test_output != solved_test_output: print(f\"Test output does not match the true output for challenge {id}.\") else: print(f\"Test output matches the true output for challenge {id}.\") #visualize_matrix(test_input, \"Input grid\") #visualize_matrix(test_output, \"True output\") #visualize_matrix(solved_test_output, \"Test Output\") print(\"-\" * 40) # Separator between entries k += 1\n\nResults: When Reasoning Works\n\nIn some cases, o3-mini was able to correctly infer a generalizable algorithm from just a few input-output demonstrations. One such example involved generating a patterned tiling based on a small 2×2 input grid.\n\nAfter just one attempt, the model converged on the following pseudocode:\n\nBEGIN Let input be a 2x2 grid, where: input[0] = [a, b] input[1] = [c, d] Initialize output as an empty list. FOR each row index r from 0 to 5 DO: Let original_row ← input[r mod 2] IF (FLOOR(r / 2)) mod 2 = 1 THEN Let base_row ← REVERSE(original_row) ELSE Let base_row ← original_row ENDIF Initialize new_row as an empty list. FOR repeat from 1 to 3 DO: Append all elements of base_row to new_row. ENDFOR Append new_row to output. ENDFOR RETURN output END\n\nHere is the expected solution (true output) and the solution from the model pseudocode (test output).\n\nTrue output grid (Image by author).\n\nTest output grid from the pseudocode (Image by author).\n\nThis algorithm demonstrates several notable reasoning capabilities:\n\nPattern abstraction: the model inferred a repeating tiling pattern from limited data;\n\nModulo logic: it introduced modulo-based indexing ( r mod 2 and (r // 2) mod 2 ) to alternate row behavior, mimicking visual mirroring;\n\nand ) to alternate row behavior, mimicking visual mirroring; Grid construction: the solution scales up the 2×2 input into a larger 6×6 grid through repeated copying and reversal;\n\nThe fact that the model discovered this structure without hardcoded rules suggests it was engaging in a form of algorithm synthesis, guided by few-shot abstraction.\n\nHere is another successful example.\n\nExample grids and test input grid (image by author).\n\nAgain, after just one attempt, the model converged on the following pseudocode:\n\nBEGIN Let N = 3 Create output as a 2D array of size (N×N) × (N×N), filled with 0 FOR each row r from 0 to N–1: FOR each column c from 0 to N–1: IF input[r][c] ≠ 0 THEN FOR each i from 0 to N–1: FOR each j from 0 to N–1: Set output[(r * N) + i][(c * N) + j] = input[i][j] RETURN output END\n\nHere is the expected solution and the solution from the model pseudocode.\n\nTrue output grid (image by author).\n\nTest output grid from the pseudocode (image by author).\n\nThis algorithm effectively tiles the full input grid into the output grid at every position where the input cell is non-zero. The tiling is aligned such that each copy of the original grid is placed at an offset determined by (r * N, c * N) — the scaled-up coordinates of the non-zero input cell.\n\nWhat’s impressive here is that the model:\n\nLearns conditional placement. It only pastes the input where the input value is non-zero;\n\nUses coordinate arithmetic to scale placement locations, showing spatial understanding;\n\nTreats the input as both control logic and content, combining layout detection with repetition.\n\n\n\nWhen Text-Based Reasoning Isn’t Enough\n\nIn the task below, the model was given a small number of demonstration input-output grid pairs and asked to infer the transformation rule.\n\nExample grids and test input grid (image by author).\n\nThe text-based model ( o3-mini ) produced a detailed pseudocode solution, structured, plausible, and internally consistent:\n\nBEGIN Let original ← input grid Let output ← deep copy of original Let R ← number of rows in original Let C ← number of columns in original // Compute ring index for every cell that is part of a non-zero region. // A cell's ring index is defined as: // - 0 if the cell is on the boundary of the grid OR if at least one of its 4-neighbors is 0 // - Otherwise, 1 + min(ring index of its 4-neighbors) Create grid ring of size R × C, filled with −1 For each cell (r, c) in original: If original[r][c] ≠ 0 then If r = 0 OR c = 0 OR r = R−1 OR c = C−1 then ring[r][c] ← 0 Else if any 4-neighbor (up, down, left, right) of (r, c) has value 0 then ring[r][c] ← 0 changed ← true While changed is true: Set changed ← false For each cell (r, c) in original such that original[r][c] ≠ 0 and (ring[r][c] < 0 or not finalized): Let candidates ← list of ring indices from any 4-neighbor (r′, c′) with a non-negative ring value If candidates is non-empty then newRing ← min(candidates) + 1 If ring[r][c] < 0 OR newRing < ring[r][c] then ring[r][c] ← newRing changed ← true // Process propagation from outer ring inward. // For each cell with ring index ≥ 1, update its value based on a neighbor with ring index one less. // Selection is deterministic: \"up, left, down, right\" Let maxRing ← maximum value in ring For layer from 1 to maxRing: For each cell (r, c) such that ring[r][c] = layer: For direction in [(−1,0), (0,−1), (1,0), (0,1)]: nr ← r + direction.row nc ← c + direction.col If (nr, nc) is in bounds AND ring[nr][nc] = layer − 1 then Let base ← output[nr][nc] If base = 2 then newValue ← 8 Else if base mod 2 = 0 then newValue ← base + 2 Else // base is odd newValue ← base + 1 output[r][c] ← newValue Break out of neighbor loop Return output END\n\nAt first glance, this looks like a sophisticated strategy: compute a ring index for each non-zero region, then diffuse values inward using deterministic rules. It even includes update logic:\n\nIf the “base” cell is 2 → assign 8\n\nIf base is even → add 2\n\nIf base is odd → add 1\n\nBut this entire algorithm, however coherent, is misguided. It completely fails to match the true underlying transformation shown in the demonstrations.\n\nExpected test output grid (image by author).\n\nTest output grid from the pseudocode (image by author).\n\nInstead of reasoning about blue-bordered regions and their nested structure, the model generated a generic flood-fill algorithm based on distance from edge and adjacency to zeros. Even the feedback keeps refining the procedural approach identified earlier:\n\n['Key lessons are to: • Precisely compute the ring index so that only', 'true boundary (or external zero) cells get index 0, ensuring that', 'inner cells receive higher indices for proper propagation. • Use a', 'reliable, consistent method for selecting the \"base\" value for', 'updates-ideally by considering all adjacent lower-ring cells or using', 'a deterministic order-and use an immutable copy of the original grid', 'for these lookups. • Apply the parity‐based update rules correctly so', 'that cells with ring index ≥ 1 get the specified value increments', '(especially the special case when the base is 2) rather than remaining', 'unchanged. • Ensure that the update logic cascades inward, allowing', 'inner cells to correctly inherit and build upon values from outer', 'rings.']\n\nSo what went wrong?\n\nTopological, not visual. The model focused on connectivity and edge proximity, ignoring the visually defined regions.\n\nProcedural, not inferential. The logic was rigid and hand-crafted, not derived from patterns in the examples.\n\nDemonstration-agnostic. There’s no sign the model meaningfully incorporated the few-shot examples. It likely defaulted to a familiar pattern — spatial growth using layers.\n\nThis isn’t surprising. Text-only LLMs have no visual grounding. They tokenize the grid as symbolic input — rows of digits, not enclosed figures or nested patterns. As a result, their inductive biases lean toward symbolic or graph-like algorithms, not perceptual abstractions.\n\nIn this case, the model fell into a common trap: generating something plausible-sounding but wrong. It produced a spatial propagation scheme that might work for a diffusion task but not the one at hand. This highlights a key weakness in text-based few-shot prompting for abstract visual reasoning: the model’s “reasoning” is disconnected from perceptual understanding. It invents algorithms based on internal priors, not external cues.\n\nWhen Reasoning Fails: Also Image Models Aren’t Magic\n\nTo improve generalization, I transitioned from purely text-based reasoning to image-based prompting, leveraging GPT-4.1’s multimodal capabilities through LangChain. This setup encoded input-output grid examples as base64 images, which were presented alongside a natural language prompt describing the task.\n\nfrom langchain_core.messages import HumanMessage import io import base64 AGENT_MODEL = \"gpt-4.1\" # Prompt for image based reasoning PROMPT_REASON_IMG = \"\"\"You are an expert at solving abstract reasoning tasks. These are unique reasoning tasks with limited examples. You are given demonstration input-output 2D grids. The colormap used is as follows: {{ 'Violet': 0, 'Indigo': 1, 'Blue': 2, 'Yellow': 3, 'Green': 4, 'Orange': 5, 'Red': 6, 'Golden': 7, 'Black': 8, 'White': 9 }} Your goal is to develop a single algorithm that maps each input grid to its corresponding output grid. A successful solution involves: - Analyzing the demonstration examples carefully - Identifying underlying visual or spatial patterns - Formulating a general transformation rule - Translating this rule into clear pseudocode If this is not your first attempt, a summary of previous feedback is also provided. Review it carefully and incorporate it to improve your solution. Test your algorithm against the demonstrations to ensure it works. Return **only the algorithm pseudocode**, formatted as plain text. Do not explain it or add extra commentary. \"\"\" # If your array is 10x10 and you want each cell to be 20x20 pixels (cell_px), the image will be 200x200 pixels. # Convert matrix into image def visualize_grid_fig(matrix, cmap=cmap, norm=norm, cell_px=20, show=False): if type(matrix) is not np.ndarray: matrix = np.array(matrix) h, w = matrix.shape[:2] figsize = (w * cell_px / 100, h * cell_px / 100) # inches fig, ax = plt.subplots(figsize=figsize) ax.imshow(matrix, cmap=cmap, norm=norm) ax.axis('off') if show: plt.show() else: plt.close(fig) return fig # encode image for model def fig_to_base64(fig, dpi=100): buf = io.BytesIO() fig.savefig(buf, format='png', dpi=dpi, bbox_inches='tight') buf.seek(0) img_base64 = base64.b64encode(buf.read()).decode('utf-8') buf.close() return img_base64 # In the loop replace reasoning code with this # reasoning with images reason_message = [{\"type\": \"text\", \"text\": PROMPT_REASON_IMG}] for i, example in enumerate(train_pairs): #fig_in = visualize_grid_fig(example['input'], cmap, norm) #fig_out = visualize_grid_fig(example['output'], cmap, norm) fig_in = visualize_grid_fig(example['input'], ) fig_out = visualize_grid_fig(example['output'], ) fig_in = fig_to_base64(fig_in) fig_out = fig_to_base64(fig_out) reason_message.append({\"type\": \"text\", \"text\": f\"### Input grid {i+1}:\"}) reason_message.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{fig_in}\"}}) reason_message.append({\"type\": \"text\", \"text\": f\"### Output grid {i+1}:\"}) reason_message.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{fig_out}\"}}) reason_message.append({\"type\": \"text\", \"text\": f\"### Feedback (summary of previous attempts): {attempt_history_summary}\"}) reason_message = HumanMessage(content=reason_message) res = AGENT_LLM.invoke([reason_message]) reasoning_template = res.content\n\nThe resulting pseudocode marked a clear step forward in expressiveness. The model was able to:\n\nDetect blue-bordered squares using visual features rather than purely symbolic structure;\n\nApply rules based on square size and nesting depth to infer interior fill colors;\n\nSort identified squares by size before filling, effectively avoiding overwrite conflicts.\n\nHere’s the generated pseudocode:\n\n1. Let grid be the input 2D array. 2. Create output_grid as a copy of grid. 3. Identify all blue-bordered squares in the grid: a. For each possible top-left corner (i, j): i. For each possible square size s (s ≥ 3, up to min(grid height, grid width)): - Check if the square of size s starting at (i, j) is fully within bounds. - Check if all *border* cells of this square are Blue (value = 2). - Check that the *interior* cells (not on the border) do not contain any Blue (2). - If all conditions are met, record the square as (i, j, s). 4. Sort the list of detected blue-bordered squares by size in ascending order (smallest first). 5. For each detected square (i, j, s), in sorted order: a. Determine the fill color: - If the square is the smallest (no other blue-bordered square is fully inside it), set fill color = Black (8). - If the square is the largest (no other blue-bordered square fully contains it), fill color = - If there are exactly 2 blue-bordered squares, set fill color = Green (4). - If there are three blue-bordered squares in the grid, fill color = Yellow (3). - If the square is nested (not smallest or largest), fill color = Black (8). - (More complex rules may generalize beyond these based on demonstrations.) b. Fill the interior of the square: For each cell (x, y) strictly inside the square (i+1 ≤ x < i+s−1) and (j+1 ≤ y < j+s−1): - If output_grid[x][y] is not Blue (2), set it to the chosen fill color. 6. Return output_grid. Special notes: - Never overwrite Blue (2) border pixels. - When filling, later (larger) squares overwrite earlier (smaller) fills in overlapping regions. - Only process valid blue-bordered squares (minimum size 3x3, complete border). - If there are multiple disjoint blue-bordered squares, treat each independently for fill color assignment as above matching the demonstration logic.\n\nThe model clearly exhibits structured reasoning. It develops an internal representation of nested geometric forms and attempts to apply rule-based transformations derived from examples.\n\nTest output grid from image-based reasoning model pseudocode (image by author).\n\nHowever, despite these advances, the model still fails to generalize reliably. In novel configurations, it mis-assigns fill colors, falling back on brittle heuristics like size-based priority or rigid nesting assumptions. For instance, it might assume the largest square is always filled with yellow, even when that logic no longer holds in a new context. This failure reveals a deeper limitation: even with image input, the model does not “see” in the human sense. It doesn’t build a holistic perceptual representation of spatial relationships. Instead, it converts the image into symbolic patterns and applies deterministic procedures like flood-fill, sorting, or positional indexing.\n\nIn practice, this means the model reasons from internal abstractions, not perceptual grounding. It infers that “smaller squares get black,” or “fill based on size rank,” without fully understanding why those assignments occurred in the demonstrations. As a result, any deviation from the expected layout can cause it to misfire.\n\nThis suggests that while multimodal prompting extends the expressive range of the model, it doesn’t yet provide the kind of flexible, generalizable visual reasoning that humans display. These tasks may ultimately require stronger forms of program induction, meta-learning, or hybrid systems that integrate perceptual grouping with learned rules.\n\nConclusions\n\nIn this study, I explored whether large language models — both text-based and multimodal — can perform meta-learning from examples on abstract reasoning tasks. Specifically, I focused on a class of problems from the ARC dataset, where solutions require identifying visual patterns, learning transformations, and generalizing them to novel test inputs.\n\nThrough direct prompting experiments, I found that:\n\nText-based models (e.g., o3-mini ) often hallucinate plausible algorithms that are topologically or procedurally sound but entirely disconnected from the task’s visual logic . These models rely on symbolic reasoning over tokenized grids, and default to familiar heuristics like flood-fill, ring propagation, or rule-based updates, regardless of the examples provided.\n\n(e.g., ) often hallucinate plausible algorithms that are topologically or procedurally sound but entirely . These models rely on symbolic reasoning over tokenized grids, and default to familiar heuristics like flood-fill, ring propagation, or rule-based updates, regardless of the examples provided. Multimodal models (e.g., GPT-4 with vision) showed a clear improvement in pattern detection and relational reasoning. They successfully identified blue-bordered regions and adapted behaviors based on relative size or nesting. However, their generalization remained fragile: they still applied brittle rules, such as fixed size-based assignments, and failed in novel layouts that deviated from the demonstrations.\n\nThese findings suggest that, even with visual input, current LLMs do not “see” as humans do. They process images symbolically, not perceptually. Their reasoning is driven by internally constructed rules, not a flexible, visual understanding of shapes, hierarchy, or affordance.\n\nThe limitations I observed reinforce a central tension: few-shot prompting alone, even with images, is not sufficient for robust abstraction. True generalization likely requires:\n\nProgram induction: inferring reusable, structured transformations from examples;\n\nPerceptual grounding: developing architectures that parse and manipulate visual scenes compositionally;\n\nMeta-learning architectures: building models that adapt their reasoning strategies dynamically rather than applying pre-learned heuristics;\n\nToday’s LLMs are astonishing in their breadth, but they’re still guessing based on priors, not learning to learn in the human sense. They lack a strong inductive bias for abstraction and transformation. ARC-style tasks expose this gap clearly: success requires more than pattern recognition, it requires reasoning from examples in a structured, compositional way. These results are not discouraging, rather clarifying. We now know where the ceiling is. And the next generation of models, those with hybrid architectures, persistent memory, and explicit meta-learning capabilities might finally break through it.",
         "2025-07-22T19:35:25",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/when-llms-try-to-reason-experiments-in-text-and-vision-based-abstraction/",
         "2025-07-26T06:23:31.390578",
         "models learn to reason abstractly from just a few examples? In this piece, I explore this question by testing both text-based (o3-mini) and image-capable (gpt-4.1) models on abstract grid transformation tasks. These experiments reveal the extent to which current models rely on pattern matching, procedural heuristics, and symbolic shortcuts rather than robust generalization. Even with multimodal inputs, reasoning often breaks down in the face of subtle abstraction. The results offer a window into the current capabilities and limitations of in-context meta-learning with LLMs. Introduction Meta-learning, the ability of a system to learn how to learn, has traditionally been explored through gradient-based optimization, memory-augmented networks, or explicit task embeddings. But with the rise of large language models (LLMs), particularly the o3 family with advanced reasoning capabilities, a new question emerges: can we use LLMs themselves as meta-learners in task-based domains like ARC? The Abstraction and Reasoning Corpus (ARC), introduced by François Chollet, is a benchmark explicitly designed to test broad generalization. It provides input-output transformation puzzles with minimal supervision, few examples per task, and often no shared surface-level structure across tasks. In other words: a playground for meta-learning. To get an understanding of typical abstraction and reasoning tasks, the reader can visit the ARC play page. Example game from the ARC website. From the demonstration grids, it is clear that the task for the test grid is to turn black areas into yellow wherever they are completely enclosed by green boundaries. Data and Setup To explore whether LLMs like o3-mini can perform meta-learning on abstract reasoning tasks, I used data from the ARC Prize 2025 Kaggle competition. The dataset repository can be found here (Apache 2.0 license). The dataset consists of input-output grid transformations that challenge models to infer abstract rules from just a few examples. Each task provides: A few training examples ( input and output 2D grids) ( and 2D grids) A single test input grid for which the model must predict the corresponding output A second dataset provides the solution grids for each of the test input grids. Here’s a simplified example of the data format: # training examples - dictionary of dictionaries. # Here is an extracted task {'train': [{'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]},..., 'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}] } # example of solution to test input grid - dictionary of lists # Here is the extracted solution for the only test input grid above [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]] Each grid is a 2D array of integers from 0–9, representing colored pixels. Grids have varying sizes and a grid transformation may also carry a size change from the input to the output grid. To visualize the arrays, I used a custom colormap with matplotlib : from matplotlib import colors cmap = colors.ListedColormap([ '#8B00FF', # Violet '#4B0082', # Indigo '#0000FF', # Blue '#FFFF00', # Yellow '#00FF00', # Green '#FF7F00', # Orange '#FF0000', # Red '#964B00', # Golden '#000000', # Black '#FFFFFF', # White ]) norm = colors.Normalize(vmin=0, vmax=9) # Function to visualize an array def visualize_matrix(matrix, title='', cmap=cmap, norm=norm): plt.imshow(matrix, cmap=cmap, norm=norm) plt.title(title) plt.axis('off') # Remove axes plt.show() For model interaction, I used OpenAI’s o3-mini model via LangChain. Later on, we will also use gpt-4.1 : from langchain_openai import ChatOpenAI import getpass import os # Prompt for a secret input openai_key = getpass.getpass(\"Enter your OpenAI API key: \") os.environ[\"OPENAI_API_KEY\"] = openai_key AGENT_MODEL = \"o3-mini\" # reasoning model, https://platform.openai.com/docs/models AGENT_LLM = ChatOpenAI(model=AGENT_MODEL) # AGENT_LLM = ChatOpenAI(model=AGENT_MODEL, reasoning_effort='low') To handle LLM responses, especially when the model returns a predicted output grid as Python code inside triple backticks, I wrote a utility: import re, ast def extract_python_code(response_string): match = re.search(r\"```python\\s*(.*?)```\", response_string, re.DOTALL) if match: return ast.literal_eval(match.group(1).strip()) return None This setup allowed me to structure a full reasoning loop: prompt the model with few-shot examples, extract and apply a generated algorithm, assess its performance on new test inputs and finally use the assessment to improve the algorithm. Testing Reasoning with o3-mini To evaluate whether LLMs can “meta-learn” on abstract reasoning tasks, I tested the <a href=\"https://platform.openai.com/docs/models\" rel=\"noreferrer noopener\" target=\"_blank\">o3-mini</a> model using a closed-loop reasoning setup inspired by how humans might approach few-shot tasks. For each ARC challenge, I provided the model with a handful of demonstration input-output grid pairs and asked it to derive a single reusable algorithm. I defined a sequence of prompts using LangChain’s ChatPromptTemplate to simulate reasoning, application, assessment, and refinement. The process mimics an inner training loop with limited supervision: PROMPT_REASON : The model is given training examples and asked to infer a general algorithm in pseudocode. : The model is given training examples and asked to infer a general algorithm in pseudocode. PROMPT_SOLVE : The generated algorithm is applied to new inputs (both training and test). : The generated algorithm is applied to new inputs (both training and test). PROMPT_ASSESS : When the algorithm fails, the model receives feedback comparing its predicted vs. expected outputs. : When the algorithm fails, the model receives feedback comparing its predicted vs. expected outputs. PROMPT_SUMMARIZE_FEEDBACK: The model summarizes cumulative feedback from failed attempts to iteratively refine its approach. from langchain_core.prompts import ChatPromptTemplate PROMPT_REASON = ChatPromptTemplate.from_messages( [ ( \"system\", \"You are an expert in solving abstract reasoning tasks. \" \"You will be given several demonstration input-output pairs of 2D arrays. \" \"Your goal is to develop a single algorithm that maps each input array to its corresponding output array. \" \"Each input and output is a 2-dimensional array of integers between 0 and 9. \" \"Solving the task involves: \" \"- Analyzing the demonstration pairs \" \"- Identifying abstract patterns or transformations \" \"- Formulating a general rule or algorithm that works across all examples \" \"- Producing pseudocode that implements the rule \" \"If prior attempts were made, you will also receive feedback summarizing what went wrong. \" \"Carefully use this feedback to improve your solution. \" \"Return only the updated algorithm as pseudocode. Do not describe or explain it. \" \"### Feedback (summary of previous attempts): {attempt_history} \" \"### Demonstration Pairs: {train_pairs} \" ), ( \"ai\", \"Answer:\" ) ] ) PROMPT_SOLVE = ChatPromptTemplate.from_messages( [ ( \"system\", \"You are an expert in abstract reasoning. \" \"Previously, you analyzed demonstration input-output pairs and developed an algorithm \" \"to transform input arrays into output arrays. \" \"Now, use that algorithm to generate an output array for a new, unseen input array. \" \"Only return the output array, formatted as valid Python code within a code block. \" \"For example: ```python [[2, 3], [5, 6]] ``` \" \"### Developed algorithm: {reasoning_template} \" \"### New input array: {test_input} \" ), ( \"ai\", \"Answer:\" ) ] ) PROMPT_ASSESS = ChatPromptTemplate.from_messages( [ ( \"system\", \"You are an expert in abstract reasoning. \" \"A solution array was generated by applying the algorithm to the input array. \" \"Compare the generated solution to the actual target output. \" \"Analyze why the two arrays differ, and provide **clear and concise feedback** on how to improve the algorithm. \" \"Only return your feedback-do not repeat the arrays or algorithm. \" \"### Algorithm: {reasoning_template} \" \"### Input array: {test_input} \" \"### Solution array (generated by algorithm): {solved_test_output} \" \"### Target output array: {test_output} \" ), ( \"ai\", \"Answer:\" ) ] ) PROMPT_SUMMARIZE_FEEDBACK = ChatPromptTemplate.from_messages( [ ( \"system\", \"You are an expert in summarizing feedback on algorithm development. \" \"You will be given a history of past attempts, each containing an algorithm and feedback about its performance. \" \"Your goal is to produce a **concise summary** of the most important lessons learned-\" \"focusing on how the algorithm should be improved and what mistakes should be avoided in future versions. \" \"Return only the feedback summary. Do not repeat the original attempts or feedback. \" \"### Attempt History: {attempt_history} \" ), ( \"ai\", \"Answer:\" ) ] ) These prompts are linked into a simple LangChain pipeline: reasoning_chain = PROMPT_REASON | AGENT_LLM solve_chain = PROMPT_SOLVE | AGENT_LLM assess_chain = PROMPT_ASSESS | AGENT_LLM summarize_feedback_chain = PROMPT_SUMMARIZE_FEEDBACK | AGENT_LLM For each ARC challenge: The model receives the demonstration pairs and prior feedback; The model generates a new algorithm in pseudocode ( reasoning_template ); ); The algorithm is tested on all the demonstrations; If it fails, the model: receives detailed feedback on mismatched predictions; summarizes mistakes across attempts; refines the next version of the algorithm; Once the model gets all demonstrations correct, I test it on the unseen test input. This process repeats for up to a max number of attempts per challenge. A successful algorithm generalizes across the provided examples and applies correctly to the withheld test case. This setup tests whether the model can extract abstract patterns, improve its reasoning over time, and generalize from very few examples. reasoning_templates = {} for i, id in enumerate(id_train_challenges): print(f\"Training on challenge {i} ID: {id}\") train_pairs = train_challenges[id]['train'] test_input = train_challenges[id]['test'][0]['input'] # only pick the first test input test_output = train_sols[id][0] # only pick the first test output train_pairs_str = '' for i, train_pair in enumerate(train_pairs): train_pairs_str += f\"Demonstration pair {i+1}: input grid: {train_pair['input']} output grid: {train_pair['output']} \" train_pairs_str = train_pairs_str.strip() # keep trying until you figure out how to solve the challenge right_wrong = \"incorrect\" # Start with an empty reasoning template, which will be refined over time reasoning_template = '' k = 1 max_attempts = 5 attempt_history = [] attempt_history_summary = '' while right_wrong == \"incorrect\": print(f\"Attempt {k} to solve the challenge...\") # Build the reasoning message with the current reasoning template and attempt history # This message will be used to generate a new reasoning template reason_message = { \"train_pairs\": train_pairs_str, \"attempt_history\": attempt_history_summary, } res = reasoning_chain.invoke(reason_message) reasoning_template = res.content # Assess reasoning template wrong_pairs = [] for train_pair in train_pairs: demo_input = train_pair['input'] demo_output = train_pair['output'] # Test the reasoning template on the demonstration pair test_message = { \"test_input\": demo_input, \"reasoning_template\": reasoning_template, } res = solve_chain.invoke(test_message) solved_demo_output = extract_python_code(res.content) # Compare the output with the demonstration output if solved_demo_output != demo_output: wrong_pairs.append((demo_input, demo_output, solved_demo_output)) if len(wrong_pairs) > 0: right_wrong = 'incorrect' print(f\"Reasoning template failed on {len(wrong_pairs)} demonstration pairs.\") if k >= max_attempts: print(f\"Max attempts reached ({max_attempts}). Stopping for challenge {id}.\") reasoning_templates[id] = '' break print(\"Assessing the reasoning template...\") assessment_res = f'Algorithm failed on {len(wrong_pairs)} demonstration pairs. Here is the feedback: ' for demo_input, demo_output, solved_demo_output in wrong_pairs: assess_chain_message = { \"reasoning_template\": reasoning_template, \"test_input\": demo_input, \"solved_test_output\": solved_demo_output, \"test_output\": demo_output, } res = assess_chain.invoke(assess_chain_message) assessment_res += f\" - From input {demo_input} to output {demo_output}, your solution was {solved_demo_output}: {res.content.strip()} \" attempt_history.append({ \"attempt\": k, \"reasoning_template\": reasoning_template, \"feedback\": assessment_res }) summary_message = { \"attempt_history\": attempt_history, } summary_res = summarize_feedback_chain.invoke(summary_message) attempt_history_summary = summary_res.content.strip() else: print(\"Solution is correct!\") right_wrong = \"correct\" reasoning_templates[id] = reasoning_template # test it against the test input/ output .... but do not give feedback (this is supposed to be unknown) test_message = { \"test_input\": test_input, \"reasoning_template\": reasoning_template, } res = solve_chain.invoke(test_message) solved_test_output = extract_python_code(res.content) if test_output != solved_test_output: print(f\"Test output does not match the true output for challenge {id}.\") else: print(f\"Test output matches the true output for challenge {id}.\") #visualize_matrix(test_input, \"Input grid\") #visualize_matrix(test_output, \"True output\") #visualize_matrix(solved_test_output, \"Test Output\") print(\"-\" * 40) # Separator between entries k += 1 Results: When Reasoning Works In some cases, o3-mini was able to correctly infer a generalizable algorithm from just a few input-output demonstrations. One such example involved generating a patterned tiling based on a small 2×2 input grid. After just one attempt, the model converged on the following pseudocode: BEGIN Let input be a 2x2 grid, where: input[0] = [a, b] input[1] = [c, d] Initialize output as an empty list. FOR each row index r from 0 to 5 DO: Let original_row ← input[r mod 2] IF (FLOOR(r / 2)) mod 2 = 1 THEN Let base_row ← REVERSE(original_row) ELSE Let base_row ← original_row ENDIF Initialize new_row as an empty list. FOR repeat from 1 to 3 DO: Append all elements of base_row to new_row. ENDFOR Append new_row to output. ENDFOR RETURN output END Here is the expected solution (true output) and the solution from the model pseudocode (test output). True output grid (Image by author). Test output grid from the pseudocode (Image by author). This algorithm demonstrates several notable reasoning capabilities: Pattern abstraction: the model inferred a repeating tiling pattern from limited data; Modulo logic: it introduced modulo-based indexing ( r mod 2 and (r // 2) mod 2 ) to alternate row behavior, mimicking visual mirroring; and ) to alternate row behavior, mimicking visual mirroring; Grid construction: the solution scales up the 2×2 input into a larger 6×6 grid through repeated copying and reversal; The fact that the model discovered this structure without hardcoded rules suggests it was engaging in a form of algorithm synthesis, guided by few-shot abstraction. Here is another successful example. Example grids and test input grid (image by author). Again, after just one attempt, the model converged on the following pseudocode: BEGIN Let N = 3 Create output as a 2D array of size (N×N) × (N×N), filled with 0 FOR each row r from 0 to N–1: FOR each column c from 0 to N–1: IF input[r][c] ≠ 0 THEN FOR each i from 0 to N–1: FOR each j from 0 to N–1: Set output[(r * N) + i][(c * N) + j] = input[i][j] RETURN output END Here is the expected solution and the solution from the model pseudocode. True output grid (image by author). Test output grid from the pseudocode (image by author). This algorithm effectively tiles the full input grid into the output grid at every position where the input cell is non-zero. The tiling is aligned such that each copy of the original grid is placed at an offset determined by (r * N, c * N) — the scaled-up coordinates of the non-zero input cell. What’s impressive here is that the model: Learns conditional placement. It only pastes the input where the input value is non-zero; Uses coordinate arithmetic to scale placement locations, showing spatial understanding; Treats the input as both control logic and content, combining layout detection with repetition. When Text-Based Reasoning Isn’t Enough In the task below, the model was given a small number of demonstration input-output grid pairs and asked to infer the transformation rule. Example grids and test input grid (image by author). The text-based model ( o3-mini ) produced a detailed pseudocode solution, structured, plausible, and internally consistent: BEGIN Let original ← input grid Let output ← deep copy of original Let R ← number of rows in original Let C ← number of columns in original // Compute ring index for every cell that is part of a non-zero region. // A cell's ring index is defined as: // - 0 if the cell is on the boundary of the grid OR if at least one of its 4-neighbors is 0 // - Otherwise, 1 + min(ring index of its 4-neighbors) Create grid ring of size R × C, filled with −1 For each cell (r, c) in original: If original[r][c] ≠ 0 then If r = 0 OR c = 0 OR r = R−1 OR c = C−1 then ring[r][c] ← 0 Else if any 4-neighbor (up, down, left, right) of (r, c) has value 0 then ring[r][c] ← 0 changed ← true While changed is true: Set changed ← false For each cell (r, c) in original such that original[r][c] ≠ 0 and (ring[r][c] < 0 or not finalized): Let candidates ← list of ring indices from any 4-neighbor (r′, c′) with a non-negative ring value If candidates is non-empty then newRing ← min(candidates) + 1 If ring[r][c] < 0 OR newRing < ring[r][c] then ring[r][c] ← newRing changed ← true // Process propagation from outer ring inward. // For each cell with ring index ≥ 1, update its value based on a neighbor with ring index one less. // Selection is deterministic: \"up, left, down, right\" Let maxRing ← maximum value in ring For layer from 1 to maxRing: For each cell (r, c) such that ring[r][c] = layer: For direction in [(−1,0), (0,−1), (1,0), (0,1)]: nr ← r + direction.row nc ← c + direction.col If (nr, nc) is in bounds AND ring[nr][nc] = layer − 1 then Let base ← output[nr][nc] If base = 2 then newValue ← 8 Else if base mod 2 = 0 then newValue ← base + 2 Else // base is odd newValue ← base + 1 output[r][c] ← newValue Break out of neighbor loop Return output END At first glance, this looks like a sophisticated strategy: compute a ring index for each non-zero region, then diffuse values inward using deterministic rules. It even includes update logic: If the “base” cell is 2 → assign 8 If base is even → add 2 If base is odd → add 1 But this entire algorithm, however coherent, is misguided. It completely fails to match the true underlying transformation shown in the demonstrations. Expected test output grid (image by author). Test output grid from the pseudocode (image by author). Instead of reasoning about blue-bordered regions and their nested structure, the model generated a generic flood-fill algorithm based on distance from edge and adjacency to zeros. Even the feedback keeps refining the procedural approach identified earlier: ['Key lessons are to: • Precisely compute the ring index so that only', 'true boundary (or external zero) cells get index 0, ensuring that', 'inner cells receive higher indices for proper propagation. • Use a', 'reliable, consistent method for selecting the \"base\" value for', 'updates-ideally by considering all adjacent lower-ring cells or using', 'a deterministic order-and use an immutable copy of the original grid', 'for these lookups. • Apply the parity‐based update rules correctly so', 'that cells with ring index ≥ 1 get the specified value increments', '(especially the special case when the base is 2) rather than remaining', 'unchanged. • Ensure that the update logic cascades inward, allowing', 'inner cells to correctly inherit and build upon values from outer', 'rings.'] So what went wrong? Topological, not visual. The model focused on connectivity and edge proximity, ignoring the visually defined regions. Procedural, not inferential. The logic was rigid and hand-crafted, not derived from patterns in the examples. Demonstration-agnostic. There’s no sign the model meaningfully incorporated the few-shot examples. It likely defaulted to a familiar pattern — spatial growth using layers. This isn’t surprising. Text-only LLMs have no visual grounding. They tokenize the grid as symbolic input — rows of digits, not enclosed figures or nested patterns. As a result, their inductive biases lean toward symbolic or graph-like algorithms, not perceptual abstractions. In this case, the model fell into a common trap: generating something plausible-sounding but wrong. It produced a spatial propagation scheme that might work for a diffusion task but not the one at hand. This highlights a key weakness in text-based few-shot prompting for abstract visual reasoning: the model’s “reasoning” is disconnected from perceptual understanding. It invents algorithms based on internal priors, not external cues. When Reasoning Fails: Also Image Models Aren’t Magic To improve generalization, I transitioned from purely text-based reasoning to image-based prompting, leveraging GPT-4.1’s multimodal capabilities through LangChain. This setup encoded input-output grid examples as base64 images, which were presented alongside a natural language prompt describing the task. from langchain_core.messages import HumanMessage import io import base64 AGENT_MODEL = \"gpt-4.1\" # Prompt for image based reasoning PROMPT_REASON_IMG = \"\"\"You are an expert at solving abstract reasoning tasks. These are unique reasoning tasks with limited examples. You are given demonstration input-output 2D grids. The colormap used is as follows: {{ 'Violet': 0, 'Indigo': 1, 'Blue': 2, 'Yellow': 3, 'Green': 4, 'Orange': 5, 'Red': 6, 'Golden': 7, 'Black': 8, 'White': 9 }} Your goal is to develop a single algorithm that maps each input grid to its corresponding output grid. A successful solution involves: - Analyzing the demonstration examples carefully - Identifying underlying visual or spatial patterns - Formulating a general transformation rule - Translating this rule into clear pseudocode If this is not your first attempt, a summary of previous feedback is also provided. Review it carefully and incorporate it to improve your solution. Test your algorithm against the demonstrations to ensure it works. Return **only the algorithm pseudocode**, formatted as plain text. Do not explain it or add extra commentary. \"\"\" # If your array is 10x10 and you want each cell to be 20x20 pixels (cell_px), the image will be 200x200 pixels. # Convert matrix into image def visualize_grid_fig(matrix, cmap=cmap, norm=norm, cell_px=20, show=False): if type(matrix) is not np.ndarray: matrix = np.array(matrix) h, w = matrix.shape[:2] figsize = (w * cell_px / 100, h * cell_px / 100) # inches fig, ax = plt.subplots(figsize=figsize) ax.imshow(matrix, cmap=cmap, norm=norm) ax.axis('off') if show: plt.show() else: plt.close(fig) return fig # encode image for model def fig_to_base64(fig, dpi=100): buf = io.BytesIO() fig.savefig(buf, format='png', dpi=dpi, bbox_inches='tight') buf.seek(0) img_base64 = base64.b64encode(buf.read()).decode('utf-8') buf.close() return img_base64 # In the loop replace reasoning code with this # reasoning with images reason_message = [{\"type\": \"text\", \"text\": PROMPT_REASON_IMG}] for i, example in enumerate(train_pairs): #fig_in = visualize_grid_fig(example['input'], cmap, norm) #fig_out = visualize_grid_fig(example['output'], cmap, norm) fig_in = visualize_grid_fig(example['input'], ) fig_out = visualize_grid_fig(example['output'], ) fig_in = fig_to_base64(fig_in) fig_out = fig_to_base64(fig_out) reason_message.append({\"type\": \"text\", \"text\": f\"### Input grid {i+1}:\"}) reason_message.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{fig_in}\"}}) reason_message.append({\"type\": \"text\", \"text\": f\"### Output grid {i+1}:\"}) reason_message.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{fig_out}\"}}) reason_message.append({\"type\": \"text\", \"text\": f\"### Feedback (summary of previous attempts): {attempt_history_summary}\"}) reason_message = HumanMessage(content=reason_message) res = AGENT_LLM.invoke([reason_message]) reasoning_template = res.content The resulting pseudocode marked a clear step forward in expressiveness. The model was able to: Detect blue-bordered squares using visual features rather than purely symbolic structure; Apply rules based on square size and nesting depth to infer interior fill colors; Sort identified squares by size before filling, effectively avoiding overwrite conflicts. Here’s the generated pseudocode: 1. Let grid be the input 2D array. 2. Create output_grid as a copy of grid. 3. Identify all blue-bordered squares in the grid: a. For each possible top-left corner (i, j): i. For each possible square size s (s ≥ 3, up to min(grid height, grid width)): - Check if the square of size s starting at (i, j) is fully within bounds. - Check if all *border* cells of this square are Blue (value = 2). - Check that the *interior* cells (not on the border) do not contain any Blue (2). - If all conditions are met, record the square as (i, j, s). 4. Sort the list of detected blue-bordered squares by size in ascending order (smallest first). 5. For each detected square (i, j, s), in sorted order: a. Determine the fill color: - If the square is the smallest (no other blue-bordered square is fully inside it), set fill color = Black (8). - If the square is the largest (no other blue-bordered square fully contains it), fill color = - If there are exactly 2 blue-bordered squares, set fill color = Green (4). - If there are three blue-bordered squares in the grid, fill color = Yellow (3). - If the square is nested (not smallest or largest), fill color = Black (8). - (More complex rules may generalize beyond these based on demonstrations.) b. Fill the interior of the square: For each cell (x, y) strictly inside the square (i+1 ≤ x < i+s−1) and (j+1 ≤ y < j+s−1): - If output_grid[x][y] is not Blue (2), set it to the chosen fill color. 6. Return output_grid. Special notes: - Never overwrite Blue (2) border pixels. - When filling, later (larger) squares overwrite earlier (smaller) fills in overlapping regions. - Only process valid blue-bordered squares (minimum size 3x3, complete border). - If there are multiple disjoint blue-bordered squares, treat each independently for fill color assignment as above matching the demonstration logic. The model clearly exhibits structured reasoning. It develops an internal representation of nested geometric forms and attempts to apply rule-based transformations derived from examples. Test output grid from image-based reasoning model pseudocode (image by author). However, despite these advances, the model still fails to generalize reliably. In novel configurations, it mis-assigns fill colors, falling back on brittle heuristics like size-based priority or rigid nesting assumptions. For instance, it might assume the largest square is always filled with yellow, even when that logic no longer holds in a new context. This failure reveals a deeper limitation: even with image input, the model does not “see” in the human sense. It doesn’t build a holistic perceptual representation of spatial relationships. Instead, it converts the image into symbolic patterns and applies deterministic procedures like flood-fill, sorting, or positional indexing. In practice, this means the model reasons from internal abstractions, not perceptual grounding. It infers that “smaller squares get black,” or “fill based on size rank,” without fully understanding why those assignments occurred in the demonstrations. As a result, any deviation from the expected layout can cause it to misfire. This suggests that while multimodal prompting extends the expressive range of the model, it doesn’t yet provide the kind of flexible, generalizable visual reasoning that humans display. These tasks may ultimately require stronger forms of program induction, meta-learning, or hybrid systems that integrate perceptual grouping with learned rules. Conclusions In this study, I explored whether large language models — both text-based and multimodal — can perform meta-learning from examples on abstract reasoning tasks. Specifically, I focused on a class of problems from the ARC dataset, where solutions require identifying visual patterns, learning transformations, and generalizing them to novel test inputs. Through direct prompting experiments, I found that: Text-based models (e.g., o3-mini ) often hallucinate plausible algorithms that are topologically or procedurally sound but entirely disconnected from the task’s visual logic . These models rely on symbolic reasoning over tokenized grids, and default to familiar heuristics like flood-fill, ring propagation, or rule-based updates, regardless of the examples provided. (e.g., ) often hallucinate plausible algorithms that are topologically or procedurally sound but entirely . These models rely on symbolic reasoning over tokenized grids, and default to familiar heuristics like flood-fill, ring propagation, or rule-based updates, regardless of the examples provided. Multimodal models (e.g., GPT-4 with vision) showed a clear improvement in pattern detection and relational reasoning. They successfully identified blue-bordered regions and adapted behaviors based on relative size or nesting. However, their generalization remained fragile: they still applied brittle rules, such as fixed size-based assignments, and failed in novel layouts that deviated from the demonstrations. These findings suggest that, even with visual input, current LLMs do not “see” as humans do. They process images symbolically, not perceptually. Their reasoning is driven by internally constructed rules, not a flexible, visual understanding of shapes, hierarchy, or affordance. The limitations I observed reinforce a central tension: few-shot prompting alone, even with images, is not sufficient for robust abstraction. True generalization likely requires: Program induction: inferring reusable, structured transformations from examples; Perceptual grounding: developing architectures that parse and manipulate visual scenes compositionally; Meta-learning architectures: building models that adapt their reasoning strategies dynamically rather than applying pre-learned heuristics; Today’s LLMs are astonishing in their breadth, but they’re still guessing based on priors, not learning to learn in the human sense. They lack a strong inductive bias for abstraction and transformation. ARC-style tasks expose this gap clearly: success requires more than pattern recognition, it requires reasoning from examples in a structured, compositional way. These results are not discouraging, rather clarifying. We now know where the ceiling is. And the next generation of models, those with hybrid architectures, persistent memory, and explicit meta-learning capabilities might finally break through it.",
         "en",
         "{'MISC': [\"# Black '#\", \"# Here is an extracted task {'train': [\", \"# Indigo '#0000FF', # Blue '#\", '# Remove axes plt.show', \"# Violet '#4B0082'\", \"# Yellow '#\", '# test it against the test input/ output ....', '- If all conditions are', 'AGENT_MODEL = \"gpt-4.1', 'ARC', 'ARC-style tasks expose this gap clearly', 'After just one attempt', 'Analyze why the two', 'Analyzing', 'And the next generation of models', 'Apache', 'Append all elements of base_row to new_row', 'Apply rules based', 'As a result', \"Black': 8\", \"Blue': 2\", 'But with the rise of large language models', 'BytesIO', 'ChatOpenAI', 'ChatPromptTemplate to simulate reasoning', 'Compute ring index for every cell that is part of a non-zero region', 'Conclusions In this study', 'Create', 'Create grid ring of size R × C', 'Create output_grid', 'C−1', 'DOTALL', 'Data and Setup To explore whether LLMs like o3-mini', 'Demonstration Pairs', 'Do not describe or', 'Do not explain it or', 'Do not repeat the', 'END At first glance', 'END Here is the expected solution', 'END Here is the expected solution and the solution from the model pseudocode', 'ENDFOR Append', 'Each task provides', 'Ensure that the update logic cascades inward', 'Even the feedback keeps refining the procedural approach', 'Even with multimodal inputs', 'Expected test output grid', 'FF0000', \"FFFF00'\", 'FOR each row index r from 0 to 5', 'FOR repeat from 1 to 3 DO:', 'For each ARC challenge', 'For each cell', 'For each cell with ring index', 'For each detected square', 'For layer from 1 to maxRing:', 'Formulating', 'From the demonstration grids', 'Function to visualize', 'GPT-4 with', \"Golden': 7\", 'Grid construction: the', 'Grids have varying sizes and', 'Here is another', 'Here is the feedback', 'Here’', 'Here’s the generated pseudocode', 'HumanMessage', 'I', 'I found that: Text', 'I provided the model with', 'I test it on the unseen', 'I used OpenAI’', 'I used data from the ARC Prize', 'If', 'If candidates is non-empty then newRing ← min(candidates', 'If it fails', 'If the “base” cell is 2 → assign 8 If base is even → add 2 If base is odd → add 1 But this entire algorithm', 'If this is not your first attempt', 'Image by author', 'In practice', 'In this piece', \"Indigo': 1\", 'Initialize', 'Input grid', 'It', 'It completely fails to match the true underlying transformation shown in the demonstrations', 'It develops an internal', 'It doesn’t build', 'It even', 'It infers that “smaller squares get black', 'It likely defaulted to a familiar pattern — spatial', 'It only pastes the input where the input value is non-zero', 'LLMs', 'LLMs are astonishing in their breadth', 'LLMs do not “see” as humans do', 'LLMs themselves as meta-learners in task-based domains like ARC', 'LangChain', 'Later', 'Let N = 3', 'Let R ← number of rows in original Let C ← number of columns in', 'Let base_row ← original_row', 'Let grid be the input 2D', 'ListedColormap', 'Meta-learning architectures', 'Modulo', 'More complex rules may generalize beyond these based on demonstrations', 'None This setup allowed me to structure a full reasoning loop', 'Normalize(vmin=0', 'Now', 'N×N', 'Once the model gets all', 'One such', 'Only return your feedback-do not repeat the arrays or algorithm', \"Orange '#\", 'PROMPT_ASSESS : When the algorithm fails', 'PROMPT_REASON :', 'PROMPT_SUMMARIZE_FEEDBACK:', 'Pattern', 'Perceptual grounding: developing architectures that parse and manipulate visual scenes compositionally', 'Precisely compute', 'Procedural', 'Process', 'Program induction: inferring reusable', 'Prompt for a secret input', 'Python', \"Red '#964B00', # Golden '#\", 'Return only the feedback summary', 'Return only the updated algorithm as pseudocode', 'Return output_grid', 'R−1 OR', 'Selection is deterministic', 'Set', 'So what went wrong?', 'Solution array', 'Sort', 'Sort the list of detected blue-bordered squares', 'Stopping for challenge {id}.', 'THEN FOR each', 'Test Output', 'Test your algorithm against the demonstrations to ensure it works', 'Testing Reasoning with o3-mini', 'The', 'The Abstraction and Reasoning Corpus', 'The algorithm is', \"The colormap used is as follows: {{ 'Violet': 0\", 'The dataset', 'The fact that the model discovered this structure without hardcoded', 'The generated algorithm is applied to new inputs', 'The model', 'The model clearly exhibits', 'The model focused', 'The model generates', 'The model is given training examples and asked to infer', 'The model was able to: Detect blue-bordered squares using visual features rather than purely symbolic structure', 'The process mimics an', 'The resulting pseudocode marked a clear step forward in expressiveness', 'The results offer', 'The tiling is aligned such that each copy of the', 'Their reasoning is driven by internally', 'There’', 'These are', 'These experiments reveal the', 'These findings suggest that', 'These results are not discouraging', 'These tasks may ultimately', 'They process', 'They successfully', 'They tokenize the grid', 'This highlights a key weakness in text', 'This isn’t surprising', 'This message will be used to generate', 'Through direct prompting experiments', 'To evaluate whether LLMs', 'To get an understanding of typical abstraction and reasoning tasks', 'To handle LLM', 'To visualize', 'Today’', 'Treats the input as both control logic and content', 'True', 'True generalization likely requires', 'True output grid', 'Use', 'Uses coordinate arithmetic to scale', 'We now know where the ceiling is.', 'What’', 'When Reasoning Fails: Also Image Models Aren’t Magic To improve generalization', 'When Reasoning Works In some cases', 'When Text', 'When the algorithm fails', 'Yellow', 'You are an expert at solving abstract reasoning tasks', 'You are an expert in abstract reasoning', 'You are an expert in solving abstract reasoning tasks', 'You are an expert in summarizing', 'You are given', 'You will be given', 'You will be given several', 'Your goal is to develop', 'a. For each', 'all blue-bordered squares in the grid', 'and failed in novel layouts that deviated from the demonstrations', 'and generalize from very few examples', 'and generalizing them to novel test inputs', 'and internally', 'and often no shared surface', 'ast def extract_python_code(response_string', 'b. Fill the interior of the square', 'both training and test', 'break print(\"Assessing the reasoning template', 'building models that adapt their reasoning strategies dynamically rather than applying pre-learned heuristics', 'carefully - Identifying underlying visual or spatial patterns', \"cells or using'\", 'cells to correctly inherit and build upon values from outer', 'color = Yellow', 'compositional way', 'c′) with', 'designed to test broad generalization', 'disconnected from the task’', 'each containing an algorithm and feedback about its performance', 'enclosed by green boundaries', 'especially when the model returns', 'even with images', 'expected outputs', 'extract_python_code(res.content', \"f'Algorithm failed on {len(wrong_pairs\", 'falling back on brittle heuristics like size-based priority', 'fig', 'fig_to_base64(fig', \"format='png\", 'from', 'game from the ARC website', 'grid - dictionary of lists # Here is the extracted solution for the only test', 'grid for which the model must', 'holds in a new context', 'https://platform.openai.com/docs/models AGENT_LLM = ChatOpenAI(model', 'ignoring the visually defined regions', 'img_base64 # In the loop', 'import re', 'index for each non-zero region', 'inspired by how humans might approach few-shot tasks', 'involved generating', 'is not sufficient for robust abstraction', 'it', 'jpeg;base64,{fig_in}', 'layout detection with', 'loop with', 'matrix = np.array(matrix', 'matrix into image', 'memory, and explicit meta-learning capabilities might finally break through it', 'message with the', 'method for selecting the \"base', 'mimicking visual mirroring', 'model using', 'models learn to reason abstractly from just', 'new algorithm in pseudocode', 'newValue Break out of neighbor loop Return', 'newValue ← 8 Else if base', 'not external cues', 'not learning to learn in the human sense', 'of the data format', 'os.environ[\"OPENAI_API_KEY', 'plt.imshow(matrix', 'python', 'r mod 2 and', 'range of the model', 'reasoning code with this # reasoning with images', 'reasoning often breaks down in the face of subtle abstraction', 'reasoning template and attempt history #', 'regardless of the', 'regardless of the examples provided.', 'set it to the chosen', 'size change from the input to the output grid', 'square size and nesting depth to infer interior', 'square size s', 'structured', 'structured transformations from examples', 'such as fixed size-based assignments', 'summarizes mistakes across attempts', 'that cells with ring index', 'the ability of', 'the assessment to improve the algorithm', 'the model converged on the following pseudocode', 'the model does not “see” in the human sense', 'the model fell into', 'the model generated', 'the model still fails to generalize reliably', 'the output with the', 'this looks like', 'this means the model reasons from internal abstractions', 'those with hybrid architectures', 'treat each independently for', 'true //', 'true While changed is true:', 'unseen', 'update its value based on a neighbor with ring index one less', 'update logic:', 'visual understanding of shapes', 'which were presented alongside a natural language', 'window into the', 'your OpenAI API', '” without fully understanding why those assignments'], 'LOC': ['A', \"A cell'\", 'Answer', 'Carefully', 'FLOOR(r', 'However', 'I', 'IF', 'Key lessons are to: •', 'N', 'PROMPT_REASON | AGENT_LLM', 'PROMPT_REASON_IMG', 'PROMPT_SUMMARIZE_FEEDBACK', 'PROMPT_SUMMARIZE_FEEDBACK | AGENT_LLM For each ARC', 'RETURN', 'Specifically', 'Topological', 'Your', 'and', 'and symbolic shortcuts rather than robust generalization', 'cmap', 'deterministic order-and', 'i', 'i][(c', 'io', 'is', 'new', 'norm', 'not', 'solved_demo_output', 'solved_demo_output in wrong_pairs', 'then', \"train_challenges[id]['test'][0]['input\", 'train_pairs_str.strip'], 'PER': ['# Green', 'Black', 'François Chollet', 'Green', 'However', 'I defined', 'I transitioned from purely text', 'Identifying', 'Introduction Meta-learning', 'Kaggle', 'They lack', 'White', 'ax.imshow(matrix', 'cmap=cmap', 'describing', 'detailed pseudocode', 'generalizable visual', 'holistic perceptual', 'however', 'it doesn’t yet provide the kind of flexible', 'leveraging GPT-4.1’s', 'nested geometric', 'noopener', 'not enclosed', 'not perceptual abstractions', 'not perceptual grounding', 'not perceptually', 'o3-mini ) often hallucinate', 'patterned tiling based on', 'plt.close(fig', 'predicted vs', 'procedural heuristics', 'repeating tiling pattern from', 'you analyzed', 'you will also receive feedback summarizing what went wrong'], 'ORG': ['ChatPromptTemplate', 'For instance', 'I used', 'Instead', 'LangChain', 'Orange', \"Red': 6\", 'Results', 'Return', 'Review it carefully and incorporate it to improve your', 'These', 'bias for abstraction', 'e.g', 'id in', 'nc ←', 'unchanged']}",
         "[0.004933114629238844, -0.06849845498800278, 0.012651192955672741, 0.035230930894613266, 0.14909468591213226, -0.06541835516691208, 0.0229023564606905, 0.020161472260951996, 0.03129513934254646, -0.0006894510588608682, -0.09179854393005371, -0.01701383665204048, 0.006914322264492512, 0.10874028503894806, 0.06978978961706161, -0.03491607680916786, 0.09262806177139282, 0.055615004152059555, -0.09397254884243011, -0.06793705374002457, 0.020031122490763664, -0.06796726584434509, 0.03210565447807312, 0.01228056475520134, -0.0022046430967748165, 0.036042243242263794, 0.006623025052249432, -0.05282072722911835, -0.0036129418294876814, -0.02136187069118023, 0.057636622339487076, 0.04780735448002815, -0.058021485805511475, 0.034241121262311935, 0.011632808484137058, 0.10548985749483109, -0.007615566253662109, 0.047728653997182846, -0.009523497894406319, -0.06765902787446976, -0.04763636365532875, -0.02230972982943058, 0.032399650663137436, -0.04283427819609642, 0.1374473124742508, -0.010341625660657883, -0.013462008908390999, -0.06339254230260849, -0.030534200370311737, 0.010586774908006191, -0.13192683458328247, -0.010644801892340183, -0.0693158507347107, -0.0033012598287314177, 0.025682758539915085, -0.010271386243402958, 0.08154068887233734, -0.0073264348320662975, -0.012228123843669891, -0.06181330233812332, -0.05511710047721863, -0.14907950162887573, -0.08559102565050125, 0.024842416867613792, -0.013676470145583153, -0.011134909465909004, 0.049366407096385956, -0.02760142646729946, 0.0061147939413785934, -0.021583925932645798, -0.03646387532353401, 0.06905023753643036, -0.01936176046729088, 0.03374718129634857, 0.020630162209272385, 0.11638163030147552, 0.04400484263896942, -0.020465638488531113, 0.03167904540896416, -0.09251329302787781, 0.03977704048156738, 0.061635445803403854, 0.02233496867120266, 0.01961750164628029, 0.07719334959983826, 0.01728195510804653, -0.016207607463002205, 0.053857188671827316, 0.02030421607196331, 0.012841925956308842, 0.031908947974443436, -0.05320226773619652, -0.018700217828154564, 0.047030091285705566, 0.10256221145391464, 0.029229797422885895, 0.023376181721687317, -0.09738454967737198, -0.05448165535926819, 0.13416606187820435, 0.02410542033612728, 0.09796658903360367, 0.0035988877061754465, -0.05688728392124176, 0.039545122534036636, 0.005381953436881304, -0.027841994538903236, 0.008828943595290184, 0.02609662525355816, -0.10688158124685287, 0.026276852935552597, -0.010571868158876896, 0.055131059139966965, 0.011970601975917816, -0.005607399623841047, -0.10693547129631042, 0.03558771312236786, -0.0737445205450058, 0.04840445518493652, 0.05575062334537506, -0.008747817017138004, 0.05956815555691719, -0.03744267299771309, 0.06034225970506668, 0.06717616319656372, -0.023818252608180046, -0.09674137085676193, 2.1279959539256485e-33, 0.040387798100709915, 0.059580422937870026, 0.04441218078136444, 0.07692906260490417, 0.06749209761619568, -0.012624653987586498, 0.06370668858289719, 0.020315635949373245, 0.06841050833463669, 0.005982936825603247, -0.016379453241825104, 0.04822897911071777, -0.0855499655008316, 0.04211697354912758, 0.04713405296206474, 0.020234718918800354, -0.05144865810871124, -0.010259894654154778, -0.05408020690083504, 0.004272039979696274, 0.03058868646621704, -0.01205714326351881, 0.011192766018211842, -0.024256423115730286, -0.038803063333034515, 0.018973134458065033, 0.015860330313444138, -0.10387856513261795, 0.0052993157878518105, 0.027920588850975037, -0.09870825707912445, -0.06746053695678711, -0.008989947848021984, 0.13284209370613098, 0.029025472700595856, -0.04739038646221161, -0.02941286191344261, -0.0672723576426506, 0.05086376145482063, -0.03441305831074715, 0.012442381121218204, 0.0059118084609508514, 0.03805689141154289, 0.0549122616648674, -0.08062230050563812, -0.04586236551403999, -0.027288969606161118, 0.03706122562289238, -0.05353901535272598, -0.0024148644879460335, 0.03594768047332764, 0.03155316412448883, -0.10417056828737259, -0.13840757310390472, 0.040716610848903656, 0.02669922076165676, -0.03419877961277962, 0.02236900106072426, 0.049836453050374985, 0.05421547219157219, -0.01282116211950779, 0.07200565934181213, -0.034455765038728714, 0.13739341497421265, 0.0019402746111154556, 0.04293416813015938, -0.05681920051574707, 0.04488089308142662, 0.05896898731589317, -0.024162685498595238, -0.018352199345827103, 0.01791536621749401, -0.056071940809488297, -0.02615353837609291, 0.059925422072410583, -0.033314138650894165, 0.0581340566277504, -0.12789270281791687, -0.015047525055706501, -0.010720445774495602, -0.0050768801011145115, 0.056716881692409515, -0.023991215974092484, -0.015902098268270493, -0.08251748234033585, -0.019461359828710556, 0.05017614737153053, -0.09943421185016632, 0.005985631607472897, -0.06426840275526047, -0.043571777641773224, -0.0407579131424427, -0.025244684889912605, 0.00790327601134777, -0.024296361953020096, -1.570948650196152e-33, -0.004951624199748039, -0.008116940036416054, -0.04112210497260094, -0.012092462740838528, -0.008508726954460144, -0.014675827696919441, -0.010506854392588139, -0.040793903172016144, -0.03723207861185074, -0.05115421488881111, -0.05162281170487404, -0.016790814697742462, 0.02398151159286499, 0.006421212572604418, -0.04107389226555824, -0.07287845015525818, -0.014999192208051682, -0.036268774420022964, -0.012250913307070732, 0.10790272802114487, 0.00031496648443862796, 0.13369518518447876, -0.13347411155700684, 0.047935158014297485, -0.03783610463142395, 0.07588668167591095, -0.03625697270035744, -0.0013029009569436312, 0.014483527280390263, 0.09875766187906265, -0.015375622548162937, 0.024844860658049583, -0.01123330369591713, -0.055160120129585266, -0.017021290957927704, 0.09603996574878693, 0.028654472902417183, -8.962452557170764e-05, -0.06823534518480301, 0.06980470567941666, 0.03866931423544884, -0.03476232290267944, -0.0029533286578953266, -0.030450589954853058, -0.010607318952679634, 0.062137141823768616, -0.036253899335861206, 0.01725679822266102, 0.0332350917160511, 0.03085804358124733, -0.018563857302069664, -0.029996564611792564, -0.04271269589662552, -0.04597678408026695, -0.025319503620266914, -0.10880246013402939, -0.007981047965586185, -0.07703667134046555, -0.00998721830546856, -0.023199651390314102, -0.04456081986427307, -0.018472593277692795, 0.04384703189134598, -0.02626201882958412, 0.017523007467389107, 0.05244815722107887, -0.0338251031935215, -0.07332020998001099, -0.004436952527612448, 0.02916795201599598, 0.04042765870690346, -0.05691884458065033, -0.04539818316698074, -0.011968663893640041, 0.07144619524478912, 0.03808348625898361, -0.001388269942253828, -0.03288376331329346, -0.06482359766960144, -0.08735356479883194, 0.017280876636505127, -0.041127316653728485, 0.04297909513115883, 0.041099995374679565, 0.018670428544282913, 0.03418268263339996, 0.008973945863544941, 0.1164020374417305, 0.034321531653404236, 0.03718417137861252, -0.00934675894677639, 0.0020222258754074574, 0.011923053301870823, 0.05917963758111, -0.019972041249275208, -5.0390710271130956e-08, -0.06851433962583542, 0.08045836538076401, -0.0013515428872779012, 0.029631000012159348, -0.020175522193312645, -0.053890835493803024, -0.02544412761926651, 0.041582465171813965, -0.009110827930271626, 0.004960416350513697, 0.03234654292464256, 0.010977718979120255, -0.029637468978762627, -0.030618304386734962, 0.011526831425726414, 0.09836974740028381, 0.04995960742235184, -0.01605975814163685, -0.0008603762835264206, -0.025418885052204132, 0.021743018180131912, -0.021214157342910767, -0.059035059064626694, -0.006076190620660782, 0.026284821331501007, -0.05075198784470558, -0.07687660306692123, 0.0669315904378891, 0.10488387942314148, 0.04823608696460724, 0.0054763187654316425, 0.02922339178621769, 0.028543511405587196, -0.009370741434395313, 0.03100176714360714, 0.005001912824809551, 0.026712609454989433, -0.04267406091094017, -0.030923210084438324, -0.06627127528190613, 0.0038545094430446625, 0.07386892288923264, -0.05121128261089325, -0.006723716855049133, 0.035363201051950455, 0.04324474558234215, -0.0149332694709301, -0.06631895899772644, -0.05681922659277916, 0.02092071995139122, -0.02408704347908497, -0.012269368395209312, -0.027694646269083023, 0.044892795383930206, 0.014743795618414879, 0.03222468122839928, 0.01225981954485178, -0.03853719308972359, -2.2426888790505473e-06, 0.036767810583114624, 0.027396220713853836, 0.0965500995516777, 0.013247969560325146, 0.015710437670350075]",
         "0.153"
        ],
        [
         "3",
         "263",
         "\"On n'a fait que du Tetris\" : on vous raconte l'histoire secrète de la cérémonie d'ouverture des Jeux de Paris, un an après",
         "Vous pensiez tout savoir du spectacle mis en scène par Thomas Jolly ? Détrompez-vous : Tony Estanguet, le pianiste de Céline Dion, le réalisateur des \"Minions\" et des dizaines d'acteurs moins connus de ce jour mémorable n'ont pas tout dit. Sauf à franceinfo.",
         "Vous pensiez tout savoir du spectacle mis en scène par Thomas Jolly ? Détrompez-vous : Tony Estanguet, le pianiste de Céline Dion, le réalisateur des \"Minions\" et des dizaines d'acteurs moins connus de ce jour mémorable n'ont pas tout dit. Sauf à franceinfo.\n\nLes neuf tableaux de la cérémonie d'ouverture du 26 juillet 2024 sont le fruit d'années de travail : 160 caméras, 6 kilomètres de spectacle, 20 000 personnes mobilisées le jour J, dont 4 000 artistes, sur 3 000 m² de scènes, avec 85 bateaux sur la Seine. Un an après le début des Jeux olympiques de Paris, voici les coulisses du plus grand spectacle jamais réalisé en France, qui a captivé un milliard de personnes.\n\nTableau 1 : \"Humidité\"\n\nThomas Jolly part se coucher le cœur léger. Après avoir assisté aux ultimes répétitions de Céline Dion, l'homme-orchestre de la cérémonie a consulté une dernière fois l'appli météo de son téléphone. \"Des nuages, mais pas de pluie\", lui assure-t-elle. \"Je me suis dit : 'c'est top, c'est beau un coucher de soleil avec des nuages, un ciel zinzolin'...\" Le hic, c'est qu'il a conservé comme ville par défaut Rouen, là où habitent ses parents.\n\nCinq heures, Paris s'éveille et le verdict tombe. Après avoir vérifié pour la millième fois les modèles météo, l'équipe de prévisionnistes de permanence assure que la soirée du 26 juillet sera arrosée. \"Les jours précédents, nos modèles nous assuraient une probabilité de 30% de pluie sur la soirée, ce qui n'était pas négligeable. Et ce chiffre n'a fait que monter au cours de la nuit\", résume Alexis Decalonne, du pôle sports de Météo-France. Décision est prise d'activer le plan pluie lors du briefing de 7 heures.\n\nAu palais de l'Elysée, les volets s'entrouvrent. Tasse de thé en main, Emmanuel Macron envoie quelques textos à ses interlocuteurs à Paris 2024. A Tony Estanguet, le président du comité d'organisation, \"Grosse journée !\"\n\nAu même moment, Philippe Frénoi serre le frein à main de son food-truck en face du Louvre. Le champion du monde de frites 2023 est parti dans la nuit de Linselles (Nord), anticipant bouchons et contrôles. Pourtant, lui et ses 800 kg de pommes de terre se posent quai François-Mitterrand comme une lettre à la poste. \"Pas un flic n'a même contrôlé mon QR code. Imaginez si j'avais planqué une bombe dans les patates ?\"\n\n\"En face de moi, des yeux baissés. Quelques larmes.\" Lourde tâche que celle d'Alexis Decalonne, qui présente ses cartes météo lors de la réunion de crise avec les équipes cornaquées par le patron des cérémonies de Paris 2024, Thierry Reboul, au Bourget. \"Tout le boulot va partir dans les égouts avec l'eau de pluie\", se lamente Jean-François Perfetti, le producteur exécutif. La cérémonie commence dans douze heures.\n\n\"C'est la fin du monde.\" Jean-François Perfetti, producteur exécutif de la cérémonie à franceinfo\n\nCoup de chaud aussi pour Pierre-Yves Guillerm. Le prévisionniste de Météo-France, qui s'occupe également de Roland-Garros, arrive en gare de Brest pour gagner la capitale. Il est attendu à 14h30. Sur les écrans de la SNCF, du rouge cramoisi. Une mystérieuse panne paralyse le réseau ferré. \"On s'est débrouillés.\"\n\nTony Estanguet, briefé dès potron-minet, est l'invité de la matinale de France Inter et prépare les esprits au \"scénario catastrophe\" détaillé quelques minutes plus tôt par l'expert de Météo-France : \"J'annonce qu'il risque de pleuvoir un peu le soir...\" De retour à l'hôtel vers 9h30, le patron des Jeux peut souffler : enfin une bonne nouvelle ! Marie-Jo Pérec et Teddy Riner viennent d'accepter d'être les derniers porteurs de la flamme. Ils ont eu un petit indice. La veille au soir, le patron des Jeux leur avait envoyé un SMS sibyllin : \"On s'appelle demain matin.\"\n\nTableau 2 : \"Formalités\"\n\n\"Qui a du scotch ?\" Le CIO, qui a débarqué au Conseil économique, social et environnemental (Cese) avec ses valises et ses exigences il y a quelques jours, poursuit son installation. Prière de masquer toutes les marques qui ne sponsorisent pas l'événement. La climatisation installée au plafond ? La marque des ascenseurs ? \"A cacher.\" Idem pour le distributeur de café, les téléviseurs des salles de réunion et même le presse-agrume de la cafétéria.\n\nSalim Akacem sèche. A dix heures de la parade, le drapeau sur le pont de son bateau, le Buci, amarré quai d'Ivry, ne lui dit rien. Du rouge, des sortes de vagues, un soleil… \"Les Kiribati\", lui souffle un officiel. \"Je ne savais même pas où c'était. J'ai dû chercher sur Google.\"\n\nChristine Bravo, elle, a \"chopé le gros lot\". Le capitaine du Frou Frou, son bateau, vient de l'informer : \"Ce sera la Syrie.\" L'animatrice télé bondit. \"Franchement, quelle chance j'avais de tomber sur un pays problématique ?\"\n\n\"La famille Assad va monter à bord !\" Christine Bravo, propriétaire du bateau de la délégation syrienne à franceinfo\n\nPas tout à fait, mais des proches du régime, certains placés sous sanctions économiques, protégés par des hommes surarmés planqués dans la soute. \"Fallait que ça tombe sur moi.\"\n\nLa délégation syrienne à bord du bateau\" Frou Frou\", appartenant à l'animatrice Christine Bravo, lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (GETTY IMAGES EUROPE)\n\n13h26. Tranquillement posé dans la cuisine de son appartement parisien, Paul savoure en cliquant sur le bouton \"Poster\". Pour la photo, \"j'ai pris toutes les affaires que je pouvais dans mes placards, et même une boîte de cornichons pour brouiller les pistes\", se marre le coordinateur à Médecins du monde, engagé dans le collectif anti-JO Le Revers de la médaille. \"Ça m'a fait mourir de rire d'imaginer la réunion de crise. On m'a dit qu'ils allaient fouiller les catacombes au cas où des plongeurs se seraient cachés.\"\n\n@Paris2024 @Interieur_Gouv on vous confirme que le revers de la médaille sera présent au cœur de la cérémonie d'ouverture ce soir 😇🫡\n\n\n\nImages à venir sur nos réseaux demain 👀\n\n\n\nPetit aperçu du matériel nécessaire pour l'accomplissement de ce happening. Merci, à toute, bisous 😘 pic.twitter.com/WRdmJlx0PU — le revers de la médaille (@reversmedaille) July 26, 2024\n\nIl n'est pas loin de la réalité : \"Ça faisait partie des scénarios que nous avions envisagés\", insiste l'entourage du ministre de l'Intérieur de l'époque, Gérald Darmanin.\n\nTony Estanguet, lui, est déjà derrière son pupitre. La copie conforme de celui derrière lequel il posera ses fiches dans quelques heures. \"J'ai lu et relu mon discours des dizaines de fois, parfois changé une phrase, un mot. Je voulais qu'il soit le plus concis et le plus impactant possible.\" Au cours de cette session bachotage dans sa chambre d'hôtel, son conseiller spécial Benjamin Brun émet une suggestion : \"Tu devrais quand même ajouter une phrase sur la pluie.\"\n\nTableau 3 : \"Fébrilité\"\n\n\"Houston, on a un problème.\" Le bateau qui supporte le cheval argenté ne peut pas accoster dans le 13e arrondissement, au point de rassemblement avant la cérémonie. La coque est trop basse et risque de passer sous le quai. \"Pas le choix, faut le tenir, sinon il se fracasse par-dessous\", soupire l'ingénieur Madeg Ciret-Le Cosquer. Pendant sept longues heures, son équipe se relaie, cordage à la main et les jambes tendues pour maintenir la coque à bonne distance.\n\nLe bateau soutenant le cheval de fer est maintenu à bout de jambes par les équipes de Madeg Ciret-Le Cosquer, quai d'Ivry, quelques heures avant le début de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (MADEG CIRET-LE COSQUER)\n\n16h30, alerte générale chez Aéroports de Paris. Le gros-porteur de la compagnie French Bee qui doit décoller d'Orly pour Fort-de-France est planté sur le tarmac. Le voyant de la jauge du réservoir fait des siennes. La course contre la montre commence : le ciel parisien doit être désert à 18 heures. Sinon, il faudra héberger en urgence les 400 passagers… alors que les hôtels du secteur sont pris d'assaut. \"C'est un incident comme il en arrive tous les jours dans un aéroport\", tempère Perrine Duglet, directrice des opérations de Paris-Orly. \"Mais au pire moment.\" L'appareil décolle finalement trente minutes avant le gong.\n\nLe ciel a l'air d'être tombé sur la tête de Tony Estanguet. L'homme-sandwich des Jeux de Paris sait qu'il sera jugé sur la qualité du spectacle proposé ce soir. Celui qui ne se départit jamais de son sourire en public depuis sept ans est livide quand il arrive à l'Elysée pour rejoindre Emmanuel Macron et les chefs d'Etat qui vont assister à la cérémonie. \"Alors que les équipes mettaient toute leur énergie pour résoudre les problèmes, je devais jouer un rôle protocolaire, trépigne-t-il. C'était mon rôle. Mais c'était difficile. J'ai toujours préféré être dans l'action.\" Ce n'est que lorsqu'il découvre la haie de policiers, plantés tous les trois mètres le long des quatre kilomètres qui séparent le cortège officiel du Trocadéro, qu'il s'autorise une blague : \"On se croirait dans Star Wars.\"\n\nC'est le moment pour Lady Gaga et ses danseurs. Sur les marches glissantes des quais de Seine, la chanteuse commence à 17 heures. \"On a tourné sept fois la scène dans le créneau imparti, le plus vite possible\", souffle Jean-François Perfetti. Lancées en même temps, les séquences de BMX resteront, elles, à tout jamais dans un tiroir. Un problème de raccord entre le soleil de 17 heures et le déluge cinq heures après. \"Ça ne marchait pas\", soupire le directeur artistique de Paris 2024.\n\n\"On n'a fait que du Tetris. La seule chose dont on était à peu près sûrs, c'est que Céline Dion allait chanter, poursuit Jean-François Perfetti. On avait un début et une fin.\" Les danseurs sur les toits de Paris ? Trappés. Les drones et les hélicoptères ? Cloués au sol.\n\n\"On ne pouvait plus faire de 'beauty', de plan large de Paris. Il a fallu repenser le conducteur pour déterminer ce qu'on allait montrer à la place.\" Jean-François Perfetti, producteur exécutif de la cérémonie à franceinfo\n\nEncore une nouvelle version de la cérémonie, retravaillée en continu depuis trois ans.\n\nLe téléphone de l'Elysée chauffe. Le Qatar réclame une rallonge de sièges pour sa délégation en tribune officielle. C'est non, comme pour tous les demandeurs de dernière minute. Le plan de table a été finalisé la veille par le \"Château\", au prix de savants arbitrages diplomatiques.\n\nDans le rush final, tout le monde se met au service du collectif. Atelier arts plastiques et loisirs créatifs pour Bruno de Lavenère, l'un des deux scénographes de la cérémonie. \"J'ai passé l'après-midi à chercher du tissu pour camoufler les bateaux. Ça ne se voit pas, mais on a fait cette cérémonie avec des bouts de ficelle. Cet ADN du bricolage, ça nous vient du théâtre, de l'univers de Thomas Jolly.\"\n\nSystème D aussi pour Johan Tonnoir. Le champion de parkour est l'un des neuf mystérieux porteurs masqués, véritable fil rouge entre chaque tableau de la cérémonie le long de la Seine. Problème, une fine pellicule de pluie s'incruste sur la balustrade du Pont-Neuf, où il est censé sprinter. Hors de question de risquer la glissade. \"J'ai trouvé un bar, au coin de la rue sur le quai, et je leur ai emprunté un balai-brosse.\"\n\nLe porteur masqué de la flamme olympique court sur le Pont-Neuf lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (MADDIE MEYER / GETTY IMAGES EUROPE)\n\nLa RATP a aussi briqué de fond en comble les rames de métro choisies pour la ligne éphémère Trocadéro-Etoile, un tronçon de la ligne 6 réservé aux VIP comme Serena Williams, Lilian Thuram ou Philippe Etchebest. \"Pas de tags, pas de fauteuil abîmé\", liste Pierre Guichard, le manager d'exploitation ferroviaire. Trafic fluide prévu tout au long de la soirée.\n\n\"Je m'étais dit : 'Tant pis, c'est une fois dans une vie.'\" Quand elle arrive sur son siège en tribune autour de 19 heures, Anne-Marie espère en avoir pour son argent. Cette cadre fondue des Jeux a acheté deux places en face du Grand Palais à 2 700 euros pièce. \"C'était le cadeau d'anniversaire de mon mari, et j'ai renoncé à en prendre pour les enfants.\" A ce tarif, des petits fours et un majordome en livrée jaune qui tient le parapluie ? \"Rien du tout, on était sous la flotte comme tout le monde, et on a payé à prix d'or un sandwich goût carton mouillé…\"\n\nTableau 4 : \"Intensité\"\n\nPlus qu'un quart d'heure avant le début du show. Une chape de plomb s'abat sur le QG des têtes pensantes de la soirée. \"On n'arrivait même plus à se regarder, décrit le scénographe Bruno de Lavenère. On était terrorisés.\" Juste à côté, l'historien Patrick Boucheron annonce : \"Ce qu'on va voir, ce sera plus un plan A prime. Quelque chose qu'on va adapter au fur et à mesure. Mais on ne va pas faire le plan B.\"\n\n\"A 19h28, j'étais encore en train de danser avec le public. A 19h30, on me dit : 'On arrête tout'.\" La cérémonie commence à peine, mais pour Louis-Maël Bastié, elle est déjà finie. Son costume de Phryge, la mascotte des JO, n'est pas imperméable et est alimenté par une batterie pour son aération. \"C'était terriblement frustrant.\" Vous ne verrez jamais les huit Phryges censées animer les bords de Seine. La mascotte n'apparaîtra que quelques secondes à l'antenne… sur la séquence de Lady Gaga, enregistrée deux heures plus tôt.\n\n\"C'est mort.\" Les trombes d'eau douchent le moral de Franck Royer. Le patron de l'entreprise La Consignerie s'est démené pour dégoter en six semaines 80 stands, restaurants, brasseries et food-trucks, 600 chapiteaux et des groupes électrogènes, \"là où il aurait fallu neuf mois en temps normal\". Tout ça pour ça. \"Qui veut acheter des frites quand votre seule priorité, c'est de trouver un abri ? Cette cérémonie, on la rembourse encore.\"\n\nUn feu d'artifice bleu-blanc-rouge illumine le pont d'Austerlitz au début de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (KEVIN C. COX / GETTY IMAGES EUROPE)\n\n20 heures. Le mystérieux porteur de flamme grimpe sur le toit de Notre-Dame. En surplomb, Quasimodo accroché à une girouette. Sous le costume, qui a reconnu Thomas Jolly en personne ? D'ailleurs, qui a reconnu sa voix annonçant les tableaux de la cérémonie ?\n\nParis 2024 a tenté de la jouer à l'économie pour le buffet des grands de ce monde. L'Elysée a empêché in extremis qu'on serve des chips et des cacahuètes dans des assiettes en carton au gratin de la planète. Le buffet élyséen servi sous un barnum judicieusement placé, au pied de la tribune VIP, devient the place to be…\n\nPour Aurélie Halbwachs, le dress code, c'était chemisette. La porte-drapeau mauricienne ne s'est pas réjouie longtemps de ce choix. \"On nous a distribué des K-Way qui ressemblaient à des sacs-poubelle.\" Tant pis, elle garde ses manches courtes jusqu'au bout. Une demi-heure plus tard, Florent Manaudou et Mélina Robert-Michon vont aussi regretter d'avoir dit non au poncho. \"On ne s'en rend pas compte à la télé, mais je vous promets, c'est le déluge, glisse la lanceuse de disque. A la toute fin, ça caillait. L'horreur.\"\n\nLa lanceuse de disque Mélina Robert-Michon, porte-drapeau de l'équipe de France en compagnie de Florent Manaudou, pose sur le bateau des Bleus, lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (MELINA ROBERT-MICHON)\n\n\"Ah ça iraaaaaaaa !\" rugit Joseph Duplantier, le chanteur de Gojira. Des Marie-Antoinette à tête coupée surgissent des fenêtres de la Conciergerie. Initialement, elles devaient sortir de guillotines géantes dans des gerbes de sang… avant que l'Elysée ne mette le holà. Non qu'Emmanuel Macron craigne de froisser les têtes couronnées, mais l'équipe présidentielle martèle devant les équipes de Thomas Jolly sa volonté de trouver un équilibre sur chaque tableau.\n\nEt dire que ce numéro a failli passer à la trappe. Lors de l'ultime répétition, le courant de la Seine était tel que les bateaux se retrouvaient obligés de naviguer à 11 km/h au lieu des 9 initialement prévus. Conséquence : ils arrivaient 8 minutes en avance. \"On nous a demandé de réfléchir à quel tableau on pouvait couper, se remémore Patrick Boucheron. Parmi les artistes qui n'étaient pas habillés par LVMH, si possible. Ça mettait Gojira en tête de liste.\" Heureusement pour les fans de metal, tout rentre dans l'ordre le jour J.\n\nPerché à 34 mètres de haut, sur le toit de la Samaritaine, Nathan Paulin s'engage sur son fil de 350 mètres tendu jusqu'à la Monnaie de Paris. Vingt minutes d'équilibrisme avant que le funambule ne tombe de haut. \"Désolé, on ne t'a pas vu sur les écrans\", lui annonce son équipe. \"Ça a été une grosse déception.\" Débordée par la densité du spectacle, la réalisation n'a pas diffusé la séquence.\n\nLe funambule Nathan Paulin s'élance depuis la Samaritaine lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (MADDIE MEYER / GETTY IMAGES EUROPE)\n\nTableau 5 : \"Ubiquité\"\n\nDans la tribune officielle, tous les grands de ce monde sont rapatriés dans la partie abritée. Tous ? Trois irréductibles Gaulois continuent à se blottir sous leur cape de plastique pour tenter d'apercevoir la suite des festivités. Oubliés par le protocole, les trois anciens Premiers ministres Edouard Philippe, Jean Castex et Elisabeth Borne. Le maire du Havre envoie paître l'émissaire élyséen. \"Si le président voulait qu'on monte [dans la tribune abritée], il aurait envoyé quelqu'un nous chercher plus tôt !\" Il faudra qu'une de ses ex-collaboratrices, passée à l'Elysée, se déplace pour que le trio abandonne son siège.\n\nNi vu, ni connu. Quelques invités de prestige s'éclipsent des gradins VIP. Amélie Mauresmo, Jean-François Lamour, Emilie Le Pennec… Evaporés dans des vans noirs. \"On a tracé dans les rues de Paris\", souffle la championne olympique de gymnastique. Direction le Louvre.\n\nSans maîtrise, la puissance n'est rien, vantait une célèbre marque de pneus. Le slogan est aussi valable pour un champion de parkour par temps humide. \"J'ai testé le bois du pont des Arts mouillé avant mon entrée en scène\", raconte Maxence De Schrooder, l'un des neuf porteurs de flamme masqués. \"J'aurais aimé faire un salto avant, mais je n'ai pas pris le risque. C'était avant tout un tableau artistique, pas athlétique. J'avais l'obligation de finir mon numéro à la seconde près.\"\n\nCérémonie d'ouverture des Jeux Olympiques de Paris 2024 présentée par Daphné Bürki, Laurent Delahousse et Alexandre Boyon depuis le Trocadéro et des envoyés spéciaux à Paris, en Île-de-France, sur le territoire, en Outre-mer et depuis les sites de compétition. 3min\n\nAya Nakamura et la garde républicaine entament le duo le plus iconique de la cérémonie en reprenant du Aznavour. Dans le plan initial, l'interprète de Djadja enquillait ses tubes, mais l'Elysée s'en est mêlé : pourquoi Céline Dion et Lady Gaga sacrifieraient-elles au répertoire classique hexagonal et pas elle ? \"J'ai répondu au président que pour moi, ses titres faisaient déjà partie du patrimoine, vu que ce sont les chansons francophones les plus écoutées dans le monde\", nuance Thomas Jolly. Un compromis est trouvé in extremis avec un medley Pookie/For me formidable entré dans la légende. Le directeur artistique, qui a le dernier mot après consultation de l'Elysée, du CIO et de la Mairie de Paris, se rappelle une tenace rumeur de reprise d'Edith Piaf par Aya Nakamura. Il l'avait promise à Céline Dion. \"Je voulais la garder pour la fin.\"\n\nLe nageur Michael Phelps et le biathlète Martin Fourcade saluent le public sur une barge transportant des malles Vuitton, lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (VICTOR LOCHON / GAMMA-RAPHO / GETTY IMAGES)\n\nSur une barge mobile, trois gigantesques malles Louis Vuitton, Martin Fourcade et Michael Phelps saluent la foule massée près de la Monnaie de Paris. On ne peut pas rater le monogramme, propriété de Bernard Arnault, principal mécène de la cérémonie. \"On nous parle beaucoup des ingérences politiques, constate Patrick Boucheron. A côté des exigences du CIO et de LVMH, ce n'était pas grand-chose.\" Les bagages devaient être lancés de danseur en danseur entre la Monnaie de Paris et la barge. Veto du leader mondial du luxe : \"Une malle Vuitton, ça ne se lance pas.\" Que le groupe se rassure, personne ne les loupera. \"Sur quatre heures de spectacle, une minute trente de pub, c'est un moindre mal\", observe Patrick Boucheron.\n\nEt plouf La Joconde ! Encore un coup des Minions, fleuron de l'animation tricolore. Pierre Coffin, leur créateur, a réalisé le film dans le plus grand secret. Un seul gag sera retoqué. Initialement, ces diables de petites bestioles jaunes traçaient une cible à la peinture sur le tableau de Léonard de Vinci. Un geste qui faisait un peu trop écho aux jets de soupe de militants écologistes sur des œuvres d'art. \"J'ai parfaitement compris, commente Pierre Coffin. Ma technique, c'est de forcer le trait jusqu'à ce qu'on me dise stop. Et cette fois, nous n'étions que trois dans la chaîne de décision. Le politiquement correct n'est jamais rentré en ligne de compte.\"\n\nLe bureau de Thomas Jolly au centre de commandement de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (THOMAS JOLLY / DR)\n\nToute la soirée, Thomas Jolly et Thierry Reboul, casque sur les oreilles, micro allumé et paquet de bonbons comme unique réconfort, prennent arbitrage sur arbitrage. Comme pour la cantatrice Axelle Saint-Cirel, prévue pour chanter La Marseillaise sur le toit du Grand Palais. Vu la météo, on envisage le plan pluie : \"La rapatrier sur le pont Alexandre-III\", décrit Thomas Jolly. Le hic, c'est que le plus beau pont de Paris est prêt... pour les épreuves de triathlon le lendemain. Y ont été installées une tribune et la signalétique des Jeux qui ôtent un peu de solennité au lieu. Ce plan B fleure bon la série Z. Plan C : Thierry Reboul se retourne vers son acolyte, une lueur dans les yeux, à 20 heures : \"Et si on la faisait monter sur le Grand Palais dès maintenant ?\" La pluie n'a pas encore rendu le chemin vers le toit trop glissant, mais il faut que la diva accepte de poireauter une heure dans le vent et le crachin. \"Elle a dit oui !\", se félicite Thomas Jolly. \"C'est le genre de décisions qu'on a prises toute la soirée. Et on a sauvé 90% de la cérémonie.\"\n\nRémy Savary a le cœur qui bat la chamade dans son préfabriqué avec vue sur la Seine. Dix statues dorées, conçues et fabriquées par son entreprise CMDS Factory, doivent fendre les flots. Dix ? A l'écran, seules neuf apparaissent. \"Le réalisateur a zappé la n°4\", soupire le chef de projet. La caméra a dû filer au secours d'un cadreur qui ne pouvait pas passer un coup de torchon sur son objectif en plein direct. \"Mais au bruit, j'ai entendu les spectateurs saluer la sortie de Simone de Beauvoir.\"\n\nLes hélicoptères censés rythmer la séquence de plans aériens sont restés au sol, et ça fait dix minutes que défilent les drag-queens Paloma, Nicky Doll et Piche, entourées du chanteur Philippe Katerine badigeonné de bleu, dans le tableau conçu autour de la DJ Barbara Butch. En tribune, Emmanuel Macron sort son téléphone de sa poche. Texto de sa garde rapprochée : \"On a un sujet, là.\" Réponse du président : \"Non, liberté artistique.\"\n\nTableau 6 : \"Générosité\"\n\nSix talkies-walkies devant lui. Et pas un qui grésille alors que l'heure du top départ est sans doute passée. Les dernières consignes de Paris 2024 avant qu'il embarque sur son Zodiac étaient claires : \"Si vous êtes en retard de dix secondes sur le timing, vous ne passerez pas.\" Madeg Ciret-Le Cosquer ne barguigne pas : il prend sur lui de donner le go à la pilote Morgane Suquart, juchée à quelques encablures devant lui sur le cheval de fer. \"On lance à 60 km/h un bateau de deux tonnes à travers un rideau d'eau sans savoir ce qu'il y a derrière.\" Soixante kilomètres/heure ? Il y a prescription, maintenant : \"Sous le pont d'Austerlitz, elle a mis les gaz à deux fois la vitesse autorisée pour rattraper son retard.\"\n\nLa cavalière du cheval de fer, Morgane Suquard, sur la Seine lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (JARED C. TILTON / GETTY IMAGES EUROPE)\n\nLes doigts crispés sur le manche, l'étrier qui s'enfonce dans son ventre, le volontaire porteur du drapeau français, Pierre-Louis Tilly, n'oubliera jamais ses deux minutes trente de gloire. \"On s'était entraînés à marcher au pas cadencé tout l'après-midi, dix mètres derrière le cheval pour ne pas l'effrayer…\" Des consignes que les cadreurs d'OBS, la société de production des Jeux, n'ont pas reçues. \"A un moment, je vois un caméraman qui nous filme se fracasser sur un cheval de la garde républicaine. Catastrophe !\" Le choc est visible en direct, le technicien perd brièvement le contrôle de la caméra. \"Imaginez, si le cheval s'était emballé…\"\n\nLes porte-drapeaux des 205 pays participant aux Jeux de Paris défilent devant la tour Eiffel, le 26 juillet 2024. (GETTY IMAGES EUROPE)\n\n22h38. Tony Estanguet va monter sur scène. Il a fini par trouver la formule qui fait mouche pour évoquer cette fichue météo : \"Quand on aime les Jeux, on ne se laisse pas impressionner par quelques gouttes de pluie.\" A la télé, personne ne le remarque, mais son staff a planqué des fiches de secours partout, à l'intérieur et sous le pupitre. \"On avait un jeu de secours, et le jeu de secours du jeu de secours\", sourit Benjamin Brun, son conseiller.\n\nLe sèche-cheveux est une denrée rare sous cette tente, près de la tribune présidentielle, où Mélina Robert-Michon a trouvé refuge, juste avant de réciter le serment olympique.\n\n\"Et là, sur qui je tombe ? Nadia Comaneci, Serena Williams, Carl Lewis, Rafael Nadal… Tous sont en train de se sécher à l'aide de serviettes. Comme moi, ils sont TREM-PÉS.\" Mélina Robert-Michon, championne de lancer de disque à franceinfo\n\nTrop occupée à mendier un tee-shirt sec, la vice-championne olympique de Rio en 2016 ne fait pas le rapprochement. \"J'ai papoté avec Nadal, très sympa. Mais, vous n'allez pas me croire, je n'ai jamais pensé à lui demander pourquoi il était là.\"\n\nLui et ses compagnons montent dans un Zodiac qui file à toute vitesse sur la Seine. Si vite que la cadette des Williams semble tout près de rendre les petits fours qu'elle vient d'avaler. Impression trompeuse, dément Nadia Comaneci : \"Personne n'avait le mal de mer. Même Serena.\"\n\nDans le quartier du Louvre, les derniers porteurs de la flamme sont en place. Sauf une. Marie-José Pérec, en 20e et dernière position, sait qu'elle sera accompagnée d'un autre athlète pour l'allumage final. Mais qui donc ? \"Elle cherchait à savoir qui était son binôme, se souvient Emilie Le Pennec. Alors elle venait nous voir un par un : 'Tu as quel numéro ?'\" Equipée d'une oreillette, la gymnaste, n°11, \"attend le go\". La championne olympique d'Athènes saisit la torche, et fait quelques pas jusqu'à David Douillet, le porteur suivant…\n\nHors caméra, la bande du Louvre ne contient plus ses larmes. \"On ne l'a pas vu à la télé, mais après l'allumage de la vasque, on s'est tous serrés les uns contre les autres, confie Emilie Le Pennec. Laura Flessel pleurait, Amélie Mauresmo pleurait. On a fait plein de photos pour immortaliser ce moment.\"\n\nLaura Flessel, Marie-José Pérec, Emilie Le Pennec, Laure Manaudou et Allison Pineau posent pour un selfie en attendant de porter la flamme olympique, lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (EMILIE LE PENNEC)\n\n\"C'est génial ! J'avais pas tout saisi au début, mais maintenant, je comprends ta vision.\" Le créateur des Minions, Pierre Coffin, envoie ce texto à Thomas Jolly quand Teddy Riner et Marie-Jo Pérec embrasent la vasque. \"Attends, il y a un dernier truc\", lui répond, énigmatique, le grand ordonnateur de la cérémonie. \"Et dire que j'ai failli éteindre la télé à ce moment-là ! sourit le réalisateur. C'est quand même dingue qu'il trouve le temps de me répondre pendant la cérémonie…\"\n\nTableau 7 : \"Eternité\"\n\nUne minute avant la prise d'antenne, le préposé au parapluie quitte le champ de la scène où Céline Dion va se produire. Ça suffit à ce que le piano de Scott Price dégouline d'eau quand les lumières s'allument. \"Ce n'était rien à côté de ce qu'on avait eu comme vent la veille au soir, quand on a répété jusqu'à 2 heures du matin, confie le complice de la star québécoise. Elle tenait vraiment à participer, les Jeux représentent beaucoup pour elle. Il aurait neigé, elle aurait chanté quand même.\"\n\nCéline Dion et son pianiste Scott Price, au premier étage de la tour Eiffel, lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (GETTY IMAGES EUROPE)\n\nUn silence. Céline Dion, discrètement équipée d'un baudrier sous sa robe Dior, échange un regard avec Scott Price. \"L'orchestre était en bas de la tour Eiffel, on n'avait aucun retour. Et d'un coup, au loin, une clameur.\" 23h29. Le public salue le vibrato de la diva qui conclut la cérémonie. \"J'enlève le mode avion de mon téléphone, poursuit le directeur musical de la chanteuse. Des centaines de messages, dont certains de personnes à qui je n'avais plus parlé depuis des années. Comme on dit au Québec, elle avait 'livré la marchandise'.\"\n\n\"C'était bien, hein ?\" Une lueur de reconnaissance point dans les yeux du mari d'Anne-Marie, une fois le grand barnum achevé. \"Je n'ai rien osé lui dire, soupire la spectatrice. On a à peine vu quelques bateaux, le numéro raboté des gars du BMX, le cheval argenté en express, Nadal et ses amis sur leur Zodiac en plus des bouts de l'écran géant.\" Et monsieur n'est \"toujours pas\" au courant du prix de la soirée à 24 euros la minute.\n\n0h20. Dix minutes avant le bouclage, le directeur adjoint de la rédaction de L'Equipe, Jean-Philippe Leclaire, pense tenir sa une, une photo des porte-drapeaux tricolores, et son titre, \"Ça ira\". \"A ce moment-là, un collègue se pointe pour me montrer une autre photo sur son téléphone. 'Tu as vu celle-ci ? Elle circule pas mal sur Twitter.'\" Sur l'écran, les ombres miniatures de Marie-José Pérec et Teddy Riner qui se détachent sur le fond incandescent de la vasque tout juste allumée. \"On change tout !\" Titre compris. Direction l'imprimerie.\n\nLa une du journal \"L'Equipe\" du 27 juillet 2024, au lendemain de la cérémonie d'ouverture des Jeux de Paris. (L'EQUIPE)\n\nPour Franck Royer, qui chapeaute une armée de food-trucks et de restos éphémères, la cérémonie est loin d'être terminée. Maintenant que Céline Dion a lâché le micro, c'est l'heure de remballer. Des épreuves se déroulent près de la Seine dès le lendemain, notamment la course cycliste. \"Le démontage a duré trente-cinq heures d'affilée. On n'est rentrés à Lille que le mardi.\"\n\nC'est l'heure où le président de la République, débarrassé des mondanités, s'empresse de saluer les équipes dans le centre de commandement installé au Cese. Comme il le fait dans les vestiaires de foot ou de rugby, Emmanuel Macron écluse une bière en serrant les paluches. Gérald Darmanin, lui, reste à l'eau. \"Il savait que ce n'était que le début\", glisse son entourage.\n\nQuand vient l'heure d'organiser un débrief dans une pizzeria pour l'état-major de Paris 2024, pas mal de contraintes logistiques se dressent entre les corps fatigués et leur réconfort houblonné. \"On n'a pas pu aller dans un rade du Trocadéro à pied, sourit Bruno de Lavenère. On avait toutes les accréditations, mais les policiers ne voulaient rien savoir.\" La dizaine de convives commande donc… un taxi pour parcourir 500 mètres et ainsi déjouer la surveillance des pandores.\n\nVoir cette publication sur Instagram Une publication partagée par daphneburki (@daphneburki)\n\nAu comptoir, \"une petite bière, car malgré la chute brutale d'adrénaline, on savait que ce n'était pas fini.\" La cérémonie repasse sur les écrans. Thomas Jolly se retrouve à discuter avec d'autres clients noctambules : \"Ils nous ont demandé : 'Vous avez vu la cérémonie ?' On a répondu : 'Non, on l'a faite !' Ils ne m'ont pas cru. Je leur ai dit : \"tapez 'Thomas Jolly JO' sur Google !'\" \"On s'est quittés au moment de rejoindre les matinales radio, se souvient Patrick Boucheron. On a fait une nuit blanche, une de plus.\" Il est 5h32, Paris s'éveille encore.",
         "2025-07-26T05:00:37",
         "https://www.francetvinfo.fr/titres.rss",
         "https://www.franceinfo.fr/les-jeux-olympiques/ceremonies-d-ouverture-et-de-cloture/recit-on-n-a-fait-que-du-tetris-on-vous-raconte-l-histoire-secrete-de-la-ceremonie-d-ouverture-des-jeux-de-paris-un-an-apres_7365063.html#xtor=RSS-3-[lestitres]",
         "2025-07-26T05:53:42.336454",
         "Vous pensiez tout savoir du spectacle mis en scène par Thomas Jolly ? Détrompez-vous : Tony Estanguet, le pianiste de Céline Dion, le réalisateur des \"Minions\" et des dizaines d'acteurs moins connus de ce jour mémorable n'ont pas tout dit. Sauf à franceinfo. Les neuf tableaux de la cérémonie d'ouverture du 26 juillet 2024 sont le fruit d'années de travail : 160 caméras, 6 kilomètres de spectacle, 20 000 personnes mobilisées le jour J, dont 4 000 artistes, sur 3 000 m² de scènes, avec 85 bateaux sur la Seine. Un an après le début des Jeux olympiques de Paris, voici les coulisses du plus grand spectacle jamais réalisé en France, qui a captivé un milliard de personnes. Tableau 1 : \"Humidité\" Thomas Jolly part se coucher le cœur léger. Après avoir assisté aux ultimes répétitions de Céline Dion, l'homme-orchestre de la cérémonie a consulté une dernière fois l'appli météo de son téléphone. \"Des nuages, mais pas de pluie\", lui assure-t-elle. \"Je me suis dit : 'c'est top, c'est beau un coucher de soleil avec des nuages, un ciel zinzolin'...\" Le hic, c'est qu'il a conservé comme ville par défaut Rouen, là où habitent ses parents. Cinq heures, Paris s'éveille et le verdict tombe. Après avoir vérifié pour la millième fois les modèles météo, l'équipe de prévisionnistes de permanence assure que la soirée du 26 juillet sera arrosée. \"Les jours précédents, nos modèles nous assuraient une probabilité de 30% de pluie sur la soirée, ce qui n'était pas négligeable. Et ce chiffre n'a fait que monter au cours de la nuit\", résume Alexis Decalonne, du pôle sports de Météo-France. Décision est prise d'activer le plan pluie lors du briefing de 7 heures. Au palais de l'Elysée, les volets s'entrouvrent. Tasse de thé en main, Emmanuel Macron envoie quelques textos à ses interlocuteurs à Paris 2024. A Tony Estanguet, le président du comité d'organisation, \"Grosse journée !\" Au même moment, Philippe Frénoi serre le frein à main de son food-truck en face du Louvre. Le champion du monde de frites 2023 est parti dans la nuit de Linselles (Nord), anticipant bouchons et contrôles. Pourtant, lui et ses 800 kg de pommes de terre se posent quai François-Mitterrand comme une lettre à la poste. \"Pas un flic n'a même contrôlé mon QR code. Imaginez si j'avais planqué une bombe dans les patates ?\" \"En face de moi, des yeux baissés. Quelques larmes.\" Lourde tâche que celle d'Alexis Decalonne, qui présente ses cartes météo lors de la réunion de crise avec les équipes cornaquées par le patron des cérémonies de Paris 2024, Thierry Reboul, au Bourget. \"Tout le boulot va partir dans les égouts avec l'eau de pluie\", se lamente Jean-François Perfetti, le producteur exécutif. La cérémonie commence dans douze heures. \"C'est la fin du monde.\" Jean-François Perfetti, producteur exécutif de la cérémonie à franceinfo Coup de chaud aussi pour Pierre-Yves Guillerm. Le prévisionniste de Météo-France, qui s'occupe également de Roland-Garros, arrive en gare de Brest pour gagner la capitale. Il est attendu à 14h30. Sur les écrans de la SNCF, du rouge cramoisi. Une mystérieuse panne paralyse le réseau ferré. \"On s'est débrouillés.\" Tony Estanguet, briefé dès potron-minet, est l'invité de la matinale de France Inter et prépare les esprits au \"scénario catastrophe\" détaillé quelques minutes plus tôt par l'expert de Météo-France : \"J'annonce qu'il risque de pleuvoir un peu le soir...\" De retour à l'hôtel vers 9h30, le patron des Jeux peut souffler : enfin une bonne nouvelle ! Marie-Jo Pérec et Teddy Riner viennent d'accepter d'être les derniers porteurs de la flamme. Ils ont eu un petit indice. La veille au soir, le patron des Jeux leur avait envoyé un SMS sibyllin : \"On s'appelle demain matin.\" Tableau 2 : \"Formalités\" \"Qui a du scotch ?\" Le CIO, qui a débarqué au Conseil économique, social et environnemental (Cese) avec ses valises et ses exigences il y a quelques jours, poursuit son installation. Prière de masquer toutes les marques qui ne sponsorisent pas l'événement. La climatisation installée au plafond ? La marque des ascenseurs ? \"A cacher.\" Idem pour le distributeur de café, les téléviseurs des salles de réunion et même le presse-agrume de la cafétéria. Salim Akacem sèche. A dix heures de la parade, le drapeau sur le pont de son bateau, le Buci, amarré quai d'Ivry, ne lui dit rien. Du rouge, des sortes de vagues, un soleil… \"Les Kiribati\", lui souffle un officiel. \"Je ne savais même pas où c'était. J'ai dû chercher sur Google.\" Christine Bravo, elle, a \"chopé le gros lot\". Le capitaine du Frou Frou, son bateau, vient de l'informer : \"Ce sera la Syrie.\" L'animatrice télé bondit. \"Franchement, quelle chance j'avais de tomber sur un pays problématique ?\" \"La famille Assad va monter à bord !\" Christine Bravo, propriétaire du bateau de la délégation syrienne à franceinfo Pas tout à fait, mais des proches du régime, certains placés sous sanctions économiques, protégés par des hommes surarmés planqués dans la soute. \"Fallait que ça tombe sur moi.\" La délégation syrienne à bord du bateau\" Frou Frou\", appartenant à l'animatrice Christine Bravo, lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (GETTY IMAGES EUROPE) 13h26. Tranquillement posé dans la cuisine de son appartement parisien, Paul savoure en cliquant sur le bouton \"Poster\". Pour la photo, \"j'ai pris toutes les affaires que je pouvais dans mes placards, et même une boîte de cornichons pour brouiller les pistes\", se marre le coordinateur à Médecins du monde, engagé dans le collectif anti-JO Le Revers de la médaille. \"Ça m'a fait mourir de rire d'imaginer la réunion de crise. On m'a dit qu'ils allaient fouiller les catacombes au cas où des plongeurs se seraient cachés.\" @Paris2024 @Interieur_Gouv on vous confirme que le revers de la médaille sera présent au cœur de la cérémonie d'ouverture ce soir 😇🫡 Images à venir sur nos réseaux demain 👀 Petit aperçu du matériel nécessaire pour l'accomplissement de ce happening. Merci, à toute, bisous 😘 pic.twitter.com/WRdmJlx0PU — le revers de la médaille (@reversmedaille) July 26, 2024 Il n'est pas loin de la réalité : \"Ça faisait partie des scénarios que nous avions envisagés\", insiste l'entourage du ministre de l'Intérieur de l'époque, Gérald Darmanin. Tony Estanguet, lui, est déjà derrière son pupitre. La copie conforme de celui derrière lequel il posera ses fiches dans quelques heures. \"J'ai lu et relu mon discours des dizaines de fois, parfois changé une phrase, un mot. Je voulais qu'il soit le plus concis et le plus impactant possible.\" Au cours de cette session bachotage dans sa chambre d'hôtel, son conseiller spécial Benjamin Brun émet une suggestion : \"Tu devrais quand même ajouter une phrase sur la pluie.\" Tableau 3 : \"Fébrilité\" \"Houston, on a un problème.\" Le bateau qui supporte le cheval argenté ne peut pas accoster dans le 13e arrondissement, au point de rassemblement avant la cérémonie. La coque est trop basse et risque de passer sous le quai. \"Pas le choix, faut le tenir, sinon il se fracasse par-dessous\", soupire l'ingénieur Madeg Ciret-Le Cosquer. Pendant sept longues heures, son équipe se relaie, cordage à la main et les jambes tendues pour maintenir la coque à bonne distance. Le bateau soutenant le cheval de fer est maintenu à bout de jambes par les équipes de Madeg Ciret-Le Cosquer, quai d'Ivry, quelques heures avant le début de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (MADEG CIRET-LE COSQUER) 16h30, alerte générale chez Aéroports de Paris. Le gros-porteur de la compagnie French Bee qui doit décoller d'Orly pour Fort-de-France est planté sur le tarmac. Le voyant de la jauge du réservoir fait des siennes. La course contre la montre commence : le ciel parisien doit être désert à 18 heures. Sinon, il faudra héberger en urgence les 400 passagers… alors que les hôtels du secteur sont pris d'assaut. \"C'est un incident comme il en arrive tous les jours dans un aéroport\", tempère Perrine Duglet, directrice des opérations de Paris-Orly. \"Mais au pire moment.\" L'appareil décolle finalement trente minutes avant le gong. Le ciel a l'air d'être tombé sur la tête de Tony Estanguet. L'homme-sandwich des Jeux de Paris sait qu'il sera jugé sur la qualité du spectacle proposé ce soir. Celui qui ne se départit jamais de son sourire en public depuis sept ans est livide quand il arrive à l'Elysée pour rejoindre Emmanuel Macron et les chefs d'Etat qui vont assister à la cérémonie. \"Alors que les équipes mettaient toute leur énergie pour résoudre les problèmes, je devais jouer un rôle protocolaire, trépigne-t-il. C'était mon rôle. Mais c'était difficile. J'ai toujours préféré être dans l'action.\" Ce n'est que lorsqu'il découvre la haie de policiers, plantés tous les trois mètres le long des quatre kilomètres qui séparent le cortège officiel du Trocadéro, qu'il s'autorise une blague : \"On se croirait dans Star Wars.\" C'est le moment pour Lady Gaga et ses danseurs. Sur les marches glissantes des quais de Seine, la chanteuse commence à 17 heures. \"On a tourné sept fois la scène dans le créneau imparti, le plus vite possible\", souffle Jean-François Perfetti. Lancées en même temps, les séquences de BMX resteront, elles, à tout jamais dans un tiroir. Un problème de raccord entre le soleil de 17 heures et le déluge cinq heures après. \"Ça ne marchait pas\", soupire le directeur artistique de Paris 2024. \"On n'a fait que du Tetris. La seule chose dont on était à peu près sûrs, c'est que Céline Dion allait chanter, poursuit Jean-François Perfetti. On avait un début et une fin.\" Les danseurs sur les toits de Paris ? Trappés. Les drones et les hélicoptères ? Cloués au sol. \"On ne pouvait plus faire de 'beauty', de plan large de Paris. Il a fallu repenser le conducteur pour déterminer ce qu'on allait montrer à la place.\" Jean-François Perfetti, producteur exécutif de la cérémonie à franceinfo Encore une nouvelle version de la cérémonie, retravaillée en continu depuis trois ans. Le téléphone de l'Elysée chauffe. Le Qatar réclame une rallonge de sièges pour sa délégation en tribune officielle. C'est non, comme pour tous les demandeurs de dernière minute. Le plan de table a été finalisé la veille par le \"Château\", au prix de savants arbitrages diplomatiques. Dans le rush final, tout le monde se met au service du collectif. Atelier arts plastiques et loisirs créatifs pour Bruno de Lavenère, l'un des deux scénographes de la cérémonie. \"J'ai passé l'après-midi à chercher du tissu pour camoufler les bateaux. Ça ne se voit pas, mais on a fait cette cérémonie avec des bouts de ficelle. Cet ADN du bricolage, ça nous vient du théâtre, de l'univers de Thomas Jolly.\" Système D aussi pour Johan Tonnoir. Le champion de parkour est l'un des neuf mystérieux porteurs masqués, véritable fil rouge entre chaque tableau de la cérémonie le long de la Seine. Problème, une fine pellicule de pluie s'incruste sur la balustrade du Pont-Neuf, où il est censé sprinter. Hors de question de risquer la glissade. \"J'ai trouvé un bar, au coin de la rue sur le quai, et je leur ai emprunté un balai-brosse.\" Le porteur masqué de la flamme olympique court sur le Pont-Neuf lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (MADDIE MEYER / GETTY IMAGES EUROPE) La RATP a aussi briqué de fond en comble les rames de métro choisies pour la ligne éphémère Trocadéro-Etoile, un tronçon de la ligne 6 réservé aux VIP comme Serena Williams, Lilian Thuram ou Philippe Etchebest. \"Pas de tags, pas de fauteuil abîmé\", liste Pierre Guichard, le manager d'exploitation ferroviaire. Trafic fluide prévu tout au long de la soirée. \"Je m'étais dit : 'Tant pis, c'est une fois dans une vie.'\" Quand elle arrive sur son siège en tribune autour de 19 heures, Anne-Marie espère en avoir pour son argent. Cette cadre fondue des Jeux a acheté deux places en face du Grand Palais à 2 700 euros pièce. \"C'était le cadeau d'anniversaire de mon mari, et j'ai renoncé à en prendre pour les enfants.\" A ce tarif, des petits fours et un majordome en livrée jaune qui tient le parapluie ? \"Rien du tout, on était sous la flotte comme tout le monde, et on a payé à prix d'or un sandwich goût carton mouillé…\" Tableau 4 : \"Intensité\" Plus qu'un quart d'heure avant le début du show. Une chape de plomb s'abat sur le QG des têtes pensantes de la soirée. \"On n'arrivait même plus à se regarder, décrit le scénographe Bruno de Lavenère. On était terrorisés.\" Juste à côté, l'historien Patrick Boucheron annonce : \"Ce qu'on va voir, ce sera plus un plan A prime. Quelque chose qu'on va adapter au fur et à mesure. Mais on ne va pas faire le plan B.\" \"A 19h28, j'étais encore en train de danser avec le public. A 19h30, on me dit : 'On arrête tout'.\" La cérémonie commence à peine, mais pour Louis-Maël Bastié, elle est déjà finie. Son costume de Phryge, la mascotte des JO, n'est pas imperméable et est alimenté par une batterie pour son aération. \"C'était terriblement frustrant.\" Vous ne verrez jamais les huit Phryges censées animer les bords de Seine. La mascotte n'apparaîtra que quelques secondes à l'antenne… sur la séquence de Lady Gaga, enregistrée deux heures plus tôt. \"C'est mort.\" Les trombes d'eau douchent le moral de Franck Royer. Le patron de l'entreprise La Consignerie s'est démené pour dégoter en six semaines 80 stands, restaurants, brasseries et food-trucks, 600 chapiteaux et des groupes électrogènes, \"là où il aurait fallu neuf mois en temps normal\". Tout ça pour ça. \"Qui veut acheter des frites quand votre seule priorité, c'est de trouver un abri ? Cette cérémonie, on la rembourse encore.\" Un feu d'artifice bleu-blanc-rouge illumine le pont d'Austerlitz au début de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (KEVIN C. COX / GETTY IMAGES EUROPE) 20 heures. Le mystérieux porteur de flamme grimpe sur le toit de Notre-Dame. En surplomb, Quasimodo accroché à une girouette. Sous le costume, qui a reconnu Thomas Jolly en personne ? D'ailleurs, qui a reconnu sa voix annonçant les tableaux de la cérémonie ? Paris 2024 a tenté de la jouer à l'économie pour le buffet des grands de ce monde. L'Elysée a empêché in extremis qu'on serve des chips et des cacahuètes dans des assiettes en carton au gratin de la planète. Le buffet élyséen servi sous un barnum judicieusement placé, au pied de la tribune VIP, devient the place to be… Pour Aurélie Halbwachs, le dress code, c'était chemisette. La porte-drapeau mauricienne ne s'est pas réjouie longtemps de ce choix. \"On nous a distribué des K-Way qui ressemblaient à des sacs-poubelle.\" Tant pis, elle garde ses manches courtes jusqu'au bout. Une demi-heure plus tard, Florent Manaudou et Mélina Robert-Michon vont aussi regretter d'avoir dit non au poncho. \"On ne s'en rend pas compte à la télé, mais je vous promets, c'est le déluge, glisse la lanceuse de disque. A la toute fin, ça caillait. L'horreur.\" La lanceuse de disque Mélina Robert-Michon, porte-drapeau de l'équipe de France en compagnie de Florent Manaudou, pose sur le bateau des Bleus, lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (MELINA ROBERT-MICHON) \"Ah ça iraaaaaaaa !\" rugit Joseph Duplantier, le chanteur de Gojira. Des Marie-Antoinette à tête coupée surgissent des fenêtres de la Conciergerie. Initialement, elles devaient sortir de guillotines géantes dans des gerbes de sang… avant que l'Elysée ne mette le holà. Non qu'Emmanuel Macron craigne de froisser les têtes couronnées, mais l'équipe présidentielle martèle devant les équipes de Thomas Jolly sa volonté de trouver un équilibre sur chaque tableau. Et dire que ce numéro a failli passer à la trappe. Lors de l'ultime répétition, le courant de la Seine était tel que les bateaux se retrouvaient obligés de naviguer à 11 km/h au lieu des 9 initialement prévus. Conséquence : ils arrivaient 8 minutes en avance. \"On nous a demandé de réfléchir à quel tableau on pouvait couper, se remémore Patrick Boucheron. Parmi les artistes qui n'étaient pas habillés par LVMH, si possible. Ça mettait Gojira en tête de liste.\" Heureusement pour les fans de metal, tout rentre dans l'ordre le jour J. Perché à 34 mètres de haut, sur le toit de la Samaritaine, Nathan Paulin s'engage sur son fil de 350 mètres tendu jusqu'à la Monnaie de Paris. Vingt minutes d'équilibrisme avant que le funambule ne tombe de haut. \"Désolé, on ne t'a pas vu sur les écrans\", lui annonce son équipe. \"Ça a été une grosse déception.\" Débordée par la densité du spectacle, la réalisation n'a pas diffusé la séquence. Le funambule Nathan Paulin s'élance depuis la Samaritaine lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (MADDIE MEYER / GETTY IMAGES EUROPE) Tableau 5 : \"Ubiquité\" Dans la tribune officielle, tous les grands de ce monde sont rapatriés dans la partie abritée. Tous ? Trois irréductibles Gaulois continuent à se blottir sous leur cape de plastique pour tenter d'apercevoir la suite des festivités. Oubliés par le protocole, les trois anciens Premiers ministres Edouard Philippe, Jean Castex et Elisabeth Borne. Le maire du Havre envoie paître l'émissaire élyséen. \"Si le président voulait qu'on monte [dans la tribune abritée], il aurait envoyé quelqu'un nous chercher plus tôt !\" Il faudra qu'une de ses ex-collaboratrices, passée à l'Elysée, se déplace pour que le trio abandonne son siège. Ni vu, ni connu. Quelques invités de prestige s'éclipsent des gradins VIP. Amélie Mauresmo, Jean-François Lamour, Emilie Le Pennec… Evaporés dans des vans noirs. \"On a tracé dans les rues de Paris\", souffle la championne olympique de gymnastique. Direction le Louvre. Sans maîtrise, la puissance n'est rien, vantait une célèbre marque de pneus. Le slogan est aussi valable pour un champion de parkour par temps humide. \"J'ai testé le bois du pont des Arts mouillé avant mon entrée en scène\", raconte Maxence De Schrooder, l'un des neuf porteurs de flamme masqués. \"J'aurais aimé faire un salto avant, mais je n'ai pas pris le risque. C'était avant tout un tableau artistique, pas athlétique. J'avais l'obligation de finir mon numéro à la seconde près.\" Cérémonie d'ouverture des Jeux Olympiques de Paris 2024 présentée par Daphné Bürki, Laurent Delahousse et Alexandre Boyon depuis le Trocadéro et des envoyés spéciaux à Paris, en Île-de-France, sur le territoire, en Outre-mer et depuis les sites de compétition. 3min Aya Nakamura et la garde républicaine entament le duo le plus iconique de la cérémonie en reprenant du Aznavour. Dans le plan initial, l'interprète de Djadja enquillait ses tubes, mais l'Elysée s'en est mêlé : pourquoi Céline Dion et Lady Gaga sacrifieraient-elles au répertoire classique hexagonal et pas elle ? \"J'ai répondu au président que pour moi, ses titres faisaient déjà partie du patrimoine, vu que ce sont les chansons francophones les plus écoutées dans le monde\", nuance Thomas Jolly. Un compromis est trouvé in extremis avec un medley Pookie/For me formidable entré dans la légende. Le directeur artistique, qui a le dernier mot après consultation de l'Elysée, du CIO et de la Mairie de Paris, se rappelle une tenace rumeur de reprise d'Edith Piaf par Aya Nakamura. Il l'avait promise à Céline Dion. \"Je voulais la garder pour la fin.\" Le nageur Michael Phelps et le biathlète Martin Fourcade saluent le public sur une barge transportant des malles Vuitton, lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (VICTOR LOCHON / GAMMA-RAPHO / GETTY IMAGES) Sur une barge mobile, trois gigantesques malles Louis Vuitton, Martin Fourcade et Michael Phelps saluent la foule massée près de la Monnaie de Paris. On ne peut pas rater le monogramme, propriété de Bernard Arnault, principal mécène de la cérémonie. \"On nous parle beaucoup des ingérences politiques, constate Patrick Boucheron. A côté des exigences du CIO et de LVMH, ce n'était pas grand-chose.\" Les bagages devaient être lancés de danseur en danseur entre la Monnaie de Paris et la barge. Veto du leader mondial du luxe : \"Une malle Vuitton, ça ne se lance pas.\" Que le groupe se rassure, personne ne les loupera. \"Sur quatre heures de spectacle, une minute trente de pub, c'est un moindre mal\", observe Patrick Boucheron. Et plouf La Joconde ! Encore un coup des Minions, fleuron de l'animation tricolore. Pierre Coffin, leur créateur, a réalisé le film dans le plus grand secret. Un seul gag sera retoqué. Initialement, ces diables de petites bestioles jaunes traçaient une cible à la peinture sur le tableau de Léonard de Vinci. Un geste qui faisait un peu trop écho aux jets de soupe de militants écologistes sur des œuvres d'art. \"J'ai parfaitement compris, commente Pierre Coffin. Ma technique, c'est de forcer le trait jusqu'à ce qu'on me dise stop. Et cette fois, nous n'étions que trois dans la chaîne de décision. Le politiquement correct n'est jamais rentré en ligne de compte.\" Le bureau de Thomas Jolly au centre de commandement de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (THOMAS JOLLY / DR) Toute la soirée, Thomas Jolly et Thierry Reboul, casque sur les oreilles, micro allumé et paquet de bonbons comme unique réconfort, prennent arbitrage sur arbitrage. Comme pour la cantatrice Axelle Saint-Cirel, prévue pour chanter La Marseillaise sur le toit du Grand Palais. Vu la météo, on envisage le plan pluie : \"La rapatrier sur le pont Alexandre-III\", décrit Thomas Jolly. Le hic, c'est que le plus beau pont de Paris est prêt... pour les épreuves de triathlon le lendemain. Y ont été installées une tribune et la signalétique des Jeux qui ôtent un peu de solennité au lieu. Ce plan B fleure bon la série Z. Plan C : Thierry Reboul se retourne vers son acolyte, une lueur dans les yeux, à 20 heures : \"Et si on la faisait monter sur le Grand Palais dès maintenant ?\" La pluie n'a pas encore rendu le chemin vers le toit trop glissant, mais il faut que la diva accepte de poireauter une heure dans le vent et le crachin. \"Elle a dit oui !\", se félicite Thomas Jolly. \"C'est le genre de décisions qu'on a prises toute la soirée. Et on a sauvé 90% de la cérémonie.\" Rémy Savary a le cœur qui bat la chamade dans son préfabriqué avec vue sur la Seine. Dix statues dorées, conçues et fabriquées par son entreprise CMDS Factory, doivent fendre les flots. Dix ? A l'écran, seules neuf apparaissent. \"Le réalisateur a zappé la n°4\", soupire le chef de projet. La caméra a dû filer au secours d'un cadreur qui ne pouvait pas passer un coup de torchon sur son objectif en plein direct. \"Mais au bruit, j'ai entendu les spectateurs saluer la sortie de Simone de Beauvoir.\" Les hélicoptères censés rythmer la séquence de plans aériens sont restés au sol, et ça fait dix minutes que défilent les drag-queens Paloma, Nicky Doll et Piche, entourées du chanteur Philippe Katerine badigeonné de bleu, dans le tableau conçu autour de la DJ Barbara Butch. En tribune, Emmanuel Macron sort son téléphone de sa poche. Texto de sa garde rapprochée : \"On a un sujet, là.\" Réponse du président : \"Non, liberté artistique.\" Tableau 6 : \"Générosité\" Six talkies-walkies devant lui. Et pas un qui grésille alors que l'heure du top départ est sans doute passée. Les dernières consignes de Paris 2024 avant qu'il embarque sur son Zodiac étaient claires : \"Si vous êtes en retard de dix secondes sur le timing, vous ne passerez pas.\" Madeg Ciret-Le Cosquer ne barguigne pas : il prend sur lui de donner le go à la pilote Morgane Suquart, juchée à quelques encablures devant lui sur le cheval de fer. \"On lance à 60 km/h un bateau de deux tonnes à travers un rideau d'eau sans savoir ce qu'il y a derrière.\" Soixante kilomètres/heure ? Il y a prescription, maintenant : \"Sous le pont d'Austerlitz, elle a mis les gaz à deux fois la vitesse autorisée pour rattraper son retard.\" La cavalière du cheval de fer, Morgane Suquard, sur la Seine lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (JARED C. TILTON / GETTY IMAGES EUROPE) Les doigts crispés sur le manche, l'étrier qui s'enfonce dans son ventre, le volontaire porteur du drapeau français, Pierre-Louis Tilly, n'oubliera jamais ses deux minutes trente de gloire. \"On s'était entraînés à marcher au pas cadencé tout l'après-midi, dix mètres derrière le cheval pour ne pas l'effrayer…\" Des consignes que les cadreurs d'OBS, la société de production des Jeux, n'ont pas reçues. \"A un moment, je vois un caméraman qui nous filme se fracasser sur un cheval de la garde républicaine. Catastrophe !\" Le choc est visible en direct, le technicien perd brièvement le contrôle de la caméra. \"Imaginez, si le cheval s'était emballé…\" Les porte-drapeaux des 205 pays participant aux Jeux de Paris défilent devant la tour Eiffel, le 26 juillet 2024. (GETTY IMAGES EUROPE) 22h38. Tony Estanguet va monter sur scène. Il a fini par trouver la formule qui fait mouche pour évoquer cette fichue météo : \"Quand on aime les Jeux, on ne se laisse pas impressionner par quelques gouttes de pluie.\" A la télé, personne ne le remarque, mais son staff a planqué des fiches de secours partout, à l'intérieur et sous le pupitre. \"On avait un jeu de secours, et le jeu de secours du jeu de secours\", sourit Benjamin Brun, son conseiller. Le sèche-cheveux est une denrée rare sous cette tente, près de la tribune présidentielle, où Mélina Robert-Michon a trouvé refuge, juste avant de réciter le serment olympique. \"Et là, sur qui je tombe ? Nadia Comaneci, Serena Williams, Carl Lewis, Rafael Nadal… Tous sont en train de se sécher à l'aide de serviettes. Comme moi, ils sont TREM-PÉS.\" Mélina Robert-Michon, championne de lancer de disque à franceinfo Trop occupée à mendier un tee-shirt sec, la vice-championne olympique de Rio en 2016 ne fait pas le rapprochement. \"J'ai papoté avec Nadal, très sympa. Mais, vous n'allez pas me croire, je n'ai jamais pensé à lui demander pourquoi il était là.\" Lui et ses compagnons montent dans un Zodiac qui file à toute vitesse sur la Seine. Si vite que la cadette des Williams semble tout près de rendre les petits fours qu'elle vient d'avaler. Impression trompeuse, dément Nadia Comaneci : \"Personne n'avait le mal de mer. Même Serena.\" Dans le quartier du Louvre, les derniers porteurs de la flamme sont en place. Sauf une. Marie-José Pérec, en 20e et dernière position, sait qu'elle sera accompagnée d'un autre athlète pour l'allumage final. Mais qui donc ? \"Elle cherchait à savoir qui était son binôme, se souvient Emilie Le Pennec. Alors elle venait nous voir un par un : 'Tu as quel numéro ?'\" Equipée d'une oreillette, la gymnaste, n°11, \"attend le go\". La championne olympique d'Athènes saisit la torche, et fait quelques pas jusqu'à David Douillet, le porteur suivant… Hors caméra, la bande du Louvre ne contient plus ses larmes. \"On ne l'a pas vu à la télé, mais après l'allumage de la vasque, on s'est tous serrés les uns contre les autres, confie Emilie Le Pennec. Laura Flessel pleurait, Amélie Mauresmo pleurait. On a fait plein de photos pour immortaliser ce moment.\" Laura Flessel, Marie-José Pérec, Emilie Le Pennec, Laure Manaudou et Allison Pineau posent pour un selfie en attendant de porter la flamme olympique, lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (EMILIE LE PENNEC) \"C'est génial ! J'avais pas tout saisi au début, mais maintenant, je comprends ta vision.\" Le créateur des Minions, Pierre Coffin, envoie ce texto à Thomas Jolly quand Teddy Riner et Marie-Jo Pérec embrasent la vasque. \"Attends, il y a un dernier truc\", lui répond, énigmatique, le grand ordonnateur de la cérémonie. \"Et dire que j'ai failli éteindre la télé à ce moment-là ! sourit le réalisateur. C'est quand même dingue qu'il trouve le temps de me répondre pendant la cérémonie…\" Tableau 7 : \"Eternité\" Une minute avant la prise d'antenne, le préposé au parapluie quitte le champ de la scène où Céline Dion va se produire. Ça suffit à ce que le piano de Scott Price dégouline d'eau quand les lumières s'allument. \"Ce n'était rien à côté de ce qu'on avait eu comme vent la veille au soir, quand on a répété jusqu'à 2 heures du matin, confie le complice de la star québécoise. Elle tenait vraiment à participer, les Jeux représentent beaucoup pour elle. Il aurait neigé, elle aurait chanté quand même.\" Céline Dion et son pianiste Scott Price, au premier étage de la tour Eiffel, lors de la cérémonie d'ouverture des Jeux de Paris, le 26 juillet 2024. (GETTY IMAGES EUROPE) Un silence. Céline Dion, discrètement équipée d'un baudrier sous sa robe Dior, échange un regard avec Scott Price. \"L'orchestre était en bas de la tour Eiffel, on n'avait aucun retour. Et d'un coup, au loin, une clameur.\" 23h29. Le public salue le vibrato de la diva qui conclut la cérémonie. \"J'enlève le mode avion de mon téléphone, poursuit le directeur musical de la chanteuse. Des centaines de messages, dont certains de personnes à qui je n'avais plus parlé depuis des années. Comme on dit au Québec, elle avait 'livré la marchandise'.\" \"C'était bien, hein ?\" Une lueur de reconnaissance point dans les yeux du mari d'Anne-Marie, une fois le grand barnum achevé. \"Je n'ai rien osé lui dire, soupire la spectatrice. On a à peine vu quelques bateaux, le numéro raboté des gars du BMX, le cheval argenté en express, Nadal et ses amis sur leur Zodiac en plus des bouts de l'écran géant.\" Et monsieur n'est \"toujours pas\" au courant du prix de la soirée à 24 euros la minute. 0h20. Dix minutes avant le bouclage, le directeur adjoint de la rédaction de L'Equipe, Jean-Philippe Leclaire, pense tenir sa une, une photo des porte-drapeaux tricolores, et son titre, \"Ça ira\". \"A ce moment-là, un collègue se pointe pour me montrer une autre photo sur son téléphone. 'Tu as vu celle-ci ? Elle circule pas mal sur Twitter.'\" Sur l'écran, les ombres miniatures de Marie-José Pérec et Teddy Riner qui se détachent sur le fond incandescent de la vasque tout juste allumée. \"On change tout !\" Titre compris. Direction l'imprimerie. La une du journal \"L'Equipe\" du 27 juillet 2024, au lendemain de la cérémonie d'ouverture des Jeux de Paris. (L'EQUIPE) Pour Franck Royer, qui chapeaute une armée de food-trucks et de restos éphémères, la cérémonie est loin d'être terminée. Maintenant que Céline Dion a lâché le micro, c'est l'heure de remballer. Des épreuves se déroulent près de la Seine dès le lendemain, notamment la course cycliste. \"Le démontage a duré trente-cinq heures d'affilée. On n'est rentrés à Lille que le mardi.\" C'est l'heure où le président de la République, débarrassé des mondanités, s'empresse de saluer les équipes dans le centre de commandement installé au Cese. Comme il le fait dans les vestiaires de foot ou de rugby, Emmanuel Macron écluse une bière en serrant les paluches. Gérald Darmanin, lui, reste à l'eau. \"Il savait que ce n'était que le début\", glisse son entourage. Quand vient l'heure d'organiser un débrief dans une pizzeria pour l'état-major de Paris 2024, pas mal de contraintes logistiques se dressent entre les corps fatigués et leur réconfort houblonné. \"On n'a pas pu aller dans un rade du Trocadéro à pied, sourit Bruno de Lavenère. On avait toutes les accréditations, mais les policiers ne voulaient rien savoir.\" La dizaine de convives commande donc… un taxi pour parcourir 500 mètres et ainsi déjouer la surveillance des pandores. Voir cette publication sur Instagram Une publication partagée par daphneburki (@daphneburki) Au comptoir, \"une petite bière, car malgré la chute brutale d'adrénaline, on savait que ce n'était pas fini.\" La cérémonie repasse sur les écrans. Thomas Jolly se retrouve à discuter avec d'autres clients noctambules : \"Ils nous ont demandé : 'Vous avez vu la cérémonie ?' On a répondu : 'Non, on l'a faite !' Ils ne m'ont pas cru. Je leur ai dit : \"tapez 'Thomas Jolly JO' sur Google !'\" \"On s'est quittés au moment de rejoindre les matinales radio, se souvient Patrick Boucheron. On a fait une nuit blanche, une de plus.\" Il est 5h32, Paris s'éveille encore.",
         "fr",
         "{'PER': ['Alexandre Boyon', 'Alexis Decalonne', 'Allison Pineau', 'Amélie Mauresmo', 'Anne-Marie', 'Assad', 'Aurélie Halbwachs', 'Axelle Saint-Cirel', 'Aya Nakamura', 'Barbara Butch', 'Benjamin Brun', 'Bernard Arnault', 'Bruno de Lavenère', 'Carl Lewis', 'Christine Bravo', 'Cloués', 'Céline Dion', 'Daphné Bürki', 'David Douillet', 'Edith Piaf', 'Edouard Philippe', 'Elisabeth Borne', 'Emilie Le Pennec', 'Emmanuel Macron', 'Eternité', 'Florent Manaudou', 'Franck Royer', 'François-Mitterrand', 'Frou Frou', 'Gérald Darmanin', 'J. Perché', 'Jean Castex', 'Jean-François Lamour', 'Jean-François Perfetti', 'Jean-Philippe Leclaire', 'Johan Tonnoir', 'Joseph Duplantier', 'KEVIN C. COX', 'La Joconde', 'Lady Gaga', 'Laura Flessel', 'Laure Manaudou', 'Laurent Delahousse', 'Lilian Thuram', 'Louis Vuitton', 'Louis-Maël Bastié', 'Léonard de Vinci', 'MADDIE MEYER', 'Madeg Ciret-Le Cosquer', 'Marie-Antoinette', 'Marie-Jo Pérec', 'Marie-José Pérec', 'Martin Fourcade', 'Maxence De Schrooder', 'Michael Phelps', 'Morgane Suquard', 'Morgane Suquart', 'Mélina Robert-Michon', 'Nadal', 'Nadia Comaneci', 'Nathan Paulin', 'Patrick Boucheron', 'Paul', 'Perrine Duglet', 'Philippe Etchebest', 'Philippe Frénoi', 'Philippe Katerine', 'Pierre Coffin', 'Pierre Guichard', 'Pierre-Louis Tilly', 'Pierre-Yves Guillerm', 'Quasimodo', 'Rafael Nadal', 'Roland-Garros', 'Rémy Savary', 'Salim Akacem', 'Scott Price', 'Serena', 'Serena Williams', 'Simone de Beauvoir', 'Teddy Riner', 'Thierry Reboul', 'Thomas Jolly', 'Thomas Jolly JO', 'Tony Estanguet', 'Vuitton', 'Williams', 'daphneburki', 'président de la République'], 'MISC': ['Aznavour', 'CIO', 'CMDS Factory', 'Catastrophe !', 'Cérémonie', 'Dior', 'Djadja', 'Désolé', 'EMILIE LE PENNEC', 'GETTY IMAGES', 'Google !', 'Images', 'Impression trompeuse', 'J', 'JARED', 'JO', 'Jeux', 'Jeux Olympiques de Paris 2024', 'Jeux de Paris', 'Jeux olympiques de Paris', 'K-Way', 'La Marseillaise', 'Le Revers de la médaille', 'Minions', 'Nicky Doll', 'OBS', 'Paloma', 'Phryges', 'Piche', 'Pookie/For me formidable', 'Poster', 'Premiers', 'QR', 'SMS', 'Star Wars', 'Système D', 'THOMAS', 'TILTON', 'Tetris', 'Texto', 'Tu as quel numéro', 'Tu as vu celle-ci ?', 'Twitter', 'VICTOR LOCHON / GAMMA-RAPHO', 'Vuitton, ça', 'Z. Plan C', 'Zodiac', \"championne olympique d'Athènes\", 'franceinfo Coup de chaud', 'the place to be…', 'Ça', '👀 Petit aperçu du matériel nécessaire'], 'ORG': ['Aéroports de Paris', 'Bleus', 'Cese', 'Conseil économique, social et environnemental', 'DR', 'EQUIPE', 'EUROPE', 'French Bee', 'Fébrilité', 'Gojira', 'Google', \"L'Equipe\", 'LVMH', 'La', 'MADEG CIRET-LE COSQUER', 'MELINA', 'Médecins du monde', 'Météo-France', 'RATP', 'SNCF', 'TREM', 'VIP', 'anti-JO', 'franceinfo', 'franceinfo Encore', 'franceinfo Pas', 'franceinfo Trop', \"ministre de l'Intérieur\"], 'LOC': ['@daphneburki', '@reversmedaille', 'A prime', 'Bourget', 'Conciergerie', 'Consignerie', 'Direction le Louvre', 'Equipée', 'Etat', 'Formalités', 'Fort-de-France', 'France', 'Gaulois', 'Grand Palais', 'Houston', 'Instagram', 'Intensité', 'Ivry', 'Kiribati', \"L'Elysée\", 'Lille', 'Louvre', 'Monnaie de Paris', 'Météo-France', 'Nord', 'Notre-Dame', 'Outre-mer', 'Paris', 'Paris-Orly', 'Phryge', 'Pont-Neuf', 'Qatar', 'Québec', 'ROBERT-MICHON', 'Rio', 'Rouen', 'Samaritaine', 'Seine', 'Syrie', 'Trappés', 'Trocadéro', 'Ubiquité', 'bande du Louvre', 'courant de la Seine', \"d'Orly\", 'de France', 'de France Inter', 'du Havre', 'gare de Brest', \"l'Elysée\", 'la Seine', 'le Pont-Neuf', 'nuit de Linselles', \"palais de l'Elysée\", 'pont Alexandre-III', \"pont d'Austerlitz\", 'pont des Arts mouillé', 'quartier du Louvre', 'tour Eiffel', 'Île-de-France']}",
         "[-0.0072211455553770065, 0.07925660908222198, 0.03234801068902016, -0.07777257263660431, 0.00722877262160182, 0.06814240664243698, 0.11341822147369385, 0.04178429767489433, 0.018265582621097565, -0.018107907846570015, -0.011464286595582962, -0.05110103264451027, 0.026483571156859398, 0.02528325840830803, -0.039128098636865616, -0.07833626121282578, -0.010262858122587204, 0.03139821067452431, 0.017556102946400642, 0.10913203656673431, 0.05348533019423485, -0.13416248559951782, -0.013240196742117405, -0.024967309087514877, -0.02881230227649212, -0.004582103807479143, -0.03991127759218216, -0.054209157824516296, 0.013562961481511593, -0.021765438839793205, 0.0258882287889719, 0.042338497936725616, -0.022260183468461037, -0.006789932493120432, 0.0020114353392273188, -0.009916098788380623, 0.025295397266745567, -0.08234623819589615, -0.02257465198636055, 0.07695929706096649, -0.020841402933001518, 0.043442655354738235, -0.1613001823425293, 0.009322096593677998, -0.010224289260804653, -0.023741908371448517, -0.03670668974518776, -0.015597568824887276, -0.0922149270772934, 0.019235234707593918, -0.13622793555259705, 0.05609565228223801, 0.0704585462808609, -0.05703926458954811, -0.03639397770166397, -0.060952432453632355, 0.016884509474039078, 0.008883769623935223, 0.13271315395832062, -0.015121891163289547, 0.006547537632286549, -0.06655913591384888, 0.042344432324171066, 0.004372871946543455, -0.02434401586651802, -0.06107837334275246, -0.0537286214530468, -0.08423244953155518, 0.0021637678146362305, 0.020870426669716835, 0.013192076236009598, 0.01332575362175703, -0.0031422413885593414, -0.046273428946733475, -0.037023887038230896, -0.012750412337481976, -0.10313666611909866, -0.036251772195100784, -0.08484921604394913, -0.08384262025356293, 0.13375070691108704, -0.03060264326632023, -0.015976879745721817, 0.0009232632583007216, -0.019077613949775696, 0.009736325591802597, -0.00088786258129403, 0.030548295006155968, -0.014295241795480251, -0.03937891498208046, -0.07642923295497894, 0.02060684934258461, -0.14548563957214355, 0.003916942980140448, 0.029977139085531235, -0.07956946641206741, 0.022648096084594727, -0.019768185913562775, 0.03756990656256676, 0.04693342372775078, 0.033016663044691086, 0.022738855332136154, 0.07320928573608398, 0.07206974923610687, -0.0029870455618947744, -0.031391534954309464, -0.0033397753722965717, -0.027309773489832878, -0.021213656291365623, -0.009560205973684788, -0.019485536962747574, 0.05138903483748436, 0.021102817729115486, -0.04380745813250542, 0.012053292244672775, -0.027945267036557198, -0.03975257650017738, -0.04341898858547211, 0.02599227800965309, 0.01824701577425003, 0.1522843837738037, 0.012845789082348347, 0.02527223341166973, 0.009430667385458946, -0.011025863699615002, 8.373597665922716e-05, 0.044845931231975555, 1.7159604985810695e-32, 0.03489697352051735, 0.07225007563829422, 0.02832420915365219, 0.011038662865757942, 0.06783134490251541, -0.013751921243965626, -0.027034521102905273, 0.08125901967287064, -0.0003502864274196327, -0.029251914471387863, -0.016921691596508026, 0.007050269283354282, -0.04179230332374573, 0.03530764579772949, 0.021127454936504364, 0.0011384935351088643, 0.09187308698892593, -0.009625484235584736, 0.01592591032385826, -0.041852470487356186, -0.07387838512659073, 0.017040496692061424, 0.029651150107383728, 0.10779894888401031, -0.057784393429756165, 0.07300508767366409, 0.02781013958156109, -0.03849881514906883, -0.028571205213665962, 0.036786071956157684, 0.034634094685316086, -0.011083453893661499, 0.04640983045101166, 0.02295392006635666, 0.06687315553426743, -0.04296639561653137, -0.05075788497924805, -0.005603714846074581, 0.007395142689347267, -0.007740366272628307, 0.006162466946989298, 0.02447352185845375, 0.03086317703127861, -0.026913218200206757, -0.10427450388669968, 0.05182228237390518, 0.01948128640651703, 0.09035403281450272, 0.02944711036980152, -0.0032255714759230614, -0.004494261462241411, 0.023049360141158104, -0.11068836599588394, -0.05381699651479721, 0.0030586037319153547, -0.015181256458163261, -0.07768936455249786, -0.05805622413754463, -0.04422978684306145, -0.02861350029706955, 0.08242442458868027, -0.0221023578196764, -0.010094145312905312, 0.02365865930914879, -0.02954970858991146, -0.02450457401573658, -0.042158033698797226, 0.02751224674284458, 0.010000022128224373, -0.0055215866304934025, -0.07172688096761703, 0.010693464428186417, 0.04680200666189194, -0.046179305762052536, 0.10010600090026855, 0.064409539103508, 0.0187927708029747, 0.0017981878481805325, -0.10124826431274414, -0.0030232847202569246, -0.12167181819677353, 0.018963560461997986, -0.0155158257111907, -0.03242005780339241, -0.04631618410348892, -0.04591698572039604, 0.05524752661585808, 0.01577247492969036, -0.054453082382678986, 0.0630522146821022, -0.04227475821971893, -0.04140341654419899, -0.013876733370125294, -0.04658854007720947, -0.07894352078437805, -1.7879745151219076e-32, -0.01684277132153511, 0.018669618293642998, 0.015311767347157001, 0.03732864931225777, -0.003484354354441166, 0.009832763113081455, 0.028910716995596886, 0.07364542782306671, 0.019430287182331085, -0.02751205302774906, -0.06251916289329529, -0.038952331990003586, 0.006746831350028515, -0.06846262514591217, -0.021831529214978218, 0.12891508638858795, 0.015550174750387669, -0.020392104983329773, -0.0377458892762661, 0.015593711286783218, -0.008836736902594566, -0.0267660953104496, 0.039172977209091187, -0.04014144465327263, -0.07512805610895157, 0.10387881100177765, 0.06689809262752533, -0.047600727528333664, -0.0719989687204361, 0.007125666365027428, 0.0390881709754467, 0.026036741212010384, -0.02250092290341854, 0.07155608385801315, 0.018456771969795227, 0.09249882400035858, 0.046343740075826645, -0.00901497807353735, -0.036534760147333145, 0.051470544189214706, -0.03467898070812225, -0.017252812162041664, 0.019631117582321167, 0.03274701535701752, 0.08914385735988617, -0.04477434232831001, -0.06345821171998978, -0.0355098582804203, -0.04046812653541565, -0.025696147233247757, -0.048313986510038376, 0.036136168986558914, -0.06561741977930069, -0.0033562935423105955, -0.0514613501727581, -0.02848799154162407, -0.019969962537288666, -0.018200820311903954, -0.019443457946181297, -0.0018536456627771258, 0.08456213027238846, 0.06793125718832016, -0.037487320601940155, -0.027592815458774567, 0.04843722656369209, -0.0343354307115078, -0.05092686042189598, 0.06341071426868439, -0.0019743742886930704, 0.01078111957758665, 0.10502621531486511, 0.0008552141371183097, 0.008574997074902058, -0.0021008679177612066, -0.06791575253009796, 0.020376132801175117, -0.02799973450601101, 0.04653454199433327, -1.708093986962922e-05, 0.07056821882724762, -0.0907081738114357, 0.037064455449581146, -0.020845353603363037, -0.02144552767276764, -0.025604501366615295, 0.06841076165437698, -0.0006693524774163961, -0.04874447360634804, -0.050917573273181915, -0.02808116190135479, 0.008752603083848953, 0.08311948925256729, -0.0230813417583704, -0.0005080250557512045, 0.092530257999897, -7.712896632483535e-08, -0.020422356203198433, -0.033193446695804596, -0.056218940764665604, -0.03193989768624306, 0.016076209023594856, -0.17883425951004028, -0.07165204733610153, 0.05773739144206047, -0.04241492971777916, 0.008200384676456451, 0.014917734079062939, -0.0281322430819273, 0.016722604632377625, -0.026339305564761162, -0.030519912019371986, 0.0072211213409900665, 0.03571518883109093, 0.03060753270983696, -0.03254286199808121, 0.07263372838497162, 0.013076775707304478, -0.017346657812595367, 0.0345294326543808, -0.10608936101198196, -0.11509562283754349, -0.06304724514484406, -0.049510806798934937, -0.11397062242031097, 0.01869150437414646, -0.06959203630685806, 0.06444165855646133, 0.06052093207836151, 0.0031006312929093838, -0.0665440559387207, -0.016094684600830078, -0.05982024222612381, -0.062129564583301544, -0.01930566132068634, -0.042038436979055405, 0.04527893289923668, 0.07713949680328369, -0.04602368548512459, -0.0073564122430980206, 0.018780222162604332, 0.06394599378108978, -0.018808338791131973, 0.017550762742757797, -0.04766101762652397, 0.01564507558941841, 0.12723173201084137, -0.102840855717659, 0.025106647983193398, -0.015688138082623482, 0.07419470697641373, -0.02189524471759796, -0.09073886275291443, 0.011478067375719547, 0.058707837015390396, -0.003894063411280513, -0.019518978893756866, -0.02286705933511257, 0.08278526365756989, -0.021913232281804085, -0.01872066594660282]",
         "0.179"
        ],
        [
         "4",
         "578",
         "How Not to Mislead with Your Data-Driven Story",
         "Data storytelling can enlighten—but it can also deceive. When persuasive narratives meet biased framing, cherry-picked data, or misleading visuals, insights risk becoming illusions. This article explores the hidden biases embedded in data-driven storytelling—from the seduction of beautiful charts to the quiet influence of AI-generated insights—and offers practical strategies to tell stories that are not only compelling, but also credible, transparent, and grounded in truth. The post How Not to Mislead with Your Data-Driven Story appeared first on Towards Data Science .",
         "is everywhere. There are countless books, articles, tutorials, and videos, some of which I have written or created.\n\n\n\nIn my experience, most of these resources tend to present data storytelling in an overwhelmingly positive light. But lately, one concern has been on my mind:\n\nWhat if our stories, instead of clarifying, mislead?\n\nImage 1. Change the perspective, and you see an entirely different story. Photos by the author\n\nThe image above shows one of the apartment buildings in my neighborhood. Now, take a look at the photo on the left and imagine one of the apartments in the white building is up for sale. You are considering buying it. You would likely focus on the immediate surroundings, especially as presented in the seller’s photos. Notice anything unusual? Probably not, at least not right away.\n\nShould the immediate setting be a dealbreaker? In my opinion, not necessarily. It’s not the most picturesque or charming spot—just a typical block in an average neighborhood in Warsaw. Or is it?\n\nLet’s take a short walk around to the back of the building. And… surprise: there’s a public lavatory right there. Still feel good about the location? Maybe yes, maybe no. One thing is clear: you would want to know that a public toilet sits just below your future balcony.\n\nAdditionally, the apartment is located in the lower part of the building, while the rest of the towers rise above it. This is another factor that may be significant. Both these “issues” for sure can be brought up in price negotiations.\n\nThis simple example illustrates how easily stories (in this case, using photos) can be misinterpreted. From one angle, everything looks fine, even inviting. Take a few steps to the right, and… whoops.\n\nThe same situation can happen in our “professional” lives. What if audiences, convinced they’re making informed, data-backed decisions, are being subtly steered in the wrong direction—not by false data, but by the way it’s presented?\n\nThis post builds on an article I wrote in 2024 about misleading visualizations [1]. Here, I want to take a bit broader perspective, exploring how the structure and flow of a story itself can unintentionally (or deliberately) lead people to incorrect conclusions, and how we can avoid that.\n\nData storytelling is subjective\n\nWe often like to believe that “data speaks for itself.” But in reality, it rarely does. Every chart, dashboard, or headline built around a dataset is shaped by human choices:\n\nwhat to include,\n\nwhat to leave out,\n\nhow to frame the message?\n\nThis highlights a core challenge of data-driven storytelling: it’s inherently subjective. That subjectivity comes from the discretion we have in proving the point we want to make:\n\nchoosing which data to present,\n\nselecting appropriate analysis technique,\n\ndeciding on arguments to emphasise,\n\nand even what to to use.\n\nSubjectivity also lies in interpretation — both ours and our audience’s — and in their willingness to act on the information. This opens the door to biases. If we are not careful, we can easily cross the line from subjectivity into unethical storytelling.\n\nThis article examines the hidden biases embedded in data storytelling and how we can transition from manipulation to meaningful insights.\n\nWe need stories\n\nSubjective or not, we need stories. Stories are essential to us because they help make sense of the world. They carry our values, preserve our history, and spark our imagination. Through stories, we connect with others, learn from past experiences, and explore what it means to be human. No matter your nationality, culture, or religion, we have all heard countless stories that have shaped us. Told us by our grandparents, parents, teachers, friends, and colleagues at work. Stories evoke emotion, inspire action, and shape our identity, both individually and collectively. In every culture and across every age, storytelling has been a powerful means of understanding life, sharing knowledge, and building community.\n\nBut while stories can enlighten, they can also mislead. A compelling narrative has the power to shape perception, even when it distorts facts or oversimplifies complex issues. Stories often rely on emotion, selective detail, and a clear message, which can make them persuasive, but also dangerously reductive. When used carelessly or manipulatively, storytelling can reinforce biases, obscure truth, or drive decisions based more on feeling than reason.\n\nIn the next part of this article, I’ll explore the potential problems with stories — especially in data-driven contexts — and how their power can unintentionally (or intentionally) misguide our understanding.\n\nImage 2. Stories have always been an essential part of our lives. Image generated by the author in ChatGPT.\n\nNarrative biases in data-driven storytelling\n\nBias 1. Data is far, far away from interpretation\n\nHere’s an example of a visual from a report titled “Kentucky Juvenile Justice Reform Evaluation: Assessing the Effects of SB 200 on Youth Dispositional Outcomes and Racial and Ethnic Disparities.”\n\nImage 3. Image from “Kentucky Juvenile Justice Reform Evaluation…”, page 18 of the report.\n\nThe graph shows that young offenders in Kentucky are less likely to reoffend if, after their first offense, they are routed through a diversion program. This program connects them with community support, such as social workers and therapists, to address deeper life challenges. That’s a powerful narrative with real-world implications: it supports reducing our reliance on an expensive criminal justice system, justifies increased funding for non-profits, and points toward meaningful ways to improve lives.\n\nBut here’s the problem: unless you already have strong data literacy and subject knowledge, those conclusions are not immediately obvious from the graph. While the report does make this point, it doesn’t do so until nearly 20 pages later. This is a classic example of how the structure of academic reporting can mute the story’s impact. It results from the fact that data is presented visually in one section and interpreted textually in different (and sometimes distant) sections of the document.\n\nBias 2. The Tale of the Missing Map: Selection Bias\n\nImage 4. Photo Ashleigh Shea, Unsplash\n\nChoosing which data points (cherries 😊) to include (and which to ignore) is one of the strongest — and often most overlooked — acts of bias. And perhaps no industry illustrated this better than Big Tobacco.\n\nThe now-famous summary of their legal strategy says it all:\n\nYes, smoking causes lung cancer, but not in people who sue us.\n\nThat quote perfectly captures the tone of tobacco litigation in the late 20th century, where companies faced a wave of lawsuits from customers suffering from diseases linked to smoking. Despite overwhelming medical and scientific consensus, tobacco firms routinely deflected responsibility using a series of arguments that, while sometimes legally strategic, were scientifically absurd.\n\nHere are four of the most egregious cherry-picking tactics they used in court, based on this article [2].\n\nCherry-pick tactic 1: use “exception fallacy” tactic in legal or rhetorical contexts.\n\nYes, smoking causes cancer — but not this one.\n\nThe plaintiff had a rare form of cancer, like bronchioloalveolar carcinoma (BAC) or mucoepidermoid carcinoma, which they claimed weren’t conclusively linked to smoking.\n\nIn one case, they argued the cancer was from the thymus, not the lungs, despite overwhelming medical evidence.\n\nCherry-pick tactic 2: Highlight obscure exceptions or rare cancer types to challenge general epidemiological evidence.\n\nIt wasn’t our brand.\n\n“Sure, tobacco may have caused the disease — but not our cigarettes.”\n\nIn Ierardi v. Lorillard, the company argued that the plaintiff’s exposure to asbestos-laced cigarette filters (Micronite) occurred outside the narrow 4-year window when they were used, even though 585 million packs were sold during that time.\n\nCherry-pick tactic 3: Focus on brand or product variation as a way to shift blame.\n\nIn several cases, such as Ierardi v. Lorillard and Lacy v. Lorillard, the defense admitted that cigarettes can cause cancer but argued that the plaintiff:\n\nDidn’t use their brand at the time of exposure,\n\nOr didn’t use the specific version of the product that was most dangerous (e.g., Kent cigarettes with the asbestos-containing Micronite filter),\n\nOr didn’t use the specific version of the product that was most dangerous (e.g., Kent cigarettes with the asbestos-containing Micronite filter),\n\nwindow years ago, making it unlikely the plaintiff was exposed.\n\nThis tactic shifts the narrative from\n\nOur product caused harm.\n\nto\n\nMaybe smoking caused harm—but not ours.\n\nCherry-pick tactic 4: Emphasize every other possible risk factor — regardless of plausibility — to deflect from tobacco’s role.\n\nThere were other risk factors.\n\nIn many lawsuits, companies pointed to alternative causes of illness: asbestos, diesel fumes, alcohol, genetics, diet, obesity, and even spicy food.\n\nIn Allgood v. RJ Reynolds, the defense blamed the plaintiff’s condition partly on his fondness for “Tex-Mex food.”\n\nCherry-picking isn’t always obvious. It can hide in legal defenses, marketing copy, dashboards, or even academic reports. But when only the data that serves the story gets told, it stops being insight and starts becoming manipulation.\n\nBias 3: The Mirror in the Forest: How the Same Data Tells Different Tales\n\nHow we phrase results can skew interpretation. Should we say “Unemployment drops to 4.9%” or “Millions still jobless despite gains”? Both can be accurate. The difference lies in emotional framing.\n\nIn essence, framing is a strategic storytelling technique that can significantly impact how a story is received, understood, and remembered. By understanding the power of framing, storytellers can craft narratives that resonate deeply with their audience and achieve their desired goals. I present some examples in Table 1.\n\nFrame A Frame B Objective description Unemployment “Unemployment hits 5-year low”\n\nSuggests progress, recovery, and strong leadership. “Millions still without jobs despite slight drop” Highlights the persistent problem and unmet needs. A modest drop in the unemployment rate. Vaccine Effectiveness “COVID vaccine reduces risk by 95%”\n\nEmphasizes protection, encourages uptake. “1 in 20 still gets infected even after the jab.”\n\nFocuses on vulnerability and doubt. A clinical trial showed a 95% relative risk reduction. Climate Data “2023 was the hottest year on record.”\n\nCalls attention to the global crisis. “Earth has always gone through natural cycles.”\n\nImplies nothing unusual is happening. Long-term temperature records. Company Financial Reports “Revenue grows 10% in Q2.”\n\nCelebrates short-term gain. “Still below pre-pandemic levels”.\n\nSignals underperformance in the long run. Quarterly earnings report. Election Polls “Candidate A leads by 3 points!”\n\nCreates a sense of momentum. “Within margin of error: race too close to call.”\n\nEmphasizes uncertainty. A poll with +/- 3% margin. Health Warnings “This drink has 25 grams of sugar.”\n\nSounds scientific, neutral. “This drink contains over six teaspoons of sugar.”\n\nSounds excessive and dangerous. 25 grams of sugar. Table 1. Different ways of framing the same story. Examples generated by the author using ChatGPT.\n\nBias 4: “The Dragon of Design: How Beauty Beguiles the Truth”\n\nVisuals simplify data, but they can also manipulate perception. In my older article [1], I listed 14 deceptive visualization tactics. Here is a summary of them.\n\nUsing the wrong chart type: Choosing charts that confuse rather than clarify — like 3D pie charts or inappropriate comparisons — makes it harder to see the story the data tells. Adding distracting elements: Stuffing visuals with logos, decorations, dark gridlines, or clutter hides the important insights behind noise and visual overload. Overusing colors: Using too many colors can distract from the focus. Without a clear color hierarchy, nothing stands out, and the viewer is overwhelmed. Random data ordering: Scrambling categories or time series data obscures patterns and prevents clear comparisons. Manipulating axis scales: Truncating the y-axis exaggerates differences. Extending it minimizes meaningful variation. Both distort perception. Creating trend illusions: Using inconsistent time frames, selective data points, or poorly spaced axes to make non-trends look significant. Cherry-picking data: Only showing the parts of the data that support your point, ignoring the full story or contradicting evidence. Omitting visual cues: Removing labels, legends, gridlines, or axis scales to make data hard to interpret, or hard to challenge. Overloading charts: Packing too much data into one chart can be distracting and confusing, especially when critical data is buried in visual chaos. Showing only cumulative values: Using cumulative plots to imply smooth progress while hiding volatility or declines in individual periods. Using 3D effects: 3D charts skew perception and make comparisons more difficult, often leading to misleading information about size or proportion. Applying gradients and shading: Fancy textures or gradients shift focus and add visual weight to areas that might not deserve it. Misleading or vague titles: A neutral or technical title can downplay the urgency of findings. A dramatic one can exaggerate a minor change. Using junk charts: Visually overdesigned, complex, or overly artistic charts that are hard to interpret and easy to misread.\n\nBias 5: “The Story-Spinning Machine: But Who Holds the Thread?”\n\nModern tools like Power BI Copilot or Tableau Pulse are increasingly generating summaries and “insights” on your behalf. Not to mention crafting summaries, narratives, or whole presentations prepared by LLMs like ChatGPT or Gemini.\n\nBut here’s the catch:\n\nThese tools are trained on patterns, not ethics.\n\nAI can’t tell when it’s creating a misleading story. If your prompt or dataset is biased, the output will likely be biased as well, and at a machine scale.\n\nThis raises a critical question: Are we using AI to democratize insight, or to mass-produce narrative spin?\n\nImage 5: Photo by Aerps.com on Unsplash\n\nA recent BBC investigation found that leading AI chatbots frequently distort or misrepresent current events, even when using BBC articles as their source. Over half of the tested responses contained significant issues, including outdated facts, fabricated or altered quotes, and confusion between opinion and reporting. Examples ranged from incorrectly stating that Rishi Sunak was still the UK prime minister to omitting key legal context in high-profile criminal cases. BBC executives warned that these inaccuracies threaten public trust in news and urged AI companies to collaborate with publishers to improve transparency and accountability.[3]\n\nFeeling overwhelmed? You’ve only seen the beginning. Data storytelling can fall prey to numerous cognitive biases, each subtly distorting the narrative.\n\nTake confirmation bias, where the storyteller highlights only data that supports their assumptions—proclaiming, “Our campaign was a success!”—while ignoring contradictory evidence. Then there’s outcome bias, which credits success to sound strategy: “We launched the product and it thrived, so our approach was perfect,”—even if luck played a major role.\n\nSurvivorship bias focuses only on the winners—startups that scaled or campaigns that went viral—while neglecting the many that failed using the same methods. Narrative bias oversimplifies complexity, shaping messy realities into tidy conclusions, such as “Vaping is always safer,” without sufficient context.\n\nAnchoring bias causes people to fixate on the first number presented—like a 20% forecast—distorting how subsequent information is interpreted. Omission bias arises when important data is left out, for instance, only highlighting top-performing regions while ignoring underperforming ones.\n\nProjection bias assumes that others interpret data the same way the analyst does: “This dashboard speaks for itself,”—yet it may not, especially for stakeholders unfamiliar with the context. Scale bias misleads with disproportionate framing—“A 300% increase!” sounds impressive until you learn it went from just one to three users.\n\nFinally, causality bias draws unfounded conclusions from correlations: “Users stayed longer after we added popups—they must love them!”—without testing whether popups were the actual cause.\n\nHow to “Unbias” Data Storytelling\n\nEvery data story is a choice. In a world where attention spans are short and AI writes faster than humans, those choices are more powerful — and dangerous — than ever.\n\nAs data scientists, analysts, and storytellers, we must approach narrative choices with the same level of rigor and thoughtfulness that we apply to statistical models. Crafting a story from data is not just about clarity or engagement—it’s about responsibility. Every choice we make in framing, emphasis, and interpretation shapes how others perceive the truth. And at the end of the day, the most dangerous stories are not the false ones—they’re the ones that feel like facts.\n\nIn this part of the article, I’ll share several practical strategies to help you strengthen your data storytelling. These ideas will focus on how to be both compelling and credible—how to craft narratives that engage your audience without oversimplifying or misleading them. Because when done well, data storytelling doesn’t just communicate insight—it builds trust.\n\nStrategy 1: The Wise Wizard’s Rule: Ask, Don’t Enchant\n\nIn the world of data and analysis, the most insightful storytellers don’t announce their conclusions with dramatic flair—they lead with thoughtful questions. Instead of presenting bold declarations, they invite reflection by asking, “What do you see?” This approach encourages others to discover insights on their own, fostering understanding rather than passive acceptance.\n\nConsider a graph showing a decline in test scores. A surface-level interpretation might immediately claim, “Our schools are failing,” sparking concern or blame. But a more careful, analytical response would be, “What factors could explain this change? Could it be a new testing format, changes in student demographics, or something else?” Similarly, when sales rise following the launch of a new feature, it’s tempting to attribute the increase solely to the feature. Yet a more rigorous approach would ask, “What other variables changed during this period?”\n\nBy leading with questions, we create space for interpretation, dialogue, and deeper thinking. This method guards against false certainty and encourages a more collaborative, thoughtful exploration of data. A strong narrative should guide the audience, rather than forcing them toward a predetermined conclusion.\n\nStrategy 2: The Mirror of Many Truths: Offer Counter-Narratives\n\nGood data storytelling doesn’t stop at a single interpretation. Complex datasets often allow for multiple valid perspectives, and it’s the storyteller’s responsibility to acknowledge them. Presenting a counter-narrative—“here’s another way to look at this”—invites critical thinking and builds credibility.\n\nFor example, a chart may show that heart disease rates are declining overall. That seems like a success. But a closer look may reveal that the improvement is concentrated in higher-income areas, while rates in rural or underserved communities remain high. Presenting both views—progress and disparity—provides a more comprehensive and honest picture of the issue.\n\nBy offering counter-narratives, we guard against oversimplification and help our audience understand the nuance behind the numbers.\n\nImage 6. Adding the income class dimension allows for better insight discovery. Chart generated in ChatGPT, fake data.\n\nStrategy 3: The Curse of Crooked Charts: Avoid Deceptive Visuals\n\nVisuals are powerful, but that power must be used responsibly. Misleading charts can distort perception through subtle tricks, such as truncated axes that exaggerate differences, unlabeled units that obscure the scale, or decorative clutter that distracts from the message. To avoid these pitfalls, always clearly label axes, start scales from zero when appropriate, and choose chart types that best fit the data, not just their aesthetic appeal. Deception doesn’t always come from malice—sometimes it’s just careless design. But either way, it erodes trust. A clean, honest visual is far more persuasive than a flashy one that hides the details.\n\nImage 7. Two versions of the same visual. One is telling the story, the other…?. Image by the author.\n\nTake, for example, the two charts shown in Image 7. The one on the left is cluttered and hard to interpret. Its title is vague, the excessive use of color is distracting, and unnecessary elements—like heavy borders, gridlines, and shading—only add to the confusion. There are no visual cues to guide the viewer, leaving the audience to guess what the author is trying to say.\n\nIn contrast, the chart on the right is far more effective. It strips away the noise, using just three colors: grey for context, blue to highlight key information, and a clean white background. Most importantly, the title conveys the main message, allowing the audience to grasp the point at a glance.\n\nStrategy 4: Speak Honestly of Shadows: The Wisdom of Embracing Uncertainty\n\nUncertainty is an inherent part of working with data, and acknowledging it doesn’t weaken your story—it strengthens your credibility. Transparency around uncertainty is a hallmark of responsible data communication. When you communicate elements like confidence intervals, margins of error, or the assumptions behind a model, you’re not just being technically accurate—you’re demonstrating honesty and humility. It shows that you respect your audience’s ability to engage with complexity, rather than oversimplifying to maintain a clean narrative.\n\nUncertainty can arise from various sources, including limited sample sizes, noisy or incomplete data, changing conditions, or the assumptions inherent in predictive models. Instead of ignoring or smoothing over these limitations, good storytellers bring them to the forefront—visually and verbally. Doing so encourages critical thinking and opens the door for discussion. It also protects your work from misinterpretation, misuse, or overconfidence in results. In short, by being open about what the data can’t tell us, we give more weight to what it can. Below, I present several examples of how you could include information on uncertainty in your data story.\n\nUpdate on confidence intervals\n\nInstead of: “Revenue will grow by 15% next quarter.”\n\nUse: “We project a 15% growth, with a 95% confidence interval of 12%–18%.” Leave a margin of error.\n\nInstead of: “Customer satisfaction is at 82%.”\n\nUse: “Customer satisfaction is 82%, ±3% margin of error.” Missing data indicators\n\nUse visual cues, such as faded bars, dashed lines, or shaded areas, on charts to indicate gaps.\n\nAdd footnotes: “Data for Q2 is incomplete due to reporting delays.” Model assumptions\n\nExample: “This forecast assumes no significant change in user behavior or market conditions.” Multiple scenarios\n\nPresent best-case, worst-case, and most-likely scenarios to reflect a range of possible outcomes. Probabilistic language\n\nInstead of: “This will happen.”\n\nUse: “There’s a 70% chance this outcome occurs under current conditions.” Data quality notes\n\nHighlight issues like small sample sizes or self-reported data:\n\n“Results are based on a survey of 100 respondents and may not reflect the broader population.” Error bars on charts\n\nVisually show uncertainty by including error bars or shaded confidence bands in graphs. Transparency in limitations\n\nExample: “This analysis does not account for seasonal variation or external economic factors.” Qualitative clarification\n\nUse captions or callouts in presentations or dashboards:\n\n“Data trends are indicative, but further validation is needed.”\n\nYou might wonder, “But won’t highlighting these uncertainties weaken my story or make me seem unsure of the results?” On the contrary, acknowledging uncertainty doesn’t signal a lack of confidence; it shows depth, professionalism, and integrity. It conveys to your audience that you understand the complexity of the data and are not trying to oversell a simplistic conclusion. Sharing what you do know, alongside what you don’t, creates a more balanced and credible narrative. People are far more likely to trust your insights when they see that you’re being honest about the limitations. It’s not about dampening your story—it’s about grounding it in reality.\n\nStrategy 5: Reveal the Roots of the Tale: Let Truth Travel with Its Sources\n\nEvery story needs roots, and in the world of data storytelling, those roots are your sources. A beautiful chart or striking number means little if your audience can’t see where it came from. Was it a randomized survey? Administrative data? Social media scraping? Just like a traveler trusts a guide who knows the path, readers are more likely to trust your insights when they can trace them back to their origins. Transparency about data sources, collection methods, assumptions, and even limitations is not a sign of weakness—it’s a mark of integrity. When we reveal the roots of the tale, we give our story depth, credibility, and resilience. Informed decisions can only grow in well-tended soil.\n\nImage 8: Image generated by the author in ChatGPT.\n\nClosing remarks\n\nData-driven storytelling is both an art and a responsibility. It gives us the power to make information meaningful—but also the power to mislead, even unintentionally. In this article, we’ve explored a forest of biases, design traps, and narrative temptations that can subtly shape perception and distort the truth. Whether you’re a data scientist, communicator, or decision-maker, your stories carry weight—not just for what they show, but for how they are told.\n\nSo let us tell stories that illuminate, not obscure. Let us lead with questions, not conclusions. Let us reveal uncertainty, not hide behind false clarity. And above all, let us anchor our insights in transparent sources and humble interpretation. The goal isn’t perfection—it’s integrity. Because in a world filled with noise and narrative spin, the most powerful story you can tell is one that’s both clear and honest.\n\nIn the end, storytelling is not about controlling the message—it’s about earning trust. And trust, once lost, is not easily won back. So choose your stories carefully. Shape them with care. And remember: the truth may not always be flashy, but it always finds its way to the light.\n\nAnd one more thing: if you’ve ever spotted (or unintentionally created) a biased data story, share your experience in the comments. The more we surface these narratives, the better we all get at telling data truths, not just data tales.\n\nReferences\n\n[1] How not to Cheat with Data Visualizations, Michal Szudejko, Towards Data Science\n\n[2] Tobacco manufacturers’ defence against plaintiffs’ claims of cancer causation: throwing mud at the wall and hoping some of it will stick, Multiple Authors, National Library of Medicine\n\n[3] AI chatbots distort and mislead when asked about current affairs, BBC finds, Matthew Weaver\n\nDisclaimer\n\nThis post was originally written using Microsoft Word, and the spelling and grammar were checked with Grammarly. I reviewed and adjusted any modifications to ensure that my intended message was accurately reflected. All other uses of AI (for instance image and sample data generation) were disclosed directly in the text.",
         "2025-07-23T19:10:41",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/how-not-to-mislead-with-your-data-driven-story/",
         "2025-07-26T06:23:31.338091",
         "is everywhere. There are countless books, articles, tutorials, and videos, some of which I have written or created. In my experience, most of these resources tend to present data storytelling in an overwhelmingly positive light. But lately, one concern has been on my mind: What if our stories, instead of clarifying, mislead? Image 1. Change the perspective, and you see an entirely different story. Photos by the author The image above shows one of the apartment buildings in my neighborhood. Now, take a look at the photo on the left and imagine one of the apartments in the white building is up for sale. You are considering buying it. You would likely focus on the immediate surroundings, especially as presented in the seller’s photos. Notice anything unusual? Probably not, at least not right away. Should the immediate setting be a dealbreaker? In my opinion, not necessarily. It’s not the most picturesque or charming spot—just a typical block in an average neighborhood in Warsaw. Or is it? Let’s take a short walk around to the back of the building. And… surprise: there’s a public lavatory right there. Still feel good about the location? Maybe yes, maybe no. One thing is clear: you would want to know that a public toilet sits just below your future balcony. Additionally, the apartment is located in the lower part of the building, while the rest of the towers rise above it. This is another factor that may be significant. Both these “issues” for sure can be brought up in price negotiations. This simple example illustrates how easily stories (in this case, using photos) can be misinterpreted. From one angle, everything looks fine, even inviting. Take a few steps to the right, and… whoops. The same situation can happen in our “professional” lives. What if audiences, convinced they’re making informed, data-backed decisions, are being subtly steered in the wrong direction—not by false data, but by the way it’s presented? This post builds on an article I wrote in 2024 about misleading visualizations [1]. Here, I want to take a bit broader perspective, exploring how the structure and flow of a story itself can unintentionally (or deliberately) lead people to incorrect conclusions, and how we can avoid that. Data storytelling is subjective We often like to believe that “data speaks for itself.” But in reality, it rarely does. Every chart, dashboard, or headline built around a dataset is shaped by human choices: what to include, what to leave out, how to frame the message? This highlights a core challenge of data-driven storytelling: it’s inherently subjective. That subjectivity comes from the discretion we have in proving the point we want to make: choosing which data to present, selecting appropriate analysis technique, deciding on arguments to emphasise, and even what to to use. Subjectivity also lies in interpretation — both ours and our audience’s — and in their willingness to act on the information. This opens the door to biases. If we are not careful, we can easily cross the line from subjectivity into unethical storytelling. This article examines the hidden biases embedded in data storytelling and how we can transition from manipulation to meaningful insights. We need stories Subjective or not, we need stories. Stories are essential to us because they help make sense of the world. They carry our values, preserve our history, and spark our imagination. Through stories, we connect with others, learn from past experiences, and explore what it means to be human. No matter your nationality, culture, or religion, we have all heard countless stories that have shaped us. Told us by our grandparents, parents, teachers, friends, and colleagues at work. Stories evoke emotion, inspire action, and shape our identity, both individually and collectively. In every culture and across every age, storytelling has been a powerful means of understanding life, sharing knowledge, and building community. But while stories can enlighten, they can also mislead. A compelling narrative has the power to shape perception, even when it distorts facts or oversimplifies complex issues. Stories often rely on emotion, selective detail, and a clear message, which can make them persuasive, but also dangerously reductive. When used carelessly or manipulatively, storytelling can reinforce biases, obscure truth, or drive decisions based more on feeling than reason. In the next part of this article, I’ll explore the potential problems with stories — especially in data-driven contexts — and how their power can unintentionally (or intentionally) misguide our understanding. Image 2. Stories have always been an essential part of our lives. Image generated by the author in ChatGPT. Narrative biases in data-driven storytelling Bias 1. Data is far, far away from interpretation Here’s an example of a visual from a report titled “Kentucky Juvenile Justice Reform Evaluation: Assessing the Effects of SB 200 on Youth Dispositional Outcomes and Racial and Ethnic Disparities.” Image 3. Image from “Kentucky Juvenile Justice Reform Evaluation…”, page 18 of the report. The graph shows that young offenders in Kentucky are less likely to reoffend if, after their first offense, they are routed through a diversion program. This program connects them with community support, such as social workers and therapists, to address deeper life challenges. That’s a powerful narrative with real-world implications: it supports reducing our reliance on an expensive criminal justice system, justifies increased funding for non-profits, and points toward meaningful ways to improve lives. But here’s the problem: unless you already have strong data literacy and subject knowledge, those conclusions are not immediately obvious from the graph. While the report does make this point, it doesn’t do so until nearly 20 pages later. This is a classic example of how the structure of academic reporting can mute the story’s impact. It results from the fact that data is presented visually in one section and interpreted textually in different (and sometimes distant) sections of the document. Bias 2. The Tale of the Missing Map: Selection Bias Image 4. Photo Ashleigh Shea, Unsplash Choosing which data points (cherries 😊) to include (and which to ignore) is one of the strongest — and often most overlooked — acts of bias. And perhaps no industry illustrated this better than Big Tobacco. The now-famous summary of their legal strategy says it all: Yes, smoking causes lung cancer, but not in people who sue us. That quote perfectly captures the tone of tobacco litigation in the late 20th century, where companies faced a wave of lawsuits from customers suffering from diseases linked to smoking. Despite overwhelming medical and scientific consensus, tobacco firms routinely deflected responsibility using a series of arguments that, while sometimes legally strategic, were scientifically absurd. Here are four of the most egregious cherry-picking tactics they used in court, based on this article [2]. Cherry-pick tactic 1: use “exception fallacy” tactic in legal or rhetorical contexts. Yes, smoking causes cancer — but not this one. The plaintiff had a rare form of cancer, like bronchioloalveolar carcinoma (BAC) or mucoepidermoid carcinoma, which they claimed weren’t conclusively linked to smoking. In one case, they argued the cancer was from the thymus, not the lungs, despite overwhelming medical evidence. Cherry-pick tactic 2: Highlight obscure exceptions or rare cancer types to challenge general epidemiological evidence. It wasn’t our brand. “Sure, tobacco may have caused the disease — but not our cigarettes.” In Ierardi v. Lorillard, the company argued that the plaintiff’s exposure to asbestos-laced cigarette filters (Micronite) occurred outside the narrow 4-year window when they were used, even though 585 million packs were sold during that time. Cherry-pick tactic 3: Focus on brand or product variation as a way to shift blame. In several cases, such as Ierardi v. Lorillard and Lacy v. Lorillard, the defense admitted that cigarettes can cause cancer but argued that the plaintiff: Didn’t use their brand at the time of exposure, Or didn’t use the specific version of the product that was most dangerous (e.g., Kent cigarettes with the asbestos-containing Micronite filter), Or didn’t use the specific version of the product that was most dangerous (e.g., Kent cigarettes with the asbestos-containing Micronite filter), window years ago, making it unlikely the plaintiff was exposed. This tactic shifts the narrative from Our product caused harm. to Maybe smoking caused harm—but not ours. Cherry-pick tactic 4: Emphasize every other possible risk factor — regardless of plausibility — to deflect from tobacco’s role. There were other risk factors. In many lawsuits, companies pointed to alternative causes of illness: asbestos, diesel fumes, alcohol, genetics, diet, obesity, and even spicy food. In Allgood v. RJ Reynolds, the defense blamed the plaintiff’s condition partly on his fondness for “Tex-Mex food.” Cherry-picking isn’t always obvious. It can hide in legal defenses, marketing copy, dashboards, or even academic reports. But when only the data that serves the story gets told, it stops being insight and starts becoming manipulation. Bias 3: The Mirror in the Forest: How the Same Data Tells Different Tales How we phrase results can skew interpretation. Should we say “Unemployment drops to 4.9%” or “Millions still jobless despite gains”? Both can be accurate. The difference lies in emotional framing. In essence, framing is a strategic storytelling technique that can significantly impact how a story is received, understood, and remembered. By understanding the power of framing, storytellers can craft narratives that resonate deeply with their audience and achieve their desired goals. I present some examples in Table 1. Frame A Frame B Objective description Unemployment “Unemployment hits 5-year low” Suggests progress, recovery, and strong leadership. “Millions still without jobs despite slight drop” Highlights the persistent problem and unmet needs. A modest drop in the unemployment rate. Vaccine Effectiveness “COVID vaccine reduces risk by 95%” Emphasizes protection, encourages uptake. “1 in 20 still gets infected even after the jab.” Focuses on vulnerability and doubt. A clinical trial showed a 95% relative risk reduction. Climate Data “2023 was the hottest year on record.” Calls attention to the global crisis. “Earth has always gone through natural cycles.” Implies nothing unusual is happening. Long-term temperature records. Company Financial Reports “Revenue grows 10% in Q2.” Celebrates short-term gain. “Still below pre-pandemic levels”. Signals underperformance in the long run. Quarterly earnings report. Election Polls “Candidate A leads by 3 points!” Creates a sense of momentum. “Within margin of error: race too close to call.” Emphasizes uncertainty. A poll with +/- 3% margin. Health Warnings “This drink has 25 grams of sugar.” Sounds scientific, neutral. “This drink contains over six teaspoons of sugar.” Sounds excessive and dangerous. 25 grams of sugar. Table 1. Different ways of framing the same story. Examples generated by the author using ChatGPT. Bias 4: “The Dragon of Design: How Beauty Beguiles the Truth” Visuals simplify data, but they can also manipulate perception. In my older article [1], I listed 14 deceptive visualization tactics. Here is a summary of them. Using the wrong chart type: Choosing charts that confuse rather than clarify — like 3D pie charts or inappropriate comparisons — makes it harder to see the story the data tells. Adding distracting elements: Stuffing visuals with logos, decorations, dark gridlines, or clutter hides the important insights behind noise and visual overload. Overusing colors: Using too many colors can distract from the focus. Without a clear color hierarchy, nothing stands out, and the viewer is overwhelmed. Random data ordering: Scrambling categories or time series data obscures patterns and prevents clear comparisons. Manipulating axis scales: Truncating the y-axis exaggerates differences. Extending it minimizes meaningful variation. Both distort perception. Creating trend illusions: Using inconsistent time frames, selective data points, or poorly spaced axes to make non-trends look significant. Cherry-picking data: Only showing the parts of the data that support your point, ignoring the full story or contradicting evidence. Omitting visual cues: Removing labels, legends, gridlines, or axis scales to make data hard to interpret, or hard to challenge. Overloading charts: Packing too much data into one chart can be distracting and confusing, especially when critical data is buried in visual chaos. Showing only cumulative values: Using cumulative plots to imply smooth progress while hiding volatility or declines in individual periods. Using 3D effects: 3D charts skew perception and make comparisons more difficult, often leading to misleading information about size or proportion. Applying gradients and shading: Fancy textures or gradients shift focus and add visual weight to areas that might not deserve it. Misleading or vague titles: A neutral or technical title can downplay the urgency of findings. A dramatic one can exaggerate a minor change. Using junk charts: Visually overdesigned, complex, or overly artistic charts that are hard to interpret and easy to misread. Bias 5: “The Story-Spinning Machine: But Who Holds the Thread?” Modern tools like Power BI Copilot or Tableau Pulse are increasingly generating summaries and “insights” on your behalf. Not to mention crafting summaries, narratives, or whole presentations prepared by LLMs like ChatGPT or Gemini. But here’s the catch: These tools are trained on patterns, not ethics. AI can’t tell when it’s creating a misleading story. If your prompt or dataset is biased, the output will likely be biased as well, and at a machine scale. This raises a critical question: Are we using AI to democratize insight, or to mass-produce narrative spin? Image 5: Photo by Aerps.com on Unsplash A recent BBC investigation found that leading AI chatbots frequently distort or misrepresent current events, even when using BBC articles as their source. Over half of the tested responses contained significant issues, including outdated facts, fabricated or altered quotes, and confusion between opinion and reporting. Examples ranged from incorrectly stating that Rishi Sunak was still the UK prime minister to omitting key legal context in high-profile criminal cases. BBC executives warned that these inaccuracies threaten public trust in news and urged AI companies to collaborate with publishers to improve transparency and accountability.[3] Feeling overwhelmed? You’ve only seen the beginning. Data storytelling can fall prey to numerous cognitive biases, each subtly distorting the narrative. Take confirmation bias, where the storyteller highlights only data that supports their assumptions—proclaiming, “Our campaign was a success!”—while ignoring contradictory evidence. Then there’s outcome bias, which credits success to sound strategy: “We launched the product and it thrived, so our approach was perfect,”—even if luck played a major role. Survivorship bias focuses only on the winners—startups that scaled or campaigns that went viral—while neglecting the many that failed using the same methods. Narrative bias oversimplifies complexity, shaping messy realities into tidy conclusions, such as “Vaping is always safer,” without sufficient context. Anchoring bias causes people to fixate on the first number presented—like a 20% forecast—distorting how subsequent information is interpreted. Omission bias arises when important data is left out, for instance, only highlighting top-performing regions while ignoring underperforming ones. Projection bias assumes that others interpret data the same way the analyst does: “This dashboard speaks for itself,”—yet it may not, especially for stakeholders unfamiliar with the context. Scale bias misleads with disproportionate framing—“A 300% increase!” sounds impressive until you learn it went from just one to three users. Finally, causality bias draws unfounded conclusions from correlations: “Users stayed longer after we added popups—they must love them!”—without testing whether popups were the actual cause. How to “Unbias” Data Storytelling Every data story is a choice. In a world where attention spans are short and AI writes faster than humans, those choices are more powerful — and dangerous — than ever. As data scientists, analysts, and storytellers, we must approach narrative choices with the same level of rigor and thoughtfulness that we apply to statistical models. Crafting a story from data is not just about clarity or engagement—it’s about responsibility. Every choice we make in framing, emphasis, and interpretation shapes how others perceive the truth. And at the end of the day, the most dangerous stories are not the false ones—they’re the ones that feel like facts. In this part of the article, I’ll share several practical strategies to help you strengthen your data storytelling. These ideas will focus on how to be both compelling and credible—how to craft narratives that engage your audience without oversimplifying or misleading them. Because when done well, data storytelling doesn’t just communicate insight—it builds trust. Strategy 1: The Wise Wizard’s Rule: Ask, Don’t Enchant In the world of data and analysis, the most insightful storytellers don’t announce their conclusions with dramatic flair—they lead with thoughtful questions. Instead of presenting bold declarations, they invite reflection by asking, “What do you see?” This approach encourages others to discover insights on their own, fostering understanding rather than passive acceptance. Consider a graph showing a decline in test scores. A surface-level interpretation might immediately claim, “Our schools are failing,” sparking concern or blame. But a more careful, analytical response would be, “What factors could explain this change? Could it be a new testing format, changes in student demographics, or something else?” Similarly, when sales rise following the launch of a new feature, it’s tempting to attribute the increase solely to the feature. Yet a more rigorous approach would ask, “What other variables changed during this period?” By leading with questions, we create space for interpretation, dialogue, and deeper thinking. This method guards against false certainty and encourages a more collaborative, thoughtful exploration of data. A strong narrative should guide the audience, rather than forcing them toward a predetermined conclusion. Strategy 2: The Mirror of Many Truths: Offer Counter-Narratives Good data storytelling doesn’t stop at a single interpretation. Complex datasets often allow for multiple valid perspectives, and it’s the storyteller’s responsibility to acknowledge them. Presenting a counter-narrative—“here’s another way to look at this”—invites critical thinking and builds credibility. For example, a chart may show that heart disease rates are declining overall. That seems like a success. But a closer look may reveal that the improvement is concentrated in higher-income areas, while rates in rural or underserved communities remain high. Presenting both views—progress and disparity—provides a more comprehensive and honest picture of the issue. By offering counter-narratives, we guard against oversimplification and help our audience understand the nuance behind the numbers. Image 6. Adding the income class dimension allows for better insight discovery. Chart generated in ChatGPT, fake data. Strategy 3: The Curse of Crooked Charts: Avoid Deceptive Visuals Visuals are powerful, but that power must be used responsibly. Misleading charts can distort perception through subtle tricks, such as truncated axes that exaggerate differences, unlabeled units that obscure the scale, or decorative clutter that distracts from the message. To avoid these pitfalls, always clearly label axes, start scales from zero when appropriate, and choose chart types that best fit the data, not just their aesthetic appeal. Deception doesn’t always come from malice—sometimes it’s just careless design. But either way, it erodes trust. A clean, honest visual is far more persuasive than a flashy one that hides the details. Image 7. Two versions of the same visual. One is telling the story, the other…?. Image by the author. Take, for example, the two charts shown in Image 7. The one on the left is cluttered and hard to interpret. Its title is vague, the excessive use of color is distracting, and unnecessary elements—like heavy borders, gridlines, and shading—only add to the confusion. There are no visual cues to guide the viewer, leaving the audience to guess what the author is trying to say. In contrast, the chart on the right is far more effective. It strips away the noise, using just three colors: grey for context, blue to highlight key information, and a clean white background. Most importantly, the title conveys the main message, allowing the audience to grasp the point at a glance. Strategy 4: Speak Honestly of Shadows: The Wisdom of Embracing Uncertainty Uncertainty is an inherent part of working with data, and acknowledging it doesn’t weaken your story—it strengthens your credibility. Transparency around uncertainty is a hallmark of responsible data communication. When you communicate elements like confidence intervals, margins of error, or the assumptions behind a model, you’re not just being technically accurate—you’re demonstrating honesty and humility. It shows that you respect your audience’s ability to engage with complexity, rather than oversimplifying to maintain a clean narrative. Uncertainty can arise from various sources, including limited sample sizes, noisy or incomplete data, changing conditions, or the assumptions inherent in predictive models. Instead of ignoring or smoothing over these limitations, good storytellers bring them to the forefront—visually and verbally. Doing so encourages critical thinking and opens the door for discussion. It also protects your work from misinterpretation, misuse, or overconfidence in results. In short, by being open about what the data can’t tell us, we give more weight to what it can. Below, I present several examples of how you could include information on uncertainty in your data story. Update on confidence intervals Instead of: “Revenue will grow by 15% next quarter.” Use: “We project a 15% growth, with a 95% confidence interval of 12%–18%.” Leave a margin of error. Instead of: “Customer satisfaction is at 82%.” Use: “Customer satisfaction is 82%, ±3% margin of error.” Missing data indicators Use visual cues, such as faded bars, dashed lines, or shaded areas, on charts to indicate gaps. Add footnotes: “Data for Q2 is incomplete due to reporting delays.” Model assumptions Example: “This forecast assumes no significant change in user behavior or market conditions.” Multiple scenarios Present best-case, worst-case, and most-likely scenarios to reflect a range of possible outcomes. Probabilistic language Instead of: “This will happen.” Use: “There’s a 70% chance this outcome occurs under current conditions.” Data quality notes Highlight issues like small sample sizes or self-reported data: “Results are based on a survey of 100 respondents and may not reflect the broader population.” Error bars on charts Visually show uncertainty by including error bars or shaded confidence bands in graphs. Transparency in limitations Example: “This analysis does not account for seasonal variation or external economic factors.” Qualitative clarification Use captions or callouts in presentations or dashboards: “Data trends are indicative, but further validation is needed.” You might wonder, “But won’t highlighting these uncertainties weaken my story or make me seem unsure of the results?” On the contrary, acknowledging uncertainty doesn’t signal a lack of confidence; it shows depth, professionalism, and integrity. It conveys to your audience that you understand the complexity of the data and are not trying to oversell a simplistic conclusion. Sharing what you do know, alongside what you don’t, creates a more balanced and credible narrative. People are far more likely to trust your insights when they see that you’re being honest about the limitations. It’s not about dampening your story—it’s about grounding it in reality. Strategy 5: Reveal the Roots of the Tale: Let Truth Travel with Its Sources Every story needs roots, and in the world of data storytelling, those roots are your sources. A beautiful chart or striking number means little if your audience can’t see where it came from. Was it a randomized survey? Administrative data? Social media scraping? Just like a traveler trusts a guide who knows the path, readers are more likely to trust your insights when they can trace them back to their origins. Transparency about data sources, collection methods, assumptions, and even limitations is not a sign of weakness—it’s a mark of integrity. When we reveal the roots of the tale, we give our story depth, credibility, and resilience. Informed decisions can only grow in well-tended soil. Image 8: Image generated by the author in ChatGPT. Closing remarks Data-driven storytelling is both an art and a responsibility. It gives us the power to make information meaningful—but also the power to mislead, even unintentionally. In this article, we’ve explored a forest of biases, design traps, and narrative temptations that can subtly shape perception and distort the truth. Whether you’re a data scientist, communicator, or decision-maker, your stories carry weight—not just for what they show, but for how they are told. So let us tell stories that illuminate, not obscure. Let us lead with questions, not conclusions. Let us reveal uncertainty, not hide behind false clarity. And above all, let us anchor our insights in transparent sources and humble interpretation. The goal isn’t perfection—it’s integrity. Because in a world filled with noise and narrative spin, the most powerful story you can tell is one that’s both clear and honest. In the end, storytelling is not about controlling the message—it’s about earning trust. And trust, once lost, is not easily won back. So choose your stories carefully. Shape them with care. And remember: the truth may not always be flashy, but it always finds its way to the light. And one more thing: if you’ve ever spotted (or unintentionally created) a biased data story, share your experience in the comments. The more we surface these narratives, the better we all get at telling data truths, not just data tales. References [1] How not to Cheat with Data Visualizations, Michal Szudejko, Towards Data Science [2] Tobacco manufacturers’ defence against plaintiffs’ claims of cancer causation: throwing mud at the wall and hoping some of it will stick, Multiple Authors, National Library of Medicine [3] AI chatbots distort and mislead when asked about current affairs, BBC finds, Matthew Weaver Disclaimer This post was originally written using Microsoft Word, and the spelling and grammar were checked with Grammarly. I reviewed and adjusted any modifications to ensure that my intended message was accurately reflected. All other uses of AI (for instance image and sample data generation) were disclosed directly in the text.",
         "en",
         "{'MISC': ['A clean', 'AI chatbots distort and mislead', 'AI chatbots frequently distort or', 'Add', 'All other uses of AI', 'And above all', 'And at the end of the day', 'Applying gradients and shading', 'Are we using AI to democratize insight', 'Ask', 'Because in a world filled with noise and narrative spin', 'Because when done well', 'Below', 'Bias 2', 'Bias 3:', 'Bias 4: “The Dragon of Design', 'Bias 5: “The Story-Spinning Machine: But Who Holds the Thread', 'Both can be accurate', 'Both distort', 'Both these “issues” for sure can be brought up in price negotiations', 'But either way', 'By offering counter-narratives', 'By understanding the power of framing', 'COVID', 'Calls attention to the global crisis', 'Change the perspective', 'ChatGPT', 'ChatGPT or Gemini', 'Choosing charts that confuse rather than clarify', 'Climate Data “2023 was the hottest year on record', 'Closing remarks Data-driven storytelling is both an art and a responsibility', 'Complex datasets often allow for multiple', 'Could it be a new testing format', 'Crafting', 'Deception doesn’t always come from malice—sometimes it’s just careless design', 'Didn’t use their brand at the time of exposure', 'Different ways of framing the same story', 'Doing so', 'Don’t Enchant In the world of data and analysis', 'Earth has always gone through natural cycles', 'Election Polls “', 'Emphasize every other possible risk factor', 'Error', 'Every', 'Example', 'Examples generated by the author using ChatGPT', 'Fancy textures or gradients', 'Feeling overwhelmed', 'Focus on brand or', 'Focuses on vulnerability and doubt', 'Frame B', 'From one angle', 'Here are four of the most egregious cherry', 'Here is a summary of them', 'Here’', 'Highlight', 'Highlights the', 'How Beauty Beguiles the Truth” Visuals simplify data', 'How not to Cheat with Data Visualizations', 'How the Same Data Tells', 'How to “Unbias” Data Storytelling Every data story is', 'I reviewed and adjusted any modifications to ensure that my intended', 'I want to take', 'If we are not careful', 'If your prompt or dataset is biased', 'Image 1', 'Image 2', 'Image 5:', 'Image 6', 'Image 7', 'Image by the author', 'Image from “Kentucky Juvenile', 'Image generated by the author in', 'Image generated by the author in ChatGPT', 'In', 'In Allgood v. RJ Reynolds', 'In Ierardi v. Lorillard', 'In every culture and across every age', 'In many lawsuits', 'In my older', 'In one case', 'Informed', 'Instead of ignoring or smoothing over these limitations', 'Instead of: “Customer satisfaction is at 82', 'Instead of: “Revenue will grow by', 'It also protects your work from misinterpretation', 'It can hide in legal', 'It conveys to your audience that you understand the complexity of the data and are not trying to oversell', 'It gives us the power to make information meaningful—but also the power to mislead', 'It results from the fact that data is presented visually in one section and interpreted textually in different', 'It shows that you respect your audience’', 'It strips away the noise', 'It wasn’t our brand', 'It’s not about dampening your story', 'It’s not the most picturesque', 'I’ll', 'I’ll share several practical strategies to help you strengthen your data storytelling', 'Just like', 'Kentucky Juvenile Justice Reform Evaluation: Assessing the Effects of SB', 'Let us lead with questions', 'Let us reveal uncertainty', 'Maybe yes', 'Micronite', 'Model', 'Most importantly', 'Multiple', 'Multiple Authors', 'No matter your nationality', 'Not to mention crafting', 'Now', 'Omitting visual', 'One is telling the story', 'One thing is clear: you would want to know that', 'Only showing the parts of the data that support your point', 'Our schools are failing', 'Over half of the', 'Packing too much data into one chart can be distracting and confusing', 'People are far more likely to trust your insights when they see that you’re being honest about the limitations', 'Photos by the author The image above shows one of the apartment buildings in my neighborhood', 'Power BI Copilot', 'Present best-case', 'Presenting both views—progress and disparity', 'Probably not', 'Random', 'Removing labels', 'Scale bias misleads with disproportionate', 'Shape them with care', 'Sharing what you do know', 'Should the immediate setting be a dealbreaker', 'Should we say “Unemployment drops to 4.9%” or “Millions still jobless', 'Showing only cumulative values', 'Signals underperformance in the long run', 'Similarly', 'So choose your stories carefully', 'So let us tell stories that illuminate', 'Social media scraping', 'Speak Honestly of Shadows:', 'Still below pre', 'Still feel good about the location?', 'Stories are essential to us because they help make sense of the world', 'Stories evoke', 'Stories have always been an essential part of our lives', 'Stories often rely on emotion', 'Strategy 1: The Wise Wizard’', 'Strategy 2:', 'Strategy 3:', 'Strategy 4', 'Strategy 5:', 'Stuffing visuals with logos', 'Subjectivity also lies in interpretation —', 'Suggests progress', 'Survivorship bias focuses only on the winners', 'Tales How we phrase results can', 'That seems like', 'That subjectivity comes from the discretion we have in proving the point we want to make: choosing which data to present', 'That’', 'The', 'The Tale of the Missing Map: Selection Bias Image 4', 'The goal isn’t perfection', 'The graph shows that young offenders in Kentucky are less likely to reoffend if', 'The one on the left is cluttered and hard to interpret', 'The same', 'Then there’s outcome bias', 'There are no visual cues', 'There were other risk factors', 'These ideas will focus on how to be both compelling and credible', 'They carry our values', 'This highlights a core challenge of data-driven storytelling: it’', 'This is a classic', 'This method guards', 'This opens the door to biases', 'This tactic shifts the narrative from Our', 'Through stories', 'To avoid these pitfalls', 'Truncating the y-axis exaggerates differences', 'Two versions of the same visual', 'Unemployment “Unemployment', 'Unsplash A', 'Unsplash Choosing which data points', 'Update', 'Use captions or callouts in', 'Use visual cues', 'Use: “We project', 'Users stayed longer after we added popups—they must love them!”—without testing whether popups were the actual', 'Using 3D', 'Using inconsistent time frames', 'Using junk charts', 'Using too many colors can distract from the focus', 'Visually show uncertainty by including error bars or shaded confidence', 'We need stories Subjective or not, we need stories', 'We often like', 'What do you see?', 'What other variables', 'When used carelessly or manipulatively', 'When we reveal the roots of the tale', 'When you communicate elements', 'Whether you’re', 'While the report does make', 'Without', 'You are considering buying it', 'You might wonder', 'You would likely focus on the immediate surroundings', 'Youth Dispositional Outcomes and Racial and Ethnic', 'You’ve only seen the beginning', 'after their first offense', 'and a clean white background', 'and a clear message', 'and acknowledging it doesn’t weaken your story—it strengthens your credibility', 'and at', 'and colleagues at work', 'and confusion between opinion and reporting', 'and in the world of data storytelling', 'and interpretation shapes how others perceive the truth.', 'and it’s the storyteller’s responsibility to acknowledge them', 'and points toward meaningful ways to improve lives', 'and shape our identity', 'and spark our imagination', 'and storytellers', 'and the spelling and grammar were checked with', 'and videos', 'and you see an entirely different story', 'assumptions', 'blue to highlight key information', 'both individually and collectively', 'both ours and our audience’', 'but for how they are told', 'causality bias draws', 'chart may show that heart disease rates are declining overall', 'counter-narrative—“here’s another way to look at this”—invites critical thinking and builds credibility', 'credibility', 'each subtly distorting the narrative', 'especially as presented in the seller’', 'especially when critical data is buried in visual chaos', 'explored a forest of biases', 'fostering understanding rather than passive acceptance', 'good storytellers bring them to the forefront', 'grey for context', 'has been on my mind: What if our stories', 'how the structure and flow of a story itself can unintentionally', 'ignoring the full story or contradicting evidence', 'increased funding for non-profits', 'it rarely does', 'it shows depth', 'it stops being insight and starts becoming manipulation', 'it supports reducing our', 'it’', 'leaving the audience to guess what the author is trying to say', 'let us anchor our insights in transparent sources and humble interpretation', 'like 3D', 'makes it harder to see the story the data tells', 'may reveal that the', 'most of these resources', 'not ethics', 'not hide behind false clarity.', 'not just their aesthetic appeal', 'not necessarily', 'not the lungs', 'of', 'once lost', 'one of the apartments in the white building is up for sale', 'problem and unmet needs', 'recovery', 'rise following the launch of a new feature', 'shaping messy realities into tidy', 'share your experience in the comments', 'sizes or', 'so our approach was perfect,”—even if luck played', 'some of which I have written or created', 'storytellers can craft narratives that resonate deeply with their audience and achieve their desired goals', 'storytelling can reinforce biases', 'storytelling has been a powerful means of understanding life', 'such as social workers and therapists', 'such as “Vaping is always safer', 'that best fit the data', 'that others interpret data the same way the analyst does: “This dashboard speaks for itself,”—yet it may not', 'the better we all get at telling data truths', 'the chart on the right is far more effective', 'the defense blamed', 'the hidden biases embedded in data storytelling and how we can transition from manipulation to meaningful insights', 'the most insightful storytellers don’t', 'the output will likely be biased as well', 'the title conveys the main message', 'the tone of tobacco litigation in the late 20th century', 'the two charts shown in Image 7', 'there’s', 'this better than Big Tobacco', 'throwing mud at the wall and hoping some of it will stick', 'to Maybe smoking', 'to address deeper life challenges', 'unlabeled units that obscure the scale', 'using just three colors', 'wave of lawsuits from customers suffering from diseases linked to smoking', 'we can easily cross the line from subjectivity into unethical', 'we connect with others', 'we create space for interpretation', 'we give more weight to what it can', 'we give our story depth', 'we guard against oversimplification and help our audience understand the nuance behind the numbers', 'what to leave out', 'which can make them persuasive', 'while neglecting the many that failed using the same methods', 'while the rest of the towers rise above it', 'window when they were used', 'window years ago', 'worst-case', 'your stories carry weight—not just for what they show', 'you’re demonstrating honesty and humility', '” sparking concern or', '” without'], 'ORG': ['BBC', 'BBC finds', 'BBC investigation found that leading', 'Celebrates short-term gain', 'Creates', 'For', 'Health Warnings “This drink has 25 grams of sugar', 'Instead of presenting', 'Or didn’t use the specific version of the product that was most dangerous', 'Q2', 'Tobacco manufacturers’ defence against plaintiffs’ claims of cancer causation', 'Towards Data Science', 'Yes', 'data storytelling doesn’t just communicate insight—', 'for instance', 'one', 'take', 'we’ve', 'which credits success to sound strategy: “We launched the product and it thrived'], 'LOC': ['Emphasizes', 'I', 'Kent', 'Manipulating', 'National Library of Medicine', 'Overusing', 'Presenting', 'Probabilistic language', 'always clearly label', 'and most-likely scenarios to reflect', 'and shading', 'biased', 'gridlines', 'instead of clarifying', 'legends', 'like bronchioloalveolar carcinoma', 'mislead', 'preserve our history', 'with'], 'PER': ['Anchoring', 'Ashleigh Shea', 'Creating', 'Despite', 'Finally', 'Here', 'Matthew Weaver Disclaimer This post was originally written using Microsoft Word', 'Michal Szudejko', 'Micronite', 'Misleading', 'Overloading charts', 'Take', 'Tex-Mex', 'Told', 'Visually overdesigned', 'Yet', 'acknowledging uncertainty doesn’t', 'analytical response would be', 'are being subtly', 'distorting how', 'even unintentionally', 'fabricated or altered quotes', 'fallacy', 'it doesn’t do so until nearly 20', 'it erodes', 'just', 'lavatory right there', 'not obscure', 'they', 'they are routed through', 'they argued the cancer was from the thymus', 'they lead with thoughtful questions', 'this change?', 'those choices are more powerful —', 'until you learn it went from just one to three', 'we must', 'were scientifically absurd', 'weren’t conclusively linked to smoking']}",
         "[0.05727158114314079, 0.09395787864923477, 0.038815293461084366, 0.05790336802601814, 0.013605168089270592, -0.023133711889386177, -0.05361616611480713, -0.014794105663895607, 0.0364348329603672, -0.02621336653828621, 0.05556399002671242, 0.08433191478252411, 0.05457526817917824, 0.050853900611400604, 0.04097660630941391, -0.043721433728933334, 0.08310352265834808, 0.05128299444913864, 0.00033496247488074005, 0.001367021701298654, 0.04593614116311073, -0.049690794199705124, 0.04043472185730934, -0.020544670522212982, 0.04531818628311157, -0.03716989606618881, -0.004876794759184122, 0.055958159267902374, 0.012987177819013596, -0.07187982648611069, 0.00955530721694231, -0.0007107154815457761, 0.040472362190485, 0.028792493045330048, 0.08118309825658798, 0.02196582593023777, 0.04787279665470123, -0.009265393950045109, 0.07125353068113327, 0.008887178264558315, 0.045299630612134933, -0.008921259082853794, -0.02363218367099762, 0.03288138657808304, -0.003922083880752325, 0.007752490695565939, 0.0208565853536129, 0.04039712995290756, -0.02106589265167713, -0.0821276381611824, -0.03621682897210121, 0.06736986339092255, -0.030592311173677444, -0.022483952343463898, -0.02999999187886715, 0.04622839763760567, -0.03282376751303673, 0.011794568970799446, 0.07337279617786407, -0.06647186726331711, 0.08279434591531754, -0.04388139024376869, -0.050377920269966125, 0.03355143219232559, 0.04684612900018692, 0.01874108612537384, -0.006479187402874231, 0.05396615341305733, 0.018325120210647583, -0.06984847784042358, 0.060797642916440964, -0.007753204088658094, 0.054539669305086136, 0.005587778519839048, -0.04736005514860153, -0.0036706305108964443, -0.0013399726012721658, -0.044360674917697906, -0.07807473838329315, -0.08861254900693893, 0.09646303206682205, -0.03301519528031349, -0.05130549147725105, 0.011212809011340141, -0.03750564530491829, -0.03427469730377197, 0.029752643778920174, 0.05920396000146866, 0.04291439801454544, -0.026297954842448235, -0.0224770437926054, -0.0873655453324318, -0.08599674701690674, -0.0035191820934414864, 0.03903608396649361, 0.05598359927535057, -0.05086531862616539, -0.02743203192949295, 0.019062846899032593, 0.05498585104942322, 0.026645513251423836, 0.01503816619515419, 0.049650609493255615, -0.05555320903658867, 0.009576726704835892, -0.10431134700775146, -0.028740519657731056, 0.05990366265177727, -0.06455127149820328, 0.00547758350148797, -0.015146369114518166, 0.007244386710226536, -0.050182044506073, 0.014313861727714539, 0.06473053246736526, -0.02770415134727955, 0.08471664041280746, -0.03803018108010292, -0.05612308159470558, -0.020750368013978004, 0.07249434292316437, -0.01349463127553463, 0.01758156716823578, 0.04517542943358421, 0.02521466463804245, -0.047660380601882935, 0.051025938242673874, 1.6954689504497492e-33, -0.02376139909029007, 0.06719473749399185, -0.09687936305999756, 0.09374610334634781, 0.08976703882217407, 0.025852032005786896, -0.034120626747608185, 0.026897292584180832, -0.020716670900583267, 0.1297721564769745, 0.09518096596002579, -0.01872873865067959, -0.01951831392943859, 0.0267341248691082, -0.02600015699863434, 0.07249458879232407, -0.030858326703310013, 0.017583658918738365, -0.033699408173561096, 0.06072309985756874, 0.04410465061664581, -0.04212620481848717, -0.0014434162294492126, -0.017247287556529045, -0.049511320888996124, -0.011782229878008366, 0.022686148062348366, -0.0051175388507544994, -0.052198659628629684, -0.026673929765820503, -0.02302289940416813, 0.005487607792019844, 0.035186924040317535, -0.02596333622932434, 0.008065667934715748, 0.03608061000704765, -0.06164395064115524, -0.06413115561008453, 0.010017240419983864, -0.0003229283611290157, -0.07851782441139221, 0.03077293373644352, -0.0986558273434639, 0.06827373057603836, 0.14841865003108978, 0.10166424512863159, -0.02505233883857727, -0.04123122617602348, -0.08287975937128067, -0.01157341804355383, 0.01205211691558361, 0.05037263408303261, -0.09380320459604263, 0.024022594094276428, -0.03295932710170746, 0.016983091831207275, 0.0667826309800148, -0.14594197273254395, 0.10553471744060516, -0.038971737027168274, 0.08360008895397186, 0.03083980083465576, -0.06442736834287643, 0.0072210850194096565, -0.048267994076013565, -0.031493667513132095, -0.04645945131778717, 0.027334166690707207, 0.03612956777215004, -0.05652432516217232, 0.005878686439245939, -0.030459105968475342, -0.039367515593767166, 0.02009688690304756, -0.011083517223596573, 0.007511293515563011, -0.0800010934472084, 0.09726405143737793, 0.009430620819330215, -0.016633978113532066, 0.05357784032821655, -0.02739045023918152, -0.012188012711703777, 0.10087881237268448, -0.05425417050719261, 0.005521990358829498, 0.06646589934825897, -0.08610683679580688, -0.08009983599185944, 0.051162850111722946, -0.005270782858133316, 0.047063197940588, -0.058647073805332184, -0.06678424030542374, 0.00537907937541604, -2.55317703606387e-33, -0.002559013431891799, -0.03675613924860954, -0.03893200308084488, -0.04138033837080002, -0.08523192256689072, 0.02877555973827839, -0.07565520703792572, -0.04601285606622696, 0.09809528291225433, 0.025881588459014893, -0.0896284282207489, -0.017218822613358498, 0.03458079695701599, -0.019869238138198853, -0.04360916092991829, 0.03029916062951088, 0.11552073806524277, -0.06662575900554657, -0.029789507389068604, 0.08352577686309814, -0.02728394605219364, 0.044708672910928726, -0.0735979899764061, 0.017819032073020935, -0.01958010531961918, 0.07165202498435974, 0.00969562865793705, -0.04571561887860298, -0.0988437831401825, -0.07011397927999496, -0.08834321051836014, -0.02625284157693386, 0.019891632720828056, 0.016488049179315567, -0.012269455939531326, 0.04738584905862808, 0.051903948187828064, -0.03897923603653908, -0.037347473204135895, 0.05326958745718002, 0.04275256767868996, 0.03173677250742912, -0.0768430083990097, 0.007163276430219412, -0.008944354951381683, -0.06017165258526802, 0.011411430314183235, -0.034084197133779526, -0.005301363300532103, 0.012088626623153687, 0.02152804657816887, 0.10181474685668945, -0.0261826291680336, -0.039601586759090424, 0.006489006336778402, 0.02933519519865513, -0.04544290155172348, -0.007742589805275202, -0.004813802894204855, 0.09603268653154373, 0.03277521952986717, 0.08432482928037643, -0.0891396626830101, 0.010487009771168232, -0.06331383436918259, -0.07448549568653107, -0.007865756750106812, -0.06361770629882812, 0.015124536119401455, -0.018042227253317833, -0.04465952143073082, -0.07480841130018234, -0.08450882881879807, -0.07977401465177536, 0.025320621207356453, 0.015121611766517162, 0.044328637421131134, 0.03685144707560539, -0.03022228181362152, -0.03212488070130348, -0.042049817740917206, -0.01433677040040493, -0.0018401446286588907, 0.034741438925266266, 0.06902232766151428, -0.0017262055771425366, -0.04915926232933998, -0.051635269075632095, -0.010549811646342278, 5.351079744286835e-05, -0.07251422852277756, 0.07676265388727188, -0.046092644333839417, -0.04315895959734917, 0.010043316520750523, -6.699929855358278e-08, -0.05966666713356972, 0.024558771401643753, 0.05389845743775368, -0.010027292184531689, -0.018748173490166664, -0.06803726404905319, 0.06809776276350021, 0.03952054679393768, -0.06863334029912949, 0.029663704335689545, -0.012608231045305729, -0.04883410036563873, -0.056758228689432144, 0.03722525015473366, -0.058338139206171036, 0.026756228879094124, 0.05153670907020569, -0.0776892751455307, -0.0728776603937149, 0.12829945981502533, 0.075604647397995, 0.07568187266588211, -0.015777865424752235, -0.03822625055909157, -0.008980704471468925, -0.0045537487603724, -0.050797607749700546, -0.024064602330327034, 0.012572740204632282, 0.02425071969628334, 0.017546799033880234, 0.049241725355386734, 0.02654205821454525, 0.07485590130090714, 0.009427184239029884, -0.021247969940304756, 0.05196019634604454, 0.06747358292341232, 0.0277299415320158, -0.029983246698975563, -0.04739557206630707, -0.14136694371700287, 0.06814741343259811, 0.05317077040672302, -0.008972886949777603, 0.03635537251830101, 0.0316462479531765, -0.08805184066295624, 0.005531539209187031, 0.023486154153943062, -0.038617268204689026, -0.03490854427218437, -0.024816187098622322, 0.04160900041460991, 0.06307027488946915, -0.06431516259908676, 0.0053693028166890144, -0.007969100028276443, 0.0014340768102556467, 0.03115951642394066, -0.013493611477315426, 0.02474513091146946, -0.131655752658844, -0.003781001316383481]",
         "0.194"
        ],
        [
         "5",
         "25",
         "Top 10 AI Tools in 2023 That Will Make Your Life Easier",
         "In this article, we explore the top 10 AI tools that are driving innovation and efficiency in various industries. These tools are designed to automate repetitive tasks, improve workflow, and increase productivity. The tools included in our list are some of the most advanced and widely used in the market, and are suitable for a variety of applications. Some of the tools focus on natural language processing, such as ChatGPT and Grammarly, while others focus on image and video generation, such as DALL-E and Lumen5. Other tools such as OpenAI Codex, Tabnine, Canva, Jasper AI,, and Surfer SEO are designed to help with specific tasks such as code understanding content writing and website optimization. This list is a great starting point for anyone looking to explore the possibilities of AI and how it can be applied to their business or project. So let’s dive into 1. ChatGPT ChatGPT is a large language model that generates human-like responses to a variety of prompts. It can be used for tasks such as language translation, question answering, and text completion. It can handle a wide range of topics and styles of writing, and generates coherent and fluent text, but should be used with care as it may generate text that is biased, offensive, or factually incorrect. Pros: Generates human-like responses to a variety of prompts Can be fine-tuned for specific tasks such as language translation, question answering, and text completion Can handle a wide range of topics and styles of writing Can generate coherent and fluent text, even when completing a given text prompt. Cons: May generate text that is biased or offensive Can generate text that is not accurate or factually correct May require large amounts of computational resources to run The model can sometimes generate text that is not coherent or fluent, depending on the prompt given. Overall, ChatGPT is a powerful tool for natural language processing, but it should be used with care and with an understanding of its limitations. 2. DALL-E DALL-E is a generative model developed by OpenAI that is capable of generating images from text prompts. It is based on the GPT-3 architecture, which is a transformer-based neural network language model that has been trained on a massive dataset of text. DALL-E can generate images that are similar to a training dataset and it can generate high-resolution images that are suitable for commercial use. Pros: Generates high-resolution images Can generate images from text prompts It can be fine-tuned for specific tasks such as generating images of a certain style or category Cons: May generate images that are not entirely original and could be influenced by the training data May require significant computational resources to run The quality of the generated images may vary depending on the specific prompt Overall, DALL-E is a powerful AI-based tool for generating images, it can be used for a variety of applications such as creating images for commercial use, gaming, and other creative projects. It is important to note that the generated images should be reviewed and used with care, as they may not be entirely original and could be influenced by the training data. 3. Lumen5 Lumen5 is a content creation platform that uses AI to help users create videos, social media posts, and other types of content. It has several features that make it useful for content creation and marketing, including: Pros: Automatically summarizes text from a blog post, article, or another source into a script for a video or social media post Offers a library of royalty-free videos, images, and music to use in content Has a drag-and-drop interface for easy content creation Can create videos in multiple languages Has a built-in analytics tool to track the performance of created content. Cons: The quality of the generated content may vary depending on the source material The automatic summarization feature may not always capture the main points of the source material The library of videos, images, and music is limited. The analytics feature is basic Overall, Lumen5 is a useful tool for creating content quickly and easily, it can help automate the process of creating videos, social media posts, and other types of content. However, the quality of the generated content may vary depending on the source material and it is important to review and edit the content before publishing it. 4. Grammarly Grammarly is a writing-enhancement platform that uses AI to check for grammar, punctuation, and spelling errors in the text. It also provides suggestions for improving the clarity, concision, and readability of the text. It has several features that make it useful for improving writing, including: Pros: Checks for grammar, punctuation, and spelling errors in the text Provides suggestions for improving clarity, concision, and readability Can be integrated with various apps and platforms such as Microsoft Office, Google Docs, and social media platforms Offers a browser extension and a desktop app Has a premium version with more advanced features such as plagiarism detection and more Cons: The suggestions provided may not always be accurate or appropriate The grammar checker may not always recognize context-specific language use The free version has limited features Limited to English language only Overall, Grammarly is a useful tool for improving writing, it can help users identify and correct grammar and punctuation errors, and improve the clarity, concision, and readability of their text. However, it is important to review the suggestions provided by the tool and use them with caution, as they may not always be accurate or appropriate. 5.OpenAI Codex OpenAI Codex is a system developed by OpenAI that can create code from natural language descriptions of software tasks. The system is based on the GPT-3 model and can generate code in multiple programming languages. Pros: Can automate the process of writing code Can help developers to be more productive Can help non-technical people to create software Can generate code in multiple programming languages Cons: The quality of the generated code may vary depending on the task description The generated code may not always be optimal or efficient The system may not be able to handle complex software tasks Dependence on the tool may lead to a lack of understanding of the code. Overall, OpenAI Codex is a powerful tool that can help automate the process of writing code and make it more accessible to non-technical people. However, the quality of the generated code may vary depending on the task description and it is important to review and test the code before using it in a production environment. It is important to use the tool as an aid, not a replacement for the developer's knowledge. 6. Tabnine Tabnine is a code completion tool that uses AI to predict and suggest code snippets. It is compatible with multiple programming languages and can be integrated with various code editors. Pros: Can improve coding efficiency by suggesting code snippets based on context Can complete entire code blocks Can predict variables, functions, and other elements of code Can be integrated with various code editors Cons: The suggestions may not always be accurate or appropriate The system may not always be able to understand the context of the code May not work with all code editors Dependence on the tool may lead to a lack of understanding of the code. Overall, TabNine is a useful tool for developers that can help improve coding efficiency and reduce the time spent on writing code. However, it is important to review the suggestions provided by the tool and use them with caution, as they may not always be accurate or appropriate. It is important to use the tool as an aid, not a replacement for the developer's knowledge. 7. Jasper AI Jasper is a content writing and content generation tool that uses artificial intelligence to identify the best words and sentences for your writing style and medium in the most efficient, quick, and accessible way. Pros: User-friendly interface Generates a wide variety of content types Guarantees 100% unique and free-plagiarism content SEO friendly Create articles of up to 10k words Cons: Not the cheapest AI writer on the market 8. Surfer SEO Surfer SEO is a software tool designed to help website owners and digital marketers improve their search engine optimization (SEO) efforts. The tool provides a variety of features that can be used to analyze a website's on-page SEO, including: Features: A site audit tool that checks for technical SEO issues A content editor that suggests optimizations for individual pages A keyword research tool that suggests keywords to target A SERP analyzer that shows how a website's pages rank for specific keywords A backlink analysis tool that shows the backlinks pointing to a website. Pros: Can help website owners and marketers identify technical SEO issues Can provide suggestions for optimizing individual pages Can help with keyword research Can show how a website's pages rank for specific keywords Can provide insight into a website's backlink profile Cons: Some features may require a paid subscription The tool is not a guarantee of better ranking The tool can only analyze the data it has access to The tool's suggestions may not always be applicable or optimal Overall, Surfer SEO can be a useful tool for website owners and digital marketers looking to improve their SEO efforts. However, it is important to remember that it is just a tool and should be used in conjunction with other SEO best practices. Additionally, the tool is not a guarantee of better ranking. 9. Zapier Zapier is a web automation tool that allows users to automate repetitive tasks by connecting different web applications together. It does this by creating \"Zaps\" that automatically move data between apps, and can also be used to trigger certain actions in one app based on events in another app. Features: Can connect over 3,000 web applications Can automate repetitive tasks Can create \"Zaps\" to move data between apps Can trigger certain actions in one app based on events in another app. Pros: Can automate repetitive tasks Can save time Can improve workflow Can increase productivity Can be integrated with a wide range of web applications Cons: Can be difficult to set up May require some technical skills May require a paid subscription for some features Some apps may not be compatible Dependence on the tool may lead to a lack of understanding of the apps Overall, Zapier is a useful tool that can help users automate repetitive tasks and improve workflow. It can save time and increase productivity by connecting different web applications together. However, it may require some technical skills and some features may require a paid subscription. It is important to use the tool with caution and not to rely too much on it, to understand the apps better. 10. Compose AI Compose AI is a company that specializes in developing natural language generation (NLG) software. Their software uses AI to automatically generate written or spoken text from structured data, such as spreadsheets, databases, or APIs. Features: Automatically generates written or spoken text from structured data Can be integrated with a wide range of data sources Can be used for a variety of applications such as creating reports, summaries, and explanations Provides an API and a user-friendly interface Pros: Can automate the process of creating written or spoken content Can help users create more accurate and consistent content Can help users save time by automating repetitive tasks Can be integrated with a wide range of data sources Cons: The quality of the generated content may vary depending on the data source The generated content may not always be optimal or efficient The system may not be able to handle complex tasks Dependence on the tool may lead to a lack of understanding of the data Overall, Compose AI's NLG software can be a useful tool for automating the process of creating written or spoken content from structured data. However, the quality of the generated content may vary depending on the data source, and it is essential to review the generated content before using it in a production environment. It is important to use the tool as an aid, not a replacement for the understanding of the data. Conclusion AI tools are becoming increasingly important in today's business and technology landscape. They are designed to automate repetitive tasks, improve workflow, and increase productivity. The top 10 AI tools included in this article are some of the most advanced and widely used in the market, and are suitable for various applications. Whether you're looking to improve your natural language processing, create high-resolution images, or optimize your website, there is an AI tool that can help. It's important to research and evaluate the different tools available to determine which one is the best fit for your specific needs. As AI technology continues to evolve, these tools will become even more powerful and versatile and will play an even greater role in shaping the future of business and technology.",
         "Top 10 AI Tools in 2023 That Will Make Your Life Easier\n\n\n\n\n\n\n\n\n\nIn this article, we explore the top 10 AI tools that are driving innovation and efficiency in various industries. These tools are designed to automate repetitive tasks, improve workflow, and increase productivity. The tools included in our list are some of the most advanced and widely used in the market, and are suitable for a variety of applications. Some of the tools focus on natural language processing, such as ChatGPT and Grammarly, while others focus on image and video generation, such as DALL-E and Lumen5. Other tools such as OpenAI Codex, Tabnine, Canva, Jasper AI,, and Surfer SEO are designed to help with specific tasks such as code understanding content writing and website optimization. This list is a great starting point for anyone looking to explore the possibilities of AI and how it can be applied to their business or project.\n\nSo let’s dive into\n\n1. ChatGPT\n\nChatGPT is a large language model that generates human-like responses to a variety of prompts. It can be used for tasks such as language translation, question answering, and text completion. It can handle a wide range of topics and styles of writing, and generates coherent and fluent text, but should be used with care as it may generate text that is biased, offensive, or factually incorrect.\n\nPros:\n\nGenerates human-like responses to a variety of prompts\n\nCan be fine-tuned for specific tasks such as language translation, question answering, and text completion\n\nCan handle a wide range of topics and styles of writing\n\nCan generate coherent and fluent text, even when completing a given text prompt.\n\nCons:\n\nMay generate text that is biased or offensive\n\nCan generate text that is not accurate or factually correct\n\nMay require large amounts of computational resources to run\n\nThe model can sometimes generate text that is not coherent or fluent, depending on the prompt given.\n\nOverall, ChatGPT is a powerful tool for natural language processing, but it should be used with care and with an understanding of its limitations.\n\n2. DALL-E\n\nDALL-E is a generative model developed by OpenAI that is capable of generating images from text prompts. It is based on the GPT-3 architecture, which is a transformer-based neural network language model that has been trained on a massive dataset of text. DALL-E can generate images that are similar to a training dataset and it can generate high-resolution images that are suitable for commercial use.\n\nPros:\n\nGenerates high-resolution images\n\nCan generate images from text prompts\n\nIt can be fine-tuned for specific tasks such as generating images of a certain style or category\n\nCons:\n\nMay generate images that are not entirely original and could be influenced by the training data\n\nMay require significant computational resources to run\n\nThe quality of the generated images may vary depending on the specific prompt\n\nOverall, DALL-E is a powerful AI-based tool for generating images, it can be used for a variety of applications such as creating images for commercial use, gaming, and other creative projects. It is important to note that the generated images should be reviewed and used with care, as they may not be entirely original and could be influenced by the training data.\n\n3. Lumen5\n\nLumen5 is a content creation platform that uses AI to help users create videos, social media posts, and other types of content. It has several features that make it useful for content creation and marketing, including:\n\nPros:\n\nAutomatically summarizes text from a blog post, article, or another source into a script for a video or social media post\n\nOffers a library of royalty-free videos, images, and music to use in content\n\nHas a drag-and-drop interface for easy content creation\n\nCan create videos in multiple languages\n\nHas a built-in analytics tool to track the performance of created content.\n\nCons:\n\nThe quality of the generated content may vary depending on the source material\n\nThe automatic summarization feature may not always capture the main points of the source material\n\nThe library of videos, images, and music is limited.\n\nThe analytics feature is basic\n\nOverall, Lumen5 is a useful tool for creating content quickly and easily, it can help automate the process of creating videos, social media posts, and other types of content. However, the quality of the generated content may vary depending on the source material and it is important to review and edit the content before publishing it.\n\n4. Grammarly\n\nGrammarly is a writing-enhancement platform that uses AI to check for grammar, punctuation, and spelling errors in the text. It also provides suggestions for improving the clarity, concision, and readability of the text. It has several features that make it useful for improving writing, including:\n\nPros:\n\nChecks for grammar, punctuation, and spelling errors in the text\n\nProvides suggestions for improving clarity, concision, and readability\n\nCan be integrated with various apps and platforms such as Microsoft Office, Google Docs, and social media platforms\n\nOffers a browser extension and a desktop app\n\nHas a premium version with more advanced features such as plagiarism detection and more\n\nCons:\n\nThe suggestions provided may not always be accurate or appropriate\n\nThe grammar checker may not always recognize context-specific language use\n\nThe free version has limited features\n\nLimited to English language only\n\nOverall, Grammarly is a useful tool for improving writing, it can help users identify and correct grammar and punctuation errors, and improve the clarity, concision, and readability of their text. However, it is important to review the suggestions provided by the tool and use them with caution, as they may not always be accurate or appropriate.\n\n5.OpenAI Codex\n\nOpenAI Codex is a system developed by OpenAI that can create code from natural language descriptions of software tasks. The system is based on the GPT-3 model and can generate code in multiple programming languages.\n\nPros:\n\nCan automate the process of writing code\n\nCan help developers to be more productive\n\nCan help non-technical people to create software\n\nCan generate code in multiple programming languages\n\nCons:\n\nThe quality of the generated code may vary depending on the task description\n\nThe generated code may not always be optimal or efficient\n\nThe system may not be able to handle complex software tasks\n\nDependence on the tool may lead to a lack of understanding of the code.\n\nOverall, OpenAI Codex is a powerful tool that can help automate the process of writing code and make it more accessible to non-technical people. However, the quality of the generated code may vary depending on the task description and it is important to review and test the code before using it in a production environment. It is important to use the tool as an aid, not a replacement for the developer's knowledge.\n\n6. Tabnine\n\nTabnine is a code completion tool that uses AI to predict and suggest code snippets. It is compatible with multiple programming languages and can be integrated with various code editors.\n\nPros:\n\nCan improve coding efficiency by suggesting code snippets based on context\n\nCan complete entire code blocks\n\nCan predict variables, functions, and other elements of code\n\nCan be integrated with various code editors\n\nCons:\n\nThe suggestions may not always be accurate or appropriate\n\nThe system may not always be able to understand the context of the code\n\nMay not work with all code editors\n\nDependence on the tool may lead to a lack of understanding of the code.\n\nOverall, TabNine is a useful tool for developers that can help improve coding efficiency and reduce the time spent on writing code. However, it is important to review the suggestions provided by the tool and use them with caution, as they may not always be accurate or appropriate. It is important to use the tool as an aid, not a replacement for the developer's knowledge.\n\nJasper is a content writing and content generation tool that uses artificial intelligence to identify the best words and sentences for your writing style and medium in the most efficient, quick, and accessible way.\n\nPros:\n\nUser-friendly interface\n\nGenerates a wide variety of content types\n\nGuarantees 100% unique and free-plagiarism content\n\nSEO friendly\n\nCreate articles of up to 10k words\n\nCons:\n\nNot the cheapest AI writer on the market\n\nSurfer SEO is a software tool designed to help website owners and digital marketers improve their search engine optimization (SEO) efforts. The tool provides a variety of features that can be used to analyze a website's on-page SEO, including:\n\nFeatures:\n\nA site audit tool that checks for technical SEO issues\n\nA content editor that suggests optimizations for individual pages\n\nA keyword research tool that suggests keywords to target\n\nA SERP analyzer that shows how a website's pages rank for specific keywords\n\nA backlink analysis tool that shows the backlinks pointing to a website.\n\nPros:\n\nCan help website owners and marketers identify technical SEO issues\n\nCan provide suggestions for optimizing individual pages\n\nCan help with keyword research\n\nCan show how a website's pages rank for specific keywords\n\nCan provide insight into a website's backlink profile\n\nCons:\n\nSome features may require a paid subscription\n\nThe tool is not a guarantee of better ranking\n\nThe tool can only analyze the data it has access to\n\nThe tool's suggestions may not always be applicable or optimal\n\nOverall, Surfer SEO can be a useful tool for website owners and digital marketers looking to improve their SEO efforts. However, it is important to remember that it is just a tool and should be used in conjunction with other SEO best practices. Additionally, the tool is not a guarantee of better ranking.\n\n9. Zapier\n\nZapier is a web automation tool that allows users to automate repetitive tasks by connecting different web applications together. It does this by creating \"Zaps\" that automatically move data between apps, and can also be used to trigger certain actions in one app based on events in another app.\n\nFeatures:\n\nCan connect over 3,000 web applications\n\nCan automate repetitive tasks\n\nCan create \"Zaps\" to move data between apps\n\nCan trigger certain actions in one app based on events in another app.\n\nPros:\n\nCan automate repetitive tasks\n\nCan save time\n\nCan improve workflow\n\nCan increase productivity\n\nCan be integrated with a wide range of web applications\n\nCons:\n\nCan be difficult to set up\n\nMay require some technical skills\n\nMay require a paid subscription for some features\n\nSome apps may not be compatible\n\nDependence on the tool may lead to a lack of understanding of the apps\n\nOverall, Zapier is a useful tool that can help users automate repetitive tasks and improve workflow. It can save time and increase productivity by connecting different web applications together. However, it may require some technical skills and some features may require a paid subscription. It is important to use the tool with caution and not to rely too much on it, to understand the apps better.\n\n10. Compose AI\n\nCompose AI is a company that specializes in developing natural language generation (NLG) software. Their software uses AI to automatically generate written or spoken text from structured data, such as spreadsheets, databases, or APIs.\n\nFeatures:\n\nAutomatically generates written or spoken text from structured data\n\nCan be integrated with a wide range of data sources\n\nCan be used for a variety of applications such as creating reports, summaries, and explanations\n\nProvides an API and a user-friendly interface\n\nPros:\n\nCan automate the process of creating written or spoken content\n\nCan help users create more accurate and consistent content\n\nCan help users save time by automating repetitive tasks\n\nCan be integrated with a wide range of data sources\n\nCons:\n\nThe quality of the generated content may vary depending on the data source\n\nThe generated content may not always be optimal or efficient\n\nThe system may not be able to handle complex tasks\n\nDependence on the tool may lead to a lack of understanding of the data\n\nOverall, Compose AI's NLG software can be a useful tool for automating the process of creating written or spoken content from structured data. However, the quality of the generated content may vary depending on the data source, and it is essential to review the generated content before using it in a production environment. It is important to use the tool as an aid, not a replacement for the understanding of the data.\n\nConclusion\n\nAI tools are becoming increasingly important in today's business and technology landscape. They are designed to automate repetitive tasks, improve workflow, and increase productivity. The top 10 AI tools included in this article are some of the most advanced and widely used in the market, and are suitable for various applications. Whether you're looking to improve your natural language processing, create high-resolution images, or optimize your website, there is an AI tool that can help. It's important to research and evaluate the different tools available to determine which one is the best fit for your specific needs. As AI technology continues to evolve, these tools will become even more powerful and versatile and will play an even greater role in shaping the future of business and technology.",
         "2023-01-25T19:52:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2023/01/top-10-ai-tools-in-2023-that-will-make.html",
         "2025-07-26T05:41:35.772289",
         "Top 10 AI Tools in 2023 That Will Make Your Life Easier In this article, we explore the top 10 AI tools that are driving innovation and efficiency in various industries. These tools are designed to automate repetitive tasks, improve workflow, and increase productivity. The tools included in our list are some of the most advanced and widely used in the market, and are suitable for a variety of applications. Some of the tools focus on natural language processing, such as ChatGPT and Grammarly, while others focus on image and video generation, such as DALL-E and Lumen5. Other tools such as OpenAI Codex, Tabnine, Canva, Jasper AI,, and Surfer SEO are designed to help with specific tasks such as code understanding content writing and website optimization. This list is a great starting point for anyone looking to explore the possibilities of AI and how it can be applied to their business or project. So let’s dive into 1. ChatGPT ChatGPT is a large language model that generates human-like responses to a variety of prompts. It can be used for tasks such as language translation, question answering, and text completion. It can handle a wide range of topics and styles of writing, and generates coherent and fluent text, but should be used with care as it may generate text that is biased, offensive, or factually incorrect. Pros: Generates human-like responses to a variety of prompts Can be fine-tuned for specific tasks such as language translation, question answering, and text completion Can handle a wide range of topics and styles of writing Can generate coherent and fluent text, even when completing a given text prompt. Cons: May generate text that is biased or offensive Can generate text that is not accurate or factually correct May require large amounts of computational resources to run The model can sometimes generate text that is not coherent or fluent, depending on the prompt given. Overall, ChatGPT is a powerful tool for natural language processing, but it should be used with care and with an understanding of its limitations. 2. DALL-E DALL-E is a generative model developed by OpenAI that is capable of generating images from text prompts. It is based on the GPT-3 architecture, which is a transformer-based neural network language model that has been trained on a massive dataset of text. DALL-E can generate images that are similar to a training dataset and it can generate high-resolution images that are suitable for commercial use. Pros: Generates high-resolution images Can generate images from text prompts It can be fine-tuned for specific tasks such as generating images of a certain style or category Cons: May generate images that are not entirely original and could be influenced by the training data May require significant computational resources to run The quality of the generated images may vary depending on the specific prompt Overall, DALL-E is a powerful AI-based tool for generating images, it can be used for a variety of applications such as creating images for commercial use, gaming, and other creative projects. It is important to note that the generated images should be reviewed and used with care, as they may not be entirely original and could be influenced by the training data. 3. Lumen5 Lumen5 is a content creation platform that uses AI to help users create videos, social media posts, and other types of content. It has several features that make it useful for content creation and marketing, including: Pros: Automatically summarizes text from a blog post, article, or another source into a script for a video or social media post Offers a library of royalty-free videos, images, and music to use in content Has a drag-and-drop interface for easy content creation Can create videos in multiple languages Has a built-in analytics tool to track the performance of created content. Cons: The quality of the generated content may vary depending on the source material The automatic summarization feature may not always capture the main points of the source material The library of videos, images, and music is limited. The analytics feature is basic Overall, Lumen5 is a useful tool for creating content quickly and easily, it can help automate the process of creating videos, social media posts, and other types of content. However, the quality of the generated content may vary depending on the source material and it is important to review and edit the content before publishing it. 4. Grammarly Grammarly is a writing-enhancement platform that uses AI to check for grammar, punctuation, and spelling errors in the text. It also provides suggestions for improving the clarity, concision, and readability of the text. It has several features that make it useful for improving writing, including: Pros: Checks for grammar, punctuation, and spelling errors in the text Provides suggestions for improving clarity, concision, and readability Can be integrated with various apps and platforms such as Microsoft Office, Google Docs, and social media platforms Offers a browser extension and a desktop app Has a premium version with more advanced features such as plagiarism detection and more Cons: The suggestions provided may not always be accurate or appropriate The grammar checker may not always recognize context-specific language use The free version has limited features Limited to English language only Overall, Grammarly is a useful tool for improving writing, it can help users identify and correct grammar and punctuation errors, and improve the clarity, concision, and readability of their text. However, it is important to review the suggestions provided by the tool and use them with caution, as they may not always be accurate or appropriate. 5.OpenAI Codex OpenAI Codex is a system developed by OpenAI that can create code from natural language descriptions of software tasks. The system is based on the GPT-3 model and can generate code in multiple programming languages. Pros: Can automate the process of writing code Can help developers to be more productive Can help non-technical people to create software Can generate code in multiple programming languages Cons: The quality of the generated code may vary depending on the task description The generated code may not always be optimal or efficient The system may not be able to handle complex software tasks Dependence on the tool may lead to a lack of understanding of the code. Overall, OpenAI Codex is a powerful tool that can help automate the process of writing code and make it more accessible to non-technical people. However, the quality of the generated code may vary depending on the task description and it is important to review and test the code before using it in a production environment. It is important to use the tool as an aid, not a replacement for the developer's knowledge. 6. Tabnine Tabnine is a code completion tool that uses AI to predict and suggest code snippets. It is compatible with multiple programming languages and can be integrated with various code editors. Pros: Can improve coding efficiency by suggesting code snippets based on context Can complete entire code blocks Can predict variables, functions, and other elements of code Can be integrated with various code editors Cons: The suggestions may not always be accurate or appropriate The system may not always be able to understand the context of the code May not work with all code editors Dependence on the tool may lead to a lack of understanding of the code. Overall, TabNine is a useful tool for developers that can help improve coding efficiency and reduce the time spent on writing code. However, it is important to review the suggestions provided by the tool and use them with caution, as they may not always be accurate or appropriate. It is important to use the tool as an aid, not a replacement for the developer's knowledge. Jasper is a content writing and content generation tool that uses artificial intelligence to identify the best words and sentences for your writing style and medium in the most efficient, quick, and accessible way. Pros: User-friendly interface Generates a wide variety of content types Guarantees 100% unique and free-plagiarism content SEO friendly Create articles of up to 10k words Cons: Not the cheapest AI writer on the market Surfer SEO is a software tool designed to help website owners and digital marketers improve their search engine optimization (SEO) efforts. The tool provides a variety of features that can be used to analyze a website's on-page SEO, including: Features: A site audit tool that checks for technical SEO issues A content editor that suggests optimizations for individual pages A keyword research tool that suggests keywords to target A SERP analyzer that shows how a website's pages rank for specific keywords A backlink analysis tool that shows the backlinks pointing to a website. Pros: Can help website owners and marketers identify technical SEO issues Can provide suggestions for optimizing individual pages Can help with keyword research Can show how a website's pages rank for specific keywords Can provide insight into a website's backlink profile Cons: Some features may require a paid subscription The tool is not a guarantee of better ranking The tool can only analyze the data it has access to The tool's suggestions may not always be applicable or optimal Overall, Surfer SEO can be a useful tool for website owners and digital marketers looking to improve their SEO efforts. However, it is important to remember that it is just a tool and should be used in conjunction with other SEO best practices. Additionally, the tool is not a guarantee of better ranking. 9. Zapier Zapier is a web automation tool that allows users to automate repetitive tasks by connecting different web applications together. It does this by creating \"Zaps\" that automatically move data between apps, and can also be used to trigger certain actions in one app based on events in another app. Features: Can connect over 3,000 web applications Can automate repetitive tasks Can create \"Zaps\" to move data between apps Can trigger certain actions in one app based on events in another app. Pros: Can automate repetitive tasks Can save time Can improve workflow Can increase productivity Can be integrated with a wide range of web applications Cons: Can be difficult to set up May require some technical skills May require a paid subscription for some features Some apps may not be compatible Dependence on the tool may lead to a lack of understanding of the apps Overall, Zapier is a useful tool that can help users automate repetitive tasks and improve workflow. It can save time and increase productivity by connecting different web applications together. However, it may require some technical skills and some features may require a paid subscription. It is important to use the tool with caution and not to rely too much on it, to understand the apps better. 10. Compose AI Compose AI is a company that specializes in developing natural language generation (NLG) software. Their software uses AI to automatically generate written or spoken text from structured data, such as spreadsheets, databases, or APIs. Features: Automatically generates written or spoken text from structured data Can be integrated with a wide range of data sources Can be used for a variety of applications such as creating reports, summaries, and explanations Provides an API and a user-friendly interface Pros: Can automate the process of creating written or spoken content Can help users create more accurate and consistent content Can help users save time by automating repetitive tasks Can be integrated with a wide range of data sources Cons: The quality of the generated content may vary depending on the data source The generated content may not always be optimal or efficient The system may not be able to handle complex tasks Dependence on the tool may lead to a lack of understanding of the data Overall, Compose AI's NLG software can be a useful tool for automating the process of creating written or spoken content from structured data. However, the quality of the generated content may vary depending on the data source, and it is essential to review the generated content before using it in a production environment. It is important to use the tool as an aid, not a replacement for the understanding of the data. Conclusion AI tools are becoming increasingly important in today's business and technology landscape. They are designed to automate repetitive tasks, improve workflow, and increase productivity. The top 10 AI tools included in this article are some of the most advanced and widely used in the market, and are suitable for various applications. Whether you're looking to improve your natural language processing, create high-resolution images, or optimize your website, there is an AI tool that can help. It's important to research and evaluate the different tools available to determine which one is the best fit for your specific needs. As AI technology continues to evolve, these tools will become even more powerful and versatile and will play an even greater role in shaping the future of business and technology.",
         "en",
         "{'MISC': ['A content editor that suggests optimizations for individual', 'A keyword research', 'AI Compose AI is a company that specializes in developing natural language generation', 'AI to automatically generate written or spoken', 'AI to predict and suggest', 'APIs', 'Additionally, the tool is not a guarantee of better ranking', 'Can', 'Can be', 'Can be fine', 'Can be integrated with a wide range of data', 'Can be integrated with various', 'Can create videos in multiple languages Has a built', 'Can generate images from text', 'Can generate text that is not accurate or factually', 'Can handle a wide range of topics and styles of writing Can generate', 'Can help developers to be more productive', 'Can help users create more accurate and', 'Can provide suggestions', 'Canva', 'ChatGPT', 'ChatGPT and', 'ChatGPT is a powerful tool for natural language processing', 'Codex OpenAI', 'Codex is', 'Cons', 'Cons:', 'Cons: The quality of the generated content may vary depending on the data', 'Dependence', 'Generates a wide', 'Generates high', 'Google Docs', 'Grammarly', 'Guarantees', 'It also provides suggestions for improving the clarity', 'It can be fine', 'It can be used for tasks such as language', 'It can handle a wide range of topics and styles of writing', 'It can save time and increase productivity by connecting different web applications together', 'It does this by creating \"Zaps', 'It has several features', 'It is based on the GPT-3 architecture', 'It is compatible with multiple programming languages and can be integrated with various', 'It is important to note that the generated images should be reviewed and used with care', 'It is important to use the tool as an aid', 'It is important to use the tool with caution and not to rely too much on it', \"It'\", 'Jasper is a content writing and content generation tool', 'Limited to English language only Overall', 'Lumen5', 'Lumen5 is a useful tool for creating content quickly and easily', 'Make Your Life Easier In this article', 'May', 'May generate images that are not entirely', 'May generate text that is biased or', 'Microsoft Office', 'NLG', 'NLG software can be a useful tool', 'Offers', 'OpenAI', 'OpenAI that is capable of generating images from text', 'Other tools such as OpenAI', 'Overall', 'Pros:', 'Pros: Checks for grammar', 'Provides suggestions for improving clarity', 'So let’', 'Some apps may not be', 'Some features may', 'Some of the tools focus on natural language processing', 'Surfer SEO can be a useful tool for website owners and digital marketers looking to improve their SEO', 'Surfer SEO is a software tool designed to help website owners and digital marketers improve their search engine', 'TabNine is a useful tool for developers that can help improve coding efficiency and reduce the time', 'The analytics feature is basic Overall', 'The free version has', 'The generated code may not always be optimal or', 'The generated content may not always be optimal or', 'The grammar checker may not always recognize context', 'The quality of the generated content may vary depending on the source material The automatic summarization feature may not always capture the main points of the source material The library of videos', 'The system is based on the GPT-3 model and can', 'The system may not always be able to understand the context of the code May not work with all', 'The system may not be able to handle complex software tasks Dependence', 'The system may not be able to handle complex tasks Dependence', \"The tool is not a guarantee of better ranking The tool can only analyze the data it has access to The tool'\", 'The tools', 'The top 10 AI', 'Their software uses', 'These tools are designed to automate repetitive tasks', 'They are designed to automate repetitive tasks', 'Top 10 AI Tools in', \"Whether you're looking to improve your natural language processing\", 'Zapier is a useful tool that can', 'and are suitable for', 'and are suitable for various applications', 'and improve the clarity', 'and increase productivity', 'and music to use in content Has a drag-and-drop interface for easy content creation', 'and readability of the text', 'and readability of their text', 'answering, and text', 'create high', 'gaming, and other creative projects', 'improve workflow', 'it can be used for', 'of software tasks', 'paid subscription', 'paid subscription for some features', 'point for anyone looking to explore', 'post', 'snippets based on context', 'such as DALL', 'that are suitable for commercial', 'the best words and sentences for your writing style and medium in the most', 'the quality of the generated code may vary depending on the task description and it is important to review and test the code before using it in', 'the quality of the generated content may vary depending on the data', 'the quality of the generated content may vary depending on the source material and it is important to review and edit the content before publishing it', 'these tools will become even more powerful and versatile and will play an even greater role in shaping the future of business and technology', 'to understand the apps better', 'understanding content writing and website optimization', 'we', \"website'\"], 'PER': [\"AI'\", 'However', 'Jasper AI', 'Tabnine', 'Zapier Zapier is a web automation', 'and readability', 'depending on the'], 'ORG': ['Can', 'Can be difficult to set up May', 'Features', 'and generates', 'summaries'], 'LOC': ['Automatically', 'Features', 'May', 'Pros', 'and spelling errors in the text', 'not']}",
         "[-0.11302992701530457, -0.08803797513246536, 0.015575987286865711, 0.00032999791437759995, 0.03810613602399826, -0.046201061457395554, 0.045850880444049835, 0.04401774704456329, 0.010813307948410511, -0.025853265076875687, -0.07179535180330276, -0.0018584352219477296, -0.0078117744997143745, 0.03540593385696411, 0.01843256503343582, 0.03011765144765377, 0.03475261479616165, -0.02460617758333683, -0.036245305091142654, -0.15015757083892822, 0.0180674996227026, 0.05636512488126755, 0.0701831504702568, -0.05025672912597656, 0.020251423120498657, 0.08043131232261658, -0.02935820072889328, -0.12700483202934265, 0.010330401360988617, -0.036111705005168915, 0.0026480937376618385, 0.0014239728916436434, 0.02500186301767826, 0.06473381072282791, -0.0917133018374443, 0.04205360263586044, -0.043610330671072006, -0.007231826428323984, 0.07512470334768295, -0.051861442625522614, -0.08981242775917053, -0.06688828766345978, -0.010196805000305176, -0.05794090777635574, 0.13666586577892303, -0.04254871606826782, -0.06564588844776154, -0.025167550891637802, 0.01315445639193058, 0.06539499759674072, -0.14640913903713226, -0.03866703435778618, -0.007038415409624577, 0.02456849440932274, -0.02906102128326893, 0.059638503938913345, -0.008843396790325642, 0.009034167975187302, 0.057964298874139786, -0.06868033111095428, 0.02151322551071644, -0.036073748022317886, 0.0030024144798517227, -0.006736839655786753, -0.00419598026201129, -0.02219134382903576, -0.001022832002490759, -0.0020775108132511377, 0.005903038661926985, -0.04206858202815056, -0.019559118896722794, 0.05510394275188446, -0.04318516328930855, 0.06228864938020706, -0.03480345755815506, 0.05621124804019928, 0.030146833509206772, -0.04344166815280914, 0.00027717655757442117, -0.0507567897439003, 0.020752156153321266, -0.013840560801327229, 0.03987828642129898, 0.05059158802032471, -0.019437547773122787, -0.009740631096065044, 0.04033610224723816, 0.064368836581707, 0.04624921828508377, 0.0558585450053215, -0.017923878505825996, -0.028784651309251785, 0.0631285160779953, -0.010782693512737751, 0.012731176801025867, 0.012262189760804176, -0.013338764198124409, -0.09806373715400696, -0.07427410036325455, 0.030178038403391838, -0.0009504553745500743, 0.026920637115836143, 0.03207134082913399, -0.10594387352466583, -0.06373194605112076, 0.023124800994992256, 0.1189812645316124, -0.009790686890482903, 0.05951208993792534, -0.04825343191623688, -0.04669009894132614, 0.00016202266851905733, -0.004744893405586481, -0.07052841037511826, 0.06865633279085159, -0.00834766123443842, -0.010790364816784859, 0.021947050467133522, 0.06405746936798096, 0.08896361291408539, -0.012784342281520367, 0.04690203443169594, -0.04151299595832825, 0.029010944068431854, 0.054007213562726974, 0.05894146114587784, -0.03317425400018692, 3.8190680044903455e-33, 0.04527157172560692, 0.021008867770433426, -0.01646970957517624, 0.06374548375606537, 0.05162477865815163, 0.007260264363139868, 0.004021310713142157, 0.024338534101843834, -0.06714075058698654, -0.05908307060599327, -0.03715327009558678, 0.04391011968255043, -0.09810749441385269, 0.08915512263774872, 0.06337888538837433, -0.05002303421497345, -0.009481387212872505, 0.04350076615810394, 0.017625318840146065, -0.01070212572813034, 0.001382574555464089, -0.03681088238954544, 0.04071860387921333, 0.06910049170255661, 0.08884335309267044, 0.039518311619758606, 0.09180636703968048, -0.08667203783988953, 0.030228156596422195, 0.006558036431670189, -0.07216306775808334, -0.03540471941232681, -0.03269893676042557, 0.052961770445108414, -0.04179457202553749, -0.008839637041091919, -0.0870877206325531, -0.07018152624368668, -0.006789147853851318, 0.09467107057571411, -0.04802923649549484, 0.00273248297162354, -0.006475887726992369, -0.039420660585165024, -0.030558977276086807, -0.03514332324266434, -0.029491450637578964, 0.0559072382748127, 0.03423332795500755, 0.037007637321949005, -0.03210299089550972, 0.04566512629389763, 0.030146056786179543, -0.0017676458228379488, 0.01275365799665451, -0.04199910908937454, 0.006165327038615942, 0.005347547587007284, 0.06480036675930023, 0.04517127946019173, -0.017654573544859886, -0.004216494504362345, -0.06608716398477554, 0.04547850787639618, 0.06383682787418365, 0.049188241362571716, 0.10071727633476257, 0.0802096575498581, 0.043901581317186356, 0.007562451064586639, -0.026795323938131332, -0.018717382103204727, 0.05642208456993103, 0.0021214131265878677, -0.028102288022637367, 0.0240616612136364, 0.0064122844487428665, -0.12601271271705627, 0.027966419234871864, -0.018999753519892693, -0.06216064468026161, 0.02472071908414364, 0.01596875488758087, -0.05843197554349899, 0.03474901244044304, -0.05900251492857933, 0.015051674097776413, -0.056377410888671875, 0.008075719699263573, 0.03596584126353264, -0.06179705634713173, 0.03839469701051712, -0.021662987768650055, 0.05723724141716957, -0.03250689432024956, -1.68542728995785e-33, -0.02054961957037449, -0.026925960555672646, -0.09842691570520401, 0.08622147142887115, -0.015488690696656704, -0.029891783371567726, 0.03281817585229874, -0.007219705265015364, 0.04550044983625412, -0.07602711766958237, -0.0270738136023283, -0.030640754848718643, 0.010450109839439392, 0.004204574041068554, 0.01729862578213215, -0.025177277624607086, -0.010518544353544712, -0.11798873543739319, -0.05108098313212395, 0.033246200531721115, 0.021023914217948914, 0.08813102543354034, -0.0967116504907608, -0.009274921379983425, 0.00988373626023531, 0.014089846983551979, -0.04232199117541313, 0.02546810731291771, -0.042927488684654236, 0.0016350921941921115, 0.03855577111244202, 0.04831821098923683, -0.01226873230189085, 0.02765890769660473, 0.03650200739502907, 0.05913681164383888, 0.13877637684345245, -0.0159592367708683, -0.059622325003147125, 0.08833086490631104, 0.11181917041540146, -0.018032921478152275, -0.015826677903532982, -0.03827616572380066, -0.041133180260658264, 0.07549068331718445, -0.1416463851928711, 0.02987242490053177, -0.05970705673098564, 0.0325188934803009, 0.017109153792262077, -0.02232212945818901, -0.04536036401987076, -0.061034586280584335, -0.019000185653567314, -0.0685686320066452, -0.0006557397427968681, -0.021736543625593185, -0.042810793966054916, 0.0038475238252431154, -0.059221301227808, 0.003985194023698568, 0.11714255064725876, 0.0027241280768066645, -0.006473483517765999, -0.04168849438428879, 0.022832229733467102, 0.04690165817737579, -0.06081775203347206, -0.05446184426546097, 0.07406147569417953, -0.09157862514257431, 0.06717191636562347, 0.03561349958181381, -0.0312986746430397, 0.028002530336380005, 0.03548138588666916, -0.032896995544433594, 0.047053564339876175, -0.08702331781387329, 0.03651057183742523, -0.007802710868418217, 0.017892271280288696, 0.018655797466635704, 0.03605477511882782, 0.08215297013521194, -0.01741110347211361, 0.0848969966173172, 0.038506317883729935, 0.05960094928741455, -0.03748852387070656, 0.02352854423224926, -0.04215692728757858, 0.12517383694648743, -0.04053279757499695, -4.9971017546113217e-08, -0.0321381539106369, -0.041675273329019547, -0.015840373933315277, 0.05937350168824196, 0.013941636309027672, -0.026774214580655098, 0.017179517075419426, 0.09614633768796921, 0.00920154806226492, -0.019020894542336464, 0.07179751992225647, -0.07167882472276688, -0.043876584619283676, 0.020975878462195396, 0.0518016442656517, 0.018128570169210434, 0.0016310252249240875, -0.00853127520531416, 0.01017807424068451, -0.08606308698654175, 0.09132678806781769, 0.02233969233930111, -0.011229983530938625, 0.005073979962617159, 0.012646627612411976, -0.09060044586658478, -0.04122157022356987, 0.03315373882651329, -0.04345424845814705, 0.01728329062461853, 0.04346165806055069, -0.00407390296459198, 0.037313781678676605, -0.03046942874789238, 0.09700122475624084, -0.0033395299687981606, 0.02401246502995491, -0.046726521104574203, -0.03652739152312279, 0.04860817641019821, 0.08374924957752228, 0.07263803482055664, -0.01256726123392582, -0.05786525458097458, 0.029683807864785194, -0.07155205309391022, -0.04800192639231682, -0.0972224697470665, 0.042826972901821136, -0.05532263219356537, -0.07067934423685074, -0.027677718549966812, 0.015397505834698677, 0.06425315141677856, 0.09184142202138901, 0.046619195491075516, 0.015900038182735443, -0.01209162175655365, 0.04436127096414566, 0.09583966434001923, 0.01839016005396843, 0.042606718838214874, 0.01781550981104374, -0.010773252695798874]",
         "0.11"
        ],
        [
         "6",
         "580",
         "NumPy API on a GPU?",
         "It's here already from Nvidia and it's called cuNumeric. The post NumPy API on a GPU? appeared first on Towards Data Science .",
         "Is future of Python numerical computation?\n\nLate last year, NVIDIA made a significant announcement regarding the future of Python-based numerical computing. I wouldn’t be surprised if you missed it. After all, every other announcement from every AI company, then and now, seems mega-important.\n\nThat announcement introduced the cuNumeric library, a drop-in replacement for the ubiquitous NumPy library built on top of the Legate framework.\n\nWho are Nvidia?\n\nMost people will probably know Nvidia from their ultra-fast chips that power computers and data centres all over the world. You may also be familiar with Nvidia’s charismatic, leather jacket-loving CEO, Jensen Huang, who seems to pop up on the stage of every AI conference these days.\n\nWhat many people don’t know is that Nvidia also designs and creates innovative device architectures and associated software. One of its most prized products is the Compute Unified Device Architecture (CUDA). CUDA is NVIDIA’s proprietary parallel-computing platform and programming model. Since its launch in 2007, it has evolved into a comprehensive ecosystem comprising drivers, runtime, compilers, math libraries, debugging and profiling tools, and container images. The result is a neatly tuned hardware and software loop that keeps NVIDIA GPUs at the centre of modern high-performance and AI workloads.\n\nWhat is Legate?\n\nLegate is an NVIDIA-led open-source runtime layer that lets you run familiar Python data-science libraries (NumPy, cuNumeric, Pandas-style APIs, sparse linear-algebra kernels, …) on multi-core CPUs, single or multi-GPU nodes, and even multi-node clusters without changing your Python code. It translates high-level array operations into a graph of fine-grained tasks and hands that graph to the C++ Legion runtime, which schedules the tasks, partitions the data, and moves tiles between CPUs, GPUs and network links for you.\n\nIn a nutshell, Legate lets familiar single-node Python libraries scale transparently to multi-GPU, multi-node machines.\n\nWhat is cuNumeric?\n\ncuNumeric is a drop-in replacement for NumPy whose array operations are executed by Legate’s task engine and accelerated on one or many NVIDIA GPUs (or, if no GPU is present, on all CPU cores). In practice, you install it and need only change one import line to start using it in place of your regular NumPy code. For example …\n\n# old import numpy as np ... ... # new import cupynumeric as np # everything else stays the same ... ...\n\n… and run your script on the terminal with the legate command.\n\nBehind the scenes, cuNumeric converts each NumPy call you make, for example, np.sin, np.linalg.svd, fancy indexing, broadcasting, reductions, etc, into Legate tasks. Those tasks will,\n\nPartition your arrays into tiles sized to fit GPU memory. Schedule each tile on the best available device (GPU or CPU). Overlap compute with communication when the workload spans multiple GPUs or nodes. Spill tiles to NVMe/SSD automatically when your dataset outruns GPU RAM.\n\nBecause the API of cuNumeric mirrors NumPy’s nearly 1-for-1, existing scientific or data-science code can scale from a laptop to a multi-GPU cluster without a rewrite.\n\nPerformance benefits\n\nSo, this all seems great, right? But it only makes sense if it results in tangible performance improvements over using NumPy, and Nvidia is making some strong claims that this is the case. As data scientists, machine learning engineers and data engineers typically use NumPy a lot, we can appreciate that this can be a crucial aspect of the systems we write and maintain.\n\nNow, I don’t have a cluster of GPUs or a supercomputer to test this on, but my desktop PC does have an Nvidia GeForce RTX 4070 GPU, and we’re going to use that to test out some of Nvidia’s claims.\n\n(base) tom@tpr-desktop:~$ nvidia-smi Sun Jun 15 15:26:36 2025 +-----------------------------------------------------------------------------------------+ | NVIDIA-SMI 565.75 Driver Version: 566.24 CUDA Version: 12.7 | |-----------------------------------------+------------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |=========================================+========================+======================| | 0 NVIDIA GeForce RTX 4070 Ti On | 00000000:01:00.0 On | N/A | | 32% 29C P8 9W / 285W | 1345MiB / 12282MiB | 2% Default | | | | N/A | +-----------------------------------------+------------------------+----------------------+ +-----------------------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=========================================================================================| | No running processes found | +-----------------------------------------------------------------------------------------+\n\nI’ll install cuNumeric and NumPy on my PC to conduct comparative tests. This will help us assess whether Nvidia’s claims are accurate and understand the performance differences between the two libraries.\n\nSetting up a development environment.\n\nAs always, I like to set up a separate development environment to run my tests. That way, nothing I do in that environment will affect any of my other projects. At the time of writing, cuNumeric is not available to install on Windows, so I’ll be using WSL2 Ubuntu for Windows instead.\n\nI’ll be using Miniconda to set up my environment, but feel free to use whichever tool you’re comfortable with.\n\n$ conda create cunumeric-env python=3.10 -c conda-forge $ conda activate cunumeric-env $ conda install -c conda-forge -c legate cupynumeric $ conda install -c conda-forge ucx cuda-cudart cuda-version=12\n\nCode example 1 — A simple matrix multiplication\n\nMatrix multiplication is the bread and butter of mathematical operations that underpin so many AI systems, so it makes sense to try that operation out first.\n\nNote that in all my examples, I will run the NumPy and cuNumeric code snippets five times in a row and average the time taken for each. I also perform a “warm-up step on the GPU before the timing run to take into account overheads such as just-in-time (JIT) compilation.\n\nimport time import gc import argparse import sys def benchmark_numpy(n, runs): \"\"\"Runs the matrix multiplication benchmark using standard NumPy on the CPU.\"\"\" import numpy as np print(f\"--- NumPy (CPU) Benchmark ---\") print(f\"Multiplying two {n}×{n} matrices ({runs} runs)\n\n\") # 1. Generate data ONCE before the timing loop. print(f\"Generating two {n}x{n} random matrices on CPU...\") A = np.random.rand(n, n).astype(np.float32) B = np.random.rand(n, n).astype(np.float32) # 2. Perform one untimed warm-up run. print(\"Performing warm-up run...\") _ = np.matmul(A, B) print(\"Warm-up complete.\n\n\") # 3. Perform the timed runs. times = [] for i in range(runs): start = time.time() # The operation being timed. The @ operator is a convenient # shorthand for np.matmul. C = A @ B end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.4f}s\") del C # Clean up the result matrix gc.collect() avg = sum(times) / len(times) print(f\"\n\nNumPy average: {avg:.4f}s\n\n\") return avg def benchmark_cunumeric(n, runs): \"\"\"Runs the matrix multiplication benchmark using cuNumeric on the GPU.\"\"\" import cupynumeric as cn import numpy as np # Import numpy for the canonical sync print(f\"--- cuNumeric (GPU) Benchmark ---\") print(f\"Multiplying two {n}×{n} matrices ({runs} runs)\n\n\") # 1. Generate data ONCE on the GPU before the timing loop. print(f\"Generating two {n}x{n} random matrices on GPU...\") A = cn.random.rand(n, n).astype(np.float32) B = cn.random.rand(n, n).astype(np.float32) # 2. Perform a crucial untimed warm-up run for JIT compilation. print(\"Performing warm-up run...\") C_warmup = cn.matmul(A, B) # The best practice for synchronization: force a copy back to the CPU. _ = np.array(C_warmup) print(\"Warm-up complete.\n\n\") # 3. Perform the timed runs. times = [] for i in range(runs): start = time.time() # Launch the operation on the GPU C = A @ B # Synchronize by converting the result to a host-side NumPy array. np.array(C) end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.4f}s\") del C gc.collect() avg = sum(times) / len(times) print(f\"\n\ncuNumeric average: {avg:.4f}s\n\n\") return avg if __name__ == \"__main__\": parser = argparse.ArgumentParser( description=\"Benchmark matrix multiplication on NumPy (CPU) vs. cuNumeric (GPU).\" ) parser.add_argument( \"-n\", \"--n\", type=int, default=3000, help=\"Matrix size (n x n)\" ) parser.add_argument( \"-r\", \"--runs\", type=int, default=5, help=\"Number of timing runs\" ) parser.add_argument( \"--cunumeric\", action=\"store_true\", help=\"Run the cuNumeric (GPU) version\" ) args, unknown = parser.parse_known_args() # The dispatcher logic if args.cunumeric or \"--cunumeric\" in unknown: benchmark_cunumeric(args.n, args.runs) else: benchmark_numpy(args.n, args.runs)\n\nRunning the NumPy side of things uses the regular python example1.py command line syntax. For running using Legate, the syntax is more complex. What it does is disable Legate’s automatic configuration and then launch the example1.py script under Legate with one CPU, one GPU, and zero OpenMP threads using the cuNumeric backend.\n\nHere is the output.\n\n(cunumeric-env) tom@tpr-desktop:~$ python example1.py --- NumPy (CPU) Benchmark --- Multiplying two 3000×3000 matrices (5 runs) Generating two 3000x3000 random matrices on CPU... Performing warm-up run... Warm-up complete. Run 1: time = 0.0976s Run 2: time = 0.0987s Run 3: time = 0.0957s Run 4: time = 0.1063s Run 5: time = 0.0989s NumPy average: 0.0994s (cunumeric-env) tom@tpr-desktop:~$ LEGATE_AUTO_CONFIG=0 legate --cpus 1 --gpus 1 --omps 0 example1.py --cunu meric [0 - 7f2e8fcc8480] 0.000000 {5}{module_config}: Module numa can not detect resources. [0 - 7f2e8fcc8480] 0.000000 {4}{topology}: can't open /sys/devices/system/node/ [0 - 7f2e8fcc8480] 0.000049 {4}{threads}: reservation ('GPU ctxsync 0x55cd5fd34530') cannot be satisfied --- cuNumeric (GPU) Benchmark --- Multiplying two 3000×3000 matrices (5 runs) Generating two 3000x3000 random matrices on GPU... Performing warm-up run... Warm-up complete. Run 1: time = 0.0113s Run 2: time = 0.0089s Run 3: time = 0.0086s Run 4: time = 0.0090s Run 5: time = 0.0087s cuNumeric average: 0.0093s\n\nWell, that’s an impressive start. cuNumeric is registering a 10x speedup over NumPy.\n\nThe warnings that Legate is outputting can be ignored. These are informational, indicating Legate couldn’t find details about the machine’s CPU/memory layout (NUMA) or enough CPU cores to manage the GPU.\n\nCode example 2 — Logistic regression\n\nLogistic regression is a foundational tool in data science because it provides a simple, interpretable way to model and predict binary outcomes (yes/no, pass/fail, click/no-click). In this example, we’ll measure how long it takes to train a simple binary classifier on synthetic data. For each of the five runs, it first generates N samples with D features (X), and a corresponding random 0/1 label vector (Y). It initialises the weight vector w to zeros, then performs 500 iterations of batch gradient descent: computing the linear predictions z = X.dot(w), applying the sigmoid p = 1/(1+exp(–z)), computing the gradient grad = X.T.dot(p – y) / N, and updating the weights with w -= 0.1 * grad. The script records the elapsed time for each run, cleans up memory, and finally prints the average training time.\n\nimport time import gc import argparse import sys # --- Reusable Training Function --- # By putting the training loop in its own function, we avoid code duplication. # The `np` argument allows us to pass in either the numpy or cupynumeric module. def train_logistic_regression(np, X, y, iters, alpha): \"\"\"Performs a set number of gradient descent iterations.\"\"\" # Ensure w starts on the correct device (CPU or GPU) w = np.zeros(X.shape[1]) for _ in range(iters): z = X.dot(w) p = 1.0 / (1.0 + np.exp(-z)) grad = X.T.dot(p - y) / X.shape[0] w -= alpha * grad return w def benchmark_numpy(n_samples, n_features, iters, alpha): \"\"\"Runs the logistic regression benchmark using standard NumPy on the CPU.\"\"\" import numpy as np print(f\"--- NumPy (CPU) Benchmark ---\") print(f\"Training on {n_samples} samples, {n_features} features for {iters} iterations\n\n\") # 1. Generate data ONCE before the timing loop. print(\"Generating random dataset on CPU...\") X = np.random.rand(n_samples, n_features) y = (np.random.rand(n_samples) > 0.5).astype(np.float64) # 2. Perform one untimed warm-up run. print(\"Performing warm-up run...\") _ = train_logistic_regression(np, X, y, iters, alpha) print(\"Warm-up complete.\n\n\") # 3. Perform the timed runs. times = [] for i in range(args.runs): start = time.time() # The operation being timed _ = train_logistic_regression(np, X, y, iters, alpha) end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.3f}s\") gc.collect() avg = sum(times) / len(times) print(f\"\n\nNumPy average: {avg:.3f}s\n\n\") return avg def benchmark_cunumeric(n_samples, n_features, iters, alpha): \"\"\"Runs the logistic regression benchmark using cuNumeric on the GPU.\"\"\" import cupynumeric as cn import numpy as np # Also import numpy for the canonical synchronization print(f\"--- cuNumeric (GPU) Benchmark ---\") print(f\"Training on {n_samples} samples, {n_features} features for {iters} iterations\n\n\") # 1. Generate data ONCE on the GPU before the timing loop. print(\"Generating random dataset on GPU...\") X = cn.random.rand(n_samples, n_features) y = (cn.random.rand(n_samples) > 0.5).astype(np.float64) # 2. Perform a crucial untimed warm-up run for JIT compilation. print(\"Performing warm-up run...\") w_warmup = train_logistic_regression(cn, X, y, iters, alpha) # The best practice for synchronization: force a copy back to the CPU. _ = np.array(w_warmup) print(\"Warm-up complete.\n\n\") # 3. Perform the timed runs. times = [] for i in range(args.runs): start = time.time() # Launch the operation on the GPU w = train_logistic_regression(cn, X, y, iters, alpha) # Synchronize by converting the final result back to a NumPy array. np.array(w) end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.3f}s\") del w gc.collect() avg = sum(times) / len(times) print(f\"\n\ncuNumeric average: {avg:.3f}s\n\n\") return avg if __name__ == \"__main__\": # A more robust argument parsing setup parser = argparse.ArgumentParser( description=\"Benchmark logistic regression on NumPy (CPU) vs. cuNumeric (GPU).\" ) # Hyperparameters for the model parser.add_argument( \"-n\", \"--n_samples\", type=int, default=2_000_000, help=\"Number of data samples\" ) parser.add_argument( \"-d\", \"--n_features\", type=int, default=10, help=\"Number of features\" ) parser.add_argument( \"-i\", \"--iters\", type=int, default=500, help=\"Number of gradient descent iterations\" ) parser.add_argument( \"-a\", \"--alpha\", type=float, default=0.1, help=\"Learning rate\" ) # Benchmark control parser.add_argument( \"-r\", \"--runs\", type=int, default=5, help=\"Number of timing runs\" ) parser.add_argument( \"--cunumeric\", action=\"store_true\", help=\"Run the cuNumeric (GPU) version\" ) args, unknown = parser.parse_known_args() # Dispatcher logic if args.cunumeric or \"--cunumeric\" in unknown: benchmark_cunumeric(args.n_samples, args.n_features, args.iters, args.alpha) else: benchmark_numpy(args.n_samples, args.n_features, args.iters, args.alpha)\n\nAnd the outputs.\n\n(cunumeric-env) tom@tpr-desktop:~$ python example2.py --- NumPy (CPU) Benchmark --- Training on 2000000 samples, 10 features for 500 iterations Generating random dataset on CPU... Performing warm-up run... Warm-up complete. Run 1: time = 12.292s Run 2: time = 11.830s Run 3: time = 11.903s Run 4: time = 12.843s Run 5: time = 11.964s NumPy average: 12.166s (cunumeric-env) tom@tpr-desktop:~$ LEGATE_AUTO_CONFIG=0 legate --cpus 1 --gpus 1 --omps 0 example2.py --cunu meric [0 - 7f04b535c480] 0.000000 {5}{module_config}: Module numa can not detect resources. [0 - 7f04b535c480] 0.000000 {4}{topology}: can't open /sys/devices/system/node/ [0 - 7f04b535c480] 0.001149 {4}{threads}: reservation ('GPU ctxsync 0x55fb037cf140') cannot be satisfied --- cuNumeric (GPU) Benchmark --- Training on 2000000 samples, 10 features for 500 iterations Generating random dataset on GPU... Performing warm-up run... Warm-up complete. Run 1: time = 1.964s Run 2: time = 1.957s Run 3: time = 1.968s Run 4: time = 1.955s Run 5: time = 1.960s cuNumeric average: 1.961s\n\nNot quite as impressive as our first example, but a 5x to 6x speedup on an already fast NumPy program is not to be sniffed at.\n\nCode example 3 — solving linear equations\n\nThis script benchmarks how long it takes to solve a dense 3000×3000 linear algebra equation system. This is a fundamental operation in linear algebra used to solve the equation of type Ax = b, where A is a giant grid of numbers (a 3000×3000 matrix in this case), and b is a list of numbers (a vector).\n\nThe goal is to find the unknown list of numbers x that makes the equation true. This is a computationally intensive task that is at the heart of many scientific simulations, engineering problems, financial models, and even some AI algorithms.\n\nimport time import gc import argparse import sys # Import sys to check arguments # Note: The library imports (numpy and cupynumeric) are now done *inside* # their respective functions to keep them separate and avoid import errors. def benchmark_numpy(n, runs): \"\"\"Runs the linear solve benchmark using standard NumPy on the CPU.\"\"\" import numpy as np print(f\"--- NumPy (CPU) Benchmark ---\") print(f\"Solving {n}×{n} A x = b ({runs} runs)\n\n\") # 1. Generate data ONCE before the timing loop. print(\"Generating random system on CPU...\") A = np.random.randn(n, n).astype(np.float32) b = np.random.randn(n).astype(np.float32) # 2. Perform one untimed warm-up run. This is good practice even for # the CPU to ensure caches are warm and any one-time setup is done. print(\"Performing warm-up run...\") _ = np.linalg.solve(A, b) print(\"Warm-up complete.\n\n\") # 3. Perform the timed runs. times = [] for i in range(runs): start = time.time() # The operation being timed x = np.linalg.solve(A, b) end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.6f}s\") # Clean up the result to be safe with memory del x gc.collect() avg = sum(times) / len(times) print(f\"\n\nNumPy average: {avg:.6f}s\n\n\") return avg def benchmark_cunumeric(n, runs): \"\"\"Runs the linear solve benchmark using cuNumeric on the GPU.\"\"\" import cupynumeric as cn import numpy as np # Also import numpy for the canonical synchronization print(f\"--- cuNumeric (GPU) Benchmark ---\") print(f\"Solving {n}×{n} A x = b ({runs} runs)\n\n\") # 1. Generate data ONCE on the GPU before the timing loop. # This ensures we are not timing the data transfer in our main loop. print(\"Generating random system on GPU...\") A = cn.random.randn(n, n).astype(np.float32) b = cn.random.randn(n).astype(np.float32) # 2. Perform a crucial untimed warm-up run. This handles JIT # compilation and other one-time GPU setup costs. print(\"Performing warm-up run...\") x_warmup = cn.linalg.solve(A, b) # The best practice for synchronization: force a copy back to the CPU. _ = np.array(x_warmup) print(\"Warm-up complete.\n\n\") # 3. Perform the timed runs. times = [] for i in range(runs): start = time.time() # Launch the operation on the GPU x = cn.linalg.solve(A, b) # Synchronize by converting the result to a host-side NumPy array. # This is guaranteed to block until the GPU has finished. np.array(x) end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.6f}s\") # Clean up the GPU array result del x gc.collect() avg = sum(times) / len(times) print(f\"\n\ncuNumeric average: {avg:.6f}s\n\n\") return avg if __name__ == \"__main__\": # A more robust argument parsing setup parser = argparse.ArgumentParser( description=\"Benchmark linear solve on NumPy (CPU) vs. cuNumeric (GPU).\" ) parser.add_argument( \"-n\", \"--n\", type=int, default=3000, help=\"Matrix size (n x n)\" ) parser.add_argument( \"-r\", \"--runs\", type=int, default=5, help=\"Number of timing runs\" ) # Use parse_known_args() to handle potential extra arguments from Legate args, unknown = parser.parse_known_args() # The dispatcher logic: check if \"--cunumeric\" is in the command line # This is a simple and effective way to switch between modes. if \"--cunumeric\" in sys.argv or \"--cunumeric\" in unknown: benchmark_cunumeric(args.n, args.runs) else: benchmark_numpy(args.n, args.runs)\n\nThe outputs.\n\n(cunumeric-env) tom@tpr-desktop:~$ python example4.py --- NumPy (CPU) Benchmark --- Solving 3000×3000 A x = b (5 runs) Generating random system on CPU... Performing warm-up run... Warm-up complete. Run 1: time = 0.133075s Run 2: time = 0.126129s Run 3: time = 0.135849s Run 4: time = 0.137383s Run 5: time = 0.138805s NumPy average: 0.134248s (cunumeric-env) tom@tpr-desktop:~$ LEGATE_AUTO_CONFIG=0 legate --cpus 1 --gpus 1 --omps 0 example4.py --cunumeric [0 - 7f29f42ce480] 0.000000 {5}{module_config}: Module numa can not detect resources. [0 - 7f29f42ce480] 0.000000 {4}{topology}: can't open /sys/devices/system/node/ [0 - 7f29f42ce480] 0.000053 {4}{threads}: reservation ('GPU ctxsync 0x562e88c28700') cannot be satisfied --- cuNumeric (GPU) Benchmark --- Solving 3000×3000 A x = b (5 runs) Generating random system on GPU... Performing warm-up run... Warm-up complete. Run 1: time = 0.009685s Run 2: time = 0.010043s Run 3: time = 0.009966s Run 4: time = 0.009739s Run 5: time = 0.009383s cuNumeric average: 0.009763s\n\nThat is a tremendous result. The Nvidia cuNumeric run is 100x faster than the NumPy run.\n\nCode example 4 — Sorting\n\nSorting is such a fundamental part of everything that happens in computing, and modern computers are so fast that most developers don’t even think about it. But let’s see how much of a difference using cuNumeric can make to this ubiquitous operation. We’ll sort a large (30,000,000) 1D array of numbers\n\n# benchmark_sort.py import time import sys import gc # Array size n = 30_000_000 # 30 million elements def benchmark_numpy(): import numpy as np print(f\"Sorting an array of {n} elements with NumPy (5 runs)\n\n\") times = [] for i in range(5): data = np.random.randn(n).astype(np.float32) start = time.time() _ = np.sort(data) end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.6f}s\") del data gc.collect() avg = sum(times) / len(times) print(f\"\n\nNumPy average: {avg:.6f}s\n\n\") def benchmark_cunumeric(): import cupynumeric as np print(f\"Sorting an array of {n} elements with cuNumeric (5 runs)\n\n\") times = [] for i in range(5): data = np.random.randn(n).astype(np.float32) start = time.time() _ = np.sort(data) # Force GPU sync _ = np.linalg.norm(np.zeros(())) end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.6f}s\") del data gc.collect() _ = np.linalg.norm(np.zeros(())) avg = sum(times) / len(times) print(f\"\n\ncuNumeric average: {avg:.6f}s\n\n\") if __name__ == \"__main__\": if \"--cunumeric\" in sys.argv: benchmark_cunumeric() else: benchmark_numpy()\n\nThe outputs.\n\n(cunumeric-env) tom@tpr-desktop:~$ python example5.py --- NumPy (CPU) Benchmark --- Sorting an array of 30000000 elements (5 runs) Creating random array on CPU... Performing warm-up run... Warm-up complete. Run 1: time = 0.588777s Run 2: time = 0.586813s Run 3: time = 0.586745s Run 4: time = 0.586525s Run 5: time = 0.583783s NumPy average: 0.586529s ----------------------------- (cunumeric-env) tom@tpr-desktop:~$ LEGATE_AUTO_CONFIG=0 legate --cpus 1 --gpus 1 --omps 0 example5.py --cunumeric [0 - 7fd9e4615480] 0.000000 {5}{module_config}: Module numa can not detect resources. [0 - 7fd9e4615480] 0.000000 {4}{topology}: can't open /sys/devices/system/node/ [0 - 7fd9e4615480] 0.000082 {4}{threads}: reservation ('GPU ctxsync 0x564489232fd0') cannot be satisfied --- cuNumeric (GPU) Benchmark --- Sorting an array of 30000000 elements (5 runs) Creating random array on GPU... Performing warm-up run... Warm-up complete. Run 1: time = 0.010857s Run 2: time = 0.007927s Run 3: time = 0.007921s Run 4: time = 0.008240s Run 5: time = 0.007810s cuNumeric average: 0.008551s -------------------------------\n\nYet another hugely impressive performance from cuNumeric and Legate.\n\nSummary\n\nThis article introduced cuNumeric, an NVIDIA library designed as a high-performance, drop-in replacement for NumPy. The key takeaway is that data scientists can accelerate their existing Python code on NVIDIA GPUs with minimal effort, often by simply changing a single import line and running the script with the ‘legate’ command.\n\nTwo main components power the technology:\n\nLegate: An open-source runtime layer from NVIDIA that automatically translates high-level Python operations into tasks. It intelligently manages distributing these tasks across single or multiple GPUs, handling data partitioning, memory management (even spilling to disk if needed), and optimising communication. cuNumeric: The user-facing library that mirrors the NumPy API. When you make a call like np.matmul(), cuNumeric converts it into a task for the Legate engine to execute on the GPU.\n\nI was able to validate Nvidia’s performance claims by running four benchmark tests on my desktop PC (with an NVIDIA RTX 4070 Ti GPU), comparing standard NumPy on the CPU against cuNumeric on the GPU.\n\nThe results demonstrate significant performance gains for cuNumeric:\n\nMatrix Multiplication: ~10x faster than NumPy.\n\nfaster than NumPy. Logistic Regression Training: ~6x faster.\n\nfaster. Solving Linear Equations: A massive 100x+ speedup.\n\nA massive speedup. Sorting a Large Array: Another huge improvement, running approximately 70x faster.\n\nIn conclusion, I showed that cuNumeric successfully delivers on its promise, making the immense computational power of GPUs accessible to the broader Python data science community without requiring a steep learning curve or a complete code rewrite.\n\nFor more information and links to related resources, check out the original Nvidia announcement on cuNumeric here.",
         "2025-07-23T04:23:24",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/numpy-api-on-a-gpu/",
         "2025-07-26T06:23:31.350576",
         "Is future of Python numerical computation? Late last year, NVIDIA made a significant announcement regarding the future of Python-based numerical computing. I wouldn’t be surprised if you missed it. After all, every other announcement from every AI company, then and now, seems mega-important. That announcement introduced the cuNumeric library, a drop-in replacement for the ubiquitous NumPy library built on top of the Legate framework. Who are Nvidia? Most people will probably know Nvidia from their ultra-fast chips that power computers and data centres all over the world. You may also be familiar with Nvidia’s charismatic, leather jacket-loving CEO, Jensen Huang, who seems to pop up on the stage of every AI conference these days. What many people don’t know is that Nvidia also designs and creates innovative device architectures and associated software. One of its most prized products is the Compute Unified Device Architecture (CUDA). CUDA is NVIDIA’s proprietary parallel-computing platform and programming model. Since its launch in 2007, it has evolved into a comprehensive ecosystem comprising drivers, runtime, compilers, math libraries, debugging and profiling tools, and container images. The result is a neatly tuned hardware and software loop that keeps NVIDIA GPUs at the centre of modern high-performance and AI workloads. What is Legate? Legate is an NVIDIA-led open-source runtime layer that lets you run familiar Python data-science libraries (NumPy, cuNumeric, Pandas-style APIs, sparse linear-algebra kernels, …) on multi-core CPUs, single or multi-GPU nodes, and even multi-node clusters without changing your Python code. It translates high-level array operations into a graph of fine-grained tasks and hands that graph to the C++ Legion runtime, which schedules the tasks, partitions the data, and moves tiles between CPUs, GPUs and network links for you. In a nutshell, Legate lets familiar single-node Python libraries scale transparently to multi-GPU, multi-node machines. What is cuNumeric? cuNumeric is a drop-in replacement for NumPy whose array operations are executed by Legate’s task engine and accelerated on one or many NVIDIA GPUs (or, if no GPU is present, on all CPU cores). In practice, you install it and need only change one import line to start using it in place of your regular NumPy code. For example … # old import numpy as np ... ... # new import cupynumeric as np # everything else stays the same ... ... … and run your script on the terminal with the legate command. Behind the scenes, cuNumeric converts each NumPy call you make, for example, np.sin, np.linalg.svd, fancy indexing, broadcasting, reductions, etc, into Legate tasks. Those tasks will, Partition your arrays into tiles sized to fit GPU memory. Schedule each tile on the best available device (GPU or CPU). Overlap compute with communication when the workload spans multiple GPUs or nodes. Spill tiles to NVMe/SSD automatically when your dataset outruns GPU RAM. Because the API of cuNumeric mirrors NumPy’s nearly 1-for-1, existing scientific or data-science code can scale from a laptop to a multi-GPU cluster without a rewrite. Performance benefits So, this all seems great, right? But it only makes sense if it results in tangible performance improvements over using NumPy, and Nvidia is making some strong claims that this is the case. As data scientists, machine learning engineers and data engineers typically use NumPy a lot, we can appreciate that this can be a crucial aspect of the systems we write and maintain. Now, I don’t have a cluster of GPUs or a supercomputer to test this on, but my desktop PC does have an Nvidia GeForce RTX 4070 GPU, and we’re going to use that to test out some of Nvidia’s claims. (base) tom@tpr-desktop:~$ nvidia-smi Sun Jun 15 15:26:36 2025 +-----------------------------------------------------------------------------------------+ | NVIDIA-SMI 565.75 Driver Version: 566.24 CUDA Version: 12.7 | |-----------------------------------------+------------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |=========================================+========================+======================| | 0 NVIDIA GeForce RTX 4070 Ti On | 00000000:01:00.0 On | N/A | | 32% 29C P8 9W / 285W | 1345MiB / 12282MiB | 2% Default | | | | N/A | +-----------------------------------------+------------------------+----------------------+ +-----------------------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=========================================================================================| | No running processes found | +-----------------------------------------------------------------------------------------+ I’ll install cuNumeric and NumPy on my PC to conduct comparative tests. This will help us assess whether Nvidia’s claims are accurate and understand the performance differences between the two libraries. Setting up a development environment. As always, I like to set up a separate development environment to run my tests. That way, nothing I do in that environment will affect any of my other projects. At the time of writing, cuNumeric is not available to install on Windows, so I’ll be using WSL2 Ubuntu for Windows instead. I’ll be using Miniconda to set up my environment, but feel free to use whichever tool you’re comfortable with. $ conda create cunumeric-env python=3.10 -c conda-forge $ conda activate cunumeric-env $ conda install -c conda-forge -c legate cupynumeric $ conda install -c conda-forge ucx cuda-cudart cuda-version=12 Code example 1 — A simple matrix multiplication Matrix multiplication is the bread and butter of mathematical operations that underpin so many AI systems, so it makes sense to try that operation out first. Note that in all my examples, I will run the NumPy and cuNumeric code snippets five times in a row and average the time taken for each. I also perform a “warm-up step on the GPU before the timing run to take into account overheads such as just-in-time (JIT) compilation. import time import gc import argparse import sys def benchmark_numpy(n, runs): \"\"\"Runs the matrix multiplication benchmark using standard NumPy on the CPU.\"\"\" import numpy as np print(f\"--- NumPy (CPU) Benchmark ---\") print(f\"Multiplying two {n}×{n} matrices ({runs} runs) \") # 1. Generate data ONCE before the timing loop. print(f\"Generating two {n}x{n} random matrices on CPU...\") A = np.random.rand(n, n).astype(np.float32) B = np.random.rand(n, n).astype(np.float32) # 2. Perform one untimed warm-up run. print(\"Performing warm-up run...\") _ = np.matmul(A, B) print(\"Warm-up complete. \") # 3. Perform the timed runs. times = [] for i in range(runs): start = time.time() # The operation being timed. The @ operator is a convenient # shorthand for np.matmul. C = A @ B end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.4f}s\") del C # Clean up the result matrix gc.collect() avg = sum(times) / len(times) print(f\" NumPy average: {avg:.4f}s \") return avg def benchmark_cunumeric(n, runs): \"\"\"Runs the matrix multiplication benchmark using cuNumeric on the GPU.\"\"\" import cupynumeric as cn import numpy as np # Import numpy for the canonical sync print(f\"--- cuNumeric (GPU) Benchmark ---\") print(f\"Multiplying two {n}×{n} matrices ({runs} runs) \") # 1. Generate data ONCE on the GPU before the timing loop. print(f\"Generating two {n}x{n} random matrices on GPU...\") A = cn.random.rand(n, n).astype(np.float32) B = cn.random.rand(n, n).astype(np.float32) # 2. Perform a crucial untimed warm-up run for JIT compilation. print(\"Performing warm-up run...\") C_warmup = cn.matmul(A, B) # The best practice for synchronization: force a copy back to the CPU. _ = np.array(C_warmup) print(\"Warm-up complete. \") # 3. Perform the timed runs. times = [] for i in range(runs): start = time.time() # Launch the operation on the GPU C = A @ B # Synchronize by converting the result to a host-side NumPy array. np.array(C) end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.4f}s\") del C gc.collect() avg = sum(times) / len(times) print(f\" cuNumeric average: {avg:.4f}s \") return avg if __name__ == \"__main__\": parser = argparse.ArgumentParser( description=\"Benchmark matrix multiplication on NumPy (CPU) vs. cuNumeric (GPU).\" ) parser.add_argument( \"-n\", \"--n\", type=int, default=3000, help=\"Matrix size (n x n)\" ) parser.add_argument( \"-r\", \"--runs\", type=int, default=5, help=\"Number of timing runs\" ) parser.add_argument( \"--cunumeric\", action=\"store_true\", help=\"Run the cuNumeric (GPU) version\" ) args, unknown = parser.parse_known_args() # The dispatcher logic if args.cunumeric or \"--cunumeric\" in unknown: benchmark_cunumeric(args.n, args.runs) else: benchmark_numpy(args.n, args.runs) Running the NumPy side of things uses the regular python example1.py command line syntax. For running using Legate, the syntax is more complex. What it does is disable Legate’s automatic configuration and then launch the example1.py script under Legate with one CPU, one GPU, and zero OpenMP threads using the cuNumeric backend. Here is the output. (cunumeric-env) tom@tpr-desktop:~$ python example1.py --- NumPy (CPU) Benchmark --- Multiplying two 3000×3000 matrices (5 runs) Generating two 3000x3000 random matrices on CPU... Performing warm-up run... Warm-up complete. Run 1: time = 0.0976s Run 2: time = 0.0987s Run 3: time = 0.0957s Run 4: time = 0.1063s Run 5: time = 0.0989s NumPy average: 0.0994s (cunumeric-env) tom@tpr-desktop:~$ LEGATE_AUTO_CONFIG=0 legate --cpus 1 --gpus 1 --omps 0 example1.py --cunu meric [0 - 7f2e8fcc8480] 0.000000 {5}{module_config}: Module numa can not detect resources. [0 - 7f2e8fcc8480] 0.000000 {4}{topology}: can't open /sys/devices/system/node/ [0 - 7f2e8fcc8480] 0.000049 {4}{threads}: reservation ('GPU ctxsync 0x55cd5fd34530') cannot be satisfied --- cuNumeric (GPU) Benchmark --- Multiplying two 3000×3000 matrices (5 runs) Generating two 3000x3000 random matrices on GPU... Performing warm-up run... Warm-up complete. Run 1: time = 0.0113s Run 2: time = 0.0089s Run 3: time = 0.0086s Run 4: time = 0.0090s Run 5: time = 0.0087s cuNumeric average: 0.0093s Well, that’s an impressive start. cuNumeric is registering a 10x speedup over NumPy. The warnings that Legate is outputting can be ignored. These are informational, indicating Legate couldn’t find details about the machine’s CPU/memory layout (NUMA) or enough CPU cores to manage the GPU. Code example 2 — Logistic regression Logistic regression is a foundational tool in data science because it provides a simple, interpretable way to model and predict binary outcomes (yes/no, pass/fail, click/no-click). In this example, we’ll measure how long it takes to train a simple binary classifier on synthetic data. For each of the five runs, it first generates N samples with D features (X), and a corresponding random 0/1 label vector (Y). It initialises the weight vector w to zeros, then performs 500 iterations of batch gradient descent: computing the linear predictions z = X.dot(w), applying the sigmoid p = 1/(1+exp(–z)), computing the gradient grad = X.T.dot(p – y) / N, and updating the weights with w -= 0.1 * grad. The script records the elapsed time for each run, cleans up memory, and finally prints the average training time. import time import gc import argparse import sys # --- Reusable Training Function --- # By putting the training loop in its own function, we avoid code duplication. # The `np` argument allows us to pass in either the numpy or cupynumeric module. def train_logistic_regression(np, X, y, iters, alpha): \"\"\"Performs a set number of gradient descent iterations.\"\"\" # Ensure w starts on the correct device (CPU or GPU) w = np.zeros(X.shape[1]) for _ in range(iters): z = X.dot(w) p = 1.0 / (1.0 + np.exp(-z)) grad = X.T.dot(p - y) / X.shape[0] w -= alpha * grad return w def benchmark_numpy(n_samples, n_features, iters, alpha): \"\"\"Runs the logistic regression benchmark using standard NumPy on the CPU.\"\"\" import numpy as np print(f\"--- NumPy (CPU) Benchmark ---\") print(f\"Training on {n_samples} samples, {n_features} features for {iters} iterations \") # 1. Generate data ONCE before the timing loop. print(\"Generating random dataset on CPU...\") X = np.random.rand(n_samples, n_features) y = (np.random.rand(n_samples) > 0.5).astype(np.float64) # 2. Perform one untimed warm-up run. print(\"Performing warm-up run...\") _ = train_logistic_regression(np, X, y, iters, alpha) print(\"Warm-up complete. \") # 3. Perform the timed runs. times = [] for i in range(args.runs): start = time.time() # The operation being timed _ = train_logistic_regression(np, X, y, iters, alpha) end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.3f}s\") gc.collect() avg = sum(times) / len(times) print(f\" NumPy average: {avg:.3f}s \") return avg def benchmark_cunumeric(n_samples, n_features, iters, alpha): \"\"\"Runs the logistic regression benchmark using cuNumeric on the GPU.\"\"\" import cupynumeric as cn import numpy as np # Also import numpy for the canonical synchronization print(f\"--- cuNumeric (GPU) Benchmark ---\") print(f\"Training on {n_samples} samples, {n_features} features for {iters} iterations \") # 1. Generate data ONCE on the GPU before the timing loop. print(\"Generating random dataset on GPU...\") X = cn.random.rand(n_samples, n_features) y = (cn.random.rand(n_samples) > 0.5).astype(np.float64) # 2. Perform a crucial untimed warm-up run for JIT compilation. print(\"Performing warm-up run...\") w_warmup = train_logistic_regression(cn, X, y, iters, alpha) # The best practice for synchronization: force a copy back to the CPU. _ = np.array(w_warmup) print(\"Warm-up complete. \") # 3. Perform the timed runs. times = [] for i in range(args.runs): start = time.time() # Launch the operation on the GPU w = train_logistic_regression(cn, X, y, iters, alpha) # Synchronize by converting the final result back to a NumPy array. np.array(w) end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.3f}s\") del w gc.collect() avg = sum(times) / len(times) print(f\" cuNumeric average: {avg:.3f}s \") return avg if __name__ == \"__main__\": # A more robust argument parsing setup parser = argparse.ArgumentParser( description=\"Benchmark logistic regression on NumPy (CPU) vs. cuNumeric (GPU).\" ) # Hyperparameters for the model parser.add_argument( \"-n\", \"--n_samples\", type=int, default=2_000_000, help=\"Number of data samples\" ) parser.add_argument( \"-d\", \"--n_features\", type=int, default=10, help=\"Number of features\" ) parser.add_argument( \"-i\", \"--iters\", type=int, default=500, help=\"Number of gradient descent iterations\" ) parser.add_argument( \"-a\", \"--alpha\", type=float, default=0.1, help=\"Learning rate\" ) # Benchmark control parser.add_argument( \"-r\", \"--runs\", type=int, default=5, help=\"Number of timing runs\" ) parser.add_argument( \"--cunumeric\", action=\"store_true\", help=\"Run the cuNumeric (GPU) version\" ) args, unknown = parser.parse_known_args() # Dispatcher logic if args.cunumeric or \"--cunumeric\" in unknown: benchmark_cunumeric(args.n_samples, args.n_features, args.iters, args.alpha) else: benchmark_numpy(args.n_samples, args.n_features, args.iters, args.alpha) And the outputs. (cunumeric-env) tom@tpr-desktop:~$ python example2.py --- NumPy (CPU) Benchmark --- Training on 2000000 samples, 10 features for 500 iterations Generating random dataset on CPU... Performing warm-up run... Warm-up complete. Run 1: time = 12.292s Run 2: time = 11.830s Run 3: time = 11.903s Run 4: time = 12.843s Run 5: time = 11.964s NumPy average: 12.166s (cunumeric-env) tom@tpr-desktop:~$ LEGATE_AUTO_CONFIG=0 legate --cpus 1 --gpus 1 --omps 0 example2.py --cunu meric [0 - 7f04b535c480] 0.000000 {5}{module_config}: Module numa can not detect resources. [0 - 7f04b535c480] 0.000000 {4}{topology}: can't open /sys/devices/system/node/ [0 - 7f04b535c480] 0.001149 {4}{threads}: reservation ('GPU ctxsync 0x55fb037cf140') cannot be satisfied --- cuNumeric (GPU) Benchmark --- Training on 2000000 samples, 10 features for 500 iterations Generating random dataset on GPU... Performing warm-up run... Warm-up complete. Run 1: time = 1.964s Run 2: time = 1.957s Run 3: time = 1.968s Run 4: time = 1.955s Run 5: time = 1.960s cuNumeric average: 1.961s Not quite as impressive as our first example, but a 5x to 6x speedup on an already fast NumPy program is not to be sniffed at. Code example 3 — solving linear equations This script benchmarks how long it takes to solve a dense 3000×3000 linear algebra equation system. This is a fundamental operation in linear algebra used to solve the equation of type Ax = b, where A is a giant grid of numbers (a 3000×3000 matrix in this case), and b is a list of numbers (a vector). The goal is to find the unknown list of numbers x that makes the equation true. This is a computationally intensive task that is at the heart of many scientific simulations, engineering problems, financial models, and even some AI algorithms. import time import gc import argparse import sys # Import sys to check arguments # Note: The library imports (numpy and cupynumeric) are now done *inside* # their respective functions to keep them separate and avoid import errors. def benchmark_numpy(n, runs): \"\"\"Runs the linear solve benchmark using standard NumPy on the CPU.\"\"\" import numpy as np print(f\"--- NumPy (CPU) Benchmark ---\") print(f\"Solving {n}×{n} A x = b ({runs} runs) \") # 1. Generate data ONCE before the timing loop. print(\"Generating random system on CPU...\") A = np.random.randn(n, n).astype(np.float32) b = np.random.randn(n).astype(np.float32) # 2. Perform one untimed warm-up run. This is good practice even for # the CPU to ensure caches are warm and any one-time setup is done. print(\"Performing warm-up run...\") _ = np.linalg.solve(A, b) print(\"Warm-up complete. \") # 3. Perform the timed runs. times = [] for i in range(runs): start = time.time() # The operation being timed x = np.linalg.solve(A, b) end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.6f}s\") # Clean up the result to be safe with memory del x gc.collect() avg = sum(times) / len(times) print(f\" NumPy average: {avg:.6f}s \") return avg def benchmark_cunumeric(n, runs): \"\"\"Runs the linear solve benchmark using cuNumeric on the GPU.\"\"\" import cupynumeric as cn import numpy as np # Also import numpy for the canonical synchronization print(f\"--- cuNumeric (GPU) Benchmark ---\") print(f\"Solving {n}×{n} A x = b ({runs} runs) \") # 1. Generate data ONCE on the GPU before the timing loop. # This ensures we are not timing the data transfer in our main loop. print(\"Generating random system on GPU...\") A = cn.random.randn(n, n).astype(np.float32) b = cn.random.randn(n).astype(np.float32) # 2. Perform a crucial untimed warm-up run. This handles JIT # compilation and other one-time GPU setup costs. print(\"Performing warm-up run...\") x_warmup = cn.linalg.solve(A, b) # The best practice for synchronization: force a copy back to the CPU. _ = np.array(x_warmup) print(\"Warm-up complete. \") # 3. Perform the timed runs. times = [] for i in range(runs): start = time.time() # Launch the operation on the GPU x = cn.linalg.solve(A, b) # Synchronize by converting the result to a host-side NumPy array. # This is guaranteed to block until the GPU has finished. np.array(x) end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.6f}s\") # Clean up the GPU array result del x gc.collect() avg = sum(times) / len(times) print(f\" cuNumeric average: {avg:.6f}s \") return avg if __name__ == \"__main__\": # A more robust argument parsing setup parser = argparse.ArgumentParser( description=\"Benchmark linear solve on NumPy (CPU) vs. cuNumeric (GPU).\" ) parser.add_argument( \"-n\", \"--n\", type=int, default=3000, help=\"Matrix size (n x n)\" ) parser.add_argument( \"-r\", \"--runs\", type=int, default=5, help=\"Number of timing runs\" ) # Use parse_known_args() to handle potential extra arguments from Legate args, unknown = parser.parse_known_args() # The dispatcher logic: check if \"--cunumeric\" is in the command line # This is a simple and effective way to switch between modes. if \"--cunumeric\" in sys.argv or \"--cunumeric\" in unknown: benchmark_cunumeric(args.n, args.runs) else: benchmark_numpy(args.n, args.runs) The outputs. (cunumeric-env) tom@tpr-desktop:~$ python example4.py --- NumPy (CPU) Benchmark --- Solving 3000×3000 A x = b (5 runs) Generating random system on CPU... Performing warm-up run... Warm-up complete. Run 1: time = 0.133075s Run 2: time = 0.126129s Run 3: time = 0.135849s Run 4: time = 0.137383s Run 5: time = 0.138805s NumPy average: 0.134248s (cunumeric-env) tom@tpr-desktop:~$ LEGATE_AUTO_CONFIG=0 legate --cpus 1 --gpus 1 --omps 0 example4.py --cunumeric [0 - 7f29f42ce480] 0.000000 {5}{module_config}: Module numa can not detect resources. [0 - 7f29f42ce480] 0.000000 {4}{topology}: can't open /sys/devices/system/node/ [0 - 7f29f42ce480] 0.000053 {4}{threads}: reservation ('GPU ctxsync 0x562e88c28700') cannot be satisfied --- cuNumeric (GPU) Benchmark --- Solving 3000×3000 A x = b (5 runs) Generating random system on GPU... Performing warm-up run... Warm-up complete. Run 1: time = 0.009685s Run 2: time = 0.010043s Run 3: time = 0.009966s Run 4: time = 0.009739s Run 5: time = 0.009383s cuNumeric average: 0.009763s That is a tremendous result. The Nvidia cuNumeric run is 100x faster than the NumPy run. Code example 4 — Sorting Sorting is such a fundamental part of everything that happens in computing, and modern computers are so fast that most developers don’t even think about it. But let’s see how much of a difference using cuNumeric can make to this ubiquitous operation. We’ll sort a large (30,000,000) 1D array of numbers # benchmark_sort.py import time import sys import gc # Array size n = 30_000_000 # 30 million elements def benchmark_numpy(): import numpy as np print(f\"Sorting an array of {n} elements with NumPy (5 runs) \") times = [] for i in range(5): data = np.random.randn(n).astype(np.float32) start = time.time() _ = np.sort(data) end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.6f}s\") del data gc.collect() avg = sum(times) / len(times) print(f\" NumPy average: {avg:.6f}s \") def benchmark_cunumeric(): import cupynumeric as np print(f\"Sorting an array of {n} elements with cuNumeric (5 runs) \") times = [] for i in range(5): data = np.random.randn(n).astype(np.float32) start = time.time() _ = np.sort(data) # Force GPU sync _ = np.linalg.norm(np.zeros(())) end = time.time() duration = end - start times.append(duration) print(f\"Run {i+1}: time = {duration:.6f}s\") del data gc.collect() _ = np.linalg.norm(np.zeros(())) avg = sum(times) / len(times) print(f\" cuNumeric average: {avg:.6f}s \") if __name__ == \"__main__\": if \"--cunumeric\" in sys.argv: benchmark_cunumeric() else: benchmark_numpy() The outputs. (cunumeric-env) tom@tpr-desktop:~$ python example5.py --- NumPy (CPU) Benchmark --- Sorting an array of 30000000 elements (5 runs) Creating random array on CPU... Performing warm-up run... Warm-up complete. Run 1: time = 0.588777s Run 2: time = 0.586813s Run 3: time = 0.586745s Run 4: time = 0.586525s Run 5: time = 0.583783s NumPy average: 0.586529s ----------------------------- (cunumeric-env) tom@tpr-desktop:~$ LEGATE_AUTO_CONFIG=0 legate --cpus 1 --gpus 1 --omps 0 example5.py --cunumeric [0 - 7fd9e4615480] 0.000000 {5}{module_config}: Module numa can not detect resources. [0 - 7fd9e4615480] 0.000000 {4}{topology}: can't open /sys/devices/system/node/ [0 - 7fd9e4615480] 0.000082 {4}{threads}: reservation ('GPU ctxsync 0x564489232fd0') cannot be satisfied --- cuNumeric (GPU) Benchmark --- Sorting an array of 30000000 elements (5 runs) Creating random array on GPU... Performing warm-up run... Warm-up complete. Run 1: time = 0.010857s Run 2: time = 0.007927s Run 3: time = 0.007921s Run 4: time = 0.008240s Run 5: time = 0.007810s cuNumeric average: 0.008551s ------------------------------- Yet another hugely impressive performance from cuNumeric and Legate. Summary This article introduced cuNumeric, an NVIDIA library designed as a high-performance, drop-in replacement for NumPy. The key takeaway is that data scientists can accelerate their existing Python code on NVIDIA GPUs with minimal effort, often by simply changing a single import line and running the script with the ‘legate’ command. Two main components power the technology: Legate: An open-source runtime layer from NVIDIA that automatically translates high-level Python operations into tasks. It intelligently manages distributing these tasks across single or multiple GPUs, handling data partitioning, memory management (even spilling to disk if needed), and optimising communication. cuNumeric: The user-facing library that mirrors the NumPy API. When you make a call like np.matmul(), cuNumeric converts it into a task for the Legate engine to execute on the GPU. I was able to validate Nvidia’s performance claims by running four benchmark tests on my desktop PC (with an NVIDIA RTX 4070 Ti GPU), comparing standard NumPy on the CPU against cuNumeric on the GPU. The results demonstrate significant performance gains for cuNumeric: Matrix Multiplication: ~10x faster than NumPy. faster than NumPy. Logistic Regression Training: ~6x faster. faster. Solving Linear Equations: A massive 100x+ speedup. A massive speedup. Sorting a Large Array: Another huge improvement, running approximately 70x faster. In conclusion, I showed that cuNumeric successfully delivers on its promise, making the immense computational power of GPUs accessible to the broader Python data science community without requiring a steep learning curve or a complete code rewrite. For more information and links to related resources, check out the original Nvidia announcement on cuNumeric here.",
         "en",
         "{'MISC': ['# Force GPU sync', '# The `np` argument allows us to pass in either the numpy or cupynumeric module', '# This ensures', '# This is guaranteed to block until the GPU has finished', '# shorthand for np.matmul', '-----------------------------------------------------------------------------------------+ | NVIDIA-SMI', '-----------------------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID', 'APIs', 'Another huge', 'At the time of writing', 'Ax = b', 'Because the API of cuNumeric', 'Benchmark', 'But let’s see how much of a difference using cuNumeric can', 'CPU or', 'CPUs', 'CUDA', 'CUDA Version', 'CUDA is', 'Clean up the GPU', 'Clean up the result to be safe with memory del x gc.collect', 'Dispatcher', 'Driver Version', 'For each of the five', 'For example', 'For more information and links to related resources', 'For running using Legate', 'GPU memory', 'GPUs', 'GPUs or', 'Generating', 'Generating random', 'Generating random dataset', 'Generating random system', 'Generating random system on CPU', 'Here is the output', 'Hyperparameters for the model', 'I don’t have a cluster of GPUs or', 'I like to set up a separate development environment to run my tests', 'I showed that cuNumeric successfully', 'I will run the NumPy and cuNumeric', 'I wouldn’t be surprised if you missed it', 'Import sys to check arguments', 'Is', 'It initialises the weight vector w to zeros', 'It intelligently manages distributing these tasks across single or', 'It translates high-level', 'I’ll', 'I’ll be using Miniconda to set up my environment', 'JIT', 'LEGATE_AUTO_CONFIG=0 legate', 'Late last year', 'Launch the operation on the GPU', 'Launch the operation on the GPU C = A @ B', 'Legate couldn’t find details about the machine’s CPU', 'Legate with one CPU', 'Legate: An open', 'Matrix', 'Matrix Multiplication', 'Module numa can not detect resources', 'Most people will probably know', 'NVIDIA GPUs with', 'NVIDIA’', 'Name Persistence-', 'Now', 'NumPy', 'NumPy a lot', 'NumPy array', 'NumPy average', 'NumPy on the CPU', 'NumPy on the CPU against cuNumeric on the GPU', 'Nvidia cuNumeric run is 100x faster than the NumPy run', 'Nvidia from their ultra-fast chips that power computers and data centres all over the world', 'Nvidia is making some strong claims that this is the case', 'One of its most prized products is the Compute Unified Device', 'OpenMP', 'Overlap compute', 'P8', 'Pandas', 'Partition your arrays', 'Performance benefits So', 'Performing warm', 'Python', 'Regression Training: ~6x faster', 'Run 1', 'Run 2', 'Run 3', 'Run 4', 'Run 5', 'Running the NumPy side of things uses the regular python', 'Schedule each tile on the best available device', 'Setting up a development environment', 'Since its launch in 2007', 'Solving Linear Equations: A massive 100x+ speedup', 'Sorting Sorting is such', 'Sorting an', 'Spill tiles to NVMe', 'Synchronize by converting', 'Synchronize by converting the result to a host-side', 'That way', 'The', 'The @ operator is', 'The best practice for synchronization', 'The key takeaway is that data scientists can accelerate their', 'The result is a neatly tuned hardware and software loop that keeps NVIDIA GPUs', 'The results demonstrate', 'The script records the elapsed time for each run', 'The warnings that Legate is outputting can be ignored', 'These are informational', 'This', 'This handles JIT', 'This is good practice even for # the CPU to ensure caches are warm and any one-time setup is done', 'This will help us assess whether Nvidia’', 'Those tasks will', 'Two', 'Usage', 'What is Legate', 'What is cuNumeric?', 'What it does is', 'What many people don’t know is that Nvidia also designs and creates innovative', 'When you make a call like np.matmul', 'Who are Nvidia', 'X', 'X.dot(w', 'You may also be familiar with Nvidia’', 'all CPU', 'and modern computers are so fast that most developers don’t even think about it.', 'and moves tiles', 'and optimising', 'and we’re going to use that to test out some of Nvidia’', 'applying the sigmoid p = 1/(1+exp(–z', 'args.n_features', 'benchmark_numpy(n', \"can't open\", 'cleans up memory', 'computing the', 'ctxsync', 'cuNumeric', 'cuNumeric and Legate', 'cuNumeric and NumPy on my PC to', 'cuNumeric converts each', 'cuNumeric converts it into a task for the Legate engine to', 'cuNumeric here', 'cuNumeric is not available to install on Windows', 'cuNumeric is registering', 'debugging and profiling tools', 'def train_logistic_regression(np', 'default=2_000_000', 'device architectures and associated software', 'drop-in replacement', 'faster than', 'faster.', 'gc', 'handling data partitioning', 'help=\"Learning', 'help=\"Run the cuNumeric', 'import time', 'into Legate tasks', 'it has evolved into', 'line and running the script with the ‘legate’ command', 'machine learning engineers and data engineers typically', 'my desktop PC does have an Nvidia GeForce RTX 4070 GPU', 'nothing I do in that environment will affect any of my other projects', 'np # everything else stays the same', 'numpy as', 'numpy as np', 'numpy as np # Also', 'often by simply', 'one GPU', 'our first example', 'partitions the data', 'power of GPUs', 'python', 'random 0/1 label vector', 'right?', 'runtime', 'task engine and', 'that mirrors the NumPy API', 'that’', 'the cuNumeric', 'then', 'then and now', 'time = 0.0086s Run 4', 'time = 0.009685s Run 2', 'time = 0.009966s Run 4', 'time = 0.0976s Run 2', 'time = 0.1063s Run 5', 'time = 11.830s Run 3', 'using cuNumeric on the GPU', 'warm-up run', 'we’ll measure how long it takes to train', 'which schedules the tasks', 'whichever tool you’re comfortable with', 'you install it and need only change one', '|-----------------------------------------+------------------------+----------------------+'], 'ORG': ['After all', 'CPU', 'C_warmup', 'Default | | | | N', 'ECC', 'Ensure', 'GPUs and network links for you', 'Generate data ONCE before the timing loop', 'Generate data ONCE on the GPU before the timing loop', 'In a nutshell', 'Logistic', 'Logistic regression', 'N', 'NVIDIA', 'Nvidia', 'Perform', 'X', 'memory management', 'np.random.randn(n).astype(np.float32', 'sys def benchmark_numpy(n'], 'PER': ['Jensen Huang', 'Legate', 'Multiplying', 'Performs', 'Sorting', 'Sun Jun', 'X.T.dot(p', 'X.shape[0', 'and', 'command line syntax', 'ctxsync', 'leather jacket-loving CEO', 'legate cupynumeric', 'sparse linear'], 'LOC': ['-c conda-forge', '-c conda-forge -c', 'ArgumentParser', 'B', 'Cap | Memory', 'Large Array', 'NumPy’', 'X.T.dot(p - y', 'b', 'grad return w def benchmark_numpy(n_samples', 'help=\"Matrix size', 'iters', 'loop', 'np.array(x_warmup', 'of', 'print(f\"Multiplying', 'times', 'where A is']}",
         "[-0.10975639522075653, -0.03256487473845482, -0.04713495820760727, -0.013118945062160492, 0.012176905758678913, -0.11370624601840973, -0.07349758595228195, 0.008951687254011631, -0.052429575473070145, -0.047941166907548904, -0.10549934953451157, -0.03002496063709259, 0.018932659178972244, 0.013308749534189701, 0.028176968917250633, -0.00849984772503376, -0.01549591775983572, -0.013073992915451527, -0.007922332733869553, -0.055515944957733154, -0.0880049392580986, 0.08175546675920486, -0.023542368784546852, -0.02630889043211937, 0.025682441890239716, -0.02057061158120632, 0.0020927719306200743, -0.07494544982910156, 0.028349261730909348, -0.00881172064691782, 0.013660593889653683, 0.06234844774007797, 0.031385865062475204, 0.04133007302880287, 0.0007232719799503684, 0.004537671804428101, -0.005790440831333399, -0.09292010217905045, -0.07984647154808044, -0.017725883051753044, 0.024192381650209427, -0.04798400402069092, -0.007438604719936848, 0.03514236584305763, 0.025430049747228622, 0.027523040771484375, 0.05166320130228996, -0.03425433486700058, 0.015399275347590446, -0.05245915800333023, -0.0466097816824913, -0.03432502970099449, 0.024086911231279373, -0.008423307910561562, -0.028671203181147575, 0.011778408661484718, 0.021513231098651886, -0.11168714612722397, -0.007677583955228329, -0.026016486808657646, 0.04586444050073624, -0.03902207314968109, 0.0007103635580278933, 0.04590928927063942, 0.03947203978896141, 0.0018213215516880155, 0.028819091618061066, -0.05421767383813858, 0.07763585448265076, -0.010060926899313927, 0.03974152356386185, 0.012551640160381794, 0.026148010045289993, 0.004863854963332415, -0.008950280025601387, -0.024541951715946198, 0.054279789328575134, -0.018085533753037453, 0.07988063246011734, -0.03828130289912224, 0.021976420655846596, 0.03063906915485859, 0.0750037208199501, -0.019089773297309875, 0.0643041804432869, -0.041918862611055374, 0.009094332344830036, 0.0907936617732048, 0.012989453971385956, -0.08294250071048737, 0.04516689479351044, 0.025663994252681732, 0.012164103798568249, 0.011226383969187737, -0.022307779639959335, 0.022091953083872795, 0.019711647182703018, -0.027104761451482773, -0.06853131204843521, 0.06471439450979233, -0.02343716099858284, -0.004341004882007837, 0.02898450568318367, 0.03758494555950165, 0.042666610330343246, 0.04333123564720154, 0.07436944544315338, 0.026348115876317024, -0.030431389808654785, -0.0009421907016076148, -0.013408936560153961, 0.0010364647023379803, -0.01778397709131241, 0.0007766500930301845, 0.04228677600622177, 0.020096642896533012, -0.05191102251410484, 0.026109879836440086, 0.04314858466386795, 0.011533097364008427, -0.0530054084956646, -0.008307332172989845, -0.01671561226248741, 0.028491320088505745, 0.018462298437952995, 0.076425701379776, -0.08721165359020233, 2.716693994064012e-33, -0.07115999609231949, 0.02011038362979889, 0.032839491963386536, -0.01878739334642887, 0.050710998475551605, 0.01887536607682705, 0.020320449024438858, 0.030534835532307625, 0.006598811596632004, 0.012743598781526089, -0.09535685181617737, 0.14503049850463867, -0.017390133813023567, 0.11308220773935318, 0.06963346898555756, -0.08471016585826874, -0.03653625026345253, 0.030556514859199524, 0.012937352992594242, 0.024168986827135086, 0.105780228972435, 0.043244097381830215, 0.001161467283964157, 0.028244812041521072, 0.007476954720914364, 0.06812785565853119, -0.026549236848950386, -0.024549661204218864, 0.0600157268345356, 0.04238620400428772, -0.09236286580562592, 0.005891422275453806, -0.020887136459350586, -0.041957080364227295, 0.02588149905204773, 0.02040540799498558, -0.0549301877617836, -0.05669086053967476, 0.03369113802909851, 0.04313261806964874, 0.005146303214132786, 0.08876083046197891, -0.004315217025578022, -0.12317485362291336, -0.13806527853012085, 0.0050943633541464806, 0.01058813277631998, 0.04930150508880615, -0.0009760985267348588, -0.06203006953001022, -0.060834500938653946, 0.005721921566873789, -0.0386284664273262, -0.021231750026345253, 0.0585634782910347, -0.06689158827066422, 0.03627581149339676, 0.001316883135586977, 0.07330282777547836, -0.0076739005744457245, -0.035208944231271744, -0.01988198049366474, -0.047008804976940155, -0.025821376591920853, -0.04802539572119713, 0.05587492510676384, 0.05615426227450371, 0.10697140544652939, -0.01975257880985737, 0.030724534764885902, -0.07780276983976364, 0.06478896737098694, -0.11097906529903412, -0.07231087237596512, 0.07647811621427536, -0.012952455319464207, 0.04239760339260101, -0.10146822780370712, -0.033329129219055176, -0.003835274139419198, -0.02143351547420025, 0.09165441244840622, -0.004941971972584724, -0.04109841585159302, 0.005330560728907585, -0.042316634207963943, 0.006503452081233263, 0.05773749202489853, -0.07199213653802872, -0.08369798213243484, -0.05848319083452225, -0.027469567954540253, 0.1029212474822998, 0.03761090338230133, -0.07851622998714447, -3.2022490170734434e-33, -0.04430241882801056, -0.06933732330799103, -0.05304675176739693, 0.06857413798570633, -0.012693816795945168, -0.04705464839935303, -0.0010604682611301541, -0.05537031590938568, 0.014741813763976097, -0.06808224320411682, 0.044662728905677795, -0.014958522282540798, 0.07834470272064209, 0.05198664218187332, 0.036939650774002075, -0.011753231287002563, -0.0569707415997982, -0.009945494122803211, -0.06192050129175186, -0.1009352058172226, -0.052026428282260895, 0.040671784430742264, -0.048451732844114304, -0.09052906930446625, -0.04625320807099342, 0.012218046933412552, 0.038058776408433914, -0.09083312749862671, 0.028835143893957138, 0.00508410669863224, -0.06707420200109482, -0.00044685424654744565, -0.11091577261686325, 0.06762626022100449, 0.09463060647249222, 0.03758765012025833, 0.04027685150504112, -0.024791518226265907, -0.005837053060531616, -0.030279438942670822, 0.15937654674053192, 0.04532889276742935, 0.0014040200039744377, 0.02484203688800335, 0.01835835725069046, 0.060371749103069305, -0.051277242600917816, 0.05573207885026932, -0.0034803899470716715, -0.032664086669683456, 0.007420160807669163, 0.02339853160083294, 0.010527048259973526, -0.002436688868328929, -0.042067885398864746, 0.06132889166474342, 0.020856859162449837, 0.011313291266560555, -0.019183803349733353, -0.005253853742033243, -0.08729004114866257, -0.016012270003557205, 0.004627303685992956, -0.03091607056558132, -0.02700318768620491, 0.01605728454887867, -0.07063593715429306, 0.0736890435218811, -0.033478785306215286, -0.06325413286685944, 0.04406649246811867, -0.01939714513719082, -0.06566285341978073, 0.0327594019472599, -0.18968228995800018, 0.015854056924581528, 0.03184466436505318, -0.05140310898423195, 0.03466029837727547, -0.013853522017598152, 0.033871352672576904, -0.023891473188996315, 0.08567564934492111, 0.01648501493036747, 0.004966459237039089, 0.023244164884090424, 0.08154663443565369, -0.018510736525058746, 0.055689774453639984, 0.008455677889287472, -0.04805750772356987, 0.03303306922316551, -0.049162305891513824, 0.07762021571397781, -0.0074943616054952145, -4.630579297781878e-08, 0.03769468888640404, 0.019813353195786476, 0.03998764231801033, -0.014031857252120972, 0.006808284670114517, 0.017861900851130486, -0.015727804973721504, 0.026633743196725845, 0.0019985458347946405, 0.051654230803251266, 0.13364751636981964, -0.030661333352327347, -0.03298953175544739, -0.03615633398294449, 0.0035065317060798407, 0.2011186182498932, 0.047212038189172745, -0.03148582577705383, 0.007115003187209368, -0.028314290568232536, -0.0218563973903656, 0.020992755889892578, 0.03789811208844185, -0.004446371458470821, -0.10221125185489655, -0.027462299913167953, 0.002477658446878195, -0.006139026023447514, 0.03467327728867531, -0.04664159566164017, -0.05729459226131439, -0.0012316970387473702, 0.052734047174453735, 0.016541089862585068, 0.06243203207850456, -0.0032773262355476618, 0.044815439730882645, 0.008497131988406181, 0.087105892598629, -0.015118833631277084, -0.051676370203495026, 0.01727244071662426, -0.030354375019669533, -0.016447408124804497, 0.05876467749476433, 0.007708870340138674, -0.019206585362553596, -0.034987445920705795, -0.0302763432264328, 0.06789083778858185, -0.06063801050186157, 0.07094378769397736, -0.006757704075425863, 0.08349636942148209, 0.028870966285467148, 0.003287101397290826, -0.13622403144836426, -0.08514254540205002, -0.02130468562245369, 0.0358089804649353, 0.015152445062994957, -0.037355151027441025, 0.061375558376312256, 0.03765592724084854]",
         "0.141"
        ],
        [
         "7",
         "33",
         "Ahrefs vs SEMrush: Which SEO Tool Should You Use?",
         "SEMrush and Ahrefs are among the most popular tools in the SEO industry. Both companies have been in business for years and have thousands of customers per month. If you're a professional SEO or trying to do digital marketing on your own, at some point you'll likely consider using a tool to help with your efforts. Ahrefs and SEMrush are two names that will likely appear on your shortlist. In this guide, I'm going to help you learn more about these SEO tools and how to choose the one that's best for your purposes. What is SEMrush? SEMrush is a popular SEO tool with a wide range of features—it's the leading competitor research service for online marketers. SEMrush's SEO Keyword Magic tool offers over 20 billion Google-approved keywords, which are constantly updated and it's the largest keyword database. The program was developed in 2007 as SeoQuake is a small Firefox extension Features Most accurate keyword data: Accurate keyword search volume data is crucial for SEO and PPC campaigns by allowing you to identify what keywords are most likely to bring in big sales from ad clicks. SEMrush constantly updates its databases and provides the most accurate data. Largest Keyword database: SEMrush's Keyword Magic Tool now features 20-billion keywords, providing marketers and SEO professionals the largest database of keywords. All SEMrush users receive daily ranking data, mobile volume information, and the option to buy additional keywords by default with no additional payment or add-ons needed Most accurate position tracking tool: This tool provides all subscribers with basic tracking capabilities, making it suitable for SEO professionals. Plus, the Position Tracking tool provides local-level data to everyone who uses the tool. SEO Data Management: SEMrush makes managing your online data easy by allowing you to create visually appealing custom PDF reports, including Branded and White Label reports, report scheduling, and integration with GA, GMB, and GSC. Toxic link monitoring and penalty recovery: With SEMrush, you can make a detailed analysis of toxic backlinks, toxic scores, toxic markers, and outreach to those sites. Content Optimization and Creation Tools: SEMrush offers content optimization and creation tools that let you create SEO-friendly content. Some features include the SEO Writing Assistant, On-Page SEO Check, er/SEO Content Template, Content Audit, Post Tracking, Brand Monitoring. Ahrefs Ahrefs is a leading SEO platform that offers a set of tools to grow your search traffic, research your competitors, and monitor your niche. The company was founded in 2010, and it has become a popular choice among SEO tools. Ahrefs has a keyword index of over 10.3 billion keywords and offers accurate and extensive backlink data updated every 15-30 minutes and it is the world's most extensive backlink index database. Features Backlink alerts data and new keywords : Get an alert when your site is linked to or discussed in blogs, forums, comments, or when new keywords are added to a blog posting about you. Intuitive interface: The intuitive design of the widget helps you see the overall health of your website and search engine ranking at a glance. Site Explorer: The Site Explorer will give you an in-depth look at your site's search traffic. Domain Comparison Reports with charts and graphs JavaScript rendering and a site audit can identify SEO issues. A question explorer that provides well-crafted topic suggestions Direct Comparisons: Ahrefs vs SEMrush Now that you know a little more about each tool, let's take a look at how they compare. I'll analyze each tool to see how they differ in interfaces, keyword research resources, rank tracking, and competitor analysis. User Interface Ahrefs and SEMrush both offer comprehensive information and quick metrics regarding your website's SEO performance. However, Ahrefs takes a bit more of a hands-on approach to getting your account fully set up, whereas SEMrush's simpler dashboard can give you access to the data you need quickly. In this section, we provide a brief overview of the elements found on each dashboard and highlight the ease with which you can complete tasks. AHREFS The Ahrefs dashboard is less cluttered than that of SEMrush, and its primary menu is at the very top of the page, with a search bar designed only for entering URLs. Additional features of the Ahrefs platform include: You can see analytics from the dashboard, including search engine rankings to domain ratings, referring domains, and backlink Jumping from one tool to another is easy. You can use the Keyword Explorer to find a keyword to target and then directly track your ranking with one click. The website offers a tooltip helper tool that allows you to hover your mouse over something that isn't clear and get an in-depth explanation. SEMRUSH When you log into the SEMrush Tool, you will find four main modules. These include information about your domains, organic keyword analysis, ad keyword, and site traffic. You'll also find some other options like A search bar allows you to enter a domain, keyword, or anything else you wish to explore. A menu on the left side of the page provides quick links to relevant information, including marketing insights, projects, keyword analytics, and more. The customer support resources located directly within the dashboard can be used to communicate with the support team or to learn about other resources such as webinars and blogs. Detailed descriptions of every resource offered. This detail is beneficial for new marketers, who are just starting. WHO WINS? Both Ahrefs and SEMrush have user-friendly dashboards, but Ahrefs is less cluttered and easier to navigate. On the other hand, SEMrush offers dozens of extra tools, including access to customer support resources. When deciding on which dashboard to use, consider what you value in the user interface, and test out both. Rank Tracking If you're looking to track your website's search engine ranking, rank tracking features can help. You can also use them to monitor your competitors. Let's take a look at Ahrefs vs. SEMrush to see which tool does a better job. Ahrefs The Ahrefs Rank Tracker is simpler to use. Just type in the domain name and keywords you want to analyze, and it spits out a report showing you the search engine results page (SERP) ranking for each keyword you enter. Rank Tracker looks at the ranking performance of keywords and compares them with the top rankings for those keywords. Ahrefs also offers: You'll see metrics that help you understand your visibility, traffic, average position, and keyword difficulty. It gives you an idea of whether a keyword would be profitable to target or not. SEMRUSH SEMRush offers a tool called Position Tracking. This tool is a project tool—you must set it up as a new project. Below are a few of the most popular features of the SEMrush Position Tracking tool: All subscribers are given regular data updates and mobile search rankings upon subscribing The platform provides opportunities to track several SERP features, including Local tracking. Intuitive reports allow you to track statistics for the pages on your website, as well as the keywords used in those pages. Identify pages that may be competing with each other using the Cannibalization report. WHO WINS? Ahrefs is a more user-friendly option. It takes seconds to enter a domain name and keywords. From there, you can quickly decide whether to proceed with that keyword or figure out how to rank better for other keywords. SEMrush allows you to check your mobile rankings and ranking updates daily, which is something Ahrefs does not offer. SEMrush also offers social media rankings, a tool you won't find within the Ahrefs platform. Both are good which one do you like let me know in the comment. Keyword Research Keyword research is closely related to rank tracking, but it's used for deciding which keywords you plan on using for future content rather than those you use now. When it comes to SEO, keyword research is the most important thing to consider when comparing the two platforms. AHREFS The Ahrefs Keyword Explorer provides you with thousands of keyword ideas and filters search results based on the chosen search engine. Ahrefs supports several features, including: It can search multiple keywords in a single search and analyze them together. At SEMrush, you also have this feature in Keyword Overview. Ahrefs has a variety of keywords for different search engines, including Google, YouTube, Amazon, Bing, Yahoo, Yandex, and other search engines. When you click on a keyword, you can see its search volume and keyword difficulty, but also other keywords related to it, which you didn't use. SEMRUSH SEMrush's Keyword Magic Tool has over 20 billion keywords for Google. You can type in any keyword you want, and a list of suggested keywords will appear. The Keyword Magic Tool also lets you to: Show performance metrics by keyword Search results are based on both broad and exact keyword matches. Show data like search volume, trends, keyword difficulty, and CPC. Show the first 100 Google search results for any keyword. Identify SERP Features and Questions related to each keyword SEMrush has released a new Keyword Gap Tool that uncovers potentially useful keyword opportunities for you, including both paid and organic keywords. WHO WINS? Both of these tools offer keyword research features and allow users to break down complicated tasks into something that can be understood by beginners and advanced users alike. If you're interested in keyword suggestions, SEMrush appears to have more keyword suggestions than Ahrefs does. It also continues to add new features, like the Keyword Gap tool and SERP Questions recommendations. Competitor Analysis Both platforms offer competitor analysis tools, eliminating the need to come up with keywords off the top of your head. Each tool is useful for finding keywords that will be useful for your competition so you know they will be valuable to you. AHREFS Ahrefs' domain comparison tool lets you compare up to five websites (your website and four competitors) side-by-side.it also shows you how your site is ranked against others with metrics such as backlinks, domain ratings, and more. Use the Competing Domains section to see a list of your most direct competitors, and explore how many keywords matches your competitors have. To find more information about your competitor, you can look at the Site Explorer and Content Explorer tools and type in their URL instead of yours. SEMRUSH SEMrush provides a variety of insights into your competitors' marketing tactics. The platform enables you to research your competitors effectively. It also offers several resources for competitor analysis including: Traffic Analytics helps you identify where your audience comes from, how they engage with your site, what devices visitors use to view your site, and how your audiences overlap with other websites. SEMrush's Organic Research examines your website's major competitors and shows their organic search rankings, keywords they are ranking for, and even if they are ranking for any (SERP) features and more. The Market Explorer search field allows you to type in a domain and lists websites or articles similar to what you entered. Market Explorer also allows users to perform in-depth data analytics on These companies and markets. WHO WINS? SEMrush wins here because it has more tools dedicated to competitor analysis than Ahrefs. However, Ahrefs offers a lot of functionality in this area, too. It takes a combination of both tools to gain an advantage over your competition. Pricing Ahrefs Lite Monthly: $99/month Standard Monthly: $179/month Annually Lite: $990/year Annually Standard: $1790/year SEMRUSH Pro Plan: $119.95/month Guru Plan:$229.95/month Business Plan: $449.95/month Which SEO tool should you choose for digital marketing? When it comes to keyword data research, you will become confused about which one to choose. Consider choosing Ahrefs if you Like friendly and clean interface Searching for simple keyword suggestions Want to get more keywords for different search engines like Amazon, Bing, Yahoo, Yandex, Baidu, and more Consider SEMrush if you: Want more marketing and SEO features Need competitor analysis tool Need to keep your backlinks profile clean Looking for more keyword suggestions for Google Both tools are great. Choose the one which meets your requirements and if you have any experience using either Ahrefs or SEMrush let me know in the comment section which works well for you.",
         "SEMrush and Ahrefs are among the most popular tools in the SEO industry. Both companies have been in business for years and have thousands of customers per month.\n\nIf you're a professional SEO or trying to do digital marketing on your own, at some point you'll likely consider using a tool to help with your efforts. Ahrefs and SEMrush are two names that will likely appear on your shortlist.\n\nIn this guide, I'm going to help you learn more about these SEO tools and how to choose the one that's best for your purposes.\n\nWhat is SEMrush?\n\nSEMrush is a popular SEO tool with a wide range of features—it's the leading competitor research service for online marketers. SEMrush's SEO Keyword Magic tool offers over 20 billion Google-approved keywords, which are constantly updated and it's the largest keyword database.\n\nThe program was developed in 2007 as SeoQuake is a small Firefox extension\n\nFeatures\n\nMost accurate keyword data: Accurate keyword search volume data is crucial for SEO and PPC campaigns by allowing you to identify what keywords are most likely to bring in big sales from ad clicks. SEMrush constantly updates its databases and provides the most accurate data.\n\nLargest Keyword database: SEMrush's Keyword Magic Tool now features 20-billion keywords, providing marketers and SEO professionals the largest database of keywords.\n\n\n\nAll SEMrush users receive daily ranking data, mobile volume information, and the option to buy additional keywords by default with no additional payment or add-ons needed\n\nMost accurate position tracking tool: This tool provides all subscribers with basic tracking capabilities, making it suitable for SEO professionals. Plus, the Position Tracking tool provides local-level data to everyone who uses the tool.\n\nSEO Data Management: SEMrush makes managing your online data easy by allowing you to create visually appealing custom PDF reports, including Branded and White Label reports, report scheduling, and integration with GA, GMB, and GSC.\n\nToxic link monitoring and penalty recovery: With SEMrush, you can make a detailed analysis of toxic backlinks, toxic scores, toxic markers, and outreach to those sites.\n\nContent Optimization and Creation Tools: SEMrush offers content optimization and creation tools that let you create SEO-friendly content. Some features include the SEO Writing Assistant, On-Page SEO Check, er/SEO Content Template, Content Audit, Post Tracking, Brand Monitoring.\n\nAhrefs\n\nAhrefs is a leading SEO platform that offers a set of tools to grow your search traffic, research your competitors, and monitor your niche. The company was founded in 2010, and it has become a popular choice among SEO tools. Ahrefs has a keyword index of over 10.3 billion keywords and offers accurate and extensive backlink data updated every 15-30 minutes and it is the world's most extensive backlink index database.\n\nFeatures\n\nBacklink alerts data and new keywords : Get an alert when your site is linked to or discussed in blogs, forums, comments, or when new keywords are added to a blog posting about you.\n\nIntuitive interface: The intuitive design of the widget helps you see the overall health of your website and search engine ranking at a glance.\n\nSite Explorer: The Site Explorer will give you an in-depth look at your site's search traffic.\n\nDomain Comparison\n\nReports with charts and graphs\n\nJavaScript rendering and a site audit can identify SEO issues.\n\nA question explorer that provides well-crafted topic suggestions\n\nDirect Comparisons: Ahrefs vs SEMrush\n\nNow that you know a little more about each tool, let's take a look at how they compare. I'll analyze each tool to see how they differ in interfaces, keyword research resources, rank tracking, and competitor analysis.\n\nUser Interface\n\nAhrefs and SEMrush both offer comprehensive information and quick metrics regarding your website's SEO performance. However, Ahrefs takes a bit more of a hands-on approach to getting your account fully set up, whereas SEMrush's simpler dashboard can give you access to the data you need quickly.\n\nIn this section, we provide a brief overview of the elements found on each dashboard and highlight the ease with which you can complete tasks.\n\nAHREFS\n\n\n\n\n\n\n\nThe Ahrefs dashboard is less cluttered than that of SEMrush, and its primary menu is at the very top of the page, with a search bar designed only for entering URLs.\n\nAdditional features of the Ahrefs platform include:\n\nYou can see analytics from the dashboard, including search engine rankings to domain ratings, referring domains, and backlink\n\nJumping from one tool to another is easy. You can use the Keyword Explorer to find a keyword to target and then directly track your ranking with one click.\n\nThe website offers a tooltip helper tool that allows you to hover your mouse over something that isn't clear and get an in-depth explanation.\n\nSEMRUSH\n\n\n\n\n\n\n\nWhen you log into the SEMrush Tool, you will find four main modules. These include information about your domains, organic keyword analysis, ad keyword, and site traffic.\n\nYou'll also find some other options like\n\nA search bar allows you to enter a domain, keyword, or anything else you wish to explore.\n\nA menu on the left side of the page provides quick links to relevant information, including marketing insights, projects, keyword analytics, and more.\n\nThe customer support resources located directly within the dashboard can be used to communicate with the support team or to learn about other resources such as webinars and blogs.\n\nDetailed descriptions of every resource offered. This detail is beneficial for new marketers, who are just starting.\n\nWHO WINS?\n\nBoth Ahrefs and SEMrush have user-friendly dashboards, but Ahrefs is less cluttered and easier to navigate. On the other hand, SEMrush offers dozens of extra tools, including access to customer support resources.\n\nWhen deciding on which dashboard to use, consider what you value in the user interface, and test out both.\n\nRank Tracking\n\nIf you're looking to track your website's search engine ranking, rank tracking features can help. You can also use them to monitor your competitors.\n\nLet's take a look at Ahrefs vs. SEMrush to see which tool does a better job.\n\nAhrefs\n\nThe Ahrefs Rank Tracker is simpler to use. Just type in the domain name and keywords you want to analyze, and it spits out a report showing you the search engine results page (SERP) ranking for each keyword you enter.\n\nRank Tracker looks at the ranking performance of keywords and compares them with the top rankings for those keywords. Ahrefs also offers:\n\nYou'll see metrics that help you understand your visibility, traffic, average position, and keyword difficulty.\n\nIt gives you an idea of whether a keyword would be profitable to target or not.\n\nSEMRUSH\n\nSEMRush offers a tool called Position Tracking. This tool is a project tool—you must set it up as a new project. Below are a few of the most popular features of the SEMrush Position Tracking tool:\n\nAll subscribers are given regular data updates and mobile search rankings upon subscribing\n\nThe platform provides opportunities to track several SERP features, including Local tracking.\n\nIntuitive reports allow you to track statistics for the pages on your website, as well as the keywords used in those pages.\n\nIdentify pages that may be competing with each other using the Cannibalization report.\n\nWHO WINS?\n\nAhrefs is a more user-friendly option. It takes seconds to enter a domain name and keywords. From there, you can quickly decide whether to proceed with that keyword or figure out how to rank better for other keywords.\n\nSEMrush allows you to check your mobile rankings and ranking updates daily, which is something Ahrefs does not offer. SEMrush also offers social media rankings, a tool you won't find within the Ahrefs platform. Both are good which one do you like let me know in the comment.\n\nKeyword Research\n\nKeyword research is closely related to rank tracking, but it's used for deciding which keywords you plan on using for future content rather than those you use now.\n\nWhen it comes to SEO, keyword research is the most important thing to consider when comparing the two platforms.\n\nAHREFS\n\nThe Ahrefs Keyword Explorer provides you with thousands of keyword ideas and filters search results based on the chosen search engine.\n\nAhrefs supports several features, including:\n\nIt can search multiple keywords in a single search and analyze them together. At SEMrush, you also have this feature in Keyword Overview.\n\nAhrefs has a variety of keywords for different search engines, including Google, YouTube, Amazon, Bing, Yahoo, Yandex, and other search engines.\n\nWhen you click on a keyword, you can see its search volume and keyword difficulty, but also other keywords related to it, which you didn't use.\n\nSEMRUSH\n\nSEMrush's Keyword Magic Tool has over 20 billion keywords for Google. You can type in any keyword you want, and a list of suggested keywords will appear.\n\nThe Keyword Magic Tool also lets you to:\n\nShow performance metrics by keyword\n\nSearch results are based on both broad and exact keyword matches.\n\nShow data like search volume, trends, keyword difficulty, and CPC.\n\nShow the first 100 Google search results for any keyword.\n\nIdentify SERP Features and Questions related to each keyword\n\nSEMrush has released a new Keyword Gap Tool that uncovers potentially useful keyword opportunities for you, including both paid and organic keywords.\n\nWHO WINS?\n\nBoth of these tools offer keyword research features and allow users to break down complicated tasks into something that can be understood by beginners and advanced users alike.\n\nIf you're interested in keyword suggestions, SEMrush appears to have more keyword suggestions than Ahrefs does. It also continues to add new features, like the Keyword Gap tool and SERP Questions recommendations.\n\nCompetitor Analysis\n\nBoth platforms offer competitor analysis tools, eliminating the need to come up with keywords off the top of your head. Each tool is useful for finding keywords that will be useful for your competition so you know they will be valuable to you.\n\nAHREFS\n\nAhrefs' domain comparison tool lets you compare up to five websites (your website and four competitors) side-by-side.it also shows you how your site is ranked against others with metrics such as backlinks, domain ratings, and more.\n\nUse the Competing Domains section to see a list of your most direct competitors, and explore how many keywords matches your competitors have.\n\nTo find more information about your competitor, you can look at the Site Explorer and Content Explorer tools and type in their URL instead of yours.\n\nSEMRUSH\n\nSEMrush provides a variety of insights into your competitors' marketing tactics. The platform enables you to research your competitors effectively. It also offers several resources for competitor analysis including:\n\nTraffic Analytics helps you identify where your audience comes from, how they engage with your site, what devices visitors use to view your site, and how your audiences overlap with other websites.\n\nSEMrush's Organic Research examines your website's major competitors and shows their organic search rankings, keywords they are ranking for, and even if they are ranking for any (SERP) features and more.\n\nThe Market Explorer search field allows you to type in a domain and lists websites or articles similar to what you entered. Market Explorer also allows users to perform in-depth data analytics on These companies and markets.\n\nWHO WINS?\n\nSEMrush wins here because it has more tools dedicated to competitor analysis than Ahrefs. However, Ahrefs offers a lot of functionality in this area, too. It takes a combination of both tools to gain an advantage over your competition.\n\nPricing\n\nAhrefs\n\nLite Monthly: $99/month\n\nStandard Monthly: $179/month\n\nAnnually Lite: $990/year\n\nAnnually Standard: $1790/year\n\nSEMRUSH\n\nPro Plan: $119.95/month\n\nGuru Plan:$229.95/month\n\nBusiness Plan: $449.95/month\n\nWhich SEO tool should you choose for digital marketing?\n\nWhen it comes to keyword data research, you will become confused about which one to choose.\n\nConsider choosing Ahrefs if you\n\nLike friendly and clean interface\n\nSearching for simple keyword suggestions\n\nWant to get more keywords for different search engines like Amazon, Bing, Yahoo, Yandex, Baidu, and more\n\nConsider SEMrush if you:\n\nWant more marketing and SEO features\n\nNeed competitor analysis tool\n\nNeed to keep your backlinks profile clean\n\nLooking for more keyword suggestions for Google\n\nBoth tools are great. Choose the one which meets your requirements and if you have any experience using either Ahrefs or SEMrush let me know in the comment section which works well for you.",
         "2022-03-01T12:16:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/03/ahrefs-vs-semrush-which-seo-tool-should.html",
         "2025-07-26T05:41:35.865518",
         "SEMrush and Ahrefs are among the most popular tools in the SEO industry. Both companies have been in business for years and have thousands of customers per month. If you're a professional SEO or trying to do digital marketing on your own, at some point you'll likely consider using a tool to help with your efforts. Ahrefs and SEMrush are two names that will likely appear on your shortlist. In this guide, I'm going to help you learn more about these SEO tools and how to choose the one that's best for your purposes. What is SEMrush? SEMrush is a popular SEO tool with a wide range of features—it's the leading competitor research service for online marketers. SEMrush's SEO Keyword Magic tool offers over 20 billion Google-approved keywords, which are constantly updated and it's the largest keyword database. The program was developed in 2007 as SeoQuake is a small Firefox extension Features Most accurate keyword data: Accurate keyword search volume data is crucial for SEO and PPC campaigns by allowing you to identify what keywords are most likely to bring in big sales from ad clicks. SEMrush constantly updates its databases and provides the most accurate data. Largest Keyword database: SEMrush's Keyword Magic Tool now features 20-billion keywords, providing marketers and SEO professionals the largest database of keywords. All SEMrush users receive daily ranking data, mobile volume information, and the option to buy additional keywords by default with no additional payment or add-ons needed Most accurate position tracking tool: This tool provides all subscribers with basic tracking capabilities, making it suitable for SEO professionals. Plus, the Position Tracking tool provides local-level data to everyone who uses the tool. SEO Data Management: SEMrush makes managing your online data easy by allowing you to create visually appealing custom PDF reports, including Branded and White Label reports, report scheduling, and integration with GA, GMB, and GSC. Toxic link monitoring and penalty recovery: With SEMrush, you can make a detailed analysis of toxic backlinks, toxic scores, toxic markers, and outreach to those sites. Content Optimization and Creation Tools: SEMrush offers content optimization and creation tools that let you create SEO-friendly content. Some features include the SEO Writing Assistant, On-Page SEO Check, er/SEO Content Template, Content Audit, Post Tracking, Brand Monitoring. Ahrefs Ahrefs is a leading SEO platform that offers a set of tools to grow your search traffic, research your competitors, and monitor your niche. The company was founded in 2010, and it has become a popular choice among SEO tools. Ahrefs has a keyword index of over 10.3 billion keywords and offers accurate and extensive backlink data updated every 15-30 minutes and it is the world's most extensive backlink index database. Features Backlink alerts data and new keywords : Get an alert when your site is linked to or discussed in blogs, forums, comments, or when new keywords are added to a blog posting about you. Intuitive interface: The intuitive design of the widget helps you see the overall health of your website and search engine ranking at a glance. Site Explorer: The Site Explorer will give you an in-depth look at your site's search traffic. Domain Comparison Reports with charts and graphs JavaScript rendering and a site audit can identify SEO issues. A question explorer that provides well-crafted topic suggestions Direct Comparisons: Ahrefs vs SEMrush Now that you know a little more about each tool, let's take a look at how they compare. I'll analyze each tool to see how they differ in interfaces, keyword research resources, rank tracking, and competitor analysis. User Interface Ahrefs and SEMrush both offer comprehensive information and quick metrics regarding your website's SEO performance. However, Ahrefs takes a bit more of a hands-on approach to getting your account fully set up, whereas SEMrush's simpler dashboard can give you access to the data you need quickly. In this section, we provide a brief overview of the elements found on each dashboard and highlight the ease with which you can complete tasks. AHREFS The Ahrefs dashboard is less cluttered than that of SEMrush, and its primary menu is at the very top of the page, with a search bar designed only for entering URLs. Additional features of the Ahrefs platform include: You can see analytics from the dashboard, including search engine rankings to domain ratings, referring domains, and backlink Jumping from one tool to another is easy. You can use the Keyword Explorer to find a keyword to target and then directly track your ranking with one click. The website offers a tooltip helper tool that allows you to hover your mouse over something that isn't clear and get an in-depth explanation. SEMRUSH When you log into the SEMrush Tool, you will find four main modules. These include information about your domains, organic keyword analysis, ad keyword, and site traffic. You'll also find some other options like A search bar allows you to enter a domain, keyword, or anything else you wish to explore. A menu on the left side of the page provides quick links to relevant information, including marketing insights, projects, keyword analytics, and more. The customer support resources located directly within the dashboard can be used to communicate with the support team or to learn about other resources such as webinars and blogs. Detailed descriptions of every resource offered. This detail is beneficial for new marketers, who are just starting. WHO WINS? Both Ahrefs and SEMrush have user-friendly dashboards, but Ahrefs is less cluttered and easier to navigate. On the other hand, SEMrush offers dozens of extra tools, including access to customer support resources. When deciding on which dashboard to use, consider what you value in the user interface, and test out both. Rank Tracking If you're looking to track your website's search engine ranking, rank tracking features can help. You can also use them to monitor your competitors. Let's take a look at Ahrefs vs. SEMrush to see which tool does a better job. Ahrefs The Ahrefs Rank Tracker is simpler to use. Just type in the domain name and keywords you want to analyze, and it spits out a report showing you the search engine results page (SERP) ranking for each keyword you enter. Rank Tracker looks at the ranking performance of keywords and compares them with the top rankings for those keywords. Ahrefs also offers: You'll see metrics that help you understand your visibility, traffic, average position, and keyword difficulty. It gives you an idea of whether a keyword would be profitable to target or not. SEMRUSH SEMRush offers a tool called Position Tracking. This tool is a project tool—you must set it up as a new project. Below are a few of the most popular features of the SEMrush Position Tracking tool: All subscribers are given regular data updates and mobile search rankings upon subscribing The platform provides opportunities to track several SERP features, including Local tracking. Intuitive reports allow you to track statistics for the pages on your website, as well as the keywords used in those pages. Identify pages that may be competing with each other using the Cannibalization report. WHO WINS? Ahrefs is a more user-friendly option. It takes seconds to enter a domain name and keywords. From there, you can quickly decide whether to proceed with that keyword or figure out how to rank better for other keywords. SEMrush allows you to check your mobile rankings and ranking updates daily, which is something Ahrefs does not offer. SEMrush also offers social media rankings, a tool you won't find within the Ahrefs platform. Both are good which one do you like let me know in the comment. Keyword Research Keyword research is closely related to rank tracking, but it's used for deciding which keywords you plan on using for future content rather than those you use now. When it comes to SEO, keyword research is the most important thing to consider when comparing the two platforms. AHREFS The Ahrefs Keyword Explorer provides you with thousands of keyword ideas and filters search results based on the chosen search engine. Ahrefs supports several features, including: It can search multiple keywords in a single search and analyze them together. At SEMrush, you also have this feature in Keyword Overview. Ahrefs has a variety of keywords for different search engines, including Google, YouTube, Amazon, Bing, Yahoo, Yandex, and other search engines. When you click on a keyword, you can see its search volume and keyword difficulty, but also other keywords related to it, which you didn't use. SEMRUSH SEMrush's Keyword Magic Tool has over 20 billion keywords for Google. You can type in any keyword you want, and a list of suggested keywords will appear. The Keyword Magic Tool also lets you to: Show performance metrics by keyword Search results are based on both broad and exact keyword matches. Show data like search volume, trends, keyword difficulty, and CPC. Show the first 100 Google search results for any keyword. Identify SERP Features and Questions related to each keyword SEMrush has released a new Keyword Gap Tool that uncovers potentially useful keyword opportunities for you, including both paid and organic keywords. WHO WINS? Both of these tools offer keyword research features and allow users to break down complicated tasks into something that can be understood by beginners and advanced users alike. If you're interested in keyword suggestions, SEMrush appears to have more keyword suggestions than Ahrefs does. It also continues to add new features, like the Keyword Gap tool and SERP Questions recommendations. Competitor Analysis Both platforms offer competitor analysis tools, eliminating the need to come up with keywords off the top of your head. Each tool is useful for finding keywords that will be useful for your competition so you know they will be valuable to you. AHREFS Ahrefs' domain comparison tool lets you compare up to five websites (your website and four competitors) side-by-side.it also shows you how your site is ranked against others with metrics such as backlinks, domain ratings, and more. Use the Competing Domains section to see a list of your most direct competitors, and explore how many keywords matches your competitors have. To find more information about your competitor, you can look at the Site Explorer and Content Explorer tools and type in their URL instead of yours. SEMRUSH SEMrush provides a variety of insights into your competitors' marketing tactics. The platform enables you to research your competitors effectively. It also offers several resources for competitor analysis including: Traffic Analytics helps you identify where your audience comes from, how they engage with your site, what devices visitors use to view your site, and how your audiences overlap with other websites. SEMrush's Organic Research examines your website's major competitors and shows their organic search rankings, keywords they are ranking for, and even if they are ranking for any (SERP) features and more. The Market Explorer search field allows you to type in a domain and lists websites or articles similar to what you entered. Market Explorer also allows users to perform in-depth data analytics on These companies and markets. WHO WINS? SEMrush wins here because it has more tools dedicated to competitor analysis than Ahrefs. However, Ahrefs offers a lot of functionality in this area, too. It takes a combination of both tools to gain an advantage over your competition. Pricing Ahrefs Lite Monthly: $99/month Standard Monthly: $179/month Annually Lite: $990/year Annually Standard: $1790/year SEMRUSH Pro Plan: $119.95/month Guru Plan:$229.95/month Business Plan: $449.95/month Which SEO tool should you choose for digital marketing? When it comes to keyword data research, you will become confused about which one to choose. Consider choosing Ahrefs if you Like friendly and clean interface Searching for simple keyword suggestions Want to get more keywords for different search engines like Amazon, Bing, Yahoo, Yandex, Baidu, and more Consider SEMrush if you: Want more marketing and SEO features Need competitor analysis tool Need to keep your backlinks profile clean Looking for more keyword suggestions for Google Both tools are great. Choose the one which meets your requirements and if you have any experience using either Ahrefs or SEMrush let me know in the comment section which works well for you.",
         "en",
         "{'MISC': ['Ahrefs is a leading SEO platform that', 'Ahrefs is a more user-friendly option', 'Ahrefs is less cluttered and easier to navigate', 'Ahrefs takes a bit more of', 'All SEMrush', 'All subscribers are given regular data updates and mobile search rankings upon subscribing', 'Annually Standard', 'At SEMrush', 'Below are a few of the most', 'Both', 'Both Ahrefs and', 'Both are good which one do you like let me know in the', 'Both of these tools', 'Choose the one which meets your requirements and if you have any experience using either Ahrefs or SEMrush let me know in the', 'Comparison Reports', 'Content Audit', 'Content Optimization and', 'Content Template', 'Detailed descriptions of every resource', 'Each tool is useful for finding keywords that will be useful for your competition so you know they will be valuable to you', 'Explorer', 'Features and Questions related to each keyword SEMrush has released', 'From there', 'Get an alert when', 'Google search results for any keyword', 'Google-approved keywords', \"I'm going to help you learn more about these SEO tools and how to choose the one that's best for your purposes\", \"If you're\", 'Intuitive reports allow you to track statistics for the pages on your website', 'It also continues to add new features', 'It also offers several resources for competitor', 'It gives you an idea of whether', 'It takes a combination of both tools to gain an advantage over your competition', 'It takes seconds to enter', 'JavaScript', 'Just type in the domain name and keywords you want to analyze', 'Keyword Magic', 'Keyword Magic tool', 'Keyword Research', 'Largest', \"Let's take\", 'Looking for more keyword suggestions for Google Both tools are great', 'Need to keep your backlinks', 'Post Tracking', 'Pricing', \"Rank Tracking If you're looking to track your website'\", 'SEMRUSH Pro Plan', 'SEMRUSH When you', 'SEMrush', 'SEMrush allows you to check your mobile', 'SEMrush also', 'SEMrush and Ahrefs are among the most popular', 'SEMrush appears to have more keyword suggestions than Ahrefs does', 'SEMrush to see which tool does a better job', 'SEMrush wins here because it has more tools dedicated to competitor analysis than', 'SEO Data Management', \"SEO tool with a wide range of features—it's the leading competitor research service for online marketers\", 'Search results are based on both broad and exact', 'SeoQuake is a small Firefox', 'Show', 'Show data like search volume', 'Show the first 100', 'Some features', 'Standard Monthly', 'The Ahrefs', 'The Ahrefs Rank Tracker is simpler to use', 'The Market Explorer search field allows you to type in a domain and lists websites or articles', \"The Site Explorer will give you an in-depth look at your site'\", 'The platform enables you to research your competitors effectively', 'The website', 'This tool provides all subscribers with basic tracking capabilities', 'To find more information about your competitor', 'Toxic link monitoring and penalty recovery: With SEMrush', 'Traffic Analytics helps you identify where your audience comes from', 'URLs', 'Use the Competing Domains section to see a list of your most direct competitors', 'User Interface Ahrefs and SEMrush both', 'WHO WINS', 'WHO WINS?', 'Want more marketing and SEO features Need competitor', 'Want to get more keywords for different search engines like', 'What is SEMrush?', 'When deciding on which dashboard to use', 'When it comes to keyword data research', 'When you click', 'You can', 'You can also', 'You can see analytics from the dashboard', 'You can use the Keyword', \"You'll see metrics that help you understand your visibility\", 'YouTube', 'also shows you how your site is ranked against others with metrics such as backlinks', 'and', 'and CPC', 'and a list of suggested keywords will appear', 'and backlink Jumping from one tool to another is easy', 'and competitor analysis', 'and explore how many keywords matches your competitors have', 'and it spits out', 'and monitor your niche', 'and outreach to those sites', 'and shows their organic search rankings', 'and test out both', 'and the option to buy additional keywords by default with no additional payment or', 'approach to getting your account fully set up', 'as well as the keywords used in those pages', 'choosing Ahrefs if you', 'each tool to see how they', 'eliminating the need to come up with keywords off the top of your head', 'has', 'including Branded and White Label reports', 'including Google', 'including Local tracking', 'including access to customer support resources', 'including both paid and organic keywords', 'including search engine rankings to domain ratings', 'including: It can search multiple', \"let's take\", 'like the Keyword Gap tool and SERP', 'providing marketers and SEO professionals the largest database of keywords', 'scheduling', 'search and analyze them together', 'the Position Tracking tool', 'the SEO Writing Assistant', 'them with the top rankings for those keywords', 'track your ranking with one click', 'using a tool to help with your efforts', 'what you value in the', 'which is something', 'with a search bar designed', 'you also have this feature in Keyword Overview', 'you can look at the Site', 'you can quickly decide whether to proceed with that', 'you can see its search volume and keyword difficulty', 'you must set it up as', \"your website'\"], 'ORG': ['AHREFS', 'Additional features', 'Amazon', 'Baidu', 'Bing', 'Direct Comparisons', 'GMB', 'Google', 'Guru Plan:$229.95', 'Organic Research', 'SEMRUSH', \"SEMrush'\", 'SERP', 'The company was founded in 2010', 'These', 'Yahoo', 'Yandex', 'and GSC'], 'PER': ['Accurate', 'Brand Monitoring', 'Competitor', 'However', 'Rank Tracker', 'referring domains', 'you will become confused about which one to choose'], 'LOC': ['Ahrefs', 'Annually Lite', \"SEMrush'\", 'trends']}",
         "[-0.03499189019203186, -0.05507257208228111, -0.06477896869182587, 0.06275233626365662, 0.03094484657049179, -0.007092785090208054, 0.011935735121369362, 0.036071572452783585, -0.09707573056221008, -0.06249942258000374, 0.012122162617743015, 0.040253154933452606, 0.06876023858785629, -0.08590981364250183, 0.018373960629105568, 0.008001919835805893, 0.06058048829436302, -0.009253008291125298, 0.019403938204050064, -0.12572740018367767, -0.01264740340411663, 0.02452871762216091, 0.0060271923430264, 0.010317977517843246, -0.07382415980100632, -0.03542149066925049, -0.05910475552082062, 0.04082595929503441, -0.03540747985243797, -0.11158565431833267, 0.030654771253466606, -0.012034285813570023, 0.059832457453012466, 0.03849421814084053, -0.04909088835120201, 0.055015429854393005, -0.05179610475897789, 0.015754731371998787, -0.06003917008638382, 0.031280357390642166, -0.04488570615649223, -0.06009829416871071, -0.1277085393667221, -0.001275495975278318, -0.021077875047922134, -0.020892202854156494, 0.024240827187895775, -0.04258088394999504, 0.0044134799391031265, 0.14205427467823029, -0.10894661396741867, 0.010464087128639221, -0.0506427176296711, 0.057874422520399094, -0.041163504123687744, -0.044796984642744064, -0.05752689018845558, -0.013036329299211502, -0.03772985190153122, -0.04085506871342659, 0.03291068971157074, -0.03811829909682274, -0.009114615619182587, -0.03749842196702957, 0.020807892084121704, -0.028309138491749763, 0.01814352162182331, 0.007995754480361938, -0.005110884550958872, -0.06614036113023758, 0.010917829349637032, -0.031155340373516083, -0.003121346468105912, 0.11133430153131485, -0.07887791842222214, -0.02888769470155239, 0.05278826504945755, -0.026260634884238243, 0.013460338115692139, 0.043344441801309586, -0.02962147444486618, -0.005641805473715067, -0.0443226620554924, 0.07486926019191742, 0.005586540792137384, 0.029234211891889572, 0.022540345788002014, -0.04444802924990654, -0.06318407505750656, 0.0020319614559412003, 0.0866927057504654, -0.08367113023996353, 0.03660626336932182, -0.05811167135834694, 0.03971180319786072, -0.021298881620168686, -0.06955596804618835, -0.009578782133758068, 0.054411742836236954, 0.013957546092569828, -0.031521450728178024, 0.04114169999957085, -0.07390060275793076, -0.12031908333301544, -0.06312581896781921, 0.015799853950738907, -0.03331179916858673, 0.06040460243821144, 0.09586736559867859, 0.05810905247926712, -0.017183098942041397, 0.029287364333868027, -0.05413922294974327, -0.04874425381422043, 0.04631146788597107, -0.000914465228561312, -0.02947862260043621, -0.06663619726896286, 0.07279135286808014, 0.027574842795729637, -0.030159244313836098, 0.07934845238924026, 0.05665558576583862, -0.04356495663523674, -0.027261191979050636, 0.06393228471279144, -0.09662894904613495, 5.9166847762869305e-33, -0.0245076734572649, 0.0936535969376564, -0.022823873907327652, -0.05892353132367134, -0.04914804548025131, -0.018307238817214966, 0.040555842220783234, 0.07458122074604034, -0.1246132031083107, -0.007679539266973734, -0.0022526015527546406, 0.08939016610383987, -0.005897605326026678, 0.03307957202196121, -0.014764832332730293, -0.10998360067605972, 0.018820282071828842, 0.003939061891287565, -0.034721214324235916, -0.04598655551671982, 0.030264511704444885, 0.024712776765227318, 0.06847339123487473, -0.008463069796562195, 0.08079846948385239, -0.07698427140712738, -0.03541451320052147, 0.08002382516860962, 0.016841404139995575, 0.02140953578054905, -0.038216765969991684, -0.027213580906391144, -0.012788954190909863, -0.0570688359439373, 0.006910187192261219, -0.035227518528699875, -0.08541093021631241, -0.08127667754888535, -0.0360531248152256, -0.09708726406097412, -0.09380770474672318, 0.04681175947189331, 0.04377498850226402, -0.0438496395945549, -0.06631680577993393, 0.017207536846399307, -0.0447252131998539, 0.002060029422864318, 0.0848587155342102, 0.024650458246469498, 0.01634911820292473, -0.0759660080075264, 0.018022125586867332, 0.061657290905714035, -0.0916256532073021, 0.09662403166294098, -0.05633724853396416, -0.07581204921007156, 0.013936540111899376, 0.03768712282180786, 0.0029504084959626198, 0.008593869395554066, 0.026960326358675957, -0.019502609968185425, 0.016118723899126053, -0.009284008294343948, 0.029632097110152245, 0.05685653164982796, 0.022910157218575478, 0.012315701693296432, 0.07429028302431107, -0.024185461923480034, 0.028293395414948463, 0.07035546749830246, 0.045358821749687195, -0.06443754583597183, 0.0093093765899539, 0.051993660628795624, -0.010747146792709827, -0.019911574199795723, 0.02003369852900505, -0.008827665820717812, 0.04941144585609436, -0.02341984584927559, 0.009643808007240295, 0.010870693251490593, 0.042858146131038666, -0.058001596480607986, -0.02287079207599163, 0.059697266668081284, -0.03310183808207512, 0.048682212829589844, -0.035242460668087006, 0.023554934188723564, -0.09738762676715851, -6.331017147593016e-33, -0.006472598761320114, -0.0858733132481575, -0.015944795683026314, 0.09976792335510254, -0.013464697636663914, 0.05428122729063034, -0.019893065094947815, 0.023106154054403305, -0.05657890811562538, -0.03616032376885414, 0.005785172339528799, 0.03940682113170624, 0.06521444022655487, -0.031405504792928696, 0.010905493050813675, 0.006150946486741304, 0.05223969370126724, -0.08766219019889832, 0.030074836686253548, 0.033721987158060074, 0.0154110724106431, 0.07013774663209915, -0.10211782902479172, 0.022583957761526108, -0.021938985213637352, -0.017744315788149834, 0.0015837432583793998, -0.04295363277196884, -0.05797236040234566, 0.06035417318344116, -0.03596402704715729, 0.02245098166167736, -0.08306501060724258, -0.021458519622683525, -0.06640908122062683, 0.020886797457933426, -0.008753841742873192, 0.021611526608467102, -0.0031999817583709955, 0.011216952465474606, -0.00011094802903244272, 0.07773557305335999, 0.053099919110536575, -0.06017433479428291, -0.05199579522013664, 0.06600302457809448, -0.10119588673114777, 0.11622995883226395, 0.04375911504030228, 0.031902916729450226, -0.01013039331883192, -0.019220419228076935, -0.005396089982241392, 0.022368639707565308, -0.0020103976130485535, -0.019408531486988068, -0.0841471254825592, 0.009690799750387669, -0.1465120017528534, 0.050450846552848816, 0.016103873029351234, 0.04153113439679146, -0.004049029666930437, 0.02017560787498951, 0.05208565294742584, -0.03756111487746239, -0.008685859851539135, -0.0773228332400322, -0.0708363726735115, -0.04726879671216011, 0.04576323553919792, 0.09114068746566772, 0.04917335882782936, 0.0022931525018066168, -0.07582645863294601, -0.03774501383304596, -0.0012199851917102933, 0.018483353778719902, -0.019231116399168968, -0.0011990144848823547, 0.14201626181602478, 0.06676921993494034, -0.013777660205960274, 0.05410206690430641, -0.004637855105102062, 0.08307939022779465, -0.005353637505322695, 0.07682888209819794, 0.032216887921094894, -0.03613938018679619, -0.010702362284064293, -0.03351370990276337, -0.04107965528964996, 0.06251362711191177, 0.012975094839930534, -5.821494042379527e-08, 0.03848055377602577, -0.024169839918613434, 0.0471571646630764, 0.005801098886877298, -0.03686884790658951, -0.051599401980638504, 0.018238021060824394, 0.05666621774435043, -0.033480897545814514, -0.02204543724656105, 0.11136523634195328, 0.014282803051173687, -0.05848976969718933, 0.06980682909488678, 0.0015493567334488034, -0.027565281838178635, 0.0817265436053276, 0.05625542253255844, 0.018926579505205154, 0.028158128261566162, -0.025031136348843575, 0.03977570682764053, -0.016344605013728142, 0.03902342543005943, 0.1473304182291031, 0.005778279155492783, 0.03105158545076847, -0.006957125850021839, 0.020474860444664955, -0.011734379455447197, 0.0005780732608400285, -0.0025034090504050255, -0.036632366478443146, -0.03999238461256027, 0.062199536710977554, -0.01718645542860031, -0.05059001222252846, 0.014733747579157352, -0.0011644589249044657, 0.08369946479797363, 0.06758540123701096, 0.0792519748210907, 0.04984792694449425, 0.007958060130476952, -0.05684715136885643, 0.03254280611872673, -0.017388785257935524, -0.05108106508851051, 0.02397100441157818, 0.0013295814860612154, -0.0028978525660932064, -0.0029337499290704727, 0.08629065752029419, 0.015661364421248436, 0.008369261398911476, 0.00689004035666585, -0.04485621675848961, 0.0322432704269886, 0.0771397277712822, 0.005126723553985357, 0.10010906308889389, -0.030592886731028557, 0.028631744906306267, 0.07129480689764023]",
         "0.164"
        ],
        [
         "8",
         "574",
         "Automating Ticket Creation in Jira With the OpenAI Agents SDK: A Step-by-Step Guide",
         "Learn how to create AI Agents using the OpenAI Agents SDK to automate Jira ticket creation from a meeting transcript. The post Automating Ticket Creation in Jira With the OpenAI Agents SDK: A Step-by-Step Guide appeared first on Towards Data Science .",
         "What if after finishing a meeting with a colleague you would already have all your discussed items in your project-management tool? No need for writing anything down during the meeting, nor to manually create corresponding tickets! That was the thought of this short experimental project.\n\nIn this step-by-step guide we will create the Python application “TaskPilot” using OpenAI’s Agents SDK to automatically create Jira issues given a meeting transcript.\n\nThe Challenge: From Conversation to Actionable Tasks\n\nGiven the transcript of a meeting, create issues in a Jira project automatically and corresponding to what was discussed in the meeting.\n\nThe Solution: Automating with OpenAI Agents\n\nUsing the OpenAI Agents SDK we will implement an agents workflow that:\n\nReceives and reads a meeting transcript. Uses an AI agent to extract action items from the conversation. Uses another AI agent to create Jira issues from those action items.\n\nAgent flow: Image created by the author\n\nThe OpenAI Agents SDK\n\nThe OpenAI Agents SDK is a Python library to create AI agents programmatically that can interact with tools, use MCP-Servers or hand off tasks to other agents.\n\nHere are some of the key features of the SDK:\n\nAgent Loop: A built-in agent loop that handles the back-and-forth communication with the LLM until the agent is done with its task.\n\nA built-in agent loop that handles the back-and-forth communication with the LLM until the agent is done with its task. Function Tools: Turns any Python function into a tool, with automatic schema generation and Pydantic-powered validation.\n\nTurns any Python function into a tool, with automatic schema generation and Pydantic-powered validation. MCP Support : Allows agents to use MCP servers to extend its capabilities of interacting with the outside world.\n\n: Allows agents to use MCP servers to extend its capabilities of interacting with the outside world. Handoffs: Allows agents to delegate tasks to other agents depending on their expertise/role.\n\nAllows agents to delegate tasks to other agents depending on their expertise/role. Guardrails : Validates the inputs and outputs of the agents. Aborts execution early if the agent receives invalid input.\n\n: Validates the inputs and outputs of the agents. Aborts execution early if the agent receives invalid input. Sessions: Automatically manages the conversation history. Ensures that the agents have the context they need to perform their tasks.\n\nAutomatically manages the conversation history. Ensures that the agents have the context they need to perform their tasks. Tracing: Provides a tracing context manager which allows to visualize the entire execution flow of the agents, making it easy to debug and understand what’s happening under the hood.\n\nNow, let’s dive into the implementation!\n\nImplementation\n\nWe will implement our project in 8 simple steps:\n\nLet’s get hands on!\n\nStep 1: Setting Up the Project Structure\n\nFirst, let’s create the basic structure of our project:\n\nThe taskpilot directory: will contain our main application logic.\n\ndirectory: will contain our main application logic. The local_agents directory: will contain where we define the agents we will use in this project (“local_agents” so that there is no interference with the OpenAI library agents )\n\ndirectory: will contain where we define the agents we will use in this project (“local_agents” so that there is no interference with the OpenAI library ) The utils directory: for helper functions, a config parser and data models.\n\ntaskpilot_repo/ ├── config.yml ├── .env ├── README.md ├── taskpilot/ │ ├── main.py │ ├── taskpilot_runner.py │ ├── local_agents/ │ │ ├── __init__.py │ │ ├── action_items_extractor.py │ │ └── tickets_creator.py │ └── utils/ │ ├── __init__.py │ ├── agents_tools.py │ ├── config_parser.py │ ├── jira_interface_functions.py │ └── models.py\n\nStep 2: The TaskPilotRunner\n\nThe TaskPilotRunner class in taskpilot/taskpilot_runner.py will be the heart of our application. It will orchestrate the entire workflow, extracting action items from the meeting transcript and then creating the Jira tickets from the action items. At the same time it will activate the built-in tracing from the Agents SDK to collect a record of events during the agents run that will help for debugging and monitoring the agent workflows.\n\nLet’s start with the implementation:\n\nIn the __init__() method we will create the two agents used for this workflow.\n\nmethod we will create the two agents used for this workflow. The run() method will be the most important of the TaskPilotRunner class, which will receive the meeting transcript and pass it to the agents to create the Jira issues. The agents will be started and run within a trace context manager i.e. with trace(\"TaskPilot run\", trace_id): . A trace from the Agents SDK represents a single end-to-end operation of a “workflow”.\n\nmethod will be the most important of the class, which will receive the meeting transcript and pass it to the agents to create the Jira issues. The agents will be started and run within a i.e. . A trace from the Agents SDK represents a single end-to-end operation of a “workflow”. The _extract_action_items() and _create_tickets() methods will start and run each of the agents respectively. Within these methods the Runner.run() method from the OpenAI Agents SDK will be used to trigger the agents. It takes an agent and an input, and it returns the final output of the agent’s execution. Finally, the result of each agent will be parsed to its defined output type.\n\n# taskpilot/taskpilot_runner.py from agents import Runner, trace, gen_trace_id from local_agents import create_action_items_agent, create_tickets_creator_agent from utils.models import ActionItemsList, CreateIssuesResponse class TaskPilotRunner: def __init__(self): self.action_items_extractor = create_action_items_agent() self.tickets_creator = create_tickets_creator_agent() async def run(self, meeting_transcript: str) -> None: trace_id = gen_trace_id() print(f\"Starting TaskPilot run... (Trace ID: {trace_id})\") print( f\"View trace: https://platform.openai.com/traces/trace?trace_id={trace_id}\" ) with trace(\"TaskPilot run\", trace_id=trace_id): # 1. Extract action items from meeting transcript action_items = await self._extract_action_items(meeting_transcript) # 2. Create tickets from action items tickets_creation_response = await self._create_tickets(action_items) # 3. Return the results print(tickets_creation_response.text) async def _extract_action_items(self, meeting_transcript: str) -> ActionItemsList: result = await Runner.run( self.action_items_extractor, input=meeting_transcript ) final_output = result.final_output_as(ActionItemsList) return final_output async def _create_tickets(self, action_items: ActionItemsList) -> CreateIssuesResponse: result = await Runner.run( self.tickets_creator, input=str(action_items) ) final_output = result.final_output_as(CreateIssuesResponse) return final_output\n\nThe three methods are defined as asynchronous functions. The reason for this is that the Runner.run() method from the OpenAI Agents SDK is defined itself as an async coroutine. This allows multiple agents, tool calls, or streaming endpoints to run in parallel without blocking.\n\nStep 3: Defining Our Data Models\n\nWithout specific configuration agents return text in str as output. To ensure that our agents provide structured and predictable responses, the library supports the use of Pydantic models for defining the output_type of the agents (it actually supports any type that can be wrapped in a Pydantic TypeAdapter — dataclasses, lists, TypedDict, etc.). The data-models we define will be the data structures that our agents will work with.\n\nFor our usecase we will define three models in taskpilot/utils/models.py :\n\nActionItem : This model represents a single action item that is extracted from the meeting transcript.\n\nThis model represents a single action item that is extracted from the meeting transcript. ActionItemsList : This model is a list of ActionItem objects.\n\nThis model is a list of objects. CreateIssuesResponse : This model defines the structure of the response from the agent that will create the issues/tickets.\n\n# taskpilot/utils/models.py from typing import Optional from pydantic import BaseModel class ActionItem(BaseModel): title: str description: str assignee: str status: str issuetype: str project: Optional[str] = None due_date: Optional[str] = None start_date: Optional[str] = None priority: Optional[str] = None parent: Optional[str] = None children: Optional[list[str]] = None class ActionItemsList(BaseModel): action_items: list[ActionItem] class CreateIssuesResponse(BaseModel): action_items: list[ActionItem] error_messages: list[str] success_messages: list[str] text: str\n\nStep 4: Creating the Agents\n\nThe agents are the core of our application. Agents are basically an LLM configured with instructions (the AGENT_PROMPT ) and access to tools for them to act on its own on defined tasks. An agent from the OpenAI Agents SDK is defined by the following parameters:\n\nname : The name of the agent for identification.\n\nThe name of the agent for identification. instructions : The prompt to tell the agent its role or task it shall execute (aka. system prompt).\n\nThe prompt to tell the agent its role or task it shall execute (aka. system prompt). model : Which LLM to use for the agent. The SDK provides out-of-the-box support for OpenAI models, however you can also use non-OpenAI models (see Agents SDK: Models).\n\nWhich LLM to use for the agent. The SDK provides out-of-the-box support for OpenAI models, however you can also use non-OpenAI models (see Agents SDK: Models). output_type : Python object that the agent shall returned, as mentioned previously.\n\nPython object that the agent shall returned, as mentioned previously. tools : A list of python callables, that will be the tools that the agent can use to perform its tasks.\n\nBased on this information, let’s create our two agents: the ActionItemsExtractor and the TicketsCreator .\n\nAction Items Extractor\n\nThis agent’s job is to read the meeting transcript and extract the action items. We’ll create it in taskpilot/local_agents/action_items_extractor.py .\n\n# taskpilot/local_agents/action_items_extractor.py from agents import Agent from utils.config_parser import Config from utils.models import ActionItemsList AGENT_PROMPT = \"\"\" Your are an assistant to extract action items from a meeting transcript. You will be given a meeting transcript and you need to extract the action items so that they can be converted into tickets by another assistant. The action items should contain the following information: - title: The title of the action item. It should be a short description of the action item. It should be short and concise. This is mandatory. - description: The description of the action item. It should be a more extended description of the action item. This is mandatory. - assignee: The name of the person who will be responsible for the action item. You shall infer from the conversation the name of the assignee and not use \"Speaker 1\" or \"Speaker 2\" or any other speaker identifier. This is mandatory. - status: The status of the action item. It can be \"To Do\", \"In Progress\", \"In Review\" or \"Done\". You shall extract from the transcript in which state the action item is. If it is a new action item, you shall set it to \"To Do\". - due_date: The due date of the action item. It shall be in the format \"YYYY-MM-DD\". You shall extract this from the transcript, however if it is not explicitly mentioned, you shall set it to None. If relative dates are mentioned (eg. by tomorrow, in a week,...), you shall convert them to absolute dates in the format \"YYYY-MM-DD\". - start_date: The start date of the action item. It shall be in the format \"YYYY-MM-DD\". You shall extract this from the transcript, however if it is not explicitly mentioned, you shall set it to None. - priority: The priority of the action item. It can be \"Lowest\", \"Low\", \"Medium\", \"High\" or \"Highest\". You shall interpret the priority of the action item from the transcript, however if it is not clear, you shall set it to None. - issuetype: The type of the action item. It can be \"Epic\", \"Bug\", \"Task\", \"Story\", \"Subtask\". You shall interpret the issuetype of the action item from the transcript, if it is unclear set it to \"Task\". - project: The project to which the action item belongs. You shall interpret the project of the action item from the transcript, however if it is not clear, you shall set it to None. - parent: If the action item is a subtask, you shall set the parent of the action item to the title of the parent action item. If the parent action item is not clear or the action item is not a subtask, you shall set it to None. - children: If the action item is a parent task, you shall set the children of the action item to the titles of the child action items. If the children action items are not clear or the action item is not a parent task, you shall set it to None. \"\"\" def create_action_items_agent() -> Agent: return Agent( name=\"Action Items Extractor\", instructions=AGENT_PROMPT, output_type=ActionItemsList, model=Config.get().agents.model, )\n\nAs you can see, in the AGENT_PROMPT we tell the agent very detailed that its job is to extract action items and provide a detailed description of how we want the action items to be extracted.\n\nTickets Creator\n\nThis agent takes the list of action items and creates Jira issues. We’ll create it in taskpilot/local_agents/tickets_creator.py .\n\n# taskpilot/local_agents/tickets_creator.py from agents import Agent from utils.config_parser import Config from utils.agents_tools import create_jira_issue from utils.models import CreateIssuesResponse AGENT_PROMPT = \"\"\" You are an assistant that creates Jira issues given action items. You will be given a list of action items and for each action item you shall create a Jira issue using the `create_jira_issue` tool. You shall collect the responses of the `create_jira_issue` tool and return them as the provided type `CreateIssuesResponse` which contains: - action_items: list containing the action_items that were provided to you - error_messages: list containing the error messages returned by the `create_jira_issue` tool whenever there was an error trying to create the issue. - success_messages: list containing the response messages returned by the `create_jira_issue` tool whenever the issue creation was successful. - text: A text that summarizes the result of the tickets creation. It shall be a string created as following: f\"From the {len(action_items)} action items provided {len(success_messages)} were successfully created in the Jira project.\n\n{len(error_messages)} failed to be created in the Jira project.\n\n\n\nError messages:\n\n{error_messages}\" \"\"\" def create_tickets_creator_agent() -> Agent: return Agent( name=\"Tickets Creator\", instructions=AGENT_PROMPT, tools=[create_jira_issue], model=Config.get().agents.model, output_type=CreateIssuesResponse )\n\nHere we set the tools parameter and give the agent the create_jira_issue tool, which we’ll create in the next step.\n\nStep 5: Providing Tools\n\nOne of the most powerful features of agents is their ability to use tools to interact with the outside world. One could argue that the use of tools is what turns the interaction with an LLM into an agent. The OpenAI Agents SDK allows the agents to use three types of tools:\n\nHosted tools : Provided directly from OpenAI such as searching the web or files, computer use, running code, among others.\n\n: Provided directly from OpenAI such as searching the web or files, computer use, running code, among others. Function calling : Using any Python function as a tool.\n\n: Using any Python function as a tool. Agents as tools: Allowing agents to call other agents without handing off.\n\nFor our usecase, we will be using function calling and implement a function to create the Jira issues using Jira’s REST API. By personal choice, I decided to separate it in two files:\n\nIn taskpilot/utils/jira_interface_functions.py we will write the functions to interact through HTTP Requests with the Jira REST API.\n\nwe will write the functions to interact through HTTP Requests with the Jira REST API. In taskpilot/utils/agents_tools.py we will write wrappers of the functions to be provided to the agents. These wrapper-functions have additional response parsing to provide the agent a processed text response instead of a JSON. Nevertheless, the agent should also be able to handle and understand JSON as response.\n\nFirst we implement the create_issue() function in taskpilot/utils/jira_interface_functions.py :\n\n# taskpilot/utils/jira_interface_functions.py import os from typing import Optional import json from urllib.parse import urljoin import requests from requests.auth import HTTPBasicAuth from utils.config_parser import Config JIRA_AUTH = HTTPBasicAuth(Config.get().jira.user, str(os.getenv(\"ATLASSIAN_API_KEY\"))) def create_issue( project_key: str, title: str, description: str, issuetype: str, duedate: Optional[str] = None, assignee_id: Optional[str] = None, labels: Optional[list[str]] = None, priority_id: Optional[str] = None, reporter_id: Optional[str] = None, ) -> requests.Response: payload = { \"fields\": { \"project\": {\"key\": project_key}, \"summary\": title, \"issuetype\": {\"name\": issuetype}, \"description\": { \"content\": [ { \"content\": [ { \"text\": description, \"type\": \"text\", } ], \"type\": \"paragraph\", } ], \"type\": \"doc\", \"version\": 1, }, } } if duedate: payload[\"fields\"].update({\"duedate\": duedate}) if assignee_id: payload[\"fields\"].update({\"assignee\": {\"id\": assignee_id}}) if labels: payload[\"fields\"].update({\"labels\": labels}) if priority_id: payload[\"fields\"].update({\"priority\": {\"id\": priority_id}}) if reporter_id: payload[\"fields\"].update({\"reporter\": {\"id\": reporter_id}}) endpoint_url = urljoin(Config.get().jira.url_rest_api, \"issue\") headers = {\"Accept\": \"application/json\", \"Content-Type\": \"application/json\"} response = requests.post( endpoint_url, data=json.dumps(payload), headers=headers, auth=JIRA_AUTH, timeout=Config.get().jira.request_timeout, ) return response\n\nAs you can see, we need to authenticate to our Jira account using our Jira user and a corresponding API_KEY that we can obtain on Atlassian Account Management.\n\nIn taskpilot/utils/agents_tools.py we implement the create_jira_issue() function, that we will then provide to the TicketsCreator agent:\n\n# taskpilot/utils/agents_tools.py from agents import function_tool from utils.models import ActionItem from utils.jira_interface_functions import create_issue @function_tool def create_jira_issue(action_item: ActionItem) -> str: response = create_issue( project_key=action_item.project, title=action_item.title, description=action_item.description, issuetype=action_item.issuetype, duedate=action_item.due_date, assignee_id=None, labels=None, priority_id=None, reporter_id=None, ) if response.ok: return f\"Successfully created the issue. Response message: {response.text}\" else: return f\"There was an error trying to create the issue. Error message: {response.text}\"\n\nVery important: The @function_tool decorator is what makes this function usable for our agent. The agent can now call this function and pass it an ActionItem object. The function then uses the create_issue function which accesses the Jira API to create a new issue.\n\nStep 6: Configuring the Application\n\nTo make our application parametrizable, we’ll use a config.yml file for the configuration settings, as well as a .env file for the API keys.\n\nThe configuration of the application is separated in:\n\nagents : To configure the agents and the access to the OpenAI API. Here we have two parameters: model , which is the LLM that shall be used by the agents, and OPENAI_API_KEY , in the .env file, to authenticate the use of the OpenAI API. You can obtain an OpenAI API Key in your OpenAI Dev Platform.\n\n: To configure the agents and the access to the OpenAI API. Here we have two parameters: , which is the LLM that shall be used by the agents, and , in the file, to authenticate the use of the OpenAI API. You can obtain an OpenAI API Key in your OpenAI Dev Platform. jira : To configure the access to the Jira API. Here we need four parameters: url_rest_api , which is the URL to the REST API of our Jira instance; user , which is the user we use to access Jira; request_timeout , which is the timeout in seconds to wait for the server to send data before giving up, and finally ATLASSIAN_API_KEY , in the .env file, to authenticate to your Jira instance.\n\nHere is our .env file, that in the next step will be loaded to our application in the main.py using the python-dotenv library:\n\nOPENAI_API_KEY=some-api-key ATLASSIAN_API_KEY=some-api-key\n\nAnd here is our config.yml file:\n\nWe’ll also create a config parser at taskpilot/utils/config_parser.py to load this configuration. For this we implement the Config class as a singleton (meaning there can only be one instance of this class throughout the application lifespan).\n\n# taskpilot/utils/config_parser.py from pathlib import Path import yaml from pydantic import BaseModel class AgentsConfig(BaseModel): model: str class JiraConfig(BaseModel): url_rest_api: str user: str request_timeout: int class ConfigModel(BaseModel): agents: AgentsConfig jira: JiraConfig class Config: _instance: ConfigModel | None = None @classmethod def load(cls, path: str = \"config.yml\") -> None: if cls._instance is None: with open(Path(path), \"r\", encoding=\"utf-8\") as config_file: raw_config = yaml.safe_load(config_file) cls._instance = ConfigModel(**raw_config) @classmethod def get(cls, path: str = \"config.yml\") -> ConfigModel: if cls._instance is None: cls.load(path) return cls._instance\n\nStep 7: Bringing It All Together in main.py\n\nFinally, in taskpilot/main.py , we’ll bring everything together. This script will load the meeting transcript, create an instance of the TaskPilotRunner , and then call the run() method.\n\n# taskpilot/main.py import os import asyncio from dotenv import load_dotenv from taskpilot_runner import TaskPilotRunner # Load the variables in the .env file load_dotenv() def load_meeting_transcript_txt(file_path: str) -> str: # ... return meeting_transcript async def main(): print(\"TaskPilot application starting...\") meeting_transcript = load_meeting_transcript_txt(\"meeting_transcript.txt\") await TaskPilotRunner().run(meeting_transcript) if __name__ == \"__main__\": asyncio.run(main())\n\nStep 8: Monitoring Our Runs in the OpenAI Dev Platform\n\nAs mentioned, one of the advantages of the OpenAI Agents SDK is that, due to its tracing feature, it is possible to visualize the entire execution flow of our agents. This makes it easy to debug and understand what’s happening under the hood in the OpenAI Dev Platform.\n\nIn the Traces Dashboard one can:\n\nTrack each run of the agents workflow.\n\nScreenshot by the author\n\nUnderstand exactly what the agents did within the agent workflow and monitor performance.\n\nScreenshot by the author\n\nDebug every call to the OpenAI API as well as monitor how many tokens were used in each input and output.\n\nScreenshot by the author\n\nSo take advantage of this feature to evaluate, debug and monitor your agent runs.\n\nConclusion\n\nAnd that’s it! In this eight simple steps we have implemented an application that can automatically create Jira issues from a meeting transcript. Thanks to the simple interface of the OpenAI Agents SDK you can easily create agents programmatically to help you automatize your tasks!\n\nFeel free to clone the repository (the project as described in this post is in branch function_calling ), try it out for yourself, and start building your own AI-powered applications!\n\n💡 Coming Up Next:\n\nIn an upcoming post, we’ll dive into how to implement your own MCP Server to further extend our agents’ capabilities and allow them to interact with external systems beyond your local tools. Stay tuned!\n\n🙋‍♂️ Let’s Connect\n\nIf you have questions, feedback, or just want to follow along with future projects:\n\nReference\n\nThis article is inspired by the “OpenAI: Agents SDK” course from LinkedinLearning.",
         "2025-07-24T18:51:54",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/automating-ticket-creation-in-jira-with-the-openai-agents-sdk-a-step-by-step-guide/",
         "2025-07-26T06:23:31.317458",
         "What if after finishing a meeting with a colleague you would already have all your discussed items in your project-management tool? No need for writing anything down during the meeting, nor to manually create corresponding tickets! That was the thought of this short experimental project. In this step-by-step guide we will create the Python application “TaskPilot” using OpenAI’s Agents SDK to automatically create Jira issues given a meeting transcript. The Challenge: From Conversation to Actionable Tasks Given the transcript of a meeting, create issues in a Jira project automatically and corresponding to what was discussed in the meeting. The Solution: Automating with OpenAI Agents Using the OpenAI Agents SDK we will implement an agents workflow that: Receives and reads a meeting transcript. Uses an AI agent to extract action items from the conversation. Uses another AI agent to create Jira issues from those action items. Agent flow: Image created by the author The OpenAI Agents SDK The OpenAI Agents SDK is a Python library to create AI agents programmatically that can interact with tools, use MCP-Servers or hand off tasks to other agents. Here are some of the key features of the SDK: Agent Loop: A built-in agent loop that handles the back-and-forth communication with the LLM until the agent is done with its task. A built-in agent loop that handles the back-and-forth communication with the LLM until the agent is done with its task. Function Tools: Turns any Python function into a tool, with automatic schema generation and Pydantic-powered validation. Turns any Python function into a tool, with automatic schema generation and Pydantic-powered validation. MCP Support : Allows agents to use MCP servers to extend its capabilities of interacting with the outside world. : Allows agents to use MCP servers to extend its capabilities of interacting with the outside world. Handoffs: Allows agents to delegate tasks to other agents depending on their expertise/role. Allows agents to delegate tasks to other agents depending on their expertise/role. Guardrails : Validates the inputs and outputs of the agents. Aborts execution early if the agent receives invalid input. : Validates the inputs and outputs of the agents. Aborts execution early if the agent receives invalid input. Sessions: Automatically manages the conversation history. Ensures that the agents have the context they need to perform their tasks. Automatically manages the conversation history. Ensures that the agents have the context they need to perform their tasks. Tracing: Provides a tracing context manager which allows to visualize the entire execution flow of the agents, making it easy to debug and understand what’s happening under the hood. Now, let’s dive into the implementation! Implementation We will implement our project in 8 simple steps: Let’s get hands on! Step 1: Setting Up the Project Structure First, let’s create the basic structure of our project: The taskpilot directory: will contain our main application logic. directory: will contain our main application logic. The local_agents directory: will contain where we define the agents we will use in this project (“local_agents” so that there is no interference with the OpenAI library agents ) directory: will contain where we define the agents we will use in this project (“local_agents” so that there is no interference with the OpenAI library ) The utils directory: for helper functions, a config parser and data models. taskpilot_repo/ ├── config.yml ├── .env ├── README.md ├── taskpilot/ │ ├── main.py │ ├── taskpilot_runner.py │ ├── local_agents/ │ │ ├── __init__.py │ │ ├── action_items_extractor.py │ │ └── tickets_creator.py │ └── utils/ │ ├── __init__.py │ ├── agents_tools.py │ ├── config_parser.py │ ├── jira_interface_functions.py │ └── models.py Step 2: The TaskPilotRunner The TaskPilotRunner class in taskpilot/taskpilot_runner.py will be the heart of our application. It will orchestrate the entire workflow, extracting action items from the meeting transcript and then creating the Jira tickets from the action items. At the same time it will activate the built-in tracing from the Agents SDK to collect a record of events during the agents run that will help for debugging and monitoring the agent workflows. Let’s start with the implementation: In the __init__() method we will create the two agents used for this workflow. method we will create the two agents used for this workflow. The run() method will be the most important of the TaskPilotRunner class, which will receive the meeting transcript and pass it to the agents to create the Jira issues. The agents will be started and run within a trace context manager i.e. with trace(\"TaskPilot run\", trace_id): . A trace from the Agents SDK represents a single end-to-end operation of a “workflow”. method will be the most important of the class, which will receive the meeting transcript and pass it to the agents to create the Jira issues. The agents will be started and run within a i.e. . A trace from the Agents SDK represents a single end-to-end operation of a “workflow”. The _extract_action_items() and _create_tickets() methods will start and run each of the agents respectively. Within these methods the Runner.run() method from the OpenAI Agents SDK will be used to trigger the agents. It takes an agent and an input, and it returns the final output of the agent’s execution. Finally, the result of each agent will be parsed to its defined output type. # taskpilot/taskpilot_runner.py from agents import Runner, trace, gen_trace_id from local_agents import create_action_items_agent, create_tickets_creator_agent from utils.models import ActionItemsList, CreateIssuesResponse class TaskPilotRunner: def __init__(self): self.action_items_extractor = create_action_items_agent() self.tickets_creator = create_tickets_creator_agent() async def run(self, meeting_transcript: str) -> None: trace_id = gen_trace_id() print(f\"Starting TaskPilot run... (Trace ID: {trace_id})\") print( f\"View trace: https://platform.openai.com/traces/trace?trace_id={trace_id}\" ) with trace(\"TaskPilot run\", trace_id=trace_id): # 1. Extract action items from meeting transcript action_items = await self._extract_action_items(meeting_transcript) # 2. Create tickets from action items tickets_creation_response = await self._create_tickets(action_items) # 3. Return the results print(tickets_creation_response.text) async def _extract_action_items(self, meeting_transcript: str) -> ActionItemsList: result = await Runner.run( self.action_items_extractor, input=meeting_transcript ) final_output = result.final_output_as(ActionItemsList) return final_output async def _create_tickets(self, action_items: ActionItemsList) -> CreateIssuesResponse: result = await Runner.run( self.tickets_creator, input=str(action_items) ) final_output = result.final_output_as(CreateIssuesResponse) return final_output The three methods are defined as asynchronous functions. The reason for this is that the Runner.run() method from the OpenAI Agents SDK is defined itself as an async coroutine. This allows multiple agents, tool calls, or streaming endpoints to run in parallel without blocking. Step 3: Defining Our Data Models Without specific configuration agents return text in str as output. To ensure that our agents provide structured and predictable responses, the library supports the use of Pydantic models for defining the output_type of the agents (it actually supports any type that can be wrapped in a Pydantic TypeAdapter — dataclasses, lists, TypedDict, etc.). The data-models we define will be the data structures that our agents will work with. For our usecase we will define three models in taskpilot/utils/models.py : ActionItem : This model represents a single action item that is extracted from the meeting transcript. This model represents a single action item that is extracted from the meeting transcript. ActionItemsList : This model is a list of ActionItem objects. This model is a list of objects. CreateIssuesResponse : This model defines the structure of the response from the agent that will create the issues/tickets. # taskpilot/utils/models.py from typing import Optional from pydantic import BaseModel class ActionItem(BaseModel): title: str description: str assignee: str status: str issuetype: str project: Optional[str] = None due_date: Optional[str] = None start_date: Optional[str] = None priority: Optional[str] = None parent: Optional[str] = None children: Optional[list[str]] = None class ActionItemsList(BaseModel): action_items: list[ActionItem] class CreateIssuesResponse(BaseModel): action_items: list[ActionItem] error_messages: list[str] success_messages: list[str] text: str Step 4: Creating the Agents The agents are the core of our application. Agents are basically an LLM configured with instructions (the AGENT_PROMPT ) and access to tools for them to act on its own on defined tasks. An agent from the OpenAI Agents SDK is defined by the following parameters: name : The name of the agent for identification. The name of the agent for identification. instructions : The prompt to tell the agent its role or task it shall execute (aka. system prompt). The prompt to tell the agent its role or task it shall execute (aka. system prompt). model : Which LLM to use for the agent. The SDK provides out-of-the-box support for OpenAI models, however you can also use non-OpenAI models (see Agents SDK: Models). Which LLM to use for the agent. The SDK provides out-of-the-box support for OpenAI models, however you can also use non-OpenAI models (see Agents SDK: Models). output_type : Python object that the agent shall returned, as mentioned previously. Python object that the agent shall returned, as mentioned previously. tools : A list of python callables, that will be the tools that the agent can use to perform its tasks. Based on this information, let’s create our two agents: the ActionItemsExtractor and the TicketsCreator . Action Items Extractor This agent’s job is to read the meeting transcript and extract the action items. We’ll create it in taskpilot/local_agents/action_items_extractor.py . # taskpilot/local_agents/action_items_extractor.py from agents import Agent from utils.config_parser import Config from utils.models import ActionItemsList AGENT_PROMPT = \"\"\" Your are an assistant to extract action items from a meeting transcript. You will be given a meeting transcript and you need to extract the action items so that they can be converted into tickets by another assistant. The action items should contain the following information: - title: The title of the action item. It should be a short description of the action item. It should be short and concise. This is mandatory. - description: The description of the action item. It should be a more extended description of the action item. This is mandatory. - assignee: The name of the person who will be responsible for the action item. You shall infer from the conversation the name of the assignee and not use \"Speaker 1\" or \"Speaker 2\" or any other speaker identifier. This is mandatory. - status: The status of the action item. It can be \"To Do\", \"In Progress\", \"In Review\" or \"Done\". You shall extract from the transcript in which state the action item is. If it is a new action item, you shall set it to \"To Do\". - due_date: The due date of the action item. It shall be in the format \"YYYY-MM-DD\". You shall extract this from the transcript, however if it is not explicitly mentioned, you shall set it to None. If relative dates are mentioned (eg. by tomorrow, in a week,...), you shall convert them to absolute dates in the format \"YYYY-MM-DD\". - start_date: The start date of the action item. It shall be in the format \"YYYY-MM-DD\". You shall extract this from the transcript, however if it is not explicitly mentioned, you shall set it to None. - priority: The priority of the action item. It can be \"Lowest\", \"Low\", \"Medium\", \"High\" or \"Highest\". You shall interpret the priority of the action item from the transcript, however if it is not clear, you shall set it to None. - issuetype: The type of the action item. It can be \"Epic\", \"Bug\", \"Task\", \"Story\", \"Subtask\". You shall interpret the issuetype of the action item from the transcript, if it is unclear set it to \"Task\". - project: The project to which the action item belongs. You shall interpret the project of the action item from the transcript, however if it is not clear, you shall set it to None. - parent: If the action item is a subtask, you shall set the parent of the action item to the title of the parent action item. If the parent action item is not clear or the action item is not a subtask, you shall set it to None. - children: If the action item is a parent task, you shall set the children of the action item to the titles of the child action items. If the children action items are not clear or the action item is not a parent task, you shall set it to None. \"\"\" def create_action_items_agent() -> Agent: return Agent( name=\"Action Items Extractor\", instructions=AGENT_PROMPT, output_type=ActionItemsList, model=Config.get().agents.model, ) As you can see, in the AGENT_PROMPT we tell the agent very detailed that its job is to extract action items and provide a detailed description of how we want the action items to be extracted. Tickets Creator This agent takes the list of action items and creates Jira issues. We’ll create it in taskpilot/local_agents/tickets_creator.py . # taskpilot/local_agents/tickets_creator.py from agents import Agent from utils.config_parser import Config from utils.agents_tools import create_jira_issue from utils.models import CreateIssuesResponse AGENT_PROMPT = \"\"\" You are an assistant that creates Jira issues given action items. You will be given a list of action items and for each action item you shall create a Jira issue using the `create_jira_issue` tool. You shall collect the responses of the `create_jira_issue` tool and return them as the provided type `CreateIssuesResponse` which contains: - action_items: list containing the action_items that were provided to you - error_messages: list containing the error messages returned by the `create_jira_issue` tool whenever there was an error trying to create the issue. - success_messages: list containing the response messages returned by the `create_jira_issue` tool whenever the issue creation was successful. - text: A text that summarizes the result of the tickets creation. It shall be a string created as following: f\"From the {len(action_items)} action items provided {len(success_messages)} were successfully created in the Jira project. {len(error_messages)} failed to be created in the Jira project. Error messages: {error_messages}\" \"\"\" def create_tickets_creator_agent() -> Agent: return Agent( name=\"Tickets Creator\", instructions=AGENT_PROMPT, tools=[create_jira_issue], model=Config.get().agents.model, output_type=CreateIssuesResponse ) Here we set the tools parameter and give the agent the create_jira_issue tool, which we’ll create in the next step. Step 5: Providing Tools One of the most powerful features of agents is their ability to use tools to interact with the outside world. One could argue that the use of tools is what turns the interaction with an LLM into an agent. The OpenAI Agents SDK allows the agents to use three types of tools: Hosted tools : Provided directly from OpenAI such as searching the web or files, computer use, running code, among others. : Provided directly from OpenAI such as searching the web or files, computer use, running code, among others. Function calling : Using any Python function as a tool. : Using any Python function as a tool. Agents as tools: Allowing agents to call other agents without handing off. For our usecase, we will be using function calling and implement a function to create the Jira issues using Jira’s REST API. By personal choice, I decided to separate it in two files: In taskpilot/utils/jira_interface_functions.py we will write the functions to interact through HTTP Requests with the Jira REST API. we will write the functions to interact through HTTP Requests with the Jira REST API. In taskpilot/utils/agents_tools.py we will write wrappers of the functions to be provided to the agents. These wrapper-functions have additional response parsing to provide the agent a processed text response instead of a JSON. Nevertheless, the agent should also be able to handle and understand JSON as response. First we implement the create_issue() function in taskpilot/utils/jira_interface_functions.py : # taskpilot/utils/jira_interface_functions.py import os from typing import Optional import json from urllib.parse import urljoin import requests from requests.auth import HTTPBasicAuth from utils.config_parser import Config JIRA_AUTH = HTTPBasicAuth(Config.get().jira.user, str(os.getenv(\"ATLASSIAN_API_KEY\"))) def create_issue( project_key: str, title: str, description: str, issuetype: str, duedate: Optional[str] = None, assignee_id: Optional[str] = None, labels: Optional[list[str]] = None, priority_id: Optional[str] = None, reporter_id: Optional[str] = None, ) -> requests.Response: payload = { \"fields\": { \"project\": {\"key\": project_key}, \"summary\": title, \"issuetype\": {\"name\": issuetype}, \"description\": { \"content\": [ { \"content\": [ { \"text\": description, \"type\": \"text\", } ], \"type\": \"paragraph\", } ], \"type\": \"doc\", \"version\": 1, }, } } if duedate: payload[\"fields\"].update({\"duedate\": duedate}) if assignee_id: payload[\"fields\"].update({\"assignee\": {\"id\": assignee_id}}) if labels: payload[\"fields\"].update({\"labels\": labels}) if priority_id: payload[\"fields\"].update({\"priority\": {\"id\": priority_id}}) if reporter_id: payload[\"fields\"].update({\"reporter\": {\"id\": reporter_id}}) endpoint_url = urljoin(Config.get().jira.url_rest_api, \"issue\") headers = {\"Accept\": \"application/json\", \"Content-Type\": \"application/json\"} response = requests.post( endpoint_url, data=json.dumps(payload), headers=headers, auth=JIRA_AUTH, timeout=Config.get().jira.request_timeout, ) return response As you can see, we need to authenticate to our Jira account using our Jira user and a corresponding API_KEY that we can obtain on Atlassian Account Management. In taskpilot/utils/agents_tools.py we implement the create_jira_issue() function, that we will then provide to the TicketsCreator agent: # taskpilot/utils/agents_tools.py from agents import function_tool from utils.models import ActionItem from utils.jira_interface_functions import create_issue @function_tool def create_jira_issue(action_item: ActionItem) -> str: response = create_issue( project_key=action_item.project, title=action_item.title, description=action_item.description, issuetype=action_item.issuetype, duedate=action_item.due_date, assignee_id=None, labels=None, priority_id=None, reporter_id=None, ) if response.ok: return f\"Successfully created the issue. Response message: {response.text}\" else: return f\"There was an error trying to create the issue. Error message: {response.text}\" Very important: The @function_tool decorator is what makes this function usable for our agent. The agent can now call this function and pass it an ActionItem object. The function then uses the create_issue function which accesses the Jira API to create a new issue. Step 6: Configuring the Application To make our application parametrizable, we’ll use a config.yml file for the configuration settings, as well as a .env file for the API keys. The configuration of the application is separated in: agents : To configure the agents and the access to the OpenAI API. Here we have two parameters: model , which is the LLM that shall be used by the agents, and OPENAI_API_KEY , in the .env file, to authenticate the use of the OpenAI API. You can obtain an OpenAI API Key in your OpenAI Dev Platform. : To configure the agents and the access to the OpenAI API. Here we have two parameters: , which is the LLM that shall be used by the agents, and , in the file, to authenticate the use of the OpenAI API. You can obtain an OpenAI API Key in your OpenAI Dev Platform. jira : To configure the access to the Jira API. Here we need four parameters: url_rest_api , which is the URL to the REST API of our Jira instance; user , which is the user we use to access Jira; request_timeout , which is the timeout in seconds to wait for the server to send data before giving up, and finally ATLASSIAN_API_KEY , in the .env file, to authenticate to your Jira instance. Here is our .env file, that in the next step will be loaded to our application in the main.py using the python-dotenv library: OPENAI_API_KEY=some-api-key ATLASSIAN_API_KEY=some-api-key And here is our config.yml file: We’ll also create a config parser at taskpilot/utils/config_parser.py to load this configuration. For this we implement the Config class as a singleton (meaning there can only be one instance of this class throughout the application lifespan). # taskpilot/utils/config_parser.py from pathlib import Path import yaml from pydantic import BaseModel class AgentsConfig(BaseModel): model: str class JiraConfig(BaseModel): url_rest_api: str user: str request_timeout: int class ConfigModel(BaseModel): agents: AgentsConfig jira: JiraConfig class Config: _instance: ConfigModel | None = None @classmethod def load(cls, path: str = \"config.yml\") -> None: if cls._instance is None: with open(Path(path), \"r\", encoding=\"utf-8\") as config_file: raw_config = yaml.safe_load(config_file) cls._instance = ConfigModel(**raw_config) @classmethod def get(cls, path: str = \"config.yml\") -> ConfigModel: if cls._instance is None: cls.load(path) return cls._instance Step 7: Bringing It All Together in main.py Finally, in taskpilot/main.py , we’ll bring everything together. This script will load the meeting transcript, create an instance of the TaskPilotRunner , and then call the run() method. # taskpilot/main.py import os import asyncio from dotenv import load_dotenv from taskpilot_runner import TaskPilotRunner # Load the variables in the .env file load_dotenv() def load_meeting_transcript_txt(file_path: str) -> str: # ... return meeting_transcript async def main(): print(\"TaskPilot application starting...\") meeting_transcript = load_meeting_transcript_txt(\"meeting_transcript.txt\") await TaskPilotRunner().run(meeting_transcript) if __name__ == \"__main__\": asyncio.run(main()) Step 8: Monitoring Our Runs in the OpenAI Dev Platform As mentioned, one of the advantages of the OpenAI Agents SDK is that, due to its tracing feature, it is possible to visualize the entire execution flow of our agents. This makes it easy to debug and understand what’s happening under the hood in the OpenAI Dev Platform. In the Traces Dashboard one can: Track each run of the agents workflow. Screenshot by the author Understand exactly what the agents did within the agent workflow and monitor performance. Screenshot by the author Debug every call to the OpenAI API as well as monitor how many tokens were used in each input and output. Screenshot by the author So take advantage of this feature to evaluate, debug and monitor your agent runs. Conclusion And that’s it! In this eight simple steps we have implemented an application that can automatically create Jira issues from a meeting transcript. Thanks to the simple interface of the OpenAI Agents SDK you can easily create agents programmatically to help you automatize your tasks! Feel free to clone the repository (the project as described in this post is in branch function_calling ), try it out for yourself, and start building your own AI-powered applications! 💡 Coming Up Next: In an upcoming post, we’ll dive into how to implement your own MCP Server to further extend our agents’ capabilities and allow them to interact with external systems beyond your local tools. Stay tuned! 🙋‍♂️ Let’s Connect If you have questions, feedback, or just want to follow along with future projects: Reference This article is inspired by the “OpenAI: Agents SDK” course from LinkedinLearning.",
         "en",
         "{'MISC': ['# taskpilot', '@classmethod', '@function_tool', 'API_KEY that we can obtain on', 'Action Items Extractor', 'ActionItem from', 'ActionItemsList', 'ActionItemsList :', 'Agent from utils.config_parser', 'Allowing agents to call other agents without handing off', 'Allows agents to', 'Allows agents to delegate tasks to other agents depending on their expertise', 'An agent from the OpenAI Agents', 'As you can see', 'Automatically manages the conversation history', 'Based', 'Bringing It All Together in main.py Finally', 'Coming Up Next: In an upcoming post', 'Config from', 'Config.get().jira.request_timeout', 'Configuring the', 'Content-Type', 'Create', 'CreateIssuesResponse class TaskPilotRunner', 'Creator This agent takes the list of action items and creates Jira', 'Ensures that the agents have the context they need to perform their tasks', 'Error', 'Error message', 'Feel free to clone the repository', 'Finally', 'First we', 'For this we', 'Function calling : Using any Python', 'HTTPBasicAuth from', 'Here are some of the key features of the SDK: Agent Loop: A built-in agent loop that handles the back-and-forth', 'Here is our .env file', 'Here we have two parameters', 'Here we need', 'Here we set the tools parameter and give the agent the create_jira_issue tool', 'Highest', 'Hosted tools : Provided directly from OpenAI such as searching the web or files', 'I decided to separate it in two files: In taskpilot/utils/jira_interface_functions.py', 'If the action', 'If the children action items are not clear or the action', 'If the parent', 'Image created by the author', 'Implementation We will', 'In Progress', 'In the Traces Dashboard one can: Track each run of the agents workflow', 'In this step', 'It can be \"Epic', 'It can be \"Lowest', 'It can be \"To Do', 'It shall be a string created as following', 'It shall be in the format', 'It should be a more extended description of the action', 'It should be a short description of the action', 'It should be short and concise', 'It takes an agent and an input', 'It will orchestrate the entire workflow', 'Items Extractor', 'Jira project automatically and corresponding to what was discussed in the meeting', 'JiraConfig class Config', 'Let’s Connect If you have questions', 'Let’s get hands on!', 'Let’s start with the implementation: In the', 'LinkedinLearning', 'Load the variables in the', 'Low', 'Medium', 'Models', 'Nevertheless', 'No need for writing anything down during the meeting', 'None children: Optional[list[str', 'None class ActionItemsList(BaseModel', 'None start_date', 'Now', 'One could argue that the use of tools is what turns the interaction with an LLM into an agent', 'OpenAI', 'OpenAI Agents', 'Optional[str', 'Path', 'Python', 'Python object that the agent shall returned', 'README.md', 'Receives and', 'Requests with the Jira', 'Response', 'Response message: {response.text}\" else', 'Return the results print(tickets_creation_response.text', 'Runner', 'Runner.run', 'Screenshot by the author Debug every call to the OpenAI API as well as monitor how many tokens were used in each input and output', 'Screenshot by the author So take advantage of this feature to evaluate', 'Screenshot by the author Understand', 'Speaker', 'Stay tuned!', 'Step 1: Setting Up the Project Structure First', 'Step 2:', 'Step 3: Defining Our Data Models Without specific configuration agents', 'Step 5: Providing Tools One of the most powerful features of agents is their ability to', 'Step 6', 'Step 8: Monitoring Our Runs in the OpenAI Dev Platform As', 'Story', 'Subtask', 'Task', 'TaskPilot run...', 'TaskPilotRunner().run(meeting_transcript', 'TaskPilot” using OpenAI’', 'Thanks to the', 'That was the thought of this short experimental project', 'The', 'The @function_tool', 'The Challenge: From Conversation to Actionable Tasks Given the transcript of', 'The SDK', 'The Solution: Automating with OpenAI Agents Using the OpenAI Agents', 'The agent can now call this function and pass it an', 'The configuration of the application is separated in: agents', 'The description of the action', 'The name of the agent for identification', 'The priority of the action', 'The prompt to tell the agent its role or', 'The reason for this is that the Runner.run', 'The run', 'The start', 'The status of the action', 'The title of the action', 'The type of the action', 'To configure the access to the Jira API', 'To configure the agents and the access to the OpenAI API', 'To ensure that our agents provide structured and predictable', 'Trace ID: {trace_id}', 'Turns any Python function into', 'Uses an AI agent to extract action items from the conversation', 'Uses another AI agent to create Jira', 'Validates the inputs and outputs', 'We’ll also create', 'We’ll create it in taskpilot', 'Which LLM to use for the agent', 'Within these methods the Runner.run', 'You are an assistant that creates Jira', 'You can', 'You shall collect the responses of the `create_jira_issue` tool and return them as the provided type `CreateIssuesResponse', 'You shall extract from the transcript in which state the action', 'You shall extract this from the transcript', 'You shall infer from the conversation the name of the assignee and not', 'You shall interpret the issuetype of the action', 'You shall interpret the priority of the action', 'You shall interpret the project of the action', 'You will be given', 'You will be given a list of action items and for each action', 'Your are an', 'among others', 'and pass it to the agents to create the Jira', 'and then call the run', 'as well as', 'asyncio from', 'create an instance of the TaskPilotRunner', 'create issues in a', 'debug and monitor your agent', 'eg', 'extracting action items from the meeting', 'function_tool from', 'however you can also', 'int class ConfigModel(BaseModel', 'let’s create our two agents', 'let’s create the basic structure of our project:', 'method we will create the two agents used for this workflow', 'method will be the most important of the class', 'model', 'name=\"Tickets Creator', 'of a JSON', 'one of the advantages of the OpenAI Agents', 'payload[\"fields\"].update({\"priority', 'return cls._instance Step 7', 'see Agents SDK', 'self.tickets_creator', 'str Step 4: Creating the Agents The agents are the core of our application', 'str class JiraConfig(BaseModel', 'subtask', 'that in the next step will be loaded to our application in the main.py using the python-dotenv library', 'that is extracted from the meeting', 'that summarizes the result of the tickets creation', 'that we will then provide to the TicketsCreator', 'that will be the tools that the agent can use to perform its tasks', 'the agent should also be able to handle and understand JSON', 'the library supports', 'the use of Pydantic', 'to authenticate the use of the OpenAI API', 'tools', 'try it out for yourself', 'usable for our agent', 'we will write the functions to interact through HTTP Requests with the Jira', 'we’ll', 'we’ll bring everything together', 'we’ll dive into how to implement your own MCP Server to further', 'which is the LLM that shall be used by the agents', 'which we’ll create in the next step', 'will be the heart of our application', 'with a', 'with automatic', 'with the LLM until the agent is done', 'yaml from pydantic import', 'you shall create a Jira', 'you shall set it to \"To Do', 'you shall set it to None', 'you shall set the children of the action', 'you shall set the parent of the action'], 'PER': ['- assignee: The name of the person who will be responsible for the action', 'Config.get().agents.model', 'ConfigModel', 'ConfigModel(**raw_config', 'Guardrails', 'Handoffs', 'None', 'Optional[list[str', 'TypedDict', 'create_issue', 'directory', 'given', 'str', 'str assignee: str status', 'str issuetype', 'system', 'taskpilot/', 'we will be using function calling and', 'will contain our main application logic', 'with trace(\"TaskPilot run', 'you shall convert them to absolute'], 'ORG': ['Accept', 'ActionItem', 'AgentsConfig', 'Atlassian Account Management', 'Config', 'For our usecase', 'For our usecase we will define three models in taskpilot', 'In Review', 'MCP', 'Optional', 'Pydantic TypeAdapter', 'Support', 'TaskPilotRunner', 'TaskPilotRunner The TaskPilotRunner', 'let’'], 'LOC': ['ActionItemsList', 'CreateIssuesResponse', 'CreateIssuesResponse(BaseModel', 'None', 'Optional[str', 'Provides', 'Tracing', 'Validates', 'Very', 'action_item.due_date', 'cls.load(path', 'duedate', 'f\"From', 'fields', 'issuetype', 'self._create_tickets(action_items', 'str(os.getenv(\"ATLASSIAN_API_KEY']}",
         "[-0.0780370682477951, -0.015204761177301407, -0.09112419933080673, 0.03262130171060562, 0.003025440266355872, -0.023215755820274353, 0.0736398920416832, -0.021397827193140984, 4.402426930028014e-05, -0.0015557431615889072, -0.08200754970312119, -0.051523927599191666, 0.025512680411338806, 0.10037022829055786, 0.08298921585083008, 0.024527238681912422, 0.06597796082496643, -0.03656495362520218, -0.043216459453105927, -0.029823893681168556, 0.014899893663823605, 0.022768739610910416, 0.016451211646199226, -0.04398701339960098, -0.06890670955181122, -0.0016440785257145762, 0.049329157918691635, -0.06662771850824356, -0.003016714472323656, -0.012750890105962753, 0.08669847249984741, 0.05750955268740654, 0.08139641582965851, 0.04367096349596977, 0.07183489203453064, 0.06754779070615768, -0.04211971536278725, 0.06309622526168823, -0.01592278853058815, -0.0827384889125824, 0.006044936832040548, 0.02726949192583561, 0.008339256048202515, -0.07602417469024658, 0.0640413910150528, -0.04370979592204094, -0.03435289114713669, -0.058267202228307724, -0.0026689402293413877, 0.040404170751571655, -0.13392801582813263, -0.028366047888994217, 0.048510827124118805, 0.0044473037123680115, 0.04647358879446983, 0.09307503700256348, 0.029462167993187904, -0.023903317749500275, -0.01721745915710926, -0.028388915583491325, -0.025029631331562996, -0.06013837084174156, -0.026522362604737282, -0.02145753800868988, -0.07293339818716049, 0.04686165601015091, -0.011416592635214329, 0.05026652291417122, 0.0541410930454731, -0.016742831096053123, -0.022689560428261757, 0.05312882736325264, -0.027380716055631638, -0.05197243392467499, -0.030788395553827286, 0.0034760036505758762, -0.07283556461334229, 0.028613844886422157, 0.03673499450087547, -0.04751583933830261, -0.054082538932561874, -0.04695938900113106, 0.008765230886638165, 0.051841847598552704, 0.055038679391145706, 0.058305878192186356, -0.01767100766301155, 0.05362095311284065, 0.05971420928835869, 0.006699830759316683, -0.052985914051532745, -0.024779781699180603, 0.08503393083810806, -0.012853465974330902, 0.09643187373876572, 0.05186771973967552, -0.0020615574903786182, -0.02499428018927574, 0.004142190795391798, 0.08628864586353302, -0.015240340493619442, 0.009288370609283447, -0.04780992865562439, -0.01233392208814621, -0.0226444099098444, 0.020794786512851715, 0.056414924561977386, -0.06236284226179123, -0.03034176304936409, -0.002418947173282504, -0.04503783583641052, -0.05693868175148964, 0.036001235246658325, -0.017770715057849884, 0.04967204108834267, 0.0506875142455101, 0.056710854172706604, 0.0821501761674881, 0.0036018872633576393, -0.023065654560923576, 0.06756407022476196, 0.01801406219601631, 0.005279479082673788, 0.013521592132747173, 0.06462643295526505, 0.04836071655154228, 0.00012118174345232546, 4.317509935333643e-33, 0.08227203786373138, 0.010205789469182491, 0.02337496168911457, 0.007053092122077942, 0.119535431265831, 0.002246289048343897, -0.004167160950601101, -0.03759671002626419, 0.047883521765470505, -0.0384138822555542, -0.01891588233411312, 0.03009146638214588, 0.00030310446163639426, -0.00640002079308033, -0.02356533892452717, -0.04861041158437729, -0.08824064582586288, 0.08978545665740967, 0.002043637912720442, -0.014269147999584675, -0.015939772129058838, -0.09435326606035233, -0.006471368949860334, 0.05438053980469704, 0.0030300740618258715, 0.02950909733772278, 0.0906621590256691, -0.04234033823013306, 0.05317126214504242, -0.0065572443418204784, -0.035522472113370895, -0.005412307567894459, 0.02670365199446678, 0.0518963485956192, -0.025312338024377823, 0.019188763573765755, -0.08289813995361328, -0.01643335074186325, -0.010088988579809666, 0.012813985347747803, -0.018089722841978073, -0.010625576600432396, -0.007830416783690453, -0.022610601037740707, -0.09145964682102203, -0.004298916086554527, -0.043937891721725464, 0.06774666160345078, 0.08644461631774902, -0.007317392621189356, 0.0013755520340055227, -0.005954660940915346, 0.053157396614551544, -0.038747772574424744, 0.007428016513586044, -0.09006918966770172, 0.04608793929219246, -0.07060770690441132, 0.07839841395616531, 0.01164507307112217, -0.024543533101677895, 0.010511113330721855, -0.05157708749175072, 0.11909915506839752, 0.028862273320555687, 0.0540132112801075, -0.029338503256440163, 0.0009835654636844993, 0.05332989618182182, -0.07901187241077423, 0.02692662551999092, 0.05560280755162239, -0.032588452100753784, -0.020392559468746185, -0.007797221653163433, 0.013490128330886364, 0.0194698553532362, -0.026634884998202324, -0.0025457791052758694, -0.005226606968790293, -0.01135688554495573, -0.07793556898832321, -0.0099581778049469, -0.010106398724019527, -0.017437957227230072, 0.024853406473994255, -0.012747691944241524, -0.03788250312209129, -0.0341750867664814, 0.054417334496974945, -0.009112079627811909, 0.04567362368106842, -0.04520144313573837, 0.0973760187625885, 0.03414362296462059, -3.1465269114246206e-33, 0.04589512571692467, 0.05852910876274109, -0.08347579836845398, 0.008325985632836819, 0.09800582379102707, -0.02712267078459263, 0.014133167453110218, -0.03561096265912056, 0.08752977102994919, -0.025706253945827484, -0.13760517537593842, -0.09137578308582306, 0.006534204818308353, -0.04595714434981346, 0.03995693847537041, -0.09969451278448105, 0.07304257899522781, -0.011113651096820831, -1.020331728796009e-05, 0.05849749594926834, -0.025607524439692497, 0.02883305959403515, -0.07495277374982834, -0.07603608071804047, 0.04972882941365242, 0.030360504984855652, 0.059185419231653214, -0.019851427525281906, -0.008072258904576302, -0.002324371598660946, -0.0344577431678772, -0.05765257030725479, -0.09371419250965118, -0.008383950218558311, 0.06151264160871506, 0.038416970521211624, 0.0148102305829525, -0.009671863168478012, -0.03729231283068657, -0.002270556753501296, 0.07771305739879608, -0.055596332997083664, -0.08335109800100327, 0.05041750892996788, -0.0018539996817708015, 0.0001290543150389567, -0.10135748237371445, 0.0948011577129364, -0.07979952543973923, -0.01813923381268978, -0.07011633366346359, -0.016341140493750572, -0.04284084588289261, -0.08670166879892349, -0.018407385796308517, 0.0304484274238348, 0.06528185307979584, -0.02919793501496315, -0.008883553557097912, -0.03117179311811924, -0.0721607580780983, -0.09415803104639053, 0.06395351886749268, 0.007091908250004053, 0.052889883518218994, 0.014540944248437881, 0.05241626128554344, 0.05779581144452095, -0.019881360232830048, -0.006021426524966955, 0.004111206624656916, -0.1164347305893898, -0.03536897152662277, 0.05537046864628792, 0.11078356951475143, -0.022295156493782997, -0.10003571957349777, -0.046539437025785446, 0.061843108385801315, -0.038191407918930054, -0.024699505418539047, 0.04298856481909752, 0.04384424537420273, -0.000863889348693192, 0.012099933810532093, 0.06191110983490944, -0.009320208802819252, 0.07879582792520523, 0.09024400264024734, 0.10029445588588715, -0.056715574115514755, 0.006766477599740028, 0.0701960101723671, 0.0545310415327549, -0.020715123042464256, -4.7213205789375934e-08, -0.06258342415094376, -0.052745476365089417, -0.05097808688879013, -0.012755138799548149, -0.015215053223073483, -0.06784909218549728, -0.05379887670278549, 0.03744542971253395, 0.07417593896389008, 0.022473061457276344, 0.027859633788466454, -0.020253730937838554, -0.057307370007038116, 0.03506062552332878, -0.06264975666999817, 0.02855851501226425, 0.04176187142729759, 0.03481832891702652, -0.02904052473604679, -0.11411170661449432, 0.06697360426187515, -0.03232830390334129, -0.0033062922302633524, 0.021147502586245537, -0.036067213863134384, -0.027367841452360153, -0.04820183664560318, 0.06892025470733643, 0.010692269541323185, -0.015269914641976357, 0.0042346566915512085, -0.01134429220110178, 0.07494034618139267, 0.03601103648543358, -0.009192286059260368, -0.03241967782378197, -0.00997462309896946, -0.06498780846595764, 0.09525248408317566, -0.01866983249783516, -0.06489971280097961, 0.03872084990143776, -0.03944366052746773, -0.040105096995830536, -0.001070546917617321, 0.020794248208403587, -0.11015690863132477, -0.10572481900453568, -0.025336047634482384, -0.05318039655685425, -0.10773860663175583, -0.017820248380303383, 0.044054701924324036, 0.06604933738708496, 0.031117374077439308, 0.014195609837770462, 0.11621899157762527, -0.05865161120891571, 0.09295997023582458, 0.034154124557971954, -0.016077948734164238, 0.10665949434041977, -0.05237946659326553, 0.021193215623497963]",
         "0.129"
        ],
        [
         "9",
         "568",
         "What Is a Query Folding in Power BI and Why should You Care?",
         "\"Will that break a query folding?” “Does your query fold?”… Maybe someone asked you those questions, but you were like: “Query…Whaaaat?! In this article, we demistify the query folding and its importance for efficient data refresh in Power BI The post What Is a Query Folding in Power BI and Why should You Care? appeared first on Towards Data Science .",
         "a query folding?” “Does your query fold?”… Maybe someone asked you those questions, but you were like: “Query…Whaaaat?!”\n\nOr, maybe you’ve heard about query folding in Power BI, but didn’t know how to take advantage of it in real-life scenarios.\n\nIf you recognized yourself in (at least) one of the two situations specified above, then please continue reading this article.\n\nFine, you are curious to find out what a Query folding is. But, first things first…Before you proceed, we need to establish some theoretical foundations, which will put the Query folding feature in the proper context.\n\nData Shaping\n\nand why it is one of the key concepts in the data preparation phase. Now, I would like to expand on that in a (maybe) unusual way:\n\nI guess you all know about the book written by Thomas More, called “Utopia”.\n\nIn that story, everything is perfect and everyone is satisfied. In an ideal world, let’s call it “Data Utopia”, we have clean, high-quality data that just flies into our reports “as-is”, without needing to perform any kind of face-lifting or transformations along the way. Unfortunately, “Data Utopia” can exist only in books — the reality is crueler — as we have to deal with numerous challenges while nurturing our data.\n\nThat being said, one of the key concepts that we have to absorb is Data Shaping. Data shaping is the process you should perform once you get familiar with your data, and become aware of possible pitfalls within the data you are planning to use in your business intelligence solution.\n\nI’ve intentionally used the term “Business Intelligence” instead of “Power BI”, as this is a general concept that should be used outside of Power BI solutions too.\n\nIn simple words, data shaping is the process of data consolidation, BEFORE it becomes part of your data model. The key thing to keep in mind is the word: BEFORE! So, one would perform data shaping before the data goes into the report itself. Data shaping can be done at different places, and, depending on where you apply data shaping techniques, at different points in time during the data preparation process.\n\nWHERE should you perform data shaping?\n\nSource Database — This is the most obvious choice and in most cases the most desirable scenario. It is based on traditional data warehousing principles of Extracting-Transforming-Loading (ETL) data. In this scenario, you define what data you want to extract (not all data from the database is needed, and it’s usually not a good idea to import all the data). Then, you decide if your data needs to be transformed along the way, to suit your reporting needs better — for example, do you want to perform currency conversion, or do you need to conform country and city names?\n\nDo you recognize the city in the following image?\n\nYes, it’s New York. Or, is it NYC? Or, is it New York City? Which one of these three names is correct? Yes, all of them are correct — but if you import the data into your data model like this, you will get incorrect results — as each New York, NYC, and New York City will be treated as a separate entity. This, and many more potential caveats, need to be solved during the Data Shaping phase, and that’s why it’s important to spend some time massaging your data.\n\nPower Query\n\nIf you don’t perform data transformations on the source side, the next station is Power Query — it’s the built-in tool within Power BI, that enables you to perform all kinds of transformations to your data. According to Microsoft’s official documentation, you can apply more than 300 different transformations!\n\nThe key advantage of Power Query is that you can perform complex data transformations with little or no coding skills! Additionally, all steps you’ve applied during the data transformation process are being saved, so every time you refresh your dataset, those steps will be automatically applied to shape your data and prepare it for consumption via reports.\n\nUnder the hood of Power Query is a Mashup engine, that enables your data shaping to run smoothly. Power Query uses a very powerful M language for data manipulation. And, now you are probably asking yourselves, what does all this story about data shaping, Power Query, Mashup engine, M language, etc. have to do with Query folding? I don’t blame you, it’s a fair question, but we will come back soon to answer it.\n\nWhat is a Query folding?\n\nFor some data sources, such as relational databases, but also non-relational data sources, for example, OData, AD, or Exchange, the Mashup engine is able to “translate” M language to a language that the underlying data source will “understand” — in most cases, it’s SQL.\n\nBy pushing complex calculations and transformations directly to a source, Power Query leverages the capabilities of the robust relational database engines, that are built to cope with large volumes of data in the most efficient way.\n\nThat ability of Power Query’s Mashup engine to create a single SQL statement combining all M statements behind your transformations is what we call Query folding.\n\nOr, let`s make it simple: if the Mashup engine is able to generate a single SQL query that is going to be executed on the data source side, we say that the query folds.\n\nData sources that support Query folding\n\nAs already mentioned, the most obvious beneficiary of query folding is relational database sources, such as SQL Server, Oracle, or MySQL. However, it`s not just that SQL databases take advantage of the query folding concept. Essentially, any data source that supports some kind of querying language can possibly take advantage of query folding. Those other data sources are OData, SSAS, SharePoint lists, Exchange, and Entra ID.\n\nOn the other hand, when you use data sources such as Excel files, BLOB storage files, flat files, etc. in your Power BI datasets, the query can’t fold.\n\nData Transformations that support Query folding\n\nHowever, when it comes to data sources that support query folding in general, it’s important to keep in mind that not all transformations can be folded and pushed to a data source. So, just to be clear, the fact that a SQL database supports query folding doesn’t necessarily mean that your query will fold! There are some Power Query transformations that simply can`t be pushed to a SQL database engine.\n\nVery often, some subtle differences in the Power Query transformations can be decisive in the final outcome, and whether your query will fold or not. I’ll show you a few of those subtle differences in the following sections.\n\nGenerally speaking, the following transformations, when applied in Power Query, can be “translated” to a single SQL statement:\n\nRemoving columns\n\nRenaming columns\n\nFiltering rows, with static values or Power Query parameters, as they are treated as WHERE clause predicates in SQL\n\nGrouping and summarizing, which are equivalent to SQL’s Group by clause\n\nMerging of foldable queries based on the same source, as this operation can be translated to JOIN in SQL. When I said, merging of foldable queries — that means it will work if you are joining two SQL server tables, but it will not work if you are trying to join a SQL table and an Excel file\n\nqueries based on the same source, as this operation can be translated to JOIN in SQL. When I said, merging of foldable queries — that means it will work if you are joining two SQL server tables, but it will not work if you are trying to join a SQL table and an Excel file Appending foldable queries based on the same source — this transformation relates to the UNION ALL operator in SQL\n\nqueries based on the same source — this transformation relates to the UNION ALL operator in SQL Adding custom columns with simple logic. What does simple logic mean? Using M functions that have equivalents in SQL language, for example, mathematical functions, or text manipulation functions\n\nPivot and Unpivot transformations\n\nOn the other hand, some transformations that will prevent the query from folding are:\n\nMerging queries based on different sources, as explained previously\n\nAppending (union-ing) queries based on different sources — similar logic as in the previous case\n\nAdding custom columns with complex logic or using some M functions that don’t have a counterpart in SQL\n\nAdding index columns\n\nChanging a column data type. This one is a typical “it depends” case. I will show you soon what it depends on, but just keep in mind that changing a column data type can be both a foldable and a non-foldable transformation\n\nNow, let’s examine why it is important to achieve this behavior — or, maybe it’s better to say, why should you care if the query folds or not?\n\nWhy should you care about Query folding?\n\nWhen you’re using Import mode in Power BI, the data refresh process will work more efficiently when the query folds, both in terms of refresh speed and resource consumption.\n\nIf you are working with DirectQuery or Dual storage mode, as you are targeting the SQL database directly, all your transformations MUST fold — or your solution will not work.\n\nFinally, query folding is also of key importance for Incremental refresh — it’s so important that Power BI will warn you once it determines that query folding can’t be achieved. It will not break your incremental refresh “per-se”, but without query folding in place, an incremental refresh wouldn’t serve its main purpose — to reduce the amount of data that needs to be refreshed in your data model — as without query folding, Mashup engine needs to retrieve all data from the source and then apply subsequent steps to filter the data.\n\nWith all these in mind, you should tend to achieve query folding whenever possible.\n\nSlow report — don’t blame Query folding!\n\nOne important disclaimer here, and this is one of the key takeaways from this series of blog posts: if your report is slow, or your visuals need a lot of time to render, or your data model size is large, query folding has nothing to do with it!\n\nOnly if your data refresh or incremental refresh is slow and inefficient, you should investigate your Power Query steps in more depth.\n\nAll or nothing?\n\nA few more things to keep in mind regarding query folding. It’s not an all-or-nothing process. That means if you have, let’s say, 10 transformation steps within Power Query, and your query folds until the 6th step, you will still get some benefit from partial query folding. However, once the query folding is broken, it can’t be achieved anymore.\n\nImage by author\n\nTo simplify, if you have 10 transformation steps, and your query folding is broken in the 5th step, all previous steps will fold, but once the folding is broken, it can’t be achieved again, even if you have transformations that support query folding by default in steps 6 to 10 — like in our example where filtering should be a foldable step, these steps will not fold. Keep that in mind, and try to push all non-foldable steps down the pipeline as much as possible.\n\nHow do you know if the query folds?\n\nOk, now we are not rookies anymore. We know what query folding is, why we should strive to achieve it, and some subtle tricks that can make a huge difference.\n\nNow, it’s time to learn how to check if the specific query folds or not. The first and most obvious way is to right-click on the step and check what the View Native Query option looks like.\n\nIf it’s greyed out, this step probably does not fold. On the other hand, if you are able to click on this option, that means that your query will fold. I guess you are maybe confused with the word: PROBABLY!\n\nImage by author\n\nBut, that’s the proper word, as you can’t be 100% sure that if the View Native Query option is disabled, your query doesn’t fold. I will show you later how this option can trick us into thinking that the query folding was broken, even though, in reality, folding actually occurs.\n\nInstead, when you want to be sure if your query folds or not, you can use the Query Diagnostics feature within Power Query Editor, or SQL Server Profiler, like a good old and reliable way to check the queries sent to a database by the Power BI engine.\n\nAdditionally, there is a cool feature in Power Query Online, where each step is marked with the icon that shows if that step folds, does not fold, or is unknown. As I said, this feature is available only in Power Query Online at this moment, so let’s hope that the Power BI team will implement it in the Desktop version soon.\n\nImage by author\n\nThe devil is in the details…\n\nFine…You’ve probably heard about the saying that the devil is in the details. Now, it’s time to understand how little nuances can make a big difference in our data transformation process.\n\nLet’s start with one of the most curious cases in Power Query editor…\n\nDevil #1 — Merge Join\n\nThis one is very interesting, as you will hardly assume what is happening in the background. Let’s say that I want to combine two of my queries into one. I will use the Adventure Works sample database, and I need to merge the FactInternet Sales and DimCustomer tables.\n\nI’ll remove some of the columns from my fact table, and keep only the CustomerKey column, as this is a foreign key to a DimCustomer table, and the Sales Amount column. I will join the DimCustomer table as it is, without any additional steps before merging.\n\nImage by author\n\nMerging tables is equivalent to JOIN operation in SQL. Essentially, we choose the column on which we want to perform MERGE operation, and the type of join (left, outer, or inner).\n\nImage by author\n\nThe problem is that by default, when you’re merging two queries, Power Query will generate a nested join statement, which can’t be properly translated in SQL.\n\nImage by author\n\nIf I go to the Tools tab and click on Diagnose Step, I can see that the Mashup engine fired two separate queries to my underlying SQL Server database — in other words, those two queries couldn’t be executed as a single SQL statement, and that means that query didn’t fold!\n\nImage by author\n\nHow do we solve this? Let’s just choose a blank query and write our M code by hand to achieve exactly the same result.\n\nImage by author\n\nThe key thing is that we will use a similar, but still different M function: Table.Join.\n\nWe are now using Table.Join function – Image by author\n\nAll function arguments are exactly the same as previously, and let’s now check the outcome.\n\nYou remember once I told you that when the View Native Query is greyed out, your query probably doesn’t fold, but it’s not 100% correct. And, this is a good example. If you take a look at View Native Query, it still shows that our query doesn’t fold…\n\nImage by author\n\n…but let’s go to Diagnostics and check if that’s true.\n\nImage by author\n\nOh, boy, we were tricked — this step indeed folded! As you can see in the illustration above, we have a single SQL query generated and sent to a SQL Server source database to be executed.\n\nSo, we found two devils in this example — the first one was a join type, which we were able to solve by tweaking the automatically generated M code. And, the other one was the incorrect behavior of the View Native Query option. I’ll show you in the next part of the series one more example when View Native Query lies.\n\nQuery folding in Power BI — tricks, lies & ultimate performance test\n\nI assume you are now familiar with the concept of query folding in Power BI, and especially with its importance for data refresh and incremental refresh processes. We’ve also started to scratch some interesting behaviors of Power Query transformations, and in this final part of the article, I will show you a few more interesting findings.\n\nFinally, we will wrap it up with the ultimate performance test — I will show you the exact numbers behind two identical queries — one folds, and the other does not!\n\nChanging Data types\n\nOne of the most common transformations in Power Query is changing data type. It’s a well-known best practice to use proper data types in your data model — for example, if you don’t need hours, minutes, and seconds level of granularity in your reports, you should be better off getting rid of them and changing the data type of that column from Date/Time to Date only.\n\nHowever, the road to hell is paved with good intentions:)…So, let me show you one subtle difference that can cause your query to become damn slow, even though you’ve stuck with the recommendation to use a proper data type!\n\nImage by author\n\nAs you can spot in the illustration above, my OrderDate column is of Date/Time data type. And, I want to switch it to Date only. There are (at least) two possible options to do this — the first one is to right-click on the column, expand the drop-down for the Change Type option (like I did in the illustration), and select Date type (just below the Date/Time):\n\nImage by author\n\nA few important things happened here, so let me explain each of those:\n\nIn the Applied Steps pane, you can notice that our transformation step had been recorded In the column itself, you can see that the time portion disappeared When I’ve opened the View Native Query dialog box, you can see that the Mashup engine nicely translated our transformation to a T-SQL CONVERT() function The M formula applied to this transformation step is: Table.TransformColumnTypes()\n\nLet’s now examine the other option to change data type of our column:\n\nImage by author\n\nJust below our previous Change Type option, there is a Transform option. Once you expand the drop-down, you can see the Date Only transformation. Let’s click on it and check what happens:\n\nImage by author\n\nLooks quite similar, does it? But, let’s walk through all the things that happened now:\n\nInstead of the Changed Type step, we now have a step called Extracted Date The column itself looks exactly the same as in the previous example — no time part in there Ooops, the query doesn’t fold anymore! As you can see, the View Native Query option is greyed out! This time, M formula applied is: Table.TransformColumns()\n\nSo, one single different word in the M formula (Table.TransformColumnTypes vs Table.TransformColumns) affected our query so hard that it couldn’t be translated to SQL!\n\nTakeover from this story: be careful, and watch out when you’re choosing options for changing data types!\n\nLiar, Liar…\n\nI’ve promised in the previous part of the article that I will show you one more example when the View Native Query option can fool you into thinking that query folding was broken, even if in reality it’s not true…\n\nLet’s say that we want to keep only the top X rows from our table. In my case, I want to preserve the top 2000 rows from my fact table:\n\nImage by author\n\nOnce I’ve applied this step and checked the View Native Query, I can realize that my query folds, as my transformation was translated to a TOP clause in SQL:\n\nImage by author\n\nNow, let’s say that I want to apply Absolute value transformation on my Sales Amount column. Normally, this transformation easily folds, as there is an ABS function in T-SQL:\n\nImage by author\n\nHowever, if I right-click on this step, I will see that the View Native Query option is greyed out, so I would assume that this step broke my query folding!\n\nImage by author\n\nLet’s check this in our Query Diagnostics tool:\n\nImage by author\n\nOh, my God! This step folded indeed! So, we were tricked by the View Native Query option again!\n\nThe key takeover here is: whenever you’re assuming that a specific transformation step can be folded (like in this example, when we knew that SQL has an ABS function to support our transformation), double-check what really happens under the hood!\n\nThe ultimate performance test\n\nOk, if I didn’t manage to convince you so far, why you should strive to achieve query folding, let me now pull my last ace up my sleeve!\n\nI want to show you the difference in data refresh performance between the queries that return exactly the same results — one of them folds, and the other does not!\n\nTest #1 Query folding ON\n\nFor this testing, I’ll use the FactOnlineSales table from the Contoso sample database. This table has around 12.6 million rows, and it’s good to demonstrate the magnitude of importance of the query folding concept.\n\nIn the first example, I’ve applied 9 different transformation steps, and all of them are foldable, as you can see in the following illustration:\n\nImage by author\n\nDon’t pay attention to the SQL code that the Mashup engine generated: if you are a SQL professional, of course, you could write much more optimal SQL code — however, keep in mind that with auto-generated scripts by the Mashup engine, you are not getting the most optimal SQL — you are just getting correct SQL!\n\nI will hit Close & Apply and turn on my stopwatch to measure how much time my data refresh lasts.\n\nImage by author\n\nThis query took 32 seconds to load 2.8 million records in my Power BI report. Data was loaded in batches of 100.000–150.000 records, which is a good indicator that the query folding is in place.\n\nTest #2 Query folding OFF\n\nNow, I will go back to Power Query Editor, and intentionally break query folding at the 3rd step (remember the example above with changing Date/Time type to Date), using the transformation for which I know that is not foldable:\n\nImage by author\n\nTruth to be said, I will achieve a partial folding here, as first two steps will fold, but all subsequent steps after the Extracted Date transformation will not fold!\n\nLet’s turn on the stopwatch again and check what happens:\n\nImage by author\n\nThe first thing to notice: this query took 4 minutes and 41 seconds to load into our Power BI report, which is approximately 10 times more than in our previous case when the query folded. This time, batches of loaded data were between 10.000 and 20.000 records.\n\nBut, what’s even more concerning — you can see that the total number of records loaded was almost 11 million!!! Instead of 2.8 million in the previous example! Why is it happening? Well, in the previous sections, I explained that when the Mashup engine can’t translate M language to SQL, it needs to pull ALL the data (from the moment when the query folding was broken), and THEN apply transformations on the whole chunk of imported data!\n\nThe final result is exactly the same — we have 2.830.017 records in our Power BI report — but, with query folding in place, all necessary transformations were performed on the SQL database side, and the Mashup engine got an already prepared data set. While in the second scenario, after we broke the query folding, the Mashup engine pulled the whole remaining rows (approx. 11 million), and only after that was it able to apply other transformation steps.\n\nAnd, this was just a basic example, with one single table, and not so big in terms of data volume! Simply imagine the magnitude of implications on a larger dataset, with multiple tables in it.\n\nConclusion\n\nWell, we covered a lot in this article. We learned about the data shaping concept, we introduced Power Query fundamentals, and we also learned what query folding is and why we should do our best to achieve it.\n\nI’ve also shared with you some basic examples and neat tricks on how to achieve query folding in some common use cases.\n\nIn the end, please be aware that the query folding is a work in progress, and folks from the Power BI team are constantly improving this feature. So, it can happen that some of the issues with query folding I’ve shown you here are resolved in the meantime. Therefore, be sure to stay up to date with the latest improvements.\n\nThanks for reading!",
         "2025-07-25T20:33:09",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/what-is-a-query-folding-in-power-bi-and-why-should-i-care/",
         "2025-07-26T06:23:31.272668",
         "a query folding?” “Does your query fold?”… Maybe someone asked you those questions, but you were like: “Query…Whaaaat?!” Or, maybe you’ve heard about query folding in Power BI, but didn’t know how to take advantage of it in real-life scenarios. If you recognized yourself in (at least) one of the two situations specified above, then please continue reading this article. Fine, you are curious to find out what a Query folding is. But, first things first…Before you proceed, we need to establish some theoretical foundations, which will put the Query folding feature in the proper context. Data Shaping and why it is one of the key concepts in the data preparation phase. Now, I would like to expand on that in a (maybe) unusual way: I guess you all know about the book written by Thomas More, called “Utopia”. In that story, everything is perfect and everyone is satisfied. In an ideal world, let’s call it “Data Utopia”, we have clean, high-quality data that just flies into our reports “as-is”, without needing to perform any kind of face-lifting or transformations along the way. Unfortunately, “Data Utopia” can exist only in books — the reality is crueler — as we have to deal with numerous challenges while nurturing our data. That being said, one of the key concepts that we have to absorb is Data Shaping. Data shaping is the process you should perform once you get familiar with your data, and become aware of possible pitfalls within the data you are planning to use in your business intelligence solution. I’ve intentionally used the term “Business Intelligence” instead of “Power BI”, as this is a general concept that should be used outside of Power BI solutions too. In simple words, data shaping is the process of data consolidation, BEFORE it becomes part of your data model. The key thing to keep in mind is the word: BEFORE! So, one would perform data shaping before the data goes into the report itself. Data shaping can be done at different places, and, depending on where you apply data shaping techniques, at different points in time during the data preparation process. WHERE should you perform data shaping? Source Database — This is the most obvious choice and in most cases the most desirable scenario. It is based on traditional data warehousing principles of Extracting-Transforming-Loading (ETL) data. In this scenario, you define what data you want to extract (not all data from the database is needed, and it’s usually not a good idea to import all the data). Then, you decide if your data needs to be transformed along the way, to suit your reporting needs better — for example, do you want to perform currency conversion, or do you need to conform country and city names? Do you recognize the city in the following image? Yes, it’s New York. Or, is it NYC? Or, is it New York City? Which one of these three names is correct? Yes, all of them are correct — but if you import the data into your data model like this, you will get incorrect results — as each New York, NYC, and New York City will be treated as a separate entity. This, and many more potential caveats, need to be solved during the Data Shaping phase, and that’s why it’s important to spend some time massaging your data. Power Query If you don’t perform data transformations on the source side, the next station is Power Query — it’s the built-in tool within Power BI, that enables you to perform all kinds of transformations to your data. According to Microsoft’s official documentation, you can apply more than 300 different transformations! The key advantage of Power Query is that you can perform complex data transformations with little or no coding skills! Additionally, all steps you’ve applied during the data transformation process are being saved, so every time you refresh your dataset, those steps will be automatically applied to shape your data and prepare it for consumption via reports. Under the hood of Power Query is a Mashup engine, that enables your data shaping to run smoothly. Power Query uses a very powerful M language for data manipulation. And, now you are probably asking yourselves, what does all this story about data shaping, Power Query, Mashup engine, M language, etc. have to do with Query folding? I don’t blame you, it’s a fair question, but we will come back soon to answer it. What is a Query folding? For some data sources, such as relational databases, but also non-relational data sources, for example, OData, AD, or Exchange, the Mashup engine is able to “translate” M language to a language that the underlying data source will “understand” — in most cases, it’s SQL. By pushing complex calculations and transformations directly to a source, Power Query leverages the capabilities of the robust relational database engines, that are built to cope with large volumes of data in the most efficient way. That ability of Power Query’s Mashup engine to create a single SQL statement combining all M statements behind your transformations is what we call Query folding. Or, let`s make it simple: if the Mashup engine is able to generate a single SQL query that is going to be executed on the data source side, we say that the query folds. Data sources that support Query folding As already mentioned, the most obvious beneficiary of query folding is relational database sources, such as SQL Server, Oracle, or MySQL. However, it`s not just that SQL databases take advantage of the query folding concept. Essentially, any data source that supports some kind of querying language can possibly take advantage of query folding. Those other data sources are OData, SSAS, SharePoint lists, Exchange, and Entra ID. On the other hand, when you use data sources such as Excel files, BLOB storage files, flat files, etc. in your Power BI datasets, the query can’t fold. Data Transformations that support Query folding However, when it comes to data sources that support query folding in general, it’s important to keep in mind that not all transformations can be folded and pushed to a data source. So, just to be clear, the fact that a SQL database supports query folding doesn’t necessarily mean that your query will fold! There are some Power Query transformations that simply can`t be pushed to a SQL database engine. Very often, some subtle differences in the Power Query transformations can be decisive in the final outcome, and whether your query will fold or not. I’ll show you a few of those subtle differences in the following sections. Generally speaking, the following transformations, when applied in Power Query, can be “translated” to a single SQL statement: Removing columns Renaming columns Filtering rows, with static values or Power Query parameters, as they are treated as WHERE clause predicates in SQL Grouping and summarizing, which are equivalent to SQL’s Group by clause Merging of foldable queries based on the same source, as this operation can be translated to JOIN in SQL. When I said, merging of foldable queries — that means it will work if you are joining two SQL server tables, but it will not work if you are trying to join a SQL table and an Excel file queries based on the same source, as this operation can be translated to JOIN in SQL. When I said, merging of foldable queries — that means it will work if you are joining two SQL server tables, but it will not work if you are trying to join a SQL table and an Excel file Appending foldable queries based on the same source — this transformation relates to the UNION ALL operator in SQL queries based on the same source — this transformation relates to the UNION ALL operator in SQL Adding custom columns with simple logic. What does simple logic mean? Using M functions that have equivalents in SQL language, for example, mathematical functions, or text manipulation functions Pivot and Unpivot transformations On the other hand, some transformations that will prevent the query from folding are: Merging queries based on different sources, as explained previously Appending (union-ing) queries based on different sources — similar logic as in the previous case Adding custom columns with complex logic or using some M functions that don’t have a counterpart in SQL Adding index columns Changing a column data type. This one is a typical “it depends” case. I will show you soon what it depends on, but just keep in mind that changing a column data type can be both a foldable and a non-foldable transformation Now, let’s examine why it is important to achieve this behavior — or, maybe it’s better to say, why should you care if the query folds or not? Why should you care about Query folding? When you’re using Import mode in Power BI, the data refresh process will work more efficiently when the query folds, both in terms of refresh speed and resource consumption. If you are working with DirectQuery or Dual storage mode, as you are targeting the SQL database directly, all your transformations MUST fold — or your solution will not work. Finally, query folding is also of key importance for Incremental refresh — it’s so important that Power BI will warn you once it determines that query folding can’t be achieved. It will not break your incremental refresh “per-se”, but without query folding in place, an incremental refresh wouldn’t serve its main purpose — to reduce the amount of data that needs to be refreshed in your data model — as without query folding, Mashup engine needs to retrieve all data from the source and then apply subsequent steps to filter the data. With all these in mind, you should tend to achieve query folding whenever possible. Slow report — don’t blame Query folding! One important disclaimer here, and this is one of the key takeaways from this series of blog posts: if your report is slow, or your visuals need a lot of time to render, or your data model size is large, query folding has nothing to do with it! Only if your data refresh or incremental refresh is slow and inefficient, you should investigate your Power Query steps in more depth. All or nothing? A few more things to keep in mind regarding query folding. It’s not an all-or-nothing process. That means if you have, let’s say, 10 transformation steps within Power Query, and your query folds until the 6th step, you will still get some benefit from partial query folding. However, once the query folding is broken, it can’t be achieved anymore. Image by author To simplify, if you have 10 transformation steps, and your query folding is broken in the 5th step, all previous steps will fold, but once the folding is broken, it can’t be achieved again, even if you have transformations that support query folding by default in steps 6 to 10 — like in our example where filtering should be a foldable step, these steps will not fold. Keep that in mind, and try to push all non-foldable steps down the pipeline as much as possible. How do you know if the query folds? Ok, now we are not rookies anymore. We know what query folding is, why we should strive to achieve it, and some subtle tricks that can make a huge difference. Now, it’s time to learn how to check if the specific query folds or not. The first and most obvious way is to right-click on the step and check what the View Native Query option looks like. If it’s greyed out, this step probably does not fold. On the other hand, if you are able to click on this option, that means that your query will fold. I guess you are maybe confused with the word: PROBABLY! Image by author But, that’s the proper word, as you can’t be 100% sure that if the View Native Query option is disabled, your query doesn’t fold. I will show you later how this option can trick us into thinking that the query folding was broken, even though, in reality, folding actually occurs. Instead, when you want to be sure if your query folds or not, you can use the Query Diagnostics feature within Power Query Editor, or SQL Server Profiler, like a good old and reliable way to check the queries sent to a database by the Power BI engine. Additionally, there is a cool feature in Power Query Online, where each step is marked with the icon that shows if that step folds, does not fold, or is unknown. As I said, this feature is available only in Power Query Online at this moment, so let’s hope that the Power BI team will implement it in the Desktop version soon. Image by author The devil is in the details… Fine…You’ve probably heard about the saying that the devil is in the details. Now, it’s time to understand how little nuances can make a big difference in our data transformation process. Let’s start with one of the most curious cases in Power Query editor… Devil #1 — Merge Join This one is very interesting, as you will hardly assume what is happening in the background. Let’s say that I want to combine two of my queries into one. I will use the Adventure Works sample database, and I need to merge the FactInternet Sales and DimCustomer tables. I’ll remove some of the columns from my fact table, and keep only the CustomerKey column, as this is a foreign key to a DimCustomer table, and the Sales Amount column. I will join the DimCustomer table as it is, without any additional steps before merging. Image by author Merging tables is equivalent to JOIN operation in SQL. Essentially, we choose the column on which we want to perform MERGE operation, and the type of join (left, outer, or inner). Image by author The problem is that by default, when you’re merging two queries, Power Query will generate a nested join statement, which can’t be properly translated in SQL. Image by author If I go to the Tools tab and click on Diagnose Step, I can see that the Mashup engine fired two separate queries to my underlying SQL Server database — in other words, those two queries couldn’t be executed as a single SQL statement, and that means that query didn’t fold! Image by author How do we solve this? Let’s just choose a blank query and write our M code by hand to achieve exactly the same result. Image by author The key thing is that we will use a similar, but still different M function: Table.Join. We are now using Table.Join function – Image by author All function arguments are exactly the same as previously, and let’s now check the outcome. You remember once I told you that when the View Native Query is greyed out, your query probably doesn’t fold, but it’s not 100% correct. And, this is a good example. If you take a look at View Native Query, it still shows that our query doesn’t fold… Image by author …but let’s go to Diagnostics and check if that’s true. Image by author Oh, boy, we were tricked — this step indeed folded! As you can see in the illustration above, we have a single SQL query generated and sent to a SQL Server source database to be executed. So, we found two devils in this example — the first one was a join type, which we were able to solve by tweaking the automatically generated M code. And, the other one was the incorrect behavior of the View Native Query option. I’ll show you in the next part of the series one more example when View Native Query lies. Query folding in Power BI — tricks, lies & ultimate performance test I assume you are now familiar with the concept of query folding in Power BI, and especially with its importance for data refresh and incremental refresh processes. We’ve also started to scratch some interesting behaviors of Power Query transformations, and in this final part of the article, I will show you a few more interesting findings. Finally, we will wrap it up with the ultimate performance test — I will show you the exact numbers behind two identical queries — one folds, and the other does not! Changing Data types One of the most common transformations in Power Query is changing data type. It’s a well-known best practice to use proper data types in your data model — for example, if you don’t need hours, minutes, and seconds level of granularity in your reports, you should be better off getting rid of them and changing the data type of that column from Date/Time to Date only. However, the road to hell is paved with good intentions:)…So, let me show you one subtle difference that can cause your query to become damn slow, even though you’ve stuck with the recommendation to use a proper data type! Image by author As you can spot in the illustration above, my OrderDate column is of Date/Time data type. And, I want to switch it to Date only. There are (at least) two possible options to do this — the first one is to right-click on the column, expand the drop-down for the Change Type option (like I did in the illustration), and select Date type (just below the Date/Time): Image by author A few important things happened here, so let me explain each of those: In the Applied Steps pane, you can notice that our transformation step had been recorded In the column itself, you can see that the time portion disappeared When I’ve opened the View Native Query dialog box, you can see that the Mashup engine nicely translated our transformation to a T-SQL CONVERT() function The M formula applied to this transformation step is: Table.TransformColumnTypes() Let’s now examine the other option to change data type of our column: Image by author Just below our previous Change Type option, there is a Transform option. Once you expand the drop-down, you can see the Date Only transformation. Let’s click on it and check what happens: Image by author Looks quite similar, does it? But, let’s walk through all the things that happened now: Instead of the Changed Type step, we now have a step called Extracted Date The column itself looks exactly the same as in the previous example — no time part in there Ooops, the query doesn’t fold anymore! As you can see, the View Native Query option is greyed out! This time, M formula applied is: Table.TransformColumns() So, one single different word in the M formula (Table.TransformColumnTypes vs Table.TransformColumns) affected our query so hard that it couldn’t be translated to SQL! Takeover from this story: be careful, and watch out when you’re choosing options for changing data types! Liar, Liar… I’ve promised in the previous part of the article that I will show you one more example when the View Native Query option can fool you into thinking that query folding was broken, even if in reality it’s not true… Let’s say that we want to keep only the top X rows from our table. In my case, I want to preserve the top 2000 rows from my fact table: Image by author Once I’ve applied this step and checked the View Native Query, I can realize that my query folds, as my transformation was translated to a TOP clause in SQL: Image by author Now, let’s say that I want to apply Absolute value transformation on my Sales Amount column. Normally, this transformation easily folds, as there is an ABS function in T-SQL: Image by author However, if I right-click on this step, I will see that the View Native Query option is greyed out, so I would assume that this step broke my query folding! Image by author Let’s check this in our Query Diagnostics tool: Image by author Oh, my God! This step folded indeed! So, we were tricked by the View Native Query option again! The key takeover here is: whenever you’re assuming that a specific transformation step can be folded (like in this example, when we knew that SQL has an ABS function to support our transformation), double-check what really happens under the hood! The ultimate performance test Ok, if I didn’t manage to convince you so far, why you should strive to achieve query folding, let me now pull my last ace up my sleeve! I want to show you the difference in data refresh performance between the queries that return exactly the same results — one of them folds, and the other does not! Test #1 Query folding ON For this testing, I’ll use the FactOnlineSales table from the Contoso sample database. This table has around 12.6 million rows, and it’s good to demonstrate the magnitude of importance of the query folding concept. In the first example, I’ve applied 9 different transformation steps, and all of them are foldable, as you can see in the following illustration: Image by author Don’t pay attention to the SQL code that the Mashup engine generated: if you are a SQL professional, of course, you could write much more optimal SQL code — however, keep in mind that with auto-generated scripts by the Mashup engine, you are not getting the most optimal SQL — you are just getting correct SQL! I will hit Close & Apply and turn on my stopwatch to measure how much time my data refresh lasts. Image by author This query took 32 seconds to load 2.8 million records in my Power BI report. Data was loaded in batches of 100.000–150.000 records, which is a good indicator that the query folding is in place. Test #2 Query folding OFF Now, I will go back to Power Query Editor, and intentionally break query folding at the 3rd step (remember the example above with changing Date/Time type to Date), using the transformation for which I know that is not foldable: Image by author Truth to be said, I will achieve a partial folding here, as first two steps will fold, but all subsequent steps after the Extracted Date transformation will not fold! Let’s turn on the stopwatch again and check what happens: Image by author The first thing to notice: this query took 4 minutes and 41 seconds to load into our Power BI report, which is approximately 10 times more than in our previous case when the query folded. This time, batches of loaded data were between 10.000 and 20.000 records. But, what’s even more concerning — you can see that the total number of records loaded was almost 11 million!!! Instead of 2.8 million in the previous example! Why is it happening? Well, in the previous sections, I explained that when the Mashup engine can’t translate M language to SQL, it needs to pull ALL the data (from the moment when the query folding was broken), and THEN apply transformations on the whole chunk of imported data! The final result is exactly the same — we have 2.830.017 records in our Power BI report — but, with query folding in place, all necessary transformations were performed on the SQL database side, and the Mashup engine got an already prepared data set. While in the second scenario, after we broke the query folding, the Mashup engine pulled the whole remaining rows (approx. 11 million), and only after that was it able to apply other transformation steps. And, this was just a basic example, with one single table, and not so big in terms of data volume! Simply imagine the magnitude of implications on a larger dataset, with multiple tables in it. Conclusion Well, we covered a lot in this article. We learned about the data shaping concept, we introduced Power Query fundamentals, and we also learned what query folding is and why we should do our best to achieve it. I’ve also shared with you some basic examples and neat tricks on how to achieve query folding in some common use cases. In the end, please be aware that the query folding is a work in progress, and folks from the Power BI team are constantly improving this feature. So, it can happen that some of the issues with query folding I’ve shown you here are resolved in the meantime. Therefore, be sure to stay up to date with the latest improvements. Thanks for reading!",
         "en",
         "{'MISC': ['AD', 'According to Microsoft’', 'Additionally, there is a cool feature in Power Query Online', 'All or nothing?', 'And, the other one was the incorrect behavior of the View Native Query', 'As I said', 'As you can see in the illustration above', 'BLOB storage files', 'Data Shaping and why it is one of the key concepts in the data', 'Data Utopia” can', 'Data shaping can be done at different places', 'Data shaping is the process you should perform once you get familiar with your data', 'Data sources that', 'Data was loaded in batches of 100.000–150.000 records', 'Devil #1', 'Diagnose Step', 'DimCustomer table', 'Do you recognize the city in the following image', 'Dual', 'ETL', 'Exchange', 'FactInternet Sales and DimCustomer tables', 'Filtering rows', 'Finally', 'Fine…You’ve probably heard about the saying that the devil is in the details', 'For some data sources', 'Generally speaking', 'Group by', 'How do you know if the query folds?', 'I', 'I can realize that my query folds', 'I can see that the Mashup engine fired two separate queries to my underlying SQL', 'I don’t', 'I explained that when the Mashup engine can’t translate', 'I guess you are maybe confused with the word', 'I told you that when the View Native Query is greyed out', 'I want to preserve the top 2000 rows from my fact', 'I want to switch it to Date only', 'I will achieve', 'I will go back to Power Query Editor', 'I will see that the View Native Query', 'I will show you', 'I will show you later how this', 'I will show you soon what it depends', 'I will show you the exact numbers behind two', 'I will use the Adventure Works', 'I would like to expand on that in', 'If it’s greyed out', 'If you are working with DirectQuery', 'If you recognized yourself in', 'If you take a look at View Native Query', 'Image by author', 'Image by author But', 'Image by author Don’t pay attention to the SQL', 'Image by author However', 'Image by author Let’s check this in our Query Diagnostics tool: Image by author Oh', 'Image by author Looks', 'Image by author Now', 'Image by author Oh', 'Image by author Once I’ve applied this step and checked the View Native Query', 'Image by author The devil is in the details', 'Image by author The first thing to notice:', 'Image by author The key thing is that we will', 'Image by author The problem is that by default', 'Image by author To simplify', 'Image by author Truth to be said', 'Image by author …but let’s go to Diagnostics and check if that’s true', 'In my case', 'In the first example', 'In this scenario', 'It is based on traditional data warehousing principles of Extracting-Transforming-Loading', 'It will not break your incremental refresh “per-se”, but without query folding in place', 'It’s a well-known best practice to', 'It’s not an all-or-nothing process', 'I’ll show you', 'I’ll show you in the next part of the series one more example when View Native Query', 'I’ll use the FactOnlineSales table from the Contoso', 'I’ve also shared with you some basic', 'I’ve applied 9', 'Join function –', 'Keep that in mind', 'Let’', 'Let’s say that I want to combine two of my queries into one', 'Let’s turn on the stopwatch again and check what', 'Liar', 'Liar… I’ve promised in the previous part of the article that I will show you one more example when the View Native Query', 'M formula applied is: Table', 'M language', 'M language to SQL', 'Mashup engine', 'Mashup engine needs to retrieve all data from the source and then', 'Mashup engine to create', 'Maybe someone asked you', 'Merge Join This one is very interesting', 'Merging of foldable queries based on the same', 'MySQL', 'Now', 'OData', 'Ok', 'Ok, now we are not rookies anymore', 'On the other hand', 'Once you expand the drop-down', 'One', 'One of the most', 'Oracle', 'OrderDate column is of Date/Time', 'PROBABLY', 'Pivot and Unpivot', 'Power BI', 'Power BI engine', 'Power BI team are constantly improving this feature', 'Power Query', 'Power Query If you don’t perform data transformations on the source side', 'Power Query Online at this', 'Power Query fundamentals', 'Power Query is', 'Power Query is that you can perform complex data transformations with little or', 'Power Query leverages the capabilities of the', 'Power Query will generate', 'Query', 'Query folding As already mentioned', 'Query folding However', 'Query folding in Power BI', 'Query folding is', 'Query folding!', 'Query folding?', 'Removing columns Renaming', 'SQL', 'SQL Adding', 'SQL Adding index columns Changing', 'SQL Grouping and summarizing', 'SQL Server', 'SQL Server Profiler', 'SSAS', 'Sales Amount column', 'SharePoint', 'Simply imagine the magnitude of implications', 'So', 'Source Database —', 'Table', 'Takeover from this story: be careful', 'Thanks for reading!', 'That ability of Power Query’', 'That being said', 'That means if you have', 'The', 'The first and most obvious way is to right-click on the step and check what the View Native Query', 'The key thing to keep in mind is the word', 'The ultimate', 'This is the most obvious choice and in most cases the most desirable scenario', 'This time', 'Time): Image by author A few', 'TransformColumns', 'Under the hood of Power Query is a Mashup engine', 'Using M functions that', 'Very often, some subtle', 'WHERE should you perform data shaping?', 'We are now using Table', 'We know what query folding is', 'We learned about the data shaping concept', 'Well, in the previous sections', 'We’ve also started to scratch some interesting behaviors of Power Query', 'Whaaaat', 'What does simple logic mean?', 'What is a', 'When I said', 'When you’re using', 'Which one of these three names is correct', 'While in the second scenario', 'Why is it happening', 'Why should you care about Query folding', 'With all these in mind', 'above with changing Date/Time type to Date', 'after we broke the query folding', 'all necessary transformations were performed on the SQL database side', 'all your transformations MUST fold — or your solution will not work', 'and Entra ID', 'and I need', 'and all of them are foldable', 'and let’s now check the outcome', 'and select Date type', 'and that means that query didn’t fold!', 'and the Mashup engine got an already prepared data set', 'and we also learned what query folding is and why we should do our best to achieve it', 'and your query folding is broken in the 5th step', 'and your query folds until the 6th step', 'as first two steps will fold', 'as my transformation was', 'based on the same', 'basic', 'batches of loaded data were between 10.000 and 20.000 records', 'between the queries that return exactly the same results — one of them folds', 'both in terms of refresh speed and resource consumption', 'but all', 'but once the folding is broken', 'each of those: In the Applied Steps pane', 'everything is perfect and everyone is satisfied', 'folding actually occurs', 'folding in general', 'high-quality data that just flies into our reports “as-is”', 'it’', 'it’s the built-in tool within Power BI', 'just to be clear', 'let me now pull my last ace up my sleeve!', 'let me show you one subtle', 'let’s call it “Data Utopia', 'let’s say', 'let’s say that I want to apply', 'let’s walk through all the things that happened now: Instead of the Changed Type step', 'lies & ultimate', 'like I did in the illustration', 'like a good old and reliable way to check the queries', 'one folds', 'one of the key concepts that we have to absorb is Data Shaping', 'one would perform data shaping before the data goes into the report itself', 'our query so hard that it couldn’t be', 'our transformation to a T', 'please be aware that the query folding is', 'query', 'query folding', 'query folding at the 3rd step', 'query folding by default in steps 6 to 10 —', 'query folding doesn’t necessarily mean that your query', 'query folding has nothing to do with it!', 'query folding is also of key importance for Incremental refresh — it’s so important that Power BI will warn you once it determines that query folding can’t be achieved', 'query folding?', 'so let’s hope that the Power BI', 'that are built to cope with large volumes of data in the most efficient way', 'that enables you to perform all kinds of transformations to your data', 'that enables your data shaping to run smoothly', 'that means it will work if you are joining two SQL', 'that means that your query will fold', 'the Mashup engine is able to “translate” M language to a language that the underlying data source will “understand” — in most cases', 'the Mashup engine pulled the whole remaining rows', 'the View Native Query', 'the data refresh process', 'the first one was', 'the query can’t fold', 'the road to hell is paved with good intentions:)', 'the same as in the previous', 'this step indeed folded!', 'this transformation easily folds', 'to', 'transformations on the whole chunk of imported data!', 'using the transformation for which I know that is not foldable', 'we choose the column on which we want to perform', 'we now have a step called', 'we say that the query folds', 'what does all this story about data shaping', 'what is happening in the background', 'what’s even more concerning —', 'when we knew that SQL has an ABS function to', 'which are equivalent to SQL’', 'which is a good indicator that the query folding is in place', 'which we were able to solve by tweaking the automatically generated M', 'which will put the Query folding feature in the', 'why it is important to achieve this behavior — or', 'why we should strive to achieve it, and some subtle tricks that can', 'with one single table', 'with query folding in place', 'with static values or', 'word in the M formula', 'you are not getting the most optimal', 'you can', 'you can notice that our transformation step had been recorded In the column itself', 'you can see that the Mashup engine nicely', 'you can see that the time portion disappeared When I’ve opened', 'you can see that the total number of records loaded', 'you can see the Date Only transformation', 'you can use the Query Diagnostics feature within Power Query Editor', 'you define what data you want to extract', 'your query', 'your query doesn’t fold'], 'PER': ['Appending foldable', 'Essentially', 'However', 'I will', 'I’ll remove some of the columns from my fact table', 'Merging', 'Then', 'Thomas More', 'as you can see in the following illustration', 'as you can’t be 100', 'as you will hardly', 'depending on where you', 'do you want to perform currency conversion', 'even if you have transformations that', 'if you don’t need hours', 'if you have 10 transformation', 'nested', 'this step probably does not fold', 'when you', 'which can’t be properly', 'why should you care if the query folds or not?', 'why you should strive to achieve query folding', 'without needing to perform any kind of face', 'you could write much more', 'you decide if your data needs to be transformed along the way', 'you should be better off getting rid of them and changing the data', 'you should investigate your Power Query', 'you should tend to achieve query folding whenever', 'you will get incorrect results —', 'you will still get some benefit from partial'], 'LOC': ['NYC', 'New York', 'TransformColumnTypes', 'and', 'and New York City will be treated as a separate entity'], 'ORG': ['Essentially', 'Instead', 'MERGE', 'Therefore', 'Those', 'Yes', 'You', 'and THEN', 'let’', 'without any additional steps before merging']}",
         "[-0.07877665013074875, 0.02790583297610283, -0.03321076184511185, 0.08309657871723175, -0.07759767770767212, -0.06370820850133896, 0.03700629249215126, 0.039850253611803055, -0.05383705347776413, 0.06566652655601501, -0.03243347629904747, 0.06887571513652802, 0.07103616744279861, -0.05410243198275566, 0.046625085175037384, 0.09003377705812454, -0.017642347142100334, 0.018265537917613983, -0.07342702150344849, 0.027475038543343544, 0.09200933575630188, -0.024503476917743683, -0.05698972940444946, -0.0016691237688064575, -0.0092188511043787, 0.06751169264316559, 0.03297216445207596, -0.08185552060604095, 0.03519072383642197, -0.029679827392101288, -0.019781066104769707, 0.08429978042840958, 0.010438300669193268, 0.07341167330741882, 0.01089673861861229, 0.032974231988191605, 0.03835398703813553, 0.020613055676221848, -0.013904723338782787, -0.009912745095789433, 0.037663768976926804, -0.024798600003123283, -0.0376751571893692, -0.010178935714066029, -0.02701829932630062, 0.022778326645493507, -0.030370082706212997, -0.0030966773629188538, -0.05261002853512764, -0.008516410365700722, -0.1312040537595749, -0.011070921085774899, -0.023220732808113098, 0.03752527013421059, 0.018159478902816772, 0.02207202836871147, -0.043023400008678436, 0.012330637313425541, -0.04276442155241966, 0.043524403125047684, -0.04200705140829086, -0.08337155729532242, -0.0053403740748763084, 0.03993711248040199, 0.09471198171377182, 0.004405354615300894, 0.04930965229868889, 0.03548219054937363, 0.02071877010166645, -0.011361844837665558, -0.06984712928533554, 0.020972061902284622, -0.07914447039365768, 0.0030734362080693245, 0.01364002376794815, 0.021235600113868713, -0.02558307908475399, -0.0945727750658989, 0.026852188631892204, 0.05032561346888542, 0.02147722989320755, 0.020575199276208878, -0.028053347021341324, 0.07262776046991348, 0.016097765415906906, -0.04693588614463806, 0.038780637085437775, -0.12229220569133759, 0.03776383027434349, -0.041062384843826294, -0.055465131998062134, 0.016950970515608788, -0.04231448471546173, 0.061268195509910583, -0.036909062415361404, 0.03517621010541916, 0.03474500775337219, -0.06408372521400452, 0.10848823934793472, 0.029180603101849556, 0.05185191333293915, 0.1592334806919098, 0.019939402118325233, -0.018511833623051643, -0.07319443672895432, -0.1306481510400772, 0.022797511890530586, 0.04302694648504257, -0.051831167191267014, -0.02029717154800892, -0.01618395745754242, -0.007859277538955212, 0.05737874284386635, -0.09568653255701065, -0.003245750442147255, -0.008020483888685703, -0.009236735291779041, 5.104468436911702e-05, -0.04349951073527336, -0.005393635481595993, 0.006418222561478615, 0.09309320896863937, -0.021485356613993645, 0.045061465352773666, 0.0419408455491066, -0.010827695019543171, -0.06264328211545944, 1.6714488254166497e-33, 0.01753735914826393, 0.07480321079492569, 0.03175739943981171, 0.036438871175050735, -0.0038886212278157473, -0.005983167793601751, -0.060287706553936005, -0.010212558321654797, -0.0598299503326416, 0.14331012964248657, 0.022073786705732346, 0.07150866836309433, 0.018552429974079132, 0.023643549531698227, 0.043097373098134995, -0.04554335027933121, -0.04991995543241501, 0.07667898386716843, -0.059500254690647125, -0.004785496275871992, 0.054621703922748566, 0.00543452613055706, 0.07199004292488098, 0.015541044063866138, 0.03212926909327507, -0.008810855448246002, -0.07240845263004303, 0.018168466165661812, 0.029130492359399796, -1.2066947419953067e-05, -0.1235947385430336, 0.0033844527788460255, -0.08435510843992233, -0.03470674157142639, -0.0017431414453312755, 0.0266153234988451, 0.0014171261573210359, -0.05085957422852516, -0.007121681235730648, 0.08282026648521423, -0.010586024262011051, 0.047328539192676544, 0.03827297315001488, -0.022534186020493507, -0.04962527006864548, -0.03531022369861603, 0.060071881860494614, 0.020871369168162346, -0.08624647557735443, -0.028527848422527313, 0.007723721209913492, -0.012890953570604324, 0.0004052476433571428, -0.03237346187233925, 0.034181077033281326, -0.0033257422037422657, 0.057778406888246536, -0.03783206641674042, 0.0230756513774395, 0.11611349880695343, -0.04062655568122864, -0.04838249832391739, -0.04799565672874451, -0.01976853422820568, 0.02610473707318306, -0.028951255604624748, 0.04435143992304802, 0.014532286673784256, 0.09426507353782654, -0.03126158565282822, 0.012797616422176361, 0.03202124312520027, -0.09534727036952972, -0.04748046025633812, 0.03001570515334606, -0.0040289489552378654, 0.011912058107554913, 0.02256316877901554, 0.0020918529480695724, -0.009582851082086563, 0.01596725545823574, -0.04156789556145668, 0.027593562379479408, -0.041321445256471634, -0.001930620172061026, -0.02152945287525654, 0.09557140618562698, -0.02307884208858013, -0.07659696042537689, -0.05486142635345459, -0.08920737355947495, 0.007392391096800566, 0.03755699843168259, -0.06522972136735916, 0.022863533347845078, -1.3427164119149237e-33, 0.01572507992386818, -0.07544006407260895, -0.037930797785520554, 0.069759301841259, -0.023869210854172707, -0.045807451009750366, -0.009120723232626915, -0.04516412690281868, -0.040707118809223175, -0.07648420333862305, -0.07282623648643494, -0.05632835999131203, 0.12624359130859375, -0.0698264017701149, -0.005543391220271587, 0.04259152337908745, 0.035173624753952026, -0.0787971168756485, -0.05588806793093681, 0.0921989232301712, -0.01908397488296032, 0.0646192729473114, -0.14157429337501526, 0.010446271859109402, -0.00016632983169984072, 0.03794174641370773, -0.061146628111600876, 0.0218201931566, 0.08203528821468353, 0.05573881417512894, -0.052427034825086594, -0.16230975091457367, -0.001890073879621923, -0.039251916110515594, -0.06529075652360916, 0.017756709828972816, 0.012503614649176598, -0.04519946500658989, 0.045494891703128815, -0.009812596254050732, -0.04337385669350624, 0.02374429441988468, -0.08140292763710022, 0.02727978117763996, 0.04069523513317108, -0.06273751705884933, -0.0701598972082138, 0.06733132153749466, -0.040025074034929276, -0.024390768259763718, 0.024409940466284752, 0.06695842742919922, 0.01640898734331131, 0.03441310301423073, -0.0323358029127121, -0.006711860653012991, -0.026480551809072495, -0.0010632779449224472, -0.017653176560997963, 0.04107757285237312, -0.04201241582632065, 0.049603261053562164, -0.017283836379647255, -0.010377955622971058, 0.0006933378172107041, -0.05685323476791382, 0.05753016099333763, -0.07609623670578003, -0.03805002570152283, -0.0560932382941246, -0.047418948262929916, -0.069914311170578, 0.03386147320270538, -0.04304886609315872, 0.07241983711719513, 0.04117080196738243, 0.011000581085681915, 0.035646289587020874, 0.03372133895754814, 0.07030579447746277, -0.017460336908698082, 0.003198872320353985, 0.05888514593243599, 0.06785620748996735, -0.0050735208205878735, 0.05896378308534622, -0.009907841682434082, -0.00778020778670907, 0.04529895260930061, -0.021867096424102783, -0.04554753005504608, -0.10225953161716461, -0.0719633400440216, 0.0925263836979866, -0.018686816096305847, -5.6695359518244004e-08, -0.04404886066913605, 0.022466259077191353, -0.006787426304072142, 0.07411316782236099, 0.1084202229976654, -0.02822989784181118, 0.05396805331110954, 0.10131332278251648, -0.07230827212333679, -0.029116123914718628, 0.07995498925447464, 0.02235928177833557, -0.019099298864603043, 0.03193218261003494, 0.11082448810338974, -0.033864397555589676, 0.05273420736193657, 0.042698293924331665, -0.05804198607802391, 0.02537633292376995, -0.04246086627244949, 0.0015281866071745753, -0.02110040746629238, -0.03264607861638069, 0.09487807750701904, 0.018227526918053627, -0.03699979558587074, -0.0050655812956392765, 0.06615078449249268, 0.004705451894551516, -0.033969536423683167, -0.03205711022019386, 0.032716695219278336, 0.0333080030977726, 0.027618851512670517, -0.03496721386909485, 0.0018335196655243635, 0.04239320382475853, -0.04262961447238922, -0.019757051020860672, 0.10839416086673737, 0.10430846363306046, -0.0533122718334198, 0.06946376711130142, -0.021420918405056, 0.003876521484926343, 0.04039885476231575, -0.0017164541641250253, 0.04283514618873596, 0.020492980256676674, -0.018847264349460602, -0.05056389793753624, 0.03783884644508362, -0.008685518987476826, 0.00380017701536417, 0.045948326587677, 0.03133103996515274, 0.0867355614900589, -0.05190766230225563, 0.010698402300477028, 0.03976399078965187, -0.03911810368299484, -0.06825415045022964, 0.01615450531244278]",
         "0.119"
        ],
        [
         "10",
         "35",
         "Canva Review 2022: Details, Pricing & Features",
         "Are you looking for a new graphic design tool? Would you like to read a detailed review of Canva? As it's one of the tools I love using. I am also writing my first ebook using canva and publish it soon on my site you can download it is free. Let's start the review. Canva has a web version and also a mobile app What is Canva ? Canva is a free graphic design web application that allows you to create invitations, business cards , flyers, lesson plans, banners, and more using professionally designed templates. You can upload your own photos from your computer or from Google Drive, and add them to Canva's templates using a simple drag-and-drop interface. It's like having a basic version of Photoshop that doesn't require Graphic designing knowledge to use. It’s best for nongraphic designers. Who is Canva best suited for? Canva is a great tool for small business owners, online entrepreneurs, and marketers who don’t have the time and want to edit quickly. To create sophisticated graphics, a tool such as Photoshop can is ideal. To use it, you’ll need to learn its hundreds of features, get familiar with the software, and it’s best to have a good background in design, too. Also running the latest version of Photoshop you need a high-end computer. So here Canva takes place, with Canva you can do all that with drag-and-drop feature. It’s also easier to use and free. Also an even-more-affordable paid version is available for $12.95 per month. Free vs Pro vs Enterprise Pricing plan The product is available in three plans: Free, Pro ($12.99/month per user or $119.99/year for up to 5 people), and Enterprise ($30 per user per month, minimum 25 people). Free plan Features 250,000+ free templates 100+ design types (social media posts, presentations, letters, and more) Hundreds of thousands of free photos and graphics Invite members to your team Collaborate and comment in real-time 5GB of cloud storage Try Canva Pro for free for 30 days Pro Plan Features Everything Free, has plus: 100+ million premium and stock photos, videos, audio, and graphics 610,000+ premium and free templates with new designs daily Access to Background Remover and Magic Resize Create a library of your brand or campaign's colors, logos, and fonts with up to 100 Brand Kits Remove image backgrounds instantly with background remover Resize designs infinitely with Magic Resize Save designs as templates for your team to use 100GB of cloud storage Schedule social media content to 8 platforms Enterprise Plan Features Everything Pro has plus: Establish your brand's visual identity with logos, colors and fonts across multiple Brand Kits Control your team's access to apps, graphics, logos, colors and fonts with brand controls Built-in workflows to get approval on your designs Set which elements your team can edit and stay on brand with template locking Unlimited Storage Log in with single-sign on (SSO) and have access to 24/7 Enterprise-level support. How to Use Canva? To get started on Canva, you will need to create an account by providing your email address, Google, Facebook or Apple credentials. You will then choose your account type between student, teacher, small business, large company, non-profit, or personal. Based on your choice of account type, templates will be recommended to you. You can sign up for a free trial of Canva Pro, or you can start with the free version to get a sense of whether it’s the right graphic design tool for your needs. Canva Sign Up Designing with Canva When you sign up for an account, Canva will suggest different post types to choose from. Based on the type of account you set up you'll be able to see templates categorized by the following categories: social media posts, documents, presentations, marketing, events, ads, launch your business, build your online brand, etc. Start by choosing a template for your post or searching for something more specific. Search by social network name to see a list of post types on each network. Templates Next, you can choose a template. Choose from hundreds of templates that are ready to go, with customizable photos, text, and other elements. You can start your design by choosing from a variety of ready-made templates, searching for a template matching your needs, or working with a blank template. Canva has a lot to choose from, so start with a specific search.if you want to create business card just search for it and you will see alot of templates to choose from Elements Inside the Canva designer, the Elements tab gives you access to lines and shapes, graphics, photos, videos, audio, charts, photo frames, and photo grids.The search box on the Elements tab lets you search everything on Canva. To begin with, Canva has a large library of elements to choose from. To find them, be specific in your search query. You may also want to search in the following tabs to see various elements separately: Photos The Photos tab lets you search for and choose from millions of professional stock photos for your templates. You can replace the photos in our templates to create a new look. This can also make the template more suited to your industry. You can find photos on other stock photography sites like pexel, pixabay and many more or simply upload your own photos. When you choose an image, Canva’s photo editing features let you adjust the photo’s settings (brightness, contrast, saturation, etc.), crop, or animate it. When you subscribe to Canva Pro, you get access to a number of premium features, including the Background Remover. This feature allows you to remove the background from any stock photo in library or any image you upload. Text The Text tab lets you add headings, normal text, and graphical text to your design. When you click on text, you'll see options to adjust the font, font size, color, format, spacing, and text effects (like shadows). Canva Pro subscribers can choose from a large library of fonts on the Brand Kit or the Styles tab. Enterprise-level controls ensure that visual content remains on-brand, no matter how many people are working on it. Audio Create an animated image or video by adding audio to capture user’s attention in social news feeds. If you want to use audio from another stock site or your own audio tracks, you can upload them in the Uploads tab or from the more option. Video Want to create your own videos? Choose from thousands of stock video clips. You’ll find videos that range upto 2 minutes You can upload your own videos as well as videos from other stock sites in the Uploads tab. Once you have chosen a video, you can use the editing features in Canva to trim the video, flip it, and adjust its transparency. Backgrounds On the Background tab, you’ll find free stock photos to serve as backgrounds on your designs. Change out the background on a template to give it a more personal touch. Styles The Styles tab lets you quickly change the look and feel of your template with just a click. And if you have a Canva Pro subscription, you can upload your brand’s custom colors and fonts to ensure designs stay on brand. Logos If you have a Canva Pro subscription, you’ll have a Logos tab. Here, you can upload variations of your brand logo to use throughout your designs. With Canva, you can also create your own logos. Note that you cannot trademark a logo with stock content in it. Publishing with Canva With Canva, free users can download and share designs to multiple platforms including Instagram, Facebook, Twitter, LinkedIn, Pinterest, Slack and Tumblr. Canva Pro subscribers can create multiple post formats from one design. For example, you can start by designing an Instagram post, and Canva's Magic Resizer can resize it for other networks, Stories, Reels, and other formats. Canva Pro subscribers can also use Canva’s Content Planner to post content on eight different accounts on Instagram, Facebook, Twitter, LinkedIn, Pinterest, Slack, and Tumblr. Canva Team Canva Pro allows you to work with your team on visual content. Designs can be created inside Canva, and then sent to your team members for approval. Everyone can make comments, edits, revisions, and keep track via the version history. Canva Print When it comes to printing your designs, Canva has you covered. With an extensive selection of printing options, they can turn your designs into anything from banners and wall art to mugs and t-shirts. Canva Print is perfect for any business seeking to make a lasting impression. Create inspiring designs people will want to wear, keep, and share. Hand out custom business cards that leave a lasting impression on customers' minds. Canva Apps The Canva app is available on the Apple App Store and Google Play. The Canva app has earned a 4.9 out of five star rating from over 946.3K Apple users and a 4.5 out of five star rating from over 6,996,708 Google users. In addition to mobile apps, you can use Canva’s integration with other Internet services to add images and text from sources like Google Maps, Emojis, photos from Google Drive and Dropbox, YouTube videos, Flickr photos, Bitmojis, and other popular visual content elements. Canva Pros and Cons Pros: A user-friendly interface Canva is a great tool for people who want to create professional graphics but don’t have graphic design skills. Hundreds of templates, so you'll never have to start from scratch. Wide variety of templates to fit multiple uses Branding kits to keep your team consistent with the brand colors and fonts Creating visual content on the go You can find royalty free images, audio, and video without having to subscribe to another service. Cons: Some professional templates are available for Pro user only Advanced photo editing features like blurring or erasing a specific area are missing. Some elements that fall outside of a design are tricky to retrieve. Features (like Canva presentations) could use some improvement. If you are a regular user of Adobe products, you might find Canva's features limited. Prefers to work with vectors. Especially logos. Expensive enterprise pricing Conclusion In general, Canva is an excellent tool for those who need simple images for projects. If you are a graphic designer with experience, you will find Canva’s platform lacking in customization and advanced features – particularly vectors. But if you have little design experience, you will find Canva easier to use than advanced graphic design tools like Adobe Photoshop or Illustrator for most projects. If you have any queries let me know in the comments section.",
         "Are you looking for a new graphic design tool? Would you like to read a detailed review of Canva? As it's one of the tools I love using. I am also writing my first ebook using canva and publish it soon on my site you can download it is free. Let's start the review.\n\nCanva has a web version and also a mobile app\n\nWhat is Canva\n\nCanva is a free graphic design web application that allows you to create invitations, business cards, flyers, lesson plans, banners, and more using professionally designed templates. You can upload your own photos from your computer or from Google Drive, and add them to Canva's templates using a simple drag-and-drop interface. It's like having a basic version of Photoshop that doesn't require Graphic designing knowledge to use. It’s best for nongraphic designers.\n\nWho is Canva best suited for?\n\nCanva is a great tool for small business owners, online entrepreneurs, and marketers who don’t have the time and want to edit quickly.\n\nTo create sophisticated graphics, a tool such as Photoshop can is ideal. To use it, you’ll need to learn its hundreds of features, get familiar with the software, and it’s best to have a good background in design, too.\n\nAlso running the latest version of Photoshop you need a high-end computer.\n\nSo here Canva takes place, with Canva you can do all that with drag-and-drop feature. It’s also easier to use and free. Also an even-more-affordable paid version is available for $12.95 per month.\n\nFree vs Pro vs Enterprise Pricing plan\n\nThe product is available in three plans: Free, Pro ($12.99/month per user or $119.99/year for up to 5 people), and Enterprise ($30 per user per month, minimum 25 people).\n\nFree plan Features\n\n250,000+ free templates\n\n100+ design types (social media posts, presentations, letters, and more)\n\nHundreds of thousands of free photos and graphics\n\nInvite members to your team\n\nCollaborate and comment in real-time\n\n5GB of cloud storage\n\nTry Canva Pro for free for 30 days\n\nPro Plan Features\n\nEverything Free, has plus:\n\n100+ million premium and stock photos, videos, audio, and graphics\n\n610,000+ premium and free templates with new designs daily\n\nAccess to Background Remover and Magic Resize\n\nCreate a library of your brand or campaign's colors, logos, and fonts with up to 100 Brand Kits\n\nRemove image backgrounds instantly with background remover\n\nResize designs infinitely with Magic Resize\n\nSave designs as templates for your team to use\n\n100GB of cloud storage\n\nSchedule social media content to 8 platforms\n\nEnterprise Plan Features\n\nEverything Pro has plus:\n\nEstablish your brand's visual identity with logos, colors and fonts across multiple Brand Kits\n\nControl your team's access to apps, graphics, logos, colors and fonts with brand controls\n\nBuilt-in workflows to get approval on your designs\n\nSet which elements your team can edit and stay on brand with template locking\n\nUnlimited Storage\n\nLog in with single-sign on (SSO) and have access to 24/7 Enterprise-level support.\n\nHow to Use Canva?\n\nTo get started on Canva, you will need to create an account by providing your email address, Google, Facebook or Apple credentials. You will then choose your account type between student, teacher, small business, large company, non-profit, or personal. Based on your choice of account type, templates will be recommended to you.\n\nYou can sign up for a free trial of Canva Pro, or you can start with the free version to get a sense of whether it’s the right graphic design tool for your needs.\n\nDesigning with Canva\n\nWhen you sign up for an account, Canva will suggest different post types to choose from. Based on the type of account you set up you'll be able to see templates categorized by the following categories: social media posts, documents, presentations, marketing, events, ads, launch your business, build your online brand, etc.\n\nStart by choosing a template for your post or searching for something more specific. Search by social network name to see a list of post types on each network.\n\nTemplates\n\nNext, you can choose a template. Choose from hundreds of templates that are ready to go, with customizable photos, text, and other elements.\n\nYou can start your design by choosing from a variety of ready-made templates, searching for a template matching your needs, or working with a blank template.\n\n\n\nCanva has a lot to choose from, so start with a specific search.if you want to create business card just search for it and you will see alot of templates to choose from\n\nElements\n\nInside the Canva designer, the Elements tab gives you access to lines and shapes, graphics, photos, videos, audio, charts, photo frames, and photo grids.The search box on the Elements tab lets you search everything on Canva.\n\n\n\n\n\nTo begin with, Canva has a large library of elements to choose from. To find them, be specific in your search query. You may also want to search in the following tabs to see various elements separately:\n\nPhotos\n\nThe Photos tab lets you search for and choose from millions of professional stock photos for your templates.\n\nYou can replace the photos in our templates to create a new look. This can also make the template more suited to your industry.\n\nYou can find photos on other stock photography sites like pexel, pixabay and many more or simply upload your own photos.\n\n\n\n\n\nWhen you choose an image, Canva’s photo editing features let you adjust the photo’s settings (brightness, contrast, saturation, etc.), crop, or animate it.\n\nWhen you subscribe to Canva Pro, you get access to a number of premium features, including the Background Remover. This feature allows you to remove the background from any stock photo in library or any image you upload.\n\nText\n\nThe Text tab lets you add headings, normal text, and graphical text to your design.\n\nWhen you click on text, you'll see options to adjust the font, font size, color, format, spacing, and text effects (like shadows).\n\nCanva Pro subscribers can choose from a large library of fonts on the Brand Kit or the Styles tab. Enterprise-level controls ensure that visual content remains on-brand, no matter how many people are working on it.\n\nAudio\n\nCreate an animated image or video by adding audio to capture user’s attention in social news feeds.\n\nIf you want to use audio from another stock site or your own audio tracks, you can upload them in the Uploads tab or from the more option.\n\nVideo\n\nWant to create your own videos? Choose from thousands of stock video clips. You’ll find videos that range upto 2 minutes\n\nYou can upload your own videos as well as videos from other stock sites in the Uploads tab.\n\nOnce you have chosen a video, you can use the editing features in Canva to trim the video, flip it, and adjust its transparency.\n\nBackgrounds\n\nOn the Background tab, you’ll find free stock photos to serve as backgrounds on your designs. Change out the background on a template to give it a more personal touch.\n\nStyles\n\nThe Styles tab lets you quickly change the look and feel of your template with just a click. And if you have a Canva Pro subscription, you can upload your brand’s custom colors and fonts to ensure designs stay on brand.\n\nLogos\n\nIf you have a Canva Pro subscription, you’ll have a Logos tab. Here, you can upload variations of your brand logo to use throughout your designs.\n\nWith Canva, you can also create your own logos. Note that you cannot trademark a logo with stock content in it.\n\nPublishing with Canva\n\nWith Canva, free users can download and share designs to multiple platforms including Instagram, Facebook, Twitter, LinkedIn, Pinterest, Slack and Tumblr.\n\nCanva Pro subscribers can create multiple post formats from one design. For example, you can start by designing an Instagram post, and Canva's Magic Resizer can resize it for other networks, Stories, Reels, and other formats.\n\nCanva Pro subscribers can also use Canva’s Content Planner to post content on eight different accounts on Instagram, Facebook, Twitter, LinkedIn, Pinterest, Slack, and Tumblr.\n\nCanva Team\n\nCanva Pro allows you to work with your team on visual content. Designs can be created inside Canva, and then sent to your team members for approval. Everyone can make comments, edits, revisions, and keep track via the version history.\n\nCanva Print\n\nWhen it comes to printing your designs, Canva has you covered. With an extensive selection of printing options, they can turn your designs into anything from banners and wall art to mugs and t-shirts.\n\nCanva Print is perfect for any business seeking to make a lasting impression. Create inspiring designs people will want to wear, keep, and share. Hand out custom business cards that leave a lasting impression on customers' minds.\n\nCanva Apps\n\nThe Canva app is available on the Apple App Store and Google Play. The Canva app has earned a 4.9 out of five star rating from over 946.3K Apple users and a 4.5 out of five star rating from over 6,996,708 Google users.\n\nIn addition to mobile apps, you can use Canva’s integration with other Internet services to add images and text from sources like Google Maps, Emojis, photos from Google Drive and Dropbox, YouTube videos, Flickr photos, Bitmojis, and other popular visual content elements.\n\nCanva Pros and Cons\n\nPros:\n\nA user-friendly interface\n\nCanva is a great tool for people who want to create professional graphics but don’t have graphic design skills.\n\nHundreds of templates, so you'll never have to start from scratch.\n\nWide variety of templates to fit multiple uses\n\nBranding kits to keep your team consistent with the brand colors and fonts\n\nCreating visual content on the go\n\nYou can find royalty free images, audio, and video without having to subscribe to another service.\n\nCons:\n\nSome professional templates are available for Pro user only\n\nAdvanced photo editing features like blurring or erasing a specific area are missing.\n\nSome elements that fall outside of a design are tricky to retrieve.\n\nFeatures (like Canva presentations) could use some improvement.\n\nIf you are a regular user of Adobe products, you might find Canva's features limited.\n\nPrefers to work with vectors. Especially logos.\n\nExpensive enterprise pricing\n\nConclusion\n\nIn general, Canva is an excellent tool for those who need simple images for projects. If you are a graphic designer with experience, you will find Canva’s platform lacking in customization and advanced features – particularly vectors. But if you have little design experience, you will find Canva easier to use than advanced graphic design tools like Adobe Photoshop or Illustrator for most projects. If you have any queries let me know in the comments section.",
         "2022-02-20T12:02:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/02/canva-review-2022-details-pricing.html",
         "2025-07-26T05:41:35.885977",
         "Are you looking for a new graphic design tool? Would you like to read a detailed review of Canva? As it's one of the tools I love using. I am also writing my first ebook using canva and publish it soon on my site you can download it is free. Let's start the review. Canva has a web version and also a mobile app What is Canva Canva is a free graphic design web application that allows you to create invitations, business cards, flyers, lesson plans, banners, and more using professionally designed templates. You can upload your own photos from your computer or from Google Drive, and add them to Canva's templates using a simple drag-and-drop interface. It's like having a basic version of Photoshop that doesn't require Graphic designing knowledge to use. It’s best for nongraphic designers. Who is Canva best suited for? Canva is a great tool for small business owners, online entrepreneurs, and marketers who don’t have the time and want to edit quickly. To create sophisticated graphics, a tool such as Photoshop can is ideal. To use it, you’ll need to learn its hundreds of features, get familiar with the software, and it’s best to have a good background in design, too. Also running the latest version of Photoshop you need a high-end computer. So here Canva takes place, with Canva you can do all that with drag-and-drop feature. It’s also easier to use and free. Also an even-more-affordable paid version is available for $12.95 per month. Free vs Pro vs Enterprise Pricing plan The product is available in three plans: Free, Pro ($12.99/month per user or $119.99/year for up to 5 people), and Enterprise ($30 per user per month, minimum 25 people). Free plan Features 250,000+ free templates 100+ design types (social media posts, presentations, letters, and more) Hundreds of thousands of free photos and graphics Invite members to your team Collaborate and comment in real-time 5GB of cloud storage Try Canva Pro for free for 30 days Pro Plan Features Everything Free, has plus: 100+ million premium and stock photos, videos, audio, and graphics 610,000+ premium and free templates with new designs daily Access to Background Remover and Magic Resize Create a library of your brand or campaign's colors, logos, and fonts with up to 100 Brand Kits Remove image backgrounds instantly with background remover Resize designs infinitely with Magic Resize Save designs as templates for your team to use 100GB of cloud storage Schedule social media content to 8 platforms Enterprise Plan Features Everything Pro has plus: Establish your brand's visual identity with logos, colors and fonts across multiple Brand Kits Control your team's access to apps, graphics, logos, colors and fonts with brand controls Built-in workflows to get approval on your designs Set which elements your team can edit and stay on brand with template locking Unlimited Storage Log in with single-sign on (SSO) and have access to 24/7 Enterprise-level support. How to Use Canva? To get started on Canva, you will need to create an account by providing your email address, Google, Facebook or Apple credentials. You will then choose your account type between student, teacher, small business, large company, non-profit, or personal. Based on your choice of account type, templates will be recommended to you. You can sign up for a free trial of Canva Pro, or you can start with the free version to get a sense of whether it’s the right graphic design tool for your needs. Designing with Canva When you sign up for an account, Canva will suggest different post types to choose from. Based on the type of account you set up you'll be able to see templates categorized by the following categories: social media posts, documents, presentations, marketing, events, ads, launch your business, build your online brand, etc. Start by choosing a template for your post or searching for something more specific. Search by social network name to see a list of post types on each network. Templates Next, you can choose a template. Choose from hundreds of templates that are ready to go, with customizable photos, text, and other elements. You can start your design by choosing from a variety of ready-made templates, searching for a template matching your needs, or working with a blank template. Canva has a lot to choose from, so start with a specific search.if you want to create business card just search for it and you will see alot of templates to choose from Elements Inside the Canva designer, the Elements tab gives you access to lines and shapes, graphics, photos, videos, audio, charts, photo frames, and photo grids.The search box on the Elements tab lets you search everything on Canva. To begin with, Canva has a large library of elements to choose from. To find them, be specific in your search query. You may also want to search in the following tabs to see various elements separately: Photos The Photos tab lets you search for and choose from millions of professional stock photos for your templates. You can replace the photos in our templates to create a new look. This can also make the template more suited to your industry. You can find photos on other stock photography sites like pexel, pixabay and many more or simply upload your own photos. When you choose an image, Canva’s photo editing features let you adjust the photo’s settings (brightness, contrast, saturation, etc.), crop, or animate it. When you subscribe to Canva Pro, you get access to a number of premium features, including the Background Remover. This feature allows you to remove the background from any stock photo in library or any image you upload. Text The Text tab lets you add headings, normal text, and graphical text to your design. When you click on text, you'll see options to adjust the font, font size, color, format, spacing, and text effects (like shadows). Canva Pro subscribers can choose from a large library of fonts on the Brand Kit or the Styles tab. Enterprise-level controls ensure that visual content remains on-brand, no matter how many people are working on it. Audio Create an animated image or video by adding audio to capture user’s attention in social news feeds. If you want to use audio from another stock site or your own audio tracks, you can upload them in the Uploads tab or from the more option. Video Want to create your own videos? Choose from thousands of stock video clips. You’ll find videos that range upto 2 minutes You can upload your own videos as well as videos from other stock sites in the Uploads tab. Once you have chosen a video, you can use the editing features in Canva to trim the video, flip it, and adjust its transparency. Backgrounds On the Background tab, you’ll find free stock photos to serve as backgrounds on your designs. Change out the background on a template to give it a more personal touch. Styles The Styles tab lets you quickly change the look and feel of your template with just a click. And if you have a Canva Pro subscription, you can upload your brand’s custom colors and fonts to ensure designs stay on brand. Logos If you have a Canva Pro subscription, you’ll have a Logos tab. Here, you can upload variations of your brand logo to use throughout your designs. With Canva, you can also create your own logos. Note that you cannot trademark a logo with stock content in it. Publishing with Canva With Canva, free users can download and share designs to multiple platforms including Instagram, Facebook, Twitter, LinkedIn, Pinterest, Slack and Tumblr. Canva Pro subscribers can create multiple post formats from one design. For example, you can start by designing an Instagram post, and Canva's Magic Resizer can resize it for other networks, Stories, Reels, and other formats. Canva Pro subscribers can also use Canva’s Content Planner to post content on eight different accounts on Instagram, Facebook, Twitter, LinkedIn, Pinterest, Slack, and Tumblr. Canva Team Canva Pro allows you to work with your team on visual content. Designs can be created inside Canva, and then sent to your team members for approval. Everyone can make comments, edits, revisions, and keep track via the version history. Canva Print When it comes to printing your designs, Canva has you covered. With an extensive selection of printing options, they can turn your designs into anything from banners and wall art to mugs and t-shirts. Canva Print is perfect for any business seeking to make a lasting impression. Create inspiring designs people will want to wear, keep, and share. Hand out custom business cards that leave a lasting impression on customers' minds. Canva Apps The Canva app is available on the Apple App Store and Google Play. The Canva app has earned a 4.9 out of five star rating from over 946.3K Apple users and a 4.5 out of five star rating from over 6,996,708 Google users. In addition to mobile apps, you can use Canva’s integration with other Internet services to add images and text from sources like Google Maps, Emojis, photos from Google Drive and Dropbox, YouTube videos, Flickr photos, Bitmojis, and other popular visual content elements. Canva Pros and Cons Pros: A user-friendly interface Canva is a great tool for people who want to create professional graphics but don’t have graphic design skills. Hundreds of templates, so you'll never have to start from scratch. Wide variety of templates to fit multiple uses Branding kits to keep your team consistent with the brand colors and fonts Creating visual content on the go You can find royalty free images, audio, and video without having to subscribe to another service. Cons: Some professional templates are available for Pro user only Advanced photo editing features like blurring or erasing a specific area are missing. Some elements that fall outside of a design are tricky to retrieve. Features (like Canva presentations) could use some improvement. If you are a regular user of Adobe products, you might find Canva's features limited. Prefers to work with vectors. Especially logos. Expensive enterprise pricing Conclusion In general, Canva is an excellent tool for those who need simple images for projects. If you are a graphic designer with experience, you will find Canva’s platform lacking in customization and advanced features – particularly vectors. But if you have little design experience, you will find Canva easier to use than advanced graphic design tools like Adobe Photoshop or Illustrator for most projects. If you have any queries let me know in the comments section.",
         "en",
         "{'MISC': ['119.99/year for up to 5 people', 'Access to Background Remover and Magic', 'Also an even-more-affordable paid version is available for', 'Also running the latest version of Photoshop you need a high-end computer', 'And if you have a Canva Pro', 'Apple App Store and Google Play', 'Are you looking for a new graphic design tool', 'Backgrounds', \"Based on the type of account you set up you'll be able to see templates categorized by the following categories\", 'Based on your choice of account', 'Bitmojis', 'Branding kits to keep your team', 'Built-in workflows to get approval on your designs Set which elements your team can edit and stay on brand with template', 'But if you have little design experience', 'Canva', 'Canva Apps The Canva app is available on the', 'Canva Print When it comes to printing your designs', 'Canva Print is perfect for any business seeking to make', 'Canva Pro subscribers can also', 'Canva Pro subscribers can choose from', 'Canva Pro subscribers can create multiple post', 'Canva Pros and', 'Canva Team Canva Pro allows you to work with your team', 'Canva has', 'Canva has a lot to choose from', 'Canva has a web version and also', 'Canva has you covered', 'Canva is a great tool for people who want to create professional graphics but don’t have graphic design skills', 'Canva is an excellent tool for those who', 'Canva will', 'Canva’s Content Planner to post', 'Change out the background on a template to give it a more personal touch', 'Choose from hundreds of templates that are ready to go', 'Choose from thousands of stock video clips', 'Create', 'Designs can be created inside Canva, and then sent to your team members for approval', 'Emojis', 'Enterprise', \"Establish your brand'\", 'Everyone can', 'Facebook', 'Facebook or', 'Features Everything Free', 'Flickr', 'Free', 'Free plan', 'Free vs Pro vs Enterprise Pricing plan', 'GB of cloud', 'Google Drive', 'Google Drive and Dropbox', 'Google Maps', 'Graphic designing knowledge to', 'Hand out custom business', 'Here', 'How to Use Canva', 'Hundreds of templates', 'Hundreds of thousands of free photos and graphics Invite members to your team Collaborate and comment in real-time 5GB of cloud', 'I am also writing my first ebook using canva and publish it soon on my site you can download it is free', 'If you have any queries let me know in the comments section', 'If you want to', 'Illustrator for most projects', 'Instagram post', \"It's like having a basic version of Photoshop that doesn't\", 'It’s also easier to use and free', 'It’s best for nongraphic designers', \"Let's start the review\", 'Magic Resizer can resize it for other networks', 'Once you have chosen', 'Photos The Photos tab lets you search for and choose from millions of professional', 'Pinterest', 'Prefers to work with vectors', 'Pro', 'Publishing with Canva With Canva', 'Reels', 'SSO', 'Slack', 'Slack and Tumblr', 'So here Canva takes place', 'Some elements that fall outside of', 'Some professional', 'Start by choosing a template for your post or searching for something more specific', 'The Canva app has earned', 'The Styles tab lets you quickly change the look and feel of your template with just', 'The search box on the Elements tab lets you search everything on Canva', 'This can also make', 'To begin with', 'To create sophisticated graphics', 'To find them', 'To use it', 'Try Canva Pro for free for 30 days', 'Twitter', 'Unlimited Storage Log in with single-sign', 'Video Want to create your own videos?', 'What is Canva Canva is a free graphic design web application that allows you to create invitations', 'When you choose an image', 'When you click on text', 'When you subscribe to Canva Pro', 'Who is Canva best suited for?', 'Wide', 'With Canva', 'With an', 'Would you like to read', 'You can', 'You can replace the photos in our templates to create', 'You can sign up for a free trial of Canva Pro', 'You can start', 'You may also want to search in the following tabs to see various elements separately:', 'You will then choose your account type between student', 'YouTube videos', 'You’ll find videos that range upto 2', 'and fonts with up to 100 Brand Kits Remove', 'and graphical text to your design', 'and graphics', 'and more using professionally designed templates', 'and video without having to subscribe to another service', 'be specific in your search query', 'build your online brand', 'flip it, and adjust its transparency', 'get familiar with the software', 'including the Background Remover', 'keep, and share', 'launch your business', 'like pexel', 'of your brand or', 'pixabay and many more', 'searching for a template matching your needs', 'so start with a specific search.if you want to create business', \"so you'll never have to start from scratch\", 'specific area are missing', 'that visual content remains on-brand', 'the Elements tab gives you access to lines and shapes', 'they can turn your designs into anything from banners and wall art to mugs and t-shirts', 'tool for your needs', 'tools like Adobe', 'will be recommended to you', 'with Canva you can do all that with drag-and-drop feature', 'with experience', 'with the brand colors and fonts Creating visual content on the go You can find royalty free images', 'you can choose', 'you can start by designing an', 'you can upload', 'you can use', 'you can use the editing features in Canva to trim the video', 'you get access to a number of premium features', \"you'll see options to adjust the\", 'you’ll find free stock photos to', 'you’ll have', 'you’ll need to learn its hundreds of features'], 'PER': ['If you are', 'If you are a regular user of Adobe', 'lesson plans', 'normal text', 'videos', \"you might find Canva'\", 'you will find Canva easier to', 'you will find Canva’s platform lacking in customization and advanced features'], 'ORG': ['Apple', 'Audio Create an', 'Cons', 'Enterprise Plan', 'Features', 'For example', 'Google', 'K Apple', 'LinkedIn', 'Schedule', 'Stories', 'Templates Next', \"and Canva'\"], 'LOC': ['Canva’', 'Instagram', 'and Tumblr']}",
         "[-0.05691845715045929, 0.036890909075737, -0.0466669537127018, -0.0013547580456361175, 0.012114151380956173, 0.010422629304230213, -0.05440642684698105, 0.007432181388139725, -0.009898276068270206, 0.06246698647737503, 0.001473108772188425, 0.029801754280924797, 0.08083853870630264, 0.04054543003439903, 0.010333786718547344, -0.003484139684587717, 0.028966709971427917, -0.023588571697473526, 0.05127781629562378, 0.03667812421917915, 0.021698545664548874, -0.039587024599313736, 0.005648074205964804, -0.06243118643760681, 0.01622091419994831, 0.0011394477915018797, 0.010892641730606556, -0.02670018933713436, 0.04657680168747902, -0.1694203019142151, -0.01130201667547226, 0.010241600684821606, -0.050934966653585434, 0.039236463606357574, -0.04723888635635376, 0.08039050549268723, 0.018524250015616417, 0.07223101705312729, -0.08623560518026352, -0.043364059180021286, -0.14163562655448914, -1.63657696248265e-05, -0.100132517516613, 0.03664741292595863, 0.0841907411813736, -0.07614044100046158, -0.05379443243145943, 0.0019462922355160117, 0.05256948992609978, 0.0831199437379837, -0.01332078780978918, -0.12903539836406708, 0.03299444168806076, -0.10074323415756226, 0.017360327765345573, 0.02837887592613697, -0.05028688162565231, -0.04354960471391678, -0.02252120152115822, -0.07569872587919235, 0.056726787239313126, 0.004604521207511425, -0.03417611122131348, 0.01442562323063612, 0.0025814019609242678, -0.010160858742892742, 0.029528379440307617, 0.0867544561624527, 0.015900321304798126, -0.15704341232776642, -0.02043466456234455, -0.035133086144924164, 0.00622267322614789, 0.06632492691278458, -0.00906962901353836, -0.044483669102191925, 0.008608360774815083, -0.005485983565449715, -0.00500480504706502, -0.0013132997555658221, 0.07206270843744278, 0.07346077263355255, -0.09251964092254639, 0.06135304272174835, -0.0370919294655323, -0.006097448989748955, 0.019239209592342377, 0.09599025547504425, 0.04723762348294258, -0.02012556791305542, 0.06412842869758606, 0.07432197779417038, -0.005406341515481472, -0.041256435215473175, 0.06447392702102661, -0.009015684016048908, 0.0006670914008282125, -0.10508830845355988, 0.019294843077659607, 0.016378210857510567, -0.009286686778068542, -0.03287345916032791, 0.03784266114234924, -0.07011725008487701, -0.013067817315459251, 0.024343417957425117, 0.04307949170470238, -0.050621163100004196, 0.0008224292541854084, 0.04299118369817734, -0.04647144675254822, -0.04058455675840378, -0.07969310879707336, -0.054194409400224686, 0.023692592978477478, -0.0029523135162889957, 0.0017223397735506296, -0.03685034438967705, 0.0020500924438238144, -0.019575009122490883, -0.0007808063528500497, 0.05851927399635315, -0.040387772023677826, -0.042983271181583405, 0.02759094536304474, 0.03067384846508503, -0.03802982717752457, 8.680501400139531e-34, 0.06419453769922256, 0.10247459262609482, -0.02155769243836403, 0.06493168324232101, 0.08051817864179611, -0.02472706139087677, 0.0606200248003006, 0.00745801068842411, -0.08889982104301453, -0.02317315898835659, 0.05541400983929634, 0.04427814483642578, -0.07010304927825928, 0.13506931066513062, 0.08389804512262344, -0.026776015758514404, 0.04344633221626282, 0.01130769681185484, 0.03567955270409584, 0.02732730284333229, -0.1067497506737709, -0.04996202886104584, 0.02451501041650772, 0.05524647235870361, -0.02015497162938118, 0.08506770431995392, 0.04252701625227928, 0.0596219077706337, 0.05513356998562813, -0.053359199315309525, -0.0008192738168872893, -0.03776019439101219, -0.015126536600291729, -0.04666604846715927, -0.046737026423215866, -0.05045642331242561, 0.012009396217763424, -0.039303913712501526, 0.06594275683164597, -0.030517786741256714, -0.06851924955844879, 0.03152031451463699, -0.014884402975440025, -0.012150210328400135, -0.04655742645263672, 0.06741338223218918, 0.05538690835237503, 0.03120957314968109, 0.020427335053682327, 0.05916109308600426, -0.021885650232434273, -0.014568121172487736, -0.011184711940586567, 0.005933811888098717, -0.062185339629650116, 0.0002435731585137546, -0.017507312819361687, -0.01621362194418907, 0.020315980538725853, -0.015577109530568123, -0.013022552244365215, 0.061172839254140854, -0.021939460188150406, 0.07841076701879501, -0.03638232871890068, -0.0731639415025711, 0.028734169900417328, 0.07273238152265549, 0.06842433661222458, -0.05513928458094597, -0.08914868533611298, 0.028439054265618324, 0.03982686251401901, -0.08211155235767365, 0.004679777659475803, -0.02855817787349224, 0.01858670450747013, -0.01770908758044243, -0.004370597191154957, 0.027088498696684837, -0.055203117430210114, -0.005701910704374313, 0.03016781061887741, -0.022483158856630325, -0.012640428729355335, 0.04304669424891472, 0.06517279893159866, -0.007864052429795265, -0.040698278695344925, -0.015803255140781403, -0.032124970108270645, 0.08477809280157089, 0.02997792325913906, 0.0021516818087548018, 0.03998744115233421, -1.508751040042237e-33, 0.007728204596787691, -0.04587848111987114, -0.003972905687987804, 0.027040768414735794, 0.10547522455453873, 0.041795745491981506, -0.032517172396183014, 0.037352874875068665, -0.034917254000902176, -0.11474719643592834, -0.04897958040237427, 0.004501499701291323, -0.024626292288303375, -0.007813828065991402, -0.02880551666021347, -0.007965143769979477, -0.023645661771297455, -0.05035863444209099, -0.11225428432226181, -0.07629016041755676, -0.015542182140052319, 0.06191840395331383, -0.04388470947742462, -0.01563981920480728, -0.05606872960925102, 0.08589451760053635, -0.03158523142337799, -0.028758469969034195, -0.03336787968873978, 0.08265825361013412, 0.04482013359665871, -0.07945020496845245, 0.10145995020866394, 0.06132269650697708, 0.07548146694898605, -0.06582926958799362, 0.026853708550333977, 0.023248901590704918, 0.0013020230690017343, 0.046832483261823654, 0.003423884976655245, 0.012317574582993984, 0.023378055542707443, -0.11921846121549606, -0.05791265890002251, 0.011495670303702354, -0.014992019161581993, -0.04968801513314247, 0.08829006552696228, 0.015674598515033722, 0.00957223679870367, 0.023235909640789032, -0.006197894923388958, -0.020047958940267563, 0.01031772792339325, -0.08248728513717651, 0.010543394833803177, -0.049129243940114975, 0.08525319397449493, 0.021463138982653618, -0.04868398606777191, 0.009811128489673138, -0.027697952464222908, -0.022794116288423538, 0.007996900007128716, -0.0026039828080683947, -0.0008027649018913507, -0.10089809447526932, -0.05968819186091423, 0.03323476016521454, -0.040686629712581635, 0.033210862427949905, 0.051053259521722794, -0.02721511758863926, 0.009085499681532383, 0.013247890397906303, 0.05686258524656296, -0.0057415831834077835, -0.010470892302691936, -0.08986958861351013, 0.04731924831867218, -0.004204858560115099, -0.03648628294467926, 0.009636644273996353, 0.0569843053817749, 0.09886658936738968, -0.048753201961517334, -0.0733751654624939, 0.014730948954820633, 0.040048737078905106, -0.10562018305063248, 0.04910244792699814, 0.04566788673400879, 0.07799032330513, -0.024956652894616127, -4.952886811793178e-08, 0.028420545160770416, -0.06276927888393402, 0.00015758280642330647, -0.06291645020246506, -0.041187986731529236, 0.0418090783059597, 0.04983524605631828, -0.014321096241474152, 0.031723350286483765, -0.014646987430751324, 0.10088444501161575, -0.0624491311609745, -0.03374378755688667, 0.0614662803709507, 0.05357527732849121, -0.01498823706060648, 0.11313100159168243, 0.05219477042555809, -0.005757641512900591, -0.11448173224925995, -0.040939901024103165, 0.008996209129691124, -0.015042196959257126, -0.024241840466856956, -0.022413022816181183, 0.03860275447368622, -0.04026542976498604, 0.005845544394105673, 0.024980733171105385, -0.027592450380325317, 0.05214046686887741, 0.02921084128320217, 0.10612659156322479, 0.037207867950201035, 0.027161987498402596, -0.039032358676195145, 0.003164873691275716, 0.049512892961502075, -0.02640385553240776, 0.042804550379514694, 0.030898652970790863, 0.06961118429899216, -0.029650134965777397, -0.04745546728372574, -0.054650116711854935, -0.07852132618427277, 0.026249097660183907, -0.09108895063400269, -0.03655100613832474, 0.07970651239156723, -0.0541740283370018, -0.03933870419859886, 0.039194103330373764, -0.040552105754613876, -0.007830413058400154, 0.10797526687383652, 0.04033093526959419, 0.035569652915000916, 0.09357250481843948, 0.06803743541240692, -0.003186332993209362, -0.061387330293655396, 0.01378264743834734, 0.047916263341903687]",
         "0.165"
        ],
        [
         "11",
         "28",
         "TOP 11 AI MARKETING TOOLS YOU SHOULD USE (Updated 2022)",
         "The marketing industry is turning to artificial intelligence (AI) as a way to save time and execute smarter, more personalized campaigns. 61% of marketers say AI software is the most important aspect of their data strategy. If you’re late to the AI party, don’t worry. It’s easier than you think to start leveraging artificial intelligence tools in your marketing strategy. Here are 11 AI marketing tools every marketer should start using today. 1. Jasper Ai (Formerly known as Jarvis) Jasper is a content writing and content generation tool that uses artificial intelligence to identify the best words and sentences for your writing style and medium in the most efficient, quick, and accessible way. Key Features It's trusted by 50,000+ marketers for creating engaging marketing campaigns, ad copy, blog posts, and articles within minutes which would traditionally take hours or days. Special Features: Blog posts have been optimized for search engines and rank high on Google and other search engines. This is a huge plus for online businesses that want to generate traffic to their website through content marketing. 99.9% Original Content and guarantees that all content it generates will be original, so businesses can focus on their online reputation rather than worrying about penalties from Google for duplicate content. Long-Form Article Writing – Jasper.ai is also useful for long-form writing, allowing users to create articles of up to 10,000 words without any difficulty. This is ideal for businesses that want to produce in-depth content that will capture their audience’s attention. Wait! I've got a pretty sweet deal for you. Sign up through the link below, and you'll get (10k Free Credits) Also Read: Top 10 AI Content Generator & Writer Tools in 2022 2. Personalize Personalize is an AI-powered technology that helps you identify and produce highly targeted sales and marketing campaigns by tracking the products and services your contacts are most interested in at any given time. The platform uses an algorithm to identify each contact’s top three interests, which are updated in real-time based on recent site activity. K ey Features Identifies top three interests based on metrics like time on page, recency, and frequency of each contact Works with every ESP and CRM Easy to get up and running in days Enterprise-grade technology at a low cost for SMBs 3. Seventh Sense Seventh Sense provides behavioral analytics that helps you win attention in your customers’ overcrowded email inboxes. Choosing the best day and time to send an email is always a gamble. And while some days of the week generally get higher open rates than others, you’ll never be able to nail down a time that’s best for every customer. Seventh Sense eases your stress of having to figure out the perfect send-time and day for your email campaigns. The AI-based platform figures out the best timing and email frequency for each contact based on when they’re opening emails. The tool is primarily geared toward HubSpot and Marketo customers Key Features AI determines the best send-time and email frequency for each contact Connects with HubSpot and Marketo 4. Phrasee Phrasee uses artificial intelligence to help you write more effective subject lines. With its AI-based Natural Language Generation system, Phrasee uses data-driven insights to generate millions of natural-sounding copy variants that match your brand voice. The model is end-to-end, meaning when you feed the results back to Phrasee, the prediction model rebuilds so it can continuously learn from your audience. Key Features Instantly generates millions of human-sounding, brand-compliant copy variants Creates tailored language models for every customer Learns what your audience responds to and rebuilds the prediction model every time 5. Hubspot Seo HubSpot Search Engine Optimization (SEO) is an integral tool for the Human Content team. It uses machine learning to determine how search engines understand and categorize your content. HubSpot SEO helps you improve your search engine rankings and outrank your competitors. Search engines reward websites that organize their content around core subjects, or topic clusters. HubSpot SEO helps you discover and rank for the topics that matter to your business and customers. Key Features Helps you discover and rank topics that people are searching for Provides suggestions for your topic clusters and related subjects Integrates with all other HubSpot content tools to help you create a well-rounded content strategy Also Read: Top 10 AI Content Generator & Writer Tools in 2022 6. Evolve AI When you’re limited to testing two variables against each other at a time, it can take months to get the results you’re looking for. Evolv AI lets you test all your ideas at once. It uses advanced algorithms to identify the top-performing concepts, combine them with each other, and repeat the process to achieve the best site experience. Key Features Figures out which content provides the best performance Lets you test multiple ideas in a single experiment instead of having to perform many individual tests over a long period Lets you try all your ideas across multiple pages for full-funnel optimization Offers visual and code editors 7. Acrolinx Acrolinx is a content alignment platform that helps brands scale and improves the quality of their content. It’s geared toward enterprises – its major customers include big brands like Google, Adobe, and Amazon - to help them scale their writing efforts. Instead of spending time chasing down and fixing typos in multiple places throughout an article or blog post, you can use Acrolinx to do it all right there in one place. You start by setting your preferences for style, grammar, tone of voice, and company-specific word usage. Then, Acrolinx checks and scores your existing content to find what’s working and suggest areas for improvement. The platform provides real-time guidance and suggestions to make writing better and strengthen weak pages. Key features Reviews and scores existing content to ensure it meets your brand guidelines Finds opportunities to improve your content and use automation to shorten your editorial process. Integrates with more than 50 tools and platforms, including Google Docs, Microsoft Word, WordPress, and most web browsers. 8. MarketMuse MarketMuse uses an algorithm to help marketers build content strategies. The tool shows you where to target keywords to rank in specific topic categories, and recommends keywords you should go after if you want to own particular topics. It also identifies gaps and opportunities for new content and prioritizes them by their probable impact on your rankings. The algorithm compares your content with thousands of articles related to the same topic to uncover what’s missing from your site. Key features: The built-in editor shows how in-depth your topic is covered and what needs improvement Finds gaps and opportunities for new content creation, prioritized by their probable impact and your chance of ranking 9. Copilot Copilot is a suite of tools that help eCommerce businesses maintain real-time communication with customers around the clock at every stage of the funnel. Promote products, recover shopping carts and send updates or reminders directly through Messenger. Key features: Integrate Facebook Messenger directly with your website, including chat history and recent interactions for a fluid customer service experience Run drip messenger campaigns to keep customers engaged with your brand Send abandoned carts, out-of-stock, restock, preorder, order status, and shipment notifications to contacts Send branded images, promotional content, or coupon codes to those who opt in Collect post-purchase feedback, reviews, and customer insight Demonstrate social proof on your website with a widget, or push automatic Facebook posts sharing recent purchases Display a promotional banner on your website to capture contacts instantly Also Read: Top 10 AI Content Generator & Writer Tools in 2022 10. Yotpo Yotpo’s deep learning technology evaluates your customers’ product reviews to help you make better business decisions. It identifies key topics that customers mention related to your products—and their feelings toward them. The AI engine extracts relevant reviews from past buyers and presents them in smart displays to convert new shoppers. Yotpo also saves you time moderating reviews. The AI-powered moderation tool automatically assigns a score to each review and flags reviews with negative sentiment so you can focus on quality control instead of manually reviewing every post. Key features: Makes it easy for shoppers to filter reviews and find the exact information they’re looking for Analyzes customer feedback and sentiments to help you improve your products Integrates with most leading eCommerce platforms, including BigCommerce, Magento, and Shopify. 11. Albert AI Albert is a self-learning software that automates the creation of marketing campaigns for your brand. It analyzes vast amounts of data to run optimized campaigns autonomously, allowing you to feed in your own creative content and target markets, and then use data from its database to determine key characteristics of a serious buyer. Albert identifies potential customers that match those traits, and runs trial campaigns on a small group of customers—with results refined by Albert himself—before launching it on a larger scale. Albert plugs into your existing marketing technology stack, so you still have access to your accounts, ads, search, social media, and more. Albert maps tracking and attribution to your source of truth so you can determine which channels are driving your business. Key features: Breaks down large amounts of data to help you customize campaigns Plugs into your marketing technology stack and can be used across diverse media outlets, including email, content, paid media, and mobile Final Saying There are many tools and companies out there that offer AI tools, but this is a small list of resources that we have found to be helpful. If you have any other suggestions, feel free to share them in the comments below this article. As marketing evolves at such a rapid pace, new marketing strategies will be invented that we haven't even dreamed of yet. But for now, this list should give you a good starting point on your way to implementing AI into your marketing mix. Note: This article contains affiliate links, meaning we make a small commission if you buy any premium plan from our link.",
         "The marketing industry is turning to artificial intelligence (AI) as a way to save time and execute smarter, more personalized campaigns. 61% of marketers say AI software is the most important aspect of their data strategy.\n\nIf you’re late to the AI party, don’t worry. It’s easier than you think to start leveraging artificial intelligence tools in your marketing strategy. Here are 11 AI marketing tools every marketer should start using today.\n\n\n\n\n\nJasper is a content writing and content generation tool that uses artificial intelligence to identify the best words and sentences for your writing style and medium in the most efficient, quick, and accessible way. Key Features It's trusted by 50,000+ marketers for creating engaging marketing campaigns, ad copy, blog posts, and articles within minutes which would traditionally take hours or days. Special Features:\n\nBlog posts have been optimized for search engines and rank high on Google and other search engines. This is a huge plus for online businesses that want to generate traffic to their website through content marketing.\n\n99.9% Original Content and guarantees that all content it generates will be original, so businesses can focus on their online reputation rather than worrying about penalties from Google for duplicate content.\n\nLong-Form Article Writing – Jasper.ai is also useful for long-form writing, allowing users to create articles of up to 10,000 words without any difficulty. This is ideal for businesses that want to produce in-depth content that will capture their audience’s attention. Wait! I've got a pretty sweet deal for you. Sign up through the link below, and you'll get (10k Free Credits)\n\n\n\n\n\n\n\n\n\n2. Personalize\n\nPersonalize is an AI-powered technology that helps you identify and produce highly targeted sales and marketing campaigns by tracking the products and services your contacts are most interested in at any given time. The platform uses an algorithm to identify each contact’s top three interests, which are updated in real-time based on recent site activity.\n\nKey Features\n\nIdentifies top three interests based on metrics like time on page, recency, and frequency of each contact\n\nWorks with every ESP and CRM\n\nEasy to get up and running in days\n\nEnterprise-grade technology at a low cost for SMBs\n\n3. Seventh Sense\n\nSeventh Sense provides behavioral analytics that helps you win attention in your customers’ overcrowded email inboxes. Choosing the best day and time to send an email is always a gamble. And while some days of the week generally get higher open rates than others, you’ll never be able to nail down a time that’s best for every customer. Seventh Sense eases your stress of having to figure out the perfect send-time and day for your email campaigns. The AI-based platform figures out the best timing and email frequency for each contact based on when they’re opening emails. The tool is primarily geared toward HubSpot and Marketo customers\n\nKey Features\n\nAI determines the best send-time and email frequency for each contact\n\nConnects with HubSpot and Marketo\n\n4. Phrasee\n\nPhrasee uses artificial intelligence to help you write more effective subject lines. With its AI-based Natural Language Generation system, Phrasee uses data-driven insights to generate millions of natural-sounding copy variants that match your brand voice. The model is end-to-end, meaning when you feed the results back to Phrasee, the prediction model rebuilds so it can continuously learn from your audience.\n\nKey Features\n\nInstantly generates millions of human-sounding, brand-compliant copy variants\n\nCreates tailored language models for every customer\n\nLearns what your audience responds to and rebuilds the prediction model every time\n\n5. Hubspot Seo\n\nHubSpot Search Engine Optimization (SEO) is an integral tool for the Human Content team. It uses machine learning to determine how search engines understand and categorize your content. HubSpot SEO helps you improve your search engine rankings and outrank your competitors. Search engines reward websites that organize their content around core subjects, or topic clusters. HubSpot SEO helps you discover and rank for the topics that matter to your business and customers.\n\nKey Features\n\nHelps you discover and rank topics that people are searching for\n\nProvides suggestions for your topic clusters and related subjects\n\nIntegrates with all other HubSpot content tools to help you create a well-rounded content strategy\n\n6. Evolve AI\n\nWhen you’re limited to testing two variables against each other at a time, it can take months to get the results you’re looking for. Evolv AI lets you test all your ideas at once. It uses advanced algorithms to identify the top-performing concepts, combine them with each other, and repeat the process to achieve the best site experience.\n\nKey Features\n\nFigures out which content provides the best performance\n\nLets you test multiple ideas in a single experiment instead of having to perform many individual tests over a long period\n\nLets you try all your ideas across multiple pages for full-funnel optimization\n\nOffers visual and code editors\n\n7. Acrolinx\n\nAcrolinx is a content alignment platform that helps brands scale and improves the quality of their content. It’s geared toward enterprises – its major customers include big brands like Google, Adobe, and Amazon - to help them scale their writing efforts. Instead of spending time chasing down and fixing typos in multiple places throughout an article or blog post, you can use Acrolinx to do it all right there in one place. You start by setting your preferences for style, grammar, tone of voice, and company-specific word usage. Then, Acrolinx checks and scores your existing content to find what’s working and suggest areas for improvement. The platform provides real-time guidance and suggestions to make writing better and strengthen weak pages.\n\nKey features\n\nReviews and scores existing content to ensure it meets your brand guidelines\n\nFinds opportunities to improve your content and use automation to shorten your editorial process.\n\nIntegrates with more than 50 tools and platforms, including Google Docs, Microsoft Word, WordPress, and most web browsers.\n\n8. MarketMuse\n\nMarketMuse uses an algorithm to help marketers build content strategies. The tool shows you where to target keywords to rank in specific topic categories, and recommends keywords you should go after if you want to own particular topics. It also identifies gaps and opportunities for new content and prioritizes them by their probable impact on your rankings. The algorithm compares your content with thousands of articles related to the same topic to uncover what’s missing from your site.\n\nKey features:\n\nThe built-in editor shows how in-depth your topic is covered and what needs improvement\n\nFinds gaps and opportunities for new content creation, prioritized by their probable impact and your chance of ranking\n\n9. Copilot\n\nCopilot is a suite of tools that help eCommerce businesses maintain real-time communication with customers around the clock at every stage of the funnel. Promote products, recover shopping carts and send updates or reminders directly through Messenger.\n\nKey features:\n\nIntegrate Facebook Messenger directly with your website, including chat history and recent interactions for a fluid customer service experience\n\nRun drip messenger campaigns to keep customers engaged with your brand\n\nSend abandoned carts, out-of-stock, restock, preorder, order status, and shipment notifications to contacts\n\nSend branded images, promotional content, or coupon codes to those who opt in\n\nCollect post-purchase feedback, reviews, and customer insight\n\nDemonstrate social proof on your website with a widget, or push automatic Facebook posts sharing recent purchases\n\nDisplay a promotional banner on your website to capture contacts instantly\n\n10. Yotpo\n\nYotpo’s deep learning technology evaluates your customers’ product reviews to help you make better business decisions. It identifies key topics that customers mention related to your products—and their feelings toward them. The AI engine extracts relevant reviews from past buyers and presents them in smart displays to convert new shoppers. Yotpo also saves you time moderating reviews. The AI-powered moderation tool automatically assigns a score to each review and flags reviews with negative sentiment so you can focus on quality control instead of manually reviewing every post.\n\nKey features:\n\nMakes it easy for shoppers to filter reviews and find the exact information they’re looking for\n\nAnalyzes customer feedback and sentiments to help you improve your products\n\nIntegrates with most leading eCommerce platforms, including BigCommerce, Magento, and Shopify.\n\n11. Albert AI\n\nAlbert is a self-learning software that automates the creation of marketing campaigns for your brand. It analyzes vast amounts of data to run optimized campaigns autonomously, allowing you to feed in your own creative content and target markets, and then use data from its database to determine key characteristics of a serious buyer. Albert identifies potential customers that match those traits, and runs trial campaigns on a small group of customers—with results refined by Albert himself—before launching it on a larger scale.\n\nAlbert plugs into your existing marketing technology stack, so you still have access to your accounts, ads, search, social media, and more. Albert maps tracking and attribution to your source of truth so you can determine which channels are driving your business.\n\nKey features:\n\nBreaks down large amounts of data to help you customize campaigns\n\nPlugs into your marketing technology stack and can be used across diverse media outlets, including email, content, paid media, and mobile\n\n\n\n\n\nFinal Saying\n\nThere are many tools and companies out there that offer AI tools, but this is a small list of resources that we have found to be helpful. If you have any other suggestions, feel free to share them in the comments below this article. As marketing evolves at such a rapid pace, new marketing strategies will be invented that we haven't even dreamed of yet. But for now, this list should give you a good starting point on your way to implementing AI into your marketing mix.\n\nNote: This article contains affiliate links, meaning we make a small commission if you buy any premium plan from our link.",
         "2022-07-13T15:25:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/07/top-10-ai-marketing-tools-you-should-use.html",
         "2025-07-26T05:41:35.809185",
         "The marketing industry is turning to artificial intelligence (AI) as a way to save time and execute smarter, more personalized campaigns. 61% of marketers say AI software is the most important aspect of their data strategy. If you’re late to the AI party, don’t worry. It’s easier than you think to start leveraging artificial intelligence tools in your marketing strategy. Here are 11 AI marketing tools every marketer should start using today. Jasper is a content writing and content generation tool that uses artificial intelligence to identify the best words and sentences for your writing style and medium in the most efficient, quick, and accessible way. Key Features It's trusted by 50,000+ marketers for creating engaging marketing campaigns, ad copy, blog posts, and articles within minutes which would traditionally take hours or days. Special Features: Blog posts have been optimized for search engines and rank high on Google and other search engines. This is a huge plus for online businesses that want to generate traffic to their website through content marketing. 99.9% Original Content and guarantees that all content it generates will be original, so businesses can focus on their online reputation rather than worrying about penalties from Google for duplicate content. Long-Form Article Writing – Jasper.ai is also useful for long-form writing, allowing users to create articles of up to 10,000 words without any difficulty. This is ideal for businesses that want to produce in-depth content that will capture their audience’s attention. Wait! I've got a pretty sweet deal for you. Sign up through the link below, and you'll get (10k Free Credits) 2. Personalize Personalize is an AI-powered technology that helps you identify and produce highly targeted sales and marketing campaigns by tracking the products and services your contacts are most interested in at any given time. The platform uses an algorithm to identify each contact’s top three interests, which are updated in real-time based on recent site activity. Key Features Identifies top three interests based on metrics like time on page, recency, and frequency of each contact Works with every ESP and CRM Easy to get up and running in days Enterprise-grade technology at a low cost for SMBs 3. Seventh Sense Seventh Sense provides behavioral analytics that helps you win attention in your customers’ overcrowded email inboxes. Choosing the best day and time to send an email is always a gamble. And while some days of the week generally get higher open rates than others, you’ll never be able to nail down a time that’s best for every customer. Seventh Sense eases your stress of having to figure out the perfect send-time and day for your email campaigns. The AI-based platform figures out the best timing and email frequency for each contact based on when they’re opening emails. The tool is primarily geared toward HubSpot and Marketo customers Key Features AI determines the best send-time and email frequency for each contact Connects with HubSpot and Marketo 4. Phrasee Phrasee uses artificial intelligence to help you write more effective subject lines. With its AI-based Natural Language Generation system, Phrasee uses data-driven insights to generate millions of natural-sounding copy variants that match your brand voice. The model is end-to-end, meaning when you feed the results back to Phrasee, the prediction model rebuilds so it can continuously learn from your audience. Key Features Instantly generates millions of human-sounding, brand-compliant copy variants Creates tailored language models for every customer Learns what your audience responds to and rebuilds the prediction model every time 5. Hubspot Seo HubSpot Search Engine Optimization (SEO) is an integral tool for the Human Content team. It uses machine learning to determine how search engines understand and categorize your content. HubSpot SEO helps you improve your search engine rankings and outrank your competitors. Search engines reward websites that organize their content around core subjects, or topic clusters. HubSpot SEO helps you discover and rank for the topics that matter to your business and customers. Key Features Helps you discover and rank topics that people are searching for Provides suggestions for your topic clusters and related subjects Integrates with all other HubSpot content tools to help you create a well-rounded content strategy 6. Evolve AI When you’re limited to testing two variables against each other at a time, it can take months to get the results you’re looking for. Evolv AI lets you test all your ideas at once. It uses advanced algorithms to identify the top-performing concepts, combine them with each other, and repeat the process to achieve the best site experience. Key Features Figures out which content provides the best performance Lets you test multiple ideas in a single experiment instead of having to perform many individual tests over a long period Lets you try all your ideas across multiple pages for full-funnel optimization Offers visual and code editors 7. Acrolinx Acrolinx is a content alignment platform that helps brands scale and improves the quality of their content. It’s geared toward enterprises – its major customers include big brands like Google, Adobe, and Amazon - to help them scale their writing efforts. Instead of spending time chasing down and fixing typos in multiple places throughout an article or blog post, you can use Acrolinx to do it all right there in one place. You start by setting your preferences for style, grammar, tone of voice, and company-specific word usage. Then, Acrolinx checks and scores your existing content to find what’s working and suggest areas for improvement. The platform provides real-time guidance and suggestions to make writing better and strengthen weak pages. Key features Reviews and scores existing content to ensure it meets your brand guidelines Finds opportunities to improve your content and use automation to shorten your editorial process. Integrates with more than 50 tools and platforms, including Google Docs, Microsoft Word, WordPress, and most web browsers. 8. MarketMuse MarketMuse uses an algorithm to help marketers build content strategies. The tool shows you where to target keywords to rank in specific topic categories, and recommends keywords you should go after if you want to own particular topics. It also identifies gaps and opportunities for new content and prioritizes them by their probable impact on your rankings. The algorithm compares your content with thousands of articles related to the same topic to uncover what’s missing from your site. Key features: The built-in editor shows how in-depth your topic is covered and what needs improvement Finds gaps and opportunities for new content creation, prioritized by their probable impact and your chance of ranking 9. Copilot Copilot is a suite of tools that help eCommerce businesses maintain real-time communication with customers around the clock at every stage of the funnel. Promote products, recover shopping carts and send updates or reminders directly through Messenger. Key features: Integrate Facebook Messenger directly with your website, including chat history and recent interactions for a fluid customer service experience Run drip messenger campaigns to keep customers engaged with your brand Send abandoned carts, out-of-stock, restock, preorder, order status, and shipment notifications to contacts Send branded images, promotional content, or coupon codes to those who opt in Collect post-purchase feedback, reviews, and customer insight Demonstrate social proof on your website with a widget, or push automatic Facebook posts sharing recent purchases Display a promotional banner on your website to capture contacts instantly 10. Yotpo Yotpo’s deep learning technology evaluates your customers’ product reviews to help you make better business decisions. It identifies key topics that customers mention related to your products—and their feelings toward them. The AI engine extracts relevant reviews from past buyers and presents them in smart displays to convert new shoppers. Yotpo also saves you time moderating reviews. The AI-powered moderation tool automatically assigns a score to each review and flags reviews with negative sentiment so you can focus on quality control instead of manually reviewing every post. Key features: Makes it easy for shoppers to filter reviews and find the exact information they’re looking for Analyzes customer feedback and sentiments to help you improve your products Integrates with most leading eCommerce platforms, including BigCommerce, Magento, and Shopify. 11. Albert AI Albert is a self-learning software that automates the creation of marketing campaigns for your brand. It analyzes vast amounts of data to run optimized campaigns autonomously, allowing you to feed in your own creative content and target markets, and then use data from its database to determine key characteristics of a serious buyer. Albert identifies potential customers that match those traits, and runs trial campaigns on a small group of customers—with results refined by Albert himself—before launching it on a larger scale. Albert plugs into your existing marketing technology stack, so you still have access to your accounts, ads, search, social media, and more. Albert maps tracking and attribution to your source of truth so you can determine which channels are driving your business. Key features: Breaks down large amounts of data to help you customize campaigns Plugs into your marketing technology stack and can be used across diverse media outlets, including email, content, paid media, and mobile Final Saying There are many tools and companies out there that offer AI tools, but this is a small list of resources that we have found to be helpful. If you have any other suggestions, feel free to share them in the comments below this article. As marketing evolves at such a rapid pace, new marketing strategies will be invented that we haven't even dreamed of yet. But for now, this list should give you a good starting point on your way to implementing AI into your marketing mix. Note: This article contains affiliate links, meaning we make a small commission if you buy any premium plan from our link.",
         "en",
         "{'ORG': ['AI', 'Acrolinx', 'Adobe', 'Google', 'Integrates', 'Key Features', 'Key Features Figures out which content provides the best', 'Key Features Helps you discover and rank topics that people', 'Key Features Identifies', \"Key Features It'\", 'Run', 'Special Features', 'Works with every ESP and CRM Easy to get up and running in days Enterprise-grade technology at', 'You', 'instead of having to perform many individual tests over', 'search'], 'MISC': ['AI tools', 'Acrolinx checks and scores your', 'Acrolinx to do it all right there in one', 'As marketing evolves at such', 'Blog posts have been optimized for search engines and rank high on', 'Breaks down large amounts of data to help you customize campaigns', 'But for now', 'Choosing the best day and time to send an email is always a gamble', 'Creates tailored language models for every customer Learns what your audience', 'Demonstrate social proof', 'Display', 'Evolve', 'Facebook', 'Final Saying There are many tools and companies', 'Finds', 'Finds opportunities to improve your content and', 'Free Credits', 'Google and other search engines', 'Google for duplicate content', 'Here are 11 AI marketing tools every marketer should start using today', 'HubSpot SEO helps you discover and rank for the topics that matter to your business and customers', 'HubSpot SEO helps you improve your search engine rankings and outrank', 'Hubspot Seo HubSpot Search Engine', 'If you have any other suggestions', 'If you’re late to the AI party', 'Instead of spending time chasing down and fixing', 'Integrate Facebook', 'Integrates with all other HubSpot content tools to help you create a well-rounded content strategy 6', 'Integrates with more than 50 tools and platforms', 'It', 'It also', 'It analyzes vast amounts of data to run optimized campaigns autonomously', 'It uses', 'It uses advanced algorithms to identify the top-performing concepts', 'It’', 'Jasper is a content writing and content generation tool', 'Key features', 'Key features Reviews and scores', 'Key features: Makes it easy for shoppers to filter reviews and find the exact information they’re looking for Analyzes', 'Lets you test multiple ideas in', 'Magento', 'Microsoft Word', 'Offers visual and', 'Optimization', 'Original Content and guarantees that all content it generates will be', 'Personalize', 'Phrasee uses data-driven insights to generate millions of natural-sounding', 'Search engines reward websites that organize', 'Send branded images', 'Seventh Sense Seventh Sense provides behavioral analytics that helps you win attention in your customers’ overcrowded email inboxes', 'Seventh Sense eases your stress of having to figure out the perfect send', 'Shopify', \"Sign up through the link below, and you'll get\", 'The AI engine', 'The AI-based platform figures out the best timing', 'The AI-powered', 'The algorithm', 'The model is end', 'The platform uses an algorithm to identify each contact’s top three interests', 'The tool is primarily geared toward HubSpot and Marketo customers Key Features', 'The tool shows you where to target keywords to rank in specific topic categories', 'This is a huge plus for online businesses that want to generate traffic to their website through content marketing', 'Wait!', 'With its AI-based Natural Language Generation system', 'WordPress', 'Yotpo also saves you time moderating reviews', 'ads', 'allowing you to feed in your own creative content and target markets', 'and opportunities for new content and prioritizes them by their', 'and their feelings toward them', 'and then', 'brand-compliant', 'don’t worry', 'feel free to share them in the comments below this article', 'including BigCommerce', 'including Google Docs', 'including chat history and', 'intelligence tools in your marketing strategy', 'interactions for', 'key characteristics of a serious buyer', 'meaning we make', 'meaning when you feed the results back to Phrasee', \"new marketing strategies will be invented that we haven't even dreamed of yet.\", 'post', 'shopping carts and send', 'small list of resources that we have found to be helpful', 'the best words and sentences for your writing style and medium in the most', 'through Messenger', 'which are updated in real-time based', 'with customers around the clock at every stage of the funnel', 'you can', 'your content with thousands of articles related to the same topic to uncover what’s missing from your site', 'you’ll never be able to nail down a time that’s best for every customer'], 'LOC': ['Copilot Copilot is', 'Key features: The built-in editor shows how in-depth your topic is covered and what needs', 'and frequency of each', 'recency'], 'PER': ['Albert', 'Albert AI', 'Yotpo', 'and recommends keywords you should go after if you want to own particular topics', 'paid media', 'preorder', 'restock', 'so you still have access to your accounts']}",
         "[-0.09403683990240097, -0.038294680416584015, -0.056035298854112625, 0.05340290442109108, 0.03748471662402153, 0.05445585772395134, -0.03628993406891823, 0.004754126071929932, 0.011759260669350624, -0.04918374866247177, -0.019330928102135658, 0.08913885802030563, 0.06455892324447632, -0.027333837002515793, 0.060408517718315125, -0.011625508777797222, 0.07972385734319687, 0.012229044921696186, -0.06396019458770752, -0.039490971714258194, -0.0132807781919837, 0.053271129727363586, 0.04460373893380165, -0.026483239606022835, -0.013202188536524773, 0.03442169725894928, 0.0077406857162714005, -0.057823389768600464, -0.0032813798170536757, -0.08582597970962524, 0.04556482285261154, -0.013883164152503014, 0.08088546246290207, 0.019768232479691505, -0.06777715682983398, 0.044605668634176254, -0.0846816673874855, -0.04989512264728546, 0.13141945004463196, 0.024465300142765045, -0.02639068104326725, -0.16058629751205444, -0.10175538063049316, 0.013317883014678955, 0.05701008066534996, 0.020672207698225975, -0.024223793298006058, 0.039651256054639816, 0.015411538071930408, 0.06686864793300629, -0.2085561454296112, -0.02482985146343708, 0.0006727254367433488, -0.06948573142290115, -0.029719291254878044, -0.039569295942783356, -0.06862615048885345, 0.02246287278831005, -0.030053725466132164, -0.03215912729501724, 0.029076043516397476, -0.06743879616260529, 0.015526059083640575, 0.03940406069159508, 0.02167820930480957, -0.0366365909576416, -0.09345964342355728, 0.032941438257694244, -0.01848212629556656, -0.06019500270485878, 0.029092349112033844, 0.0504101924598217, -0.017148202285170555, 0.07398591190576553, -0.014853626489639282, 0.04032960534095764, 0.07709799706935883, -0.023712607100605965, 0.04343219846487045, -0.04454962909221649, 0.006173642352223396, 0.008893011137843132, -0.001195407472550869, 0.11596444994211197, -0.0633009597659111, -0.05558248981833458, 0.07117213308811188, 0.06349719315767288, 0.03456969931721687, 0.039709970355033875, 0.042766012251377106, -0.06337933987379074, 0.011371873319149017, -0.0234998669475317, 0.0027404616121202707, 0.031029313802719116, -0.06870865076780319, -0.013334393501281738, 0.02504519559442997, 0.010503502562642097, -0.002052504336461425, 0.07454731315374374, 0.028860606253147125, -0.02186136692762375, -0.04119395092129707, -0.06987286359071732, 0.06013400852680206, 0.07729916274547577, 0.004437590949237347, -0.012016259133815765, 0.030921967700123787, 0.019631003960967064, -0.048949915915727615, -0.08105647563934326, 0.09941054880619049, -0.017377905547618866, 0.005662064533680677, 0.010910619050264359, 0.05976616218686104, 0.09014430642127991, -0.015506141819059849, 0.08339934796094894, 0.001791908871382475, -0.014590642414987087, -0.002038070699200034, 0.05702892690896988, -0.058413196355104446, 5.417966236929205e-33, -0.07507206499576569, 0.1118583008646965, -0.04272980988025665, 0.04584838077425957, -0.09216244518756866, 0.00823463685810566, -0.07636122405529022, -0.02218802087008953, -0.04435015097260475, -0.032073114067316055, -0.022798726335167885, 0.07473263144493103, -0.03342759981751442, 0.09610079973936081, 0.013320320285856724, -0.03237125277519226, -0.0066310265101492405, 0.009713075123727322, 0.022626109421253204, -0.026881547644734383, 0.14792227745056152, -0.07874365895986557, 0.03252245485782623, 0.023472202941775322, -0.013710808008909225, 0.017188433557748795, 0.051239222288131714, -0.04278186336159706, -0.03920002654194832, -0.013172292150557041, 0.004326566122472286, -0.04036870226264, -0.05354088917374611, -0.005246422253549099, -0.02220234088599682, -0.0014710086397826672, -0.06036205217242241, -0.037189751863479614, 0.01916029490530491, 0.09144391864538193, -0.14832493662834167, 0.04021868109703064, 0.004919365979731083, 0.038109712302684784, -0.03446638584136963, 0.06781457364559174, -0.05220367759466171, -0.04689571633934975, 0.04710555821657181, -0.003599507501348853, 0.055713191628456116, 0.007815429009497166, 0.0945659950375557, 0.03315503150224686, 0.020385170355439186, 0.019668320193886757, -0.004703479818999767, -0.08177031576633453, 0.0018518335418775678, -0.04538993164896965, 0.04871289059519768, 0.0282332431524992, -0.010141324251890182, 0.013406534679234028, 0.00031529273837804794, 0.0534612275660038, 0.07123465090990067, 0.0392586812376976, 0.05722843110561371, 0.024341590702533722, 0.10978445410728455, -0.014787544496357441, -0.0361071415245533, -0.05140747129917145, -0.07120051234960556, -0.026993215084075928, 0.004081591498106718, -0.05894975736737251, 0.06209912523627281, 0.04258536174893379, 0.03349978104233742, -0.03044954314827919, 0.0302902739495039, -0.07446171343326569, 0.022709138691425323, -0.05383506044745445, 0.016160354018211365, -0.08189631998538971, -0.029573554173111916, 0.014566654339432716, 0.0011696279980242252, 0.09386096149682999, -0.03598273545503616, 0.0492515042424202, -0.016889704391360283, -4.83899890229275e-33, -0.061973653733730316, -0.03561229631304741, -0.054646674543619156, 0.064845509827137, -0.02887936495244503, 0.0710546150803566, -0.05126668140292168, 0.029312267899513245, 0.039412472397089005, 0.0036055573727935553, -0.07238020747900009, -0.02645798586308956, 0.023761754855513573, 0.011187538504600525, 0.0012544059427455068, 0.002907486166805029, 0.02069305256009102, -0.022097410634160042, -0.04523748531937599, 0.014008595608174801, -0.0029568709433078766, 0.1008971631526947, -0.10313311219215393, 0.006567841395735741, 0.07827911525964737, -0.012131650932133198, -0.06839366257190704, 0.05315065756440163, -0.04893505945801735, -0.022912632673978806, 0.06515880674123764, -0.034497279673814774, -0.010379647836089134, 0.012275056913495064, -0.04890642315149307, 0.05713561922311783, 0.02850474789738655, -0.005340883508324623, -0.003900979645550251, 0.03343856334686279, 0.04599400982260704, -0.02348385937511921, 0.0006594815058633685, -0.045978646725416183, -0.10280515998601913, 0.052675534039735794, -0.05258416011929512, -0.002788681536912918, 0.025114258751273155, 0.07516168057918549, -0.024785347282886505, 0.0005138341803103685, -0.06660338491201401, -0.046358540654182434, -0.07802006602287292, -0.034762244671583176, -0.03137544170022011, 0.01490804087370634, -0.07320217788219452, 0.08950377255678177, -0.024958444759249687, 0.05006581172347069, 0.048604633659124374, -0.060990605503320694, 0.02932102046906948, -0.10572025924921036, 0.05678655952215195, -0.005359025672078133, -0.048510920256376266, -0.030555007979273796, 0.07266465574502945, 0.037528593093156815, 0.015293238684535027, 0.011214492842555046, -0.02096688561141491, 0.04780269414186478, 0.010525697842240334, 0.04563377425074577, -0.06308396905660629, -0.09421034902334213, 0.03358515352010727, 0.0008930722833611071, 0.006768731866031885, 0.013139649294316769, 0.017259877175092697, 0.026271965354681015, -0.0218840092420578, -0.03590948507189751, -0.05264774337410927, 0.014943283051252365, -0.005209022667258978, -0.020084235817193985, -0.0031359309796243906, 0.10347955673933029, -0.12710250914096832, -5.311218487236147e-08, -0.0011061731493100524, -0.04131052643060684, -0.008495786227285862, 0.07488071918487549, 0.05520845204591751, 0.024364693090319633, -0.01248032134026289, -0.003556310897693038, -0.02469615638256073, -0.012634818442165852, 0.04963838681578636, -0.017031405121088028, -0.02857387252151966, 0.047315265983343124, 0.05883622169494629, -0.029739318415522575, 0.014857841655611992, -0.08730152249336243, 0.005291794426739216, -0.02385484240949154, 0.10201007127761841, -0.021557806059718132, -0.04687149077653885, -0.0397675521671772, 0.10001782327890396, -0.010770425200462341, -0.018551232293248177, -0.03003542684018612, 0.0006419306737370789, -0.029811229556798935, -0.06567513197660446, -0.005761877633631229, -0.011877724900841713, 0.06293945759534836, 0.06631521880626678, 0.002724590478464961, 0.08584631979465485, -0.03422671556472778, -0.08881156146526337, 0.01602347381412983, 0.040543872863054276, 0.041706718504428864, 0.03920723870396614, -0.032571207731962204, 0.017330868169665337, 0.05170707404613495, -0.06938524544239044, -0.06425298750400543, 0.06008066236972809, 0.03572103753685951, -0.03491254523396492, -0.058213092386722565, 0.0627874881029129, 0.018784446641802788, 0.017849288880825043, 0.006197592243552208, 0.028463618829846382, 0.06295336037874222, 0.07440416514873505, 0.06482817977666855, 0.014383535832166672, 0.020390376448631287, 0.0428030751645565, -0.02448751963675022]",
         "0.196"
        ],
        [
         "12",
         "571",
         "Getting AI Discovery Right",
         "A guide to ideating, validating, and prioritizing your AI use cases The post Getting AI Discovery Right appeared first on Towards Data Science .",
         "building with AI, complexity adds up — there’s more uncertainty, more unknowns, and more moving parts across teams, tools, and expectations. That’s why having a solid discovery process is even more important than when you are building traditional, deterministic software.\n\nAccording to recent studies, the #1 reason why AI projects fail is that companies use AI for the wrong problems. These problems can be:\n\ntoo small, so no one cares\n\ntoo simple and not worth the effort of using AI and dealing with more complexity\n\nor just fundamentally not a good fit for AI in the first place\n\nIn this article, I’ll share how we approach discovery for AI-driven products, breaking it down into three key steps:\n\nFigure 1: The discovery process\n\nI will use the example of a recent project in the automotive industry to illustrate the approach. Some of the points described will be new and specific to AI; others are known from traditional development, but gain even more meaning in the context of AI.\n\n📚 Note: This content is based on my new book The Art of AI Product Development. Check it out for a deep dive into discovery and much more!\n\nIdeation: Finding the right AI opportunities\n\nLet’s start with ideation — the first step in any discovery process, in which you try to collect a large number of ideas for your development. We will look at two familiar ways this plays out: a textbook version, where you follow the best practices of product management, and a common real-life scenario, where things tend to get a little biased and messy. Rest assured — both paths can lead to success.\n\n💡 According to Jeremy Utley’s and Perry Klebahn’s book Ideaflow, the single best predictor of the innovation capacity of a business is ideaflow — the number of novel ideas a person or group can generate around a given situation in a given amount of time.\n\nThe textbook scenario: Problem-first thinking\n\nIn the ideal world, you have a lot of time to explore and structure the opportunity space — that is, all the customer needs, desires, and pain points you’ve identified. These might come from different sources, such as:\n\nCustomer interviews and feedback\n\nSales and support conversations\n\nCompetitive research\n\nAnd sometimes just the team’s gut feeling and industry experience\n\nAs an example, here is an excerpt from the opportunity space for our automotive client, whose goal was to use AI to monitor the global automotive market and create recommendations for strategic innovation:\n\nFigure 2: Excerpt from an opportunity space\n\nNote that in this example, we are looking at a brownfield scenario. The opportunity space includes not only new feature ideas, but also critiques of existing features, such as “lack of transparency into sources.“\n\nOnce you’ve mapped out the needs, you look at the solution space — all the different ways you could technically solve those problems. For example, these can include:\n\nRule-based analytics\n\nUX improvements\n\nArtificial Intelligence\n\nAdding more domain expertise\n\n…\n\nImportantly, AI is part of the solution space, but it is in no way privileged — it is one option among many others.\n\nFinally, you match opportunities to solutions, as illustrated in the following figure:\n\nFigure 3: Mapping your opportunity space to your solution space\n\nLet’s look at some of those links:\n\nIf several users say, “I need alerts when a competitor launches new models,” you might consider using AI. However, a simple rule-based system that scrapes competitor offerings from their websites could solve that too.\n\nIf the problem is, “I need to create reports and presentations faster,” AI starts to shine. Summarizing large amounts of data or text to reframe it and generate new content is exactly where modern AI excels.\n\nBut if the issue is, “I don’t trust this data because I can’t see the sources,” AI probably isn’t the right fit at all. That’s a UX and transparency challenge, not a machine learning problem.\n\nIn this scenario, it’s important to stay impartial when matching each need to the right solution. Even if you’re secretly excited to start building with the latest AI tools (who isn’t?), you have to be patient and wait for the right opportunity to surface.\n\nThe real-life scenario: “Let’s use AI!”\n\nNow, in reality, things often start on a different note. For example, you’re in a team meeting, and someone says, “Let’s use AI!” Or your CEO makes a magic speech that suddenly puts AI on your agenda without providing any guidance or direction on what to do with it. Without further ado, you risk ending up in the “AI for the sake of AI” trap.\n\nHowever, it doesn’t have to be a disaster. We are talking about an extremely versatile technology, and you can work backwards from the AI-first imperative and find great opportunities by ideating around the core benefits and shortcomings of AI.\n\nThe AI Opportunity Tree: Focusing on the core benefits of AI\n\nWhen I work with teams who’ve already decided they “want to do AI,” I help them frame the conversation around what AI is good at. In the B2B context, there are four main benefits you can build around:\n\nAutomation & productivity: Use AI to make existing processes faster and cheaper. For example, Intercom uses AI chatbots to handle common customer service questions automatically, reducing response times and freeing up human agents for more complex cases. Improvement & augmentation: Help people improve the outcomes of their work. For example, Notion AI assists with drafting, summarizing, and refining content, while leaving the final decision and editing to the human user. Innovation & transformation: Unlock entirely new products, capabilities, or business models. For example, Tesla uses AI to shift from selling hardware to delivering continuous software-driven value with features like driver assistance, battery optimization, and in-car experiences via over-the-air updates. Personalization: Tailor outputs to specific users or contexts. For example, Spotify uses AI to create personalized playlists like Discover Weekly, adapting recommendations to each listener’s unique taste.\n\nWhen ideating, you should try to build a rich space of ideas by collecting multiple opportunities for each benefit. This will result in a structured AI Opportunity Tree. Here is a small part of the opportunity tree we built in the automotive scenario:\n\nFigure 4: Example of an AI Opportunity Tree for a market intelligence system\n\nUse the shortcomings of AI as exclusion criteria\n\nIt’s also important to recognize when AI is not the best answer. Here are some of the user-facing shortcomings of AI, which you can use to filter out inappropriate use cases:\n\nAI is often a black box — users don’t always understand how it works.\n\nExample: In financial risk assessments, if a loan applicant gets rejected by an opaque AI model, the bank needs to explain why. Without clear reasoning, the system fails both legally and ethically.\n\nAI introduces uncertainty — the same or similar inputs can produce different outputs.\n\nExample: In legal document drafting, small prompt changes can lead to widely different contract terms. This unpredictability makes it risky for high-stakes, regulated industries.\n\nAI will make mistakes — sometimes in ways you can’t fully predict.\n\nExample: In healthcare diagnostics, a wrong AI prediction isn’t just a bug — it could lead to harmful decisions with life-or-death consequences.\n\nIf your use case requires full accuracy, explainability, or predictability, move on — AI is likely not the right solution.\n\nWith your AI opportunities and use cases laid out, let’s now see how you can add more flesh to your ideas and specify them for further prioritization and development.\n\nSpecification & validation: Iterate yourself to the optimal system design\n\nOnce you’ve mapped out your use cases and potential features, the next step is specification and validation. Here, you define how you are going to build an AI system to address a specific use case. Before we dive into the frameworks, let’s pause and talk about process, and specifically about the power of iteration in the context of AI.\n\nAdopting the practice of iteration\n\nThe cover of my book The Art of AI Product Development features a dervish. Just as these dancers rotate in an endless and focused motion, you need to build the habit of iteration to get successful with AI. At the beginning of your journey, uncertainty is high:\n\nYou are exploring a new land. Compared to “traditional” software development, where we have a lot of historical wisdom to build upon, the solutions and best practices aren’t figured out yet.\n\nAI systems will make mistakes, which are a major risk for trust and adoption. From the start, you should allocate a lot of time to understanding, anticipating, and preventing these mistakes.\n\nYour users will have different levels of AI literacy. Some will know how to handle errors and uncertainty; others will blindly trust AI outputs, which can lead to problems down the line.\n\nThrough iteration, you reduce this uncertainty and build confidence both within your team and for your users. The key is to specify and validate in small steps: run quick experiments, build prototypes, and create feedback loops to understand what’s working and what’s not.\n\nMost importantly, get real feedback early. Today, it’s tempting to cocoon yourself in the world of AI-driven research and simulation. However, that’s a dangerous comfort zone. If you don’t talk to real users and put your prototypes in their hands, you risk a hard clash when your product finally launches. AI is AI, humans are humans. To build something successful, you need to understand and connect both worlds.\n\nSpecifying your system with the AI System Blueprint\n\nTo make an AI idea more concrete, we use the AI System Blueprint. This model represents both the opportunity and the solution, and its beauty lies in its simplicity and universality. Over the last two years, I was able to use it in literally every AI project I encountered to clarify what was being built. It helps align everyone around the same vision: product managers, designers, engineers, data scientists, and even executives.\n\nFigure 5: The AI System Blueprint is a simple but powerful model for specifying any AI application\n\nHere’s how to fill it out:\n\nPick a use case from your AI Opportunity Tree. Map out the value AI can realistically provide to this use case:\n\nHow much of it can you automate? Often, only partial automation is possible (and sufficient).\n\nWhat will the cost of the mistakes made by the AI be? Start with a rough estimate of the frequency and potential cost of mistakes, and correct as you get more information from prototyping and user testing.\n\nDo your users actually want automation? In some contexts — especially creative tasks — users might resist automation. They might prefer to do the task by themselves, or welcome lightweight AI assistance instead of a black-box system taking over their workflow.\n\n3. Specify the AI solution:\n\nData will be the raw material powering your AI system.\n\nwill be the raw material powering your AI system. Intelligence , which includes AI models and your larger architecture, will use AI algorithms to distill value from your data.\n\n, which includes AI models and your larger architecture, will use AI algorithms to distill value from your data. The user experience is the channel that transports this value to the user.\n\nThus, the initial blueprint for our use case of creating presentations and reports can look as follows:\n\nFigure 6: Example blueprint for an AI system that assists with the creation of slide decks and reports\n\nAvoid narrowing down your solution space too early\n\nThe following figure shows a high-level solution space for AI:\n\nFigure 7: An overview over the AI Solution Space\n\nA detailed description of this space is out of the scope of this post (you can find it in chapters 3-10 of my book). Here, I would like to guard you against a common mistake — defining your solution space too narrowly. This limits creativity, leads to poor engineering decisions, and can lock you into suboptimal paths. Watch out for these three anti-patterns:\n\n“Let’s build an agent.” Right now, every other company wants to build their own AI agent. But when you ask, “What exactly is an agent in your context?”, most teams don’t have a clear answer. That’s usually a sign of hype over strategy. “Let’s pick a model and figure it out later.” Some teams start by selecting a model or vendor, and scramble to find a use case afterward. This almost always leads to misalignment, iteration dead-ends, and wasted resources. “Let’s just go with what our platform offers.” Many companies default to whatever their cloud provider suggests, skipping critical architectural decisions. Cloud providers are biased toward their own ecosystems. If you blindly follow their playbook, you’ll limit your options and miss the chance to develop AI craft and build something truly differentiated.\n\nThus, before you decide on tooling, models, or platforms, take a step back and ask:\n\nWhat are the high-level decisions we need to make about data, models, AI architecture, and UX?\n\nHow do they interconnect?\n\nWhat trade-offs are we willing to make?\n\nAlso, make sure your entire team understands the whole solution space. In AI, cross-functional dependencies abound. For example, UX designers need to be familiar with the training data of an AI model because it largely determines the outputs users see. On the other hand, data and AI engineers need to understand the UX so they can put the AI system together in a way that allows it to serve the different insights and interactions. Therefore, everyone should be on-board with a shared mental model of the potential solutions and the final specification of your AI system.\n\nStay up-to-date with the AI solution space with our AI Radar: The more concrete your specification gets, the more difficult it is to keep up with moving parts and new developments. Our AI Radar monitors the latest AI publications, models, and use cases, and structures them in a way that makes them actionable for product teams. If you’re interested, please sign up for the waitlist here.\n\nPrioritization: Deciding what to build first\n\nThe last step in our discovery process is prioritization — deciding what to build first. Now, if you’ve done a solid job in specification and validation, this will often already point you to use cases with a high potential, making your prioritization smoother. Let’s start with the simple prioritization matrix and then learn how you can refine your prioritization criteria and process.\n\nThe prioritization matrix\n\nMost of us are familiar with the classic prioritization matrix: you define criteria like user value, technical feasibility, maybe even risk, and you score your ideas accordingly. Then, you add up the points, and the highest-scoring opportunity wins. The following figure shows an example for some of the items in our AI Opportunity Tree:\n\nFigure 8: An example prioritization matrix for AI features\n\nThis kind of framework is popular because it creates clarity and makes stakeholders feel good. There’s something reassuring about seeing messy, hairy ideas turned into numbers. However, prioritization matrices are highly simplified projections of reality. They hide the complexity and nuance behind prioritization, so you should avoid overrelying on this representation.\n\nAdding nuance to your AI prioritization\n\nEspecially when you are just about to introduce AI, you’re not just ranking features, but making long-term bets on your product direction, tech stack, and positioning and differentiation. Instead of reducing prioritization to a spreadsheet exercise, sit with the complexity, the deeper conversations and potential misalignments. Take the time to work through the subtle details, weigh the trade-offs, and make decisions that align not just with what’s easy to build now, but also with the longer-term vision for AI in your business.\n\n1. Pick the low-hanging fruits first\n\nThe AI Opportunity Tree from section 1 provides a first hint for your prioritization. Normally, you are better off starting on the left of the tree and moving to the right as you gain more experience and traction with AI. Here’s why:\n\nOn the left side, you have simple automation tasks. These are usually low risk, easy to measure, and a great way to start.\n\nAs you venture to the right side, you see more advanced, strategic use cases like trend prediction, recommendations, or even new product ideas. These can add more impact, but also more risk and complexity.\n\nStarting on the left helps you build trust and momentum. It delivers quick wins, gives your company the time to get comfortable with AI, and builds the foundation for more ambitious projects down the line.\n\n2. Work on strategic alignment\n\nBefore you decide what to build, think about the role of AI in your business. While your company might not have an explicit AI strategy (yet), you can infer important information from its corporate strategy. For example, is AI a potential differentiator, or are you just playing catch-up with the market? If you want to gain a competitive edge with AI, you will want to move fast along your opportunity tree to implement more advanced and differentiated use cases. Your engineering decisions will lean towards more custom and crafty alternatives like open-source models, custom pipelines, or even on-premise infrastructure. By contrast, if your goal is to follow competitors, you might focus on automation and productivity for longer, and choose safer, off-the-shelf solutions from large cloud vendors and model providers.\n\n3. Define custom criteria for prioritization\n\nAI projects often require custom prioritization dimensions beyond the usual trio of user value, business impact, and feasibility. Consider factors like:\n\nScalability & generalization power: Will your AI solution generalize across different user groups, markets, or domains? For example, if you need to inject heavy domain expertise for every new customer, that limits your scaling curve.\n\nWill your AI solution generalize across different user groups, markets, or domains? For example, if you need to inject heavy domain expertise for every new customer, that limits your scaling curve. Privacy & security: Some AI use cases are tightly bound to data governance and privacy concerns. If you’re in finance, healthcare, or regulated industries, this becomes critical.\n\nSome AI use cases are tightly bound to data governance and privacy concerns. If you’re in finance, healthcare, or regulated industries, this becomes critical. Competitive differentiation: Are you building something truly new, or are you following industry trends? If AI is part of your differentiation strategy, prioritize novel use cases or unique capabilities, not just features everyone else is shipping.\n\n4. Plan for spill-over effects\n\nAnother important consideration is spillover effects and the long-term value of building reusable AI assets. When you design and develop datasets, models, pipelines, or knowledge representations with reuse in mind, you’re not just solving one isolated problem, but creating a foundational AI capability. It will enable you to accelerate future initiatives, reduce redundancy, and unlock compounding recurring returns in your business. This is especially critical if AI is a strategic differentiator in your business.\n\nSummary\n\nI hope this article helped you better understand the value of a structured discovery process in the messy, complex world of AI product development. Let’s summarize the frameworks and best practices we discussed:\n\nUse the AI Opportunity Tree to collect, map, and prioritize a broad set of potential AI use cases.\n\nto collect, map, and prioritize a broad set of potential AI use cases. Rely on iteration and continuous feedback to reduce uncertainty and refine your AI product over time.\n\nto reduce uncertainty and refine your AI product over time. Leverage the AI System Blueprint to align your team around a shared vision and avoid cross-functional disconnects.\n\nto align your team around a shared vision and avoid cross-functional disconnects. Explore the full AI solution space — don’t fall into the trap of limiting yourself to specific tools, models, or vendors too early.\n\n— don’t fall into the trap of limiting yourself to specific tools, models, or vendors too early. Treat prioritization as strategic alignment, not just feature scoring. It’s a way to gradually surface, shape, and refine your larger AI strategy.\n\nNote: Unless otherwise noted, all images are the author’s.",
         "2025-07-24T20:09:01",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/getting-ai-discovery-right/",
         "2025-07-26T06:23:31.297366",
         "building with AI, complexity adds up — there’s more uncertainty, more unknowns, and more moving parts across teams, tools, and expectations. That’s why having a solid discovery process is even more important than when you are building traditional, deterministic software. According to recent studies, the #1 reason why AI projects fail is that companies use AI for the wrong problems. These problems can be: too small, so no one cares too simple and not worth the effort of using AI and dealing with more complexity or just fundamentally not a good fit for AI in the first place In this article, I’ll share how we approach discovery for AI-driven products, breaking it down into three key steps: Figure 1: The discovery process I will use the example of a recent project in the automotive industry to illustrate the approach. Some of the points described will be new and specific to AI; others are known from traditional development, but gain even more meaning in the context of AI. 📚 Note: This content is based on my new book The Art of AI Product Development. Check it out for a deep dive into discovery and much more! Ideation: Finding the right AI opportunities Let’s start with ideation — the first step in any discovery process, in which you try to collect a large number of ideas for your development. We will look at two familiar ways this plays out: a textbook version, where you follow the best practices of product management, and a common real-life scenario, where things tend to get a little biased and messy. Rest assured — both paths can lead to success. 💡 According to Jeremy Utley’s and Perry Klebahn’s book Ideaflow, the single best predictor of the innovation capacity of a business is ideaflow — the number of novel ideas a person or group can generate around a given situation in a given amount of time. The textbook scenario: Problem-first thinking In the ideal world, you have a lot of time to explore and structure the opportunity space — that is, all the customer needs, desires, and pain points you’ve identified. These might come from different sources, such as: Customer interviews and feedback Sales and support conversations Competitive research And sometimes just the team’s gut feeling and industry experience As an example, here is an excerpt from the opportunity space for our automotive client, whose goal was to use AI to monitor the global automotive market and create recommendations for strategic innovation: Figure 2: Excerpt from an opportunity space Note that in this example, we are looking at a brownfield scenario. The opportunity space includes not only new feature ideas, but also critiques of existing features, such as “lack of transparency into sources.“ Once you’ve mapped out the needs, you look at the solution space — all the different ways you could technically solve those problems. For example, these can include: Rule-based analytics UX improvements Artificial Intelligence Adding more domain expertise … Importantly, AI is part of the solution space, but it is in no way privileged — it is one option among many others. Finally, you match opportunities to solutions, as illustrated in the following figure: Figure 3: Mapping your opportunity space to your solution space Let’s look at some of those links: If several users say, “I need alerts when a competitor launches new models,” you might consider using AI. However, a simple rule-based system that scrapes competitor offerings from their websites could solve that too. If the problem is, “I need to create reports and presentations faster,” AI starts to shine. Summarizing large amounts of data or text to reframe it and generate new content is exactly where modern AI excels. But if the issue is, “I don’t trust this data because I can’t see the sources,” AI probably isn’t the right fit at all. That’s a UX and transparency challenge, not a machine learning problem. In this scenario, it’s important to stay impartial when matching each need to the right solution. Even if you’re secretly excited to start building with the latest AI tools (who isn’t?), you have to be patient and wait for the right opportunity to surface. The real-life scenario: “Let’s use AI!” Now, in reality, things often start on a different note. For example, you’re in a team meeting, and someone says, “Let’s use AI!” Or your CEO makes a magic speech that suddenly puts AI on your agenda without providing any guidance or direction on what to do with it. Without further ado, you risk ending up in the “AI for the sake of AI” trap. However, it doesn’t have to be a disaster. We are talking about an extremely versatile technology, and you can work backwards from the AI-first imperative and find great opportunities by ideating around the core benefits and shortcomings of AI. The AI Opportunity Tree: Focusing on the core benefits of AI When I work with teams who’ve already decided they “want to do AI,” I help them frame the conversation around what AI is good at. In the B2B context, there are four main benefits you can build around: Automation & productivity: Use AI to make existing processes faster and cheaper. For example, Intercom uses AI chatbots to handle common customer service questions automatically, reducing response times and freeing up human agents for more complex cases. Improvement & augmentation: Help people improve the outcomes of their work. For example, Notion AI assists with drafting, summarizing, and refining content, while leaving the final decision and editing to the human user. Innovation & transformation: Unlock entirely new products, capabilities, or business models. For example, Tesla uses AI to shift from selling hardware to delivering continuous software-driven value with features like driver assistance, battery optimization, and in-car experiences via over-the-air updates. Personalization: Tailor outputs to specific users or contexts. For example, Spotify uses AI to create personalized playlists like Discover Weekly, adapting recommendations to each listener’s unique taste. When ideating, you should try to build a rich space of ideas by collecting multiple opportunities for each benefit. This will result in a structured AI Opportunity Tree. Here is a small part of the opportunity tree we built in the automotive scenario: Figure 4: Example of an AI Opportunity Tree for a market intelligence system Use the shortcomings of AI as exclusion criteria It’s also important to recognize when AI is not the best answer. Here are some of the user-facing shortcomings of AI, which you can use to filter out inappropriate use cases: AI is often a black box — users don’t always understand how it works. Example: In financial risk assessments, if a loan applicant gets rejected by an opaque AI model, the bank needs to explain why. Without clear reasoning, the system fails both legally and ethically. AI introduces uncertainty — the same or similar inputs can produce different outputs. Example: In legal document drafting, small prompt changes can lead to widely different contract terms. This unpredictability makes it risky for high-stakes, regulated industries. AI will make mistakes — sometimes in ways you can’t fully predict. Example: In healthcare diagnostics, a wrong AI prediction isn’t just a bug — it could lead to harmful decisions with life-or-death consequences. If your use case requires full accuracy, explainability, or predictability, move on — AI is likely not the right solution. With your AI opportunities and use cases laid out, let’s now see how you can add more flesh to your ideas and specify them for further prioritization and development. Specification & validation: Iterate yourself to the optimal system design Once you’ve mapped out your use cases and potential features, the next step is specification and validation. Here, you define how you are going to build an AI system to address a specific use case. Before we dive into the frameworks, let’s pause and talk about process, and specifically about the power of iteration in the context of AI. Adopting the practice of iteration The cover of my book The Art of AI Product Development features a dervish. Just as these dancers rotate in an endless and focused motion, you need to build the habit of iteration to get successful with AI. At the beginning of your journey, uncertainty is high: You are exploring a new land. Compared to “traditional” software development, where we have a lot of historical wisdom to build upon, the solutions and best practices aren’t figured out yet. AI systems will make mistakes, which are a major risk for trust and adoption. From the start, you should allocate a lot of time to understanding, anticipating, and preventing these mistakes. Your users will have different levels of AI literacy. Some will know how to handle errors and uncertainty; others will blindly trust AI outputs, which can lead to problems down the line. Through iteration, you reduce this uncertainty and build confidence both within your team and for your users. The key is to specify and validate in small steps: run quick experiments, build prototypes, and create feedback loops to understand what’s working and what’s not. Most importantly, get real feedback early. Today, it’s tempting to cocoon yourself in the world of AI-driven research and simulation. However, that’s a dangerous comfort zone. If you don’t talk to real users and put your prototypes in their hands, you risk a hard clash when your product finally launches. AI is AI, humans are humans. To build something successful, you need to understand and connect both worlds. Specifying your system with the AI System Blueprint To make an AI idea more concrete, we use the AI System Blueprint. This model represents both the opportunity and the solution, and its beauty lies in its simplicity and universality. Over the last two years, I was able to use it in literally every AI project I encountered to clarify what was being built. It helps align everyone around the same vision: product managers, designers, engineers, data scientists, and even executives. Figure 5: The AI System Blueprint is a simple but powerful model for specifying any AI application Here’s how to fill it out: Pick a use case from your AI Opportunity Tree. Map out the value AI can realistically provide to this use case: How much of it can you automate? Often, only partial automation is possible (and sufficient). What will the cost of the mistakes made by the AI be? Start with a rough estimate of the frequency and potential cost of mistakes, and correct as you get more information from prototyping and user testing. Do your users actually want automation? In some contexts — especially creative tasks — users might resist automation. They might prefer to do the task by themselves, or welcome lightweight AI assistance instead of a black-box system taking over their workflow. 3. Specify the AI solution: Data will be the raw material powering your AI system. will be the raw material powering your AI system. Intelligence , which includes AI models and your larger architecture, will use AI algorithms to distill value from your data. , which includes AI models and your larger architecture, will use AI algorithms to distill value from your data. The user experience is the channel that transports this value to the user. Thus, the initial blueprint for our use case of creating presentations and reports can look as follows: Figure 6: Example blueprint for an AI system that assists with the creation of slide decks and reports Avoid narrowing down your solution space too early The following figure shows a high-level solution space for AI: Figure 7: An overview over the AI Solution Space A detailed description of this space is out of the scope of this post (you can find it in chapters 3-10 of my book). Here, I would like to guard you against a common mistake — defining your solution space too narrowly. This limits creativity, leads to poor engineering decisions, and can lock you into suboptimal paths. Watch out for these three anti-patterns: “Let’s build an agent.” Right now, every other company wants to build their own AI agent. But when you ask, “What exactly is an agent in your context?”, most teams don’t have a clear answer. That’s usually a sign of hype over strategy. “Let’s pick a model and figure it out later.” Some teams start by selecting a model or vendor, and scramble to find a use case afterward. This almost always leads to misalignment, iteration dead-ends, and wasted resources. “Let’s just go with what our platform offers.” Many companies default to whatever their cloud provider suggests, skipping critical architectural decisions. Cloud providers are biased toward their own ecosystems. If you blindly follow their playbook, you’ll limit your options and miss the chance to develop AI craft and build something truly differentiated. Thus, before you decide on tooling, models, or platforms, take a step back and ask: What are the high-level decisions we need to make about data, models, AI architecture, and UX? How do they interconnect? What trade-offs are we willing to make? Also, make sure your entire team understands the whole solution space. In AI, cross-functional dependencies abound. For example, UX designers need to be familiar with the training data of an AI model because it largely determines the outputs users see. On the other hand, data and AI engineers need to understand the UX so they can put the AI system together in a way that allows it to serve the different insights and interactions. Therefore, everyone should be on-board with a shared mental model of the potential solutions and the final specification of your AI system. Stay up-to-date with the AI solution space with our AI Radar: The more concrete your specification gets, the more difficult it is to keep up with moving parts and new developments. Our AI Radar monitors the latest AI publications, models, and use cases, and structures them in a way that makes them actionable for product teams. If you’re interested, please sign up for the waitlist here. Prioritization: Deciding what to build first The last step in our discovery process is prioritization — deciding what to build first. Now, if you’ve done a solid job in specification and validation, this will often already point you to use cases with a high potential, making your prioritization smoother. Let’s start with the simple prioritization matrix and then learn how you can refine your prioritization criteria and process. The prioritization matrix Most of us are familiar with the classic prioritization matrix: you define criteria like user value, technical feasibility, maybe even risk, and you score your ideas accordingly. Then, you add up the points, and the highest-scoring opportunity wins. The following figure shows an example for some of the items in our AI Opportunity Tree: Figure 8: An example prioritization matrix for AI features This kind of framework is popular because it creates clarity and makes stakeholders feel good. There’s something reassuring about seeing messy, hairy ideas turned into numbers. However, prioritization matrices are highly simplified projections of reality. They hide the complexity and nuance behind prioritization, so you should avoid overrelying on this representation. Adding nuance to your AI prioritization Especially when you are just about to introduce AI, you’re not just ranking features, but making long-term bets on your product direction, tech stack, and positioning and differentiation. Instead of reducing prioritization to a spreadsheet exercise, sit with the complexity, the deeper conversations and potential misalignments. Take the time to work through the subtle details, weigh the trade-offs, and make decisions that align not just with what’s easy to build now, but also with the longer-term vision for AI in your business. 1. Pick the low-hanging fruits first The AI Opportunity Tree from section 1 provides a first hint for your prioritization. Normally, you are better off starting on the left of the tree and moving to the right as you gain more experience and traction with AI. Here’s why: On the left side, you have simple automation tasks. These are usually low risk, easy to measure, and a great way to start. As you venture to the right side, you see more advanced, strategic use cases like trend prediction, recommendations, or even new product ideas. These can add more impact, but also more risk and complexity. Starting on the left helps you build trust and momentum. It delivers quick wins, gives your company the time to get comfortable with AI, and builds the foundation for more ambitious projects down the line. 2. Work on strategic alignment Before you decide what to build, think about the role of AI in your business. While your company might not have an explicit AI strategy (yet), you can infer important information from its corporate strategy. For example, is AI a potential differentiator, or are you just playing catch-up with the market? If you want to gain a competitive edge with AI, you will want to move fast along your opportunity tree to implement more advanced and differentiated use cases. Your engineering decisions will lean towards more custom and crafty alternatives like open-source models, custom pipelines, or even on-premise infrastructure. By contrast, if your goal is to follow competitors, you might focus on automation and productivity for longer, and choose safer, off-the-shelf solutions from large cloud vendors and model providers. 3. Define custom criteria for prioritization AI projects often require custom prioritization dimensions beyond the usual trio of user value, business impact, and feasibility. Consider factors like: Scalability & generalization power: Will your AI solution generalize across different user groups, markets, or domains? For example, if you need to inject heavy domain expertise for every new customer, that limits your scaling curve. Will your AI solution generalize across different user groups, markets, or domains? For example, if you need to inject heavy domain expertise for every new customer, that limits your scaling curve. Privacy & security: Some AI use cases are tightly bound to data governance and privacy concerns. If you’re in finance, healthcare, or regulated industries, this becomes critical. Some AI use cases are tightly bound to data governance and privacy concerns. If you’re in finance, healthcare, or regulated industries, this becomes critical. Competitive differentiation: Are you building something truly new, or are you following industry trends? If AI is part of your differentiation strategy, prioritize novel use cases or unique capabilities, not just features everyone else is shipping. 4. Plan for spill-over effects Another important consideration is spillover effects and the long-term value of building reusable AI assets. When you design and develop datasets, models, pipelines, or knowledge representations with reuse in mind, you’re not just solving one isolated problem, but creating a foundational AI capability. It will enable you to accelerate future initiatives, reduce redundancy, and unlock compounding recurring returns in your business. This is especially critical if AI is a strategic differentiator in your business. Summary I hope this article helped you better understand the value of a structured discovery process in the messy, complex world of AI product development. Let’s summarize the frameworks and best practices we discussed: Use the AI Opportunity Tree to collect, map, and prioritize a broad set of potential AI use cases. to collect, map, and prioritize a broad set of potential AI use cases. Rely on iteration and continuous feedback to reduce uncertainty and refine your AI product over time. to reduce uncertainty and refine your AI product over time. Leverage the AI System Blueprint to align your team around a shared vision and avoid cross-functional disconnects. to align your team around a shared vision and avoid cross-functional disconnects. Explore the full AI solution space — don’t fall into the trap of limiting yourself to specific tools, models, or vendors too early. — don’t fall into the trap of limiting yourself to specific tools, models, or vendors too early. Treat prioritization as strategic alignment, not just feature scoring. It’s a way to gradually surface, shape, and refine your larger AI strategy. Note: Unless otherwise noted, all images are the author’s.",
         "en",
         "{'PER': ['Adopting', 'Compared', 'Finally', 'For', 'Here', 'Here’', 'However', 'If you blindly follow their playbook', 'Let’', 'Normally', 'Pick', 'Tesla', 'Therefore', 'This', 'desires', 'everyone should be on', 'hairy ideas turned into numbers', 'more unknowns', 'not just features everyone else is shipping', 'or contexts', 'please sign up for the waitlist here', 'prioritize novel', 'reduce redundancy', 'small', 'so you should avoid', 'where you follow the best practices of product management', 'will', 'you can infer', 'you define', 'you define how you are going to build an', 'you risk', 'you see more advanced', 'you should allocate', 'you should try to build', 'you will want to move fast along your opportunity tree to implement more advanced and differentiated'], 'MISC': ['AI Opportunity', 'AI craft and build something truly differentiated', 'AI for the wrong problems', 'AI is AI', 'AI is likely not the right', 'AI is often a black box', 'AI is part of the', 'AI model', 'AI outputs', 'AI to create personalized playlists like Discover Weekly', 'AI to monitor the global automotive market and create recommendations for strategic innovation', 'AI to shift from selling hardware to delivering continuous software-driven value with features', 'AI!', 'According to', 'According to Jeremy Utley’s and Perry', 'Adding', 'An', 'An overview over the AI', 'Another', 'As you venture to the right side', 'At the beginning of your journey', 'Automation & productivity:', 'But when you ask', 'Check it out for a deep dive into discovery and much more!', 'Cloud', 'Competitive research And', 'Customer interviews and feedback', 'Data will be the raw material powering your AI system', 'Deciding what to build first The last step in our discovery process is prioritization', 'Do your', 'Especially when you are just about to', 'Figure 2: Excerpt from an opportunity space', 'Figure 3: Mapping your opportunity space to your', 'Figure 4: Example of an AI Opportunity Tree for a market intelligence system Use the shortcomings of AI as exclusion', 'Figure 5:', 'Figure 6: Example blueprint for an AI system that assists with the creation of slide decks and reports Avoid narrowing down your', 'Focusing on the core benefits of AI When I work with teams who’ve already decided they “want to do AI', 'From the start', 'Help people improve the outcomes of their work', 'Here are some of the user-facing shortcomings of AI', 'Here is', 'Here’s how to fill it out:', 'How much of it can you automate', 'I was able to use it in literally every AI project I encountered to clarify what was being built', 'I would like to guard you against', 'Ideation: Finding the right AI', 'If AI is part of your differentiation strategy', 'If several users say', 'If the problem is', 'If you don’t talk to real users and put your prototypes in their hands', 'If you want to gain', 'If your', 'If you’re in finance', 'In AI', 'In some contexts', 'In this article', 'Innovation & transformation', 'Intercom uses AI chatbots to handle', 'It delivers', 'It helps', 'It will enable you to accelerate', 'Iterate yourself to the optimal system', 'It’', 'It’s', 'I’ll share how we approach discovery for AI-driven', 'Just as these dancers rotate in an endless and focused', 'Let’s summarize the frameworks and best practices we discussed', 'Leverage the AI System Blueprint to', 'Map out the value AI can realistically provide to this', 'Most importantly', 'Note that in this example', 'Now', 'Often', 'Once you’ve mapped', 'Once you’ve mapped out your', 'Our AI Radar monitors the latest AI publications', 'Over the last two years', 'Personalization:', 'Pick the low-hanging fruits first', 'Plan for spill-over', 'Privacy & security', 'Problem-first thinking In the ideal world', 'Rest assured — both paths can lead to success', 'Right now', 'Sales and support', 'Scalability & generalization power', 'Some AI', 'Some of the', 'Some teams start by selecting', 'Some will know how to handle errors and uncertainty', 'Specification & validation', 'Specify the AI', 'Spotify', 'Start with', 'Starting on the left helps you build trust and momentum', 'Stay up-to-date with the AI', 'Summary I hope this article helped you better understand the value of', 'Take the time to work through the subtle', 'That’', 'That’s why having', 'The', 'The AI Opportunity', 'The cover of my book The Art of AI Product Development features', 'The discovery process I will use the example of', 'The following', 'The real-life scenario', 'The textbook scenario', 'There’s something reassuring about seeing messy', 'These can', 'These might come from', 'They hide the complexity and nuance behind prioritization', 'They might prefer to do the task by themselves', 'This kind of framework is popular because it creates clarity and makes', 'This model', 'This will result in', 'Through iteration', 'Thus', 'To build something successful', 'Treat', 'Tree from section 1 provides', 'UX and transparency challenge', 'UX designers need to be familiar with the training data of an', 'Unless otherwise', 'Unlock entirely new products', 'Use AI to make', 'Use the AI Opportunity Tree to collect', 'Watch out for these three anti-patterns', 'We are talking about an extremely versatile technology', 'We will look at two familiar ways this plays out: a textbook', 'What will the cost of the mistakes made by the AI be?', 'When you design and develop datasets', 'While your company might not have an', 'Will your AI', 'With your AI opportunities and', 'Without clear reasoning', 'Work', 'You are exploring', 'Your', 'Your engineering decisions will lean towards more custom and crafty alternatives like open', 'adapting recommendations to each listener’', 'all images are the author’s.', 'and', 'and builds the foundation for more ambitious projects down the line', 'and can lock you into suboptimal paths', 'and choose safer', 'and create feedback loops to understand what’s working and what’s not', 'and make decisions that', 'and model providers', 'and more moving parts across teams', 'and preventing these mistakes', 'and refining content', 'and scramble to find', 'and someone says', 'and wasted resources', 'and you can work backwards from the AI-first imperative and find great', 'and you score your ideas accordingly', 'anticipating', 'broad set of potential', 'broad set of potential AI', 'build prototypes', 'but also critiques of', 'but creating', 'cases with a high potential', 'data and AI engineers need to understand the UX so they can put the AI system together in a way that allows it to serve the different insights and interactions', 'differentiator in your business', 'don’t always understand how it works', 'don’t fall into the trap of limiting yourself to specific tools', 'easy to measure', 'explainability', 'get real feedback early', 'gut feeling and industry', 'hard clash when your product finally launches', 'is AI', 'it’', 'leads to poor engineering decisions', 'let’s now see how you can add more flesh to your ideas and specify them for further prioritization and development', 'let’s pause and talk about process', 'magic speech that suddenly puts', 'matrix Most of us are familiar with the classic prioritization matrix', 'matrix and then learn how you can refine your prioritization', 'matrix for AI', 'maybe even risk', 'mistake — defining your', 'model and figure it out later', 'most teams don’t have a clear answer', 'not a machine learning problem', 'not only new feature ideas', 'of your AI system', 'off-the-shelf solutions from large cloud', 'or predictability', 'over-the-air updates', 'problem', 'processes faster and cheaper', 'risk for trust and adoption', 'run quick experiments', 'sit with the complexity', 'space for AI', 'structured discovery process', 'such as “lack of transparency into sources', 'take a step back and ask: What are the high-level decisions', 'that limits your scaling curve', 'the #1 reason why AI projects', 'the deeper conversations and potential misalignments', 'the first step in any discovery process', 'the full AI', 'the initial blueprint for our', 'the next step is specification and', 'the single best predictor of the innovation capacity of', 'the solutions and best practices', 'the system fails both legally and ethically', 'think about the role of AI in your business', 'this will often already point you to', 'times and freeing', 'tools', 'we are looking at', 'we use the AI System Blueprint', 'weigh the trade-offs', 'where things tend to get a little biased and messy', 'where we have a lot of historical wisdom to build upon', 'while leaving the final decision and editing to the human', 'will be the raw material powering your AI system', 'with AI', 'world of AI', 'you are better off starting on the left of the tree and moving to the right as you', 'you have a lot of time to explore and structure the opportunity space — that is', 'you have simple automation tasks', 'you have to be patient and wait for the right opportunity to surface', 'you look at the', 'you might focus on automation and productivity for longer', 'you need to build the habit of iteration to get successful with AI', 'you need to understand and connect both worlds', 'you risk ending up in the “AI for the sake of AI” trap', 'your team around a shared vision and avoid cross-functional disconnects', 'you’ll limit your options and miss the chance to', '” AI starts to shine', '” I', '” you might consider using AI'], 'ORG': ['AI models and your larger architecture', 'Artificial Intelligence Adding', 'For', 'Importantly', 'Instead of reducing prioritization to', 'Intelligence', 'These', 'Today', 'and positioning and differentiation', 'and process', 'deterministic software', 'feel good', 'gives your company the time to get comfortable with AI', 'like', 'software development', 'tech stack'], 'LOC': ['AI', 'For', 'How do they interconnect', 'Tree', 'and', 'and prioritize', 'and the long', 'and unlock compounding recurring returns in your business', 'new land', 'specific', 'summarizing', 'that’', 'your AI']}",
         "[-0.0345548652112484, -0.04302263259887695, 0.05303552374243736, -0.019878461956977844, 0.06781280785799026, -0.037807464599609375, 0.029061703011393547, 0.062007930129766464, 0.04424847662448883, -0.008884081616997719, -0.10414131730794907, -0.056516945362091064, 0.049695853143930435, 0.03204648569226265, -0.016799764707684517, 0.03290870413184166, 0.02174149453639984, -0.05804237723350525, -0.010180538520216942, -0.07615654170513153, 0.012920655310153961, 0.010214658454060555, 0.029606712982058525, -0.060196325182914734, -0.09941227734088898, 0.08459190279245377, 0.043105434626340866, -0.09414418786764145, 0.0349460206925869, -0.01708463579416275, 0.030611839145421982, 0.05861829221248627, 0.0921252965927124, -0.06172646954655647, 0.07309935241937637, 0.02358934096992016, -0.008071903139352798, 0.012699045240879059, 0.08541158586740494, -0.08243373781442642, 0.013276326470077038, -0.055381402373313904, -0.007130352780222893, -0.01568358950316906, 0.08601542562246323, -0.012211447581648827, 0.025890816003084183, 0.0035206584725528955, 0.014607287012040615, -0.01829446293413639, -0.0908600240945816, -0.052284903824329376, -0.03237022086977959, -0.05258193612098694, -0.05533783882856369, 0.017565228044986725, -0.02455405704677105, 0.011976423673331738, -0.026737775653600693, 0.010190071538090706, 0.07908916473388672, -0.07744762301445007, 0.06449995934963226, -0.0882624089717865, -0.0073460363782942295, 0.007621222175657749, -0.002103797858580947, 0.039537832140922546, -0.02813408337533474, 0.010652807541191578, 0.07581052929162979, 0.07826296985149384, -0.07853028923273087, 0.03358564153313637, 0.029829999431967735, -0.02333139069378376, 0.06706584244966507, -0.025850344449281693, 0.033426251262426376, -0.07128579914569855, -0.04215807095170021, 0.03266867250204086, -0.037499457597732544, 0.10232219099998474, -0.00945986993610859, 0.0007415509899146855, 0.001067524659447372, 0.009872432798147202, 0.0294673889875412, 0.03073165938258171, -0.08086897432804108, -0.08295034617185593, -0.07268451899290085, -0.035831477493047714, 0.15349571406841278, 0.10932963341474533, 0.01834375038743019, -0.011566851288080215, 0.00549518596380949, 0.011182640679180622, -0.04194938763976097, 0.04590800032019615, 0.038768064230680466, -0.11084678024053574, -0.06912396848201752, 0.06143946573138237, 0.014202821999788284, -0.03192109614610672, 0.04443003982305527, 0.01900896616280079, -0.015678266063332558, -0.02963879331946373, 0.016800351440906525, -0.00030916676041670144, 0.025771360844373703, 0.015643293038010597, -0.045271169394254684, 0.03396023437380791, -0.02582162246108055, 0.08033792674541473, -0.041725751012563705, 0.03529845550656319, 0.03561962768435478, 0.06766088306903839, 0.03790809586644173, 0.12380876392126083, -0.030402133241295815, 5.2975460242370776e-33, -0.06152468919754028, 0.03826097026467323, 0.016511987894773483, 0.10386443883180618, 0.010487479157745838, -0.031774941831827164, 0.05826973170042038, 0.05555902421474457, -0.00659262714907527, 0.027138281613588333, -0.010633126832544804, 0.012850687839090824, -0.0483526885509491, -0.0033890227787196636, 0.08074430376291275, -0.042302206158638, 0.007785224821418524, -0.05315283313393593, 0.005884411279112101, -0.10159836709499359, -0.03146805614233017, -0.05404557287693024, 0.032654158771038055, 0.006455113645642996, 0.05290069431066513, -0.0009228996932506561, 0.042109813541173935, -0.03378141298890114, 0.013178852386772633, -0.0015876016113907099, -0.04024399816989899, 0.07203390449285507, -0.04418344423174858, 0.04622127488255501, -0.052999239414930344, -0.010870651341974735, -0.09420556575059891, -0.053770944476127625, -0.006276984233409166, 0.06899677962064743, -0.00638949079439044, 0.017327263951301575, -0.05675123631954193, 0.0031707703601568937, -0.021694153547286987, 0.046455152332782745, 0.012353026308119297, -0.018607331439852715, -0.016305530443787575, 0.00536309415474534, -0.03283742442727089, 0.009375812485814095, 0.07583867758512497, -0.06900034099817276, 0.03486505150794983, -0.009477074258029461, -0.04986179992556572, -0.06561505049467087, 0.07674725353717804, -8.715021976968274e-05, -0.06744349002838135, 0.004545297939330339, -0.012561015784740448, 0.11005391925573349, -0.03108319640159607, 0.13685540854930878, 0.05272524058818817, 0.036155495792627335, 0.02546929381787777, 0.02815689891576767, 0.03373928740620613, -0.012637998908758163, -0.0022879759781062603, -0.07133955508470535, 0.05213332921266556, 0.014976521953940392, 0.03222941979765892, -0.06101880222558975, 0.035576894879341125, -0.05637962743639946, -0.0876985415816307, 0.03587336093187332, -0.036179184913635254, 0.016676461324095726, 0.021014859899878502, -0.03529662638902664, -0.05722908675670624, 0.019930154085159302, -0.06218355894088745, 0.0823180079460144, -0.07571862637996674, 0.04232866317033768, -0.03642958030104637, 0.08282236754894257, -0.004826150834560394, -5.862983786237553e-33, -0.0026117528323084116, -0.08212007582187653, 0.028130928054451942, -0.028797028586268425, 0.05386326462030411, -0.05454925820231438, -0.09416085481643677, -0.07847180962562561, 0.07799790799617767, 0.026016997173428535, -0.06228311359882355, -0.05574961006641388, -0.019591765478253365, 0.011652834713459015, -0.04922844469547272, 0.028247151523828506, 0.05004284530878067, -0.015406313352286816, 0.10350530594587326, 0.023680705577135086, 0.004615429788827896, 0.02268592081964016, -0.11222437024116516, -0.059285905212163925, -0.003703763009980321, 0.039281442761421204, -0.05303765460848808, 0.0023011721204966307, -0.021478356793522835, -0.01091853529214859, 0.0025879847817122936, -0.05639420449733734, -0.007289382629096508, 0.036549776792526245, 0.013111930340528488, 0.06251160055398941, 0.004861787892878056, -0.0536334253847599, 0.021135633811354637, -0.03937176614999771, 0.00934000127017498, -0.053587447851896286, -0.05432768538594246, -0.05834714695811272, 0.010398111306130886, -0.06750296801328659, -0.007604049053043127, 0.02841091901063919, 0.040516287088394165, -0.031727928668260574, 0.06929820775985718, 0.04005662724375725, -0.008358417078852654, -0.10662554204463959, -0.07568644732236862, 0.049779459834098816, 0.06704191118478775, 0.024180011823773384, -0.001636410946957767, 0.07854506373405457, -0.04694008454680443, -0.04826737940311432, 0.06627633422613144, -0.017694011330604553, -0.05662787705659866, -0.017747361212968826, 0.03771909698843956, 0.009847858920693398, -0.022677266970276833, -0.04139569774270058, -0.03198321536183357, 0.012976037338376045, -0.05416407063603401, 0.050887640565633774, -0.03475984185934067, -0.010869969613850117, -0.008781248703598976, -0.011425145901739597, -0.01432652398943901, -0.08369547128677368, 0.012612534686923027, -0.029255881905555725, 0.0003568755346350372, -0.010982383973896503, -0.03731034696102142, 0.11014512926340103, -0.005738640204071999, -0.011887161061167717, 0.01694280281662941, 0.08923882991075516, -0.06735489517450333, 0.020582066848874092, -0.040501631796360016, 0.06939574331045151, -0.02796918712556362, -6.039248745537407e-08, -0.026113029569387436, -0.024073753505945206, 0.0990663394331932, -0.009062682278454304, 0.07060692459344864, 0.014626659452915192, -0.08081547915935516, 0.07273674011230469, -0.04430548846721649, -0.008766347542405128, -0.008866745047271252, -0.03395819291472435, 0.0009285962441936135, 0.09644439071416855, 0.02752762846648693, 0.038039516657590866, -0.045987751334905624, -0.032109931111335754, -0.027911311015486717, -0.03418208658695221, 0.11291328817605972, -0.00871522631496191, 0.020389322191476822, 0.012683587148785591, 0.006616909056901932, -0.18509480357170105, -0.010914293117821217, -0.05157829821109772, -0.05186185985803604, 0.026237819343805313, -0.055699218064546585, 0.01620485633611679, 0.03960113599896431, 0.05690627917647362, 0.08321523666381836, -0.07734674960374832, 0.052469052374362946, -0.03663391247391701, -0.07458052784204483, -0.048120517283678055, 0.002296167891472578, 0.10742563754320145, -0.017399964854121208, -0.07809082418680191, -0.009980302304029465, -0.03500020131468773, -0.051652826368808746, -0.06193234398961067, -0.021012693643569946, 0.04064791277050972, 0.04325087368488312, -0.009392042644321918, 0.024364428594708443, 0.06389622390270233, 0.11529543995857239, 0.1087188869714737, 0.019694363698363304, -0.05183212459087372, 0.024282915517687798, 0.04641249403357506, 0.03354471176862717, -0.015776008367538452, 0.01812181994318962, 0.05484836548566818]",
         "0.16"
        ],
        [
         "13",
         "24",
         "LimeWire AI Studio Review 2023: Details, Pricing & Features",
         "In the rapidly advancing landscape of AI technology and innovation, LimeWire emerges as a unique platform in the realm of generative AI tools. This platform not only stands out from the multitude of existing AI tools but also brings a fresh approach to content generation. LimeWire not only empowers users to create AI content but also provides creators with creative ways to share and monetize their creations. As we explore LimeWire, our aim is to uncover its features, benefits for creators, and the exciting possibilities it offers for AI content generation. This platform presents an opportunity for users to harness the power of AI in image creation, all while enjoying the advantages of a free and accessible service. Let's unravel the distinctive features that set LimeWire apart in the dynamic landscape of AI-powered tools, understanding how creators can leverage its capabilities to craft unique and engaging AI-generated images. Introduction LimeWire, a name once associated with the notorious file-sharing tool from the 2000s, has undergone a significant transformation. The LimeWire we discuss today is not the file-sharing application of the past but has re-emerged as an entirely new entity—a cutting-edge AI content publishing platform. This revamped LimeWire invites users to register and unleash their creativity by crafting original AI content, which can then be shared and showcased on the LimeWire Studio. Notably, even acclaimed artists and musicians, such as Deadmau5, Soulja Boy, and Sean Kingston, have embraced this platform to publish their content in the form of NFT music, videos, and images. Beyond providing a space for content creation and sharing, LimeWire introduces monetization models to empower users to earn revenue from their creations. This includes avenues such as earning ad revenue and participating in the burgeoning market of Non-Fungible Tokens (NFTs). As we delve further, we'll explore these monetization strategies in more detail to provide a comprehensive understanding of LimeWire's innovative approach to content creation and distribution. LimeWire Studio welcomes content creators into its fold, providing a space to craft personalized AI-focused content for sharing with fans and followers. Within this creative hub, every piece of content generated becomes not just a creation but a unique asset—ownable and tradable. Fans have the opportunity to subscribe to creators' pages, immersing themselves in the creative journey and gaining ownership of digital collectibles that hold tradeable value within the LimeWire community. Notably, creators earn a 2.5% royalty each time their content is traded, adding a rewarding element to the creative process. The platform's flexibility is evident in its content publication options. Creators can choose to share their work freely with the public or opt for a premium subscription model, granting exclusive access to specialized content for subscribers. LimeWire AI Studio As of the present moment, LimeWire focuses on AI Image Generation, offering a spectrum of creative possibilities to its user base. The platform, however, has ambitious plans on the horizon, aiming to broaden its offerings by introducing AI music and video generation tools in the near future. This strategic expansion promises creators even more avenues for expression and engagement with their audience, positioning LimeWire Studio as a dynamic and evolving platform within the realm of AI-powered content creation. AI Image Generation Tools The LimeWire AI image generation tool presents a versatile platform for both the creation and editing of images. Supporting advanced models such as Stable Diffusion 2.1, Stable Diffusion XL, and DALL-E 2, LimeWire offers a sophisticated toolkit for users to delve into the realm of generative AI art. Much like other tools in the generative AI landscape, LimeWire provides a range of options catering to various levels of complexity in image creation. Users can initiate the creative process with prompts as simple as a few words or opt for more intricate instructions, tailoring the output to their artistic vision. What sets LimeWire apart is its seamless integration of different AI models and design styles. Users have the flexibility to effortlessly switch between various AI models, exploring diverse design styles such as cinematic, digital art, pixel art, anime, analog film, and more. Each style imparts a distinctive visual identity to the generated AI art, enabling users to explore a broad spectrum of creative possibilities. The platform also offers additional features, including samplers, allowing users to fine-tune the quality and detail levels of their creations. Customization options and prompt guidance further enhance the user experience, providing a user-friendly interface for both novice and experienced creators. Excitingly, LimeWire is actively developing its proprietary AI model, signaling ongoing innovation and enhancements to its image generation capabilities. This upcoming addition holds the promise of further expanding the creative horizons for LimeWire users, making it an evolving and dynamic platform within the landscape of AI-driven art and image creation. Sign Up Now To Get Free Credits Automatically Mint Your Content As NFTs Upon completing your creative endeavor on LimeWire, the platform allows you the option to publish your content. An intriguing feature follows this step: LimeWire automates the process of minting your creation as a Non-Fungible Token (NFT), utilizing either the Polygon or Algorand blockchain. This transformative step imbues your artwork with a unique digital signature, securing its authenticity and ownership in the decentralized realm. Creators on LimeWire hold the power to decide the accessibility of their NFT creations. By opting for a public release, the content becomes discoverable by anyone, fostering a space for engagement and interaction. Furthermore, this choice opens the avenue for enthusiasts to trade the NFTs, adding a layer of community involvement to the artistic journey. Alternatively, LimeWire acknowledges the importance of exclusivity. Creators can choose to share their posts exclusively with their premium subscribers. In doing so, the content remains a special offering solely for dedicated fans, creating an intimate and personalized experience within the LimeWire community. This flexibility in sharing options emphasizes LimeWire's commitment to empowering creators with choices in how they connect with their audience and distribute their digital creations. After creating your content, you can choose to publish the content. It will automatically mint your creation as an NFT on the Polygon or Algorand blockchain. You can also choose whether to make it public or subscriber-only. If you make it public, anyone can discover your content and even trade the NFTs. If you choose to share the post only with your premium subscribers, it will be exclusive only to your fans. Earn Revenue From Your Content Additionally, you can earn ad revenue from your content creations as well. When you publish content on LimeWire, you will receive 70% of all ad revenue from other users who view your images, music, and videos on the platform. This revenue model will be much more beneficial to designers. You can experiment with the AI image and content generation tools and share your creations while earning a small income on the side. LMWR Tokens The revenue you earn from your creations will come in the form of LMWR tokens, LimeWire’s own cryptocurrency. Your earnings will be paid every month in LMWR, which you can then trade on many popular crypto exchange platforms like Kraken, ByBit, and UniSwap. You can also use your LMWR tokens to pay for prompts when using LimeWire generative AI tools. Pricing Plans You can sign up to LimeWire to use its AI tools for free. You will receive 10 credits to use and generate up to 20 AI images per day. You will also receive 50% of the ad revenue share. However, you will get more benefits with premium plans. Basic plan: For $9.99 per month, you will get 1,000 credits per month, up to 2 ,000 image generations, early access to new AI models, and 50% ad revenue share Advanced plan: For $29 per month, you will get 3750 credits per month, up to 7500 image generations, early access to new AI models, and 60% ad revenue share Pro plan: For $49 per month, you will get 5,000 credits per month, up to 10,000 image generations, early access to new AI models, and 70% ad revenue share Pro Plus plan: For $99 per month, you will get 11,250 credits per month, up to 2 2,500 image generations, early access to new AI models, and 70% ad revenue share With all premium plans, you will receive a Pro profile badge, full creation history, faster image generation, and no ads. Sign Up Now To Get Free Credits Conclusion In conclusion, LimeWire emerges as a democratizing force in the creative landscape, providing an inclusive platform where anyone can unleash their artistic potential and effortlessly share their work. With the integration of AI, LimeWire eliminates traditional barriers, empowering designers, musicians, and artists to publish their creations and earn revenue with just a few clicks. The ongoing commitment of LimeWire to innovation is evident in its plans to enhance generative AI tools with new features and models. The upcoming expansion to include music and video generation tools holds the promise of unlocking even more possibilities for creators. It sparks anticipation about the diverse and innovative ways in which artists will leverage these tools to produce and publish their own unique creations. For those eager to explore, LimeWire's AI tools are readily accessible for free, providing an opportunity to experiment and delve into the world of generative art. As LimeWire continues to evolve, creators are encouraged to stay tuned for the launch of its forthcoming AI music and video generation tools, promising a future brimming with creative potential and endless artistic exploration",
         "In the rapidly advancing landscape of AI technology and innovation, LimeWire emerges as a unique platform in the realm of generative AI tools. This platform not only stands out from the multitude of existing AI tools but also brings a fresh approach to content generation. LimeWire not only empowers users to create AI content but also provides creators with creative ways to share and monetize their creations.\n\n\n\n\n\nAs we explore LimeWire, our aim is to uncover its features, benefits for creators, and the exciting possibilities it offers for AI content generation. This platform presents an opportunity for users to harness the power of AI in image creation, all while enjoying the advantages of a free and accessible service.\n\n\n\n\n\nLet's unravel the distinctive features that set LimeWire apart in the dynamic landscape of AI-powered tools, understanding how creators can leverage its capabilities to craft unique and engaging AI-generated images.\n\n\n\n\n\nIntroduction\n\n\n\nLimeWire, a name once associated with the notorious file-sharing tool from the 2000s, has undergone a significant transformation. The LimeWire we discuss today is not the file-sharing application of the past but has re-emerged as an entirely new entity—a cutting-edge AI content publishing platform. LimeWire, a name once associated with the notorious file-sharing tool from the 2000s, has undergone a significant transformation. The LimeWire we discuss today is not the file-sharing application of the past but has re-emerged as an entirely new entity—a cutting-edge AI content publishing platform.\n\n\n\n\n\nThis revamped LimeWire invites users to register and unleash their creativity by crafting original AI content, which can then be shared and showcased on the LimeWire Studio. Notably, even acclaimed artists and musicians, such as Deadmau5, Soulja Boy, and Sean Kingston, have embraced this platform to publish their content in the form of NFT music, videos, and images.\n\n\n\n\n\nBeyond providing a space for content creation and sharing, LimeWire introduces monetization models to empower users to earn revenue from their creations. This includes avenues such as earning ad revenue and participating in the burgeoning market of Non-Fungible Tokens (NFTs). As we delve further, we'll explore these monetization strategies in more detail to provide a comprehensive understanding of LimeWire's innovative approach to content creation and distribution.\n\n\n\n\n\nLimeWire Studio welcomes content creators into its fold, providing a space to craft personalized AI-focused content for sharing with fans and followers. Within this creative hub, every piece of content generated becomes not just a creation but a unique asset—ownable and tradable. Fans have the opportunity to subscribe to creators' pages, immersing themselves in the creative journey and gaining ownership of digital collectibles that hold tradeable value within the LimeWire community. Notably, creators earn a 2.5% royalty each time their content is traded, adding a rewarding element to the creative process.\n\n\n\n\n\nThe platform's flexibility is evident in its content publication options. Creators can choose to share their work freely with the public or opt for a premium subscription model, granting exclusive access to specialized content for subscribers.\n\n\n\n\n\nAs of the present moment, LimeWire focuses on AI Image Generation, offering a spectrum of creative possibilities to its user base. The platform, however, has ambitious plans on the horizon, aiming to broaden its offerings by introducing AI music and video generation tools in the near future. This strategic expansion promises creators even more avenues for expression and engagement with their audience, positioning LimeWire Studio as a dynamic and evolving platform within the realm of AI-powered content creation.\n\n\n\n\n\nAI Image Generation Tools\n\nThe LimeWire AI image generation tool presents a versatile platform for both the creation and editing of images. Supporting advanced models such as Stable Diffusion 2.1, Stable Diffusion XL, and DALL-E 2, LimeWire offers a sophisticated toolkit for users to delve into the realm of generative AI art.\n\n\n\n\n\nMuch like other tools in the generative AI landscape, LimeWire provides a range of options catering to various levels of complexity in image creation. Users can initiate the creative process with prompts as simple as a few words or opt for more intricate instructions, tailoring the output to their artistic vision.\n\n\n\n\n\nWhat sets LimeWire apart is its seamless integration of different AI models and design styles. Users have the flexibility to effortlessly switch between various AI models, exploring diverse design styles such as cinematic, digital art, pixel art, anime, analog film, and more. Each style imparts a distinctive visual identity to the generated AI art, enabling users to explore a broad spectrum of creative possibilities.\n\n\n\n\n\nThe platform also offers additional features, including samplers, allowing users to fine-tune the quality and detail levels of their creations. Customization options and prompt guidance further enhance the user experience, providing a user-friendly interface for both novice and experienced creators.\n\n\n\n\n\nExcitingly, LimeWire is actively developing its proprietary AI model, signaling ongoing innovation and enhancements to its image generation capabilities. This upcoming addition holds the promise of further expanding the creative horizons for LimeWire users, making it an evolving and dynamic platform within the landscape of AI-driven art and image creation.\n\nSign Up Now To Get Free Credits\n\nAutomatically Mint Your Content As NFTs\n\nUpon completing your creative endeavor on LimeWire, the platform allows you the option to publish your content. An intriguing feature follows this step: LimeWire automates the process of minting your creation as a Non-Fungible Token (NFT), utilizing either the Polygon or Algorand blockchain. This transformative step imbues your artwork with a unique digital signature, securing its authenticity and ownership in the decentralized realm.\n\n\n\n\n\nCreators on LimeWire hold the power to decide the accessibility of their NFT creations. By opting for a public release, the content becomes discoverable by anyone, fostering a space for engagement and interaction. Furthermore, this choice opens the avenue for enthusiasts to trade the NFTs, adding a layer of community involvement to the artistic journey.\n\n\n\n\n\nAlternatively, LimeWire acknowledges the importance of exclusivity. Creators can choose to share their posts exclusively with their premium subscribers. In doing so, the content remains a special offering solely for dedicated fans, creating an intimate and personalized experience within the LimeWire community. This flexibility in sharing options emphasizes LimeWire's commitment to empowering creators with choices in how they connect with their audience and distribute their digital creations.\n\n\n\n\n\nAfter creating your content, you can choose to publish the content. It will automatically mint your creation as an NFT on the Polygon or Algorand blockchain. You can also choose whether to make it public or subscriber-only.\n\n\n\n\n\nIf you make it public, anyone can discover your content and even trade the NFTs. If you choose to share the post only with your premium subscribers, it will be exclusive only to your fans.\n\n\n\n\n\nEarn Revenue From Your Content\n\nAdditionally, you can earn ad revenue from your content creations as well.\n\nWhen you publish content on LimeWire, you will receive 70% of all ad revenue from other users who view your images, music, and videos on the platform.\n\n\n\n\n\nThis revenue model will be much more beneficial to designers. You can experiment with the AI image and content generation tools and share your creations while earning a small income on the side.\n\n\n\n\n\nLMWR Tokens\n\nThe revenue you earn from your creations will come in the form of LMWR tokens, LimeWire’s own cryptocurrency.\n\nYour earnings will be paid every month in LMWR, which you can then trade on many popular crypto exchange platforms like Kraken, ByBit, and UniSwap.\n\nYou can also use your LMWR tokens to pay for prompts when using LimeWire generative AI tools.\n\nPricing Plans\n\nYou can sign up to LimeWire to use its AI tools for free. You will receive 10 credits to use and generate up to 20 AI images per day. You will also receive 50% of the ad revenue share. However, you will get more benefits with premium plans.\n\nBasic plan:\n\nFor $9.99 per month, you will get 1,000 credits per month, up to 2 ,000 image generations, early access to new AI models, and 50% ad revenue share\n\nAdvanced plan:\n\nFor $29 per month, you will get 3750 credits per month, up to 7500 image generations, early access to new AI models, and 60% ad revenue share\n\nPro plan:\n\nFor $49 per month, you will get 5,000 credits per month, up to 10,000 image generations, early access to new AI models, and 70% ad revenue share\n\nPro Plus plan:\n\nFor $99 per month, you will get 11,250 credits per month, up to 2 2,500 image generations, early access to new AI models, and 70% ad revenue share\n\nWith all premium plans, you will receive a Pro profile badge, full creation history, faster image generation, and no ads.\n\nSign Up Now To Get Free Credits\n\nConclusion\n\nIn conclusion, LimeWire emerges as a democratizing force in the creative landscape, providing an inclusive platform where anyone can unleash their artistic potential and effortlessly share their work. With the integration of AI, LimeWire eliminates traditional barriers, empowering designers, musicians, and artists to publish their creations and earn revenue with just a few clicks.\n\n\n\n\n\nThe ongoing commitment of LimeWire to innovation is evident in its plans to enhance generative AI tools with new features and models. The upcoming expansion to include music and video generation tools holds the promise of unlocking even more possibilities for creators. It sparks anticipation about the diverse and innovative ways in which artists will leverage these tools to produce and publish their own unique creations.\n\n\n\n\n\nFor those eager to explore, LimeWire's AI tools are readily accessible for free, providing an opportunity to experiment and delve into the world of generative art. As LimeWire continues to evolve, creators are encouraged to stay tuned for the launch of its forthcoming AI music and video generation tools, promising a future brimming with creative potential and endless artistic exploration",
         "2023-12-12T16:10:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2023/12/limewire-ai-studio-review-2023-details.html",
         "2025-07-26T05:41:35.761190",
         "In the rapidly advancing landscape of AI technology and innovation, LimeWire emerges as a unique platform in the realm of generative AI tools. This platform not only stands out from the multitude of existing AI tools but also brings a fresh approach to content generation. LimeWire not only empowers users to create AI content but also provides creators with creative ways to share and monetize their creations. As we explore LimeWire, our aim is to uncover its features, benefits for creators, and the exciting possibilities it offers for AI content generation. This platform presents an opportunity for users to harness the power of AI in image creation, all while enjoying the advantages of a free and accessible service. Let's unravel the distinctive features that set LimeWire apart in the dynamic landscape of AI-powered tools, understanding how creators can leverage its capabilities to craft unique and engaging AI-generated images. Introduction LimeWire, a name once associated with the notorious file-sharing tool from the 2000s, has undergone a significant transformation. The LimeWire we discuss today is not the file-sharing application of the past but has re-emerged as an entirely new entity—a cutting-edge AI content publishing platform. LimeWire, a name once associated with the notorious file-sharing tool from the 2000s, has undergone a significant transformation. The LimeWire we discuss today is not the file-sharing application of the past but has re-emerged as an entirely new entity—a cutting-edge AI content publishing platform. This revamped LimeWire invites users to register and unleash their creativity by crafting original AI content, which can then be shared and showcased on the LimeWire Studio. Notably, even acclaimed artists and musicians, such as Deadmau5, Soulja Boy, and Sean Kingston, have embraced this platform to publish their content in the form of NFT music, videos, and images. Beyond providing a space for content creation and sharing, LimeWire introduces monetization models to empower users to earn revenue from their creations. This includes avenues such as earning ad revenue and participating in the burgeoning market of Non-Fungible Tokens (NFTs). As we delve further, we'll explore these monetization strategies in more detail to provide a comprehensive understanding of LimeWire's innovative approach to content creation and distribution. LimeWire Studio welcomes content creators into its fold, providing a space to craft personalized AI-focused content for sharing with fans and followers. Within this creative hub, every piece of content generated becomes not just a creation but a unique asset—ownable and tradable. Fans have the opportunity to subscribe to creators' pages, immersing themselves in the creative journey and gaining ownership of digital collectibles that hold tradeable value within the LimeWire community. Notably, creators earn a 2.5% royalty each time their content is traded, adding a rewarding element to the creative process. The platform's flexibility is evident in its content publication options. Creators can choose to share their work freely with the public or opt for a premium subscription model, granting exclusive access to specialized content for subscribers. As of the present moment, LimeWire focuses on AI Image Generation, offering a spectrum of creative possibilities to its user base. The platform, however, has ambitious plans on the horizon, aiming to broaden its offerings by introducing AI music and video generation tools in the near future. This strategic expansion promises creators even more avenues for expression and engagement with their audience, positioning LimeWire Studio as a dynamic and evolving platform within the realm of AI-powered content creation. AI Image Generation Tools The LimeWire AI image generation tool presents a versatile platform for both the creation and editing of images. Supporting advanced models such as Stable Diffusion 2.1, Stable Diffusion XL, and DALL-E 2, LimeWire offers a sophisticated toolkit for users to delve into the realm of generative AI art. Much like other tools in the generative AI landscape, LimeWire provides a range of options catering to various levels of complexity in image creation. Users can initiate the creative process with prompts as simple as a few words or opt for more intricate instructions, tailoring the output to their artistic vision. What sets LimeWire apart is its seamless integration of different AI models and design styles. Users have the flexibility to effortlessly switch between various AI models, exploring diverse design styles such as cinematic, digital art, pixel art, anime, analog film, and more. Each style imparts a distinctive visual identity to the generated AI art, enabling users to explore a broad spectrum of creative possibilities. The platform also offers additional features, including samplers, allowing users to fine-tune the quality and detail levels of their creations. Customization options and prompt guidance further enhance the user experience, providing a user-friendly interface for both novice and experienced creators. Excitingly, LimeWire is actively developing its proprietary AI model, signaling ongoing innovation and enhancements to its image generation capabilities. This upcoming addition holds the promise of further expanding the creative horizons for LimeWire users, making it an evolving and dynamic platform within the landscape of AI-driven art and image creation. Sign Up Now To Get Free Credits Automatically Mint Your Content As NFTs Upon completing your creative endeavor on LimeWire, the platform allows you the option to publish your content. An intriguing feature follows this step: LimeWire automates the process of minting your creation as a Non-Fungible Token (NFT), utilizing either the Polygon or Algorand blockchain. This transformative step imbues your artwork with a unique digital signature, securing its authenticity and ownership in the decentralized realm. Creators on LimeWire hold the power to decide the accessibility of their NFT creations. By opting for a public release, the content becomes discoverable by anyone, fostering a space for engagement and interaction. Furthermore, this choice opens the avenue for enthusiasts to trade the NFTs, adding a layer of community involvement to the artistic journey. Alternatively, LimeWire acknowledges the importance of exclusivity. Creators can choose to share their posts exclusively with their premium subscribers. In doing so, the content remains a special offering solely for dedicated fans, creating an intimate and personalized experience within the LimeWire community. This flexibility in sharing options emphasizes LimeWire's commitment to empowering creators with choices in how they connect with their audience and distribute their digital creations. After creating your content, you can choose to publish the content. It will automatically mint your creation as an NFT on the Polygon or Algorand blockchain. You can also choose whether to make it public or subscriber-only. If you make it public, anyone can discover your content and even trade the NFTs. If you choose to share the post only with your premium subscribers, it will be exclusive only to your fans. Earn Revenue From Your Content Additionally, you can earn ad revenue from your content creations as well. When you publish content on LimeWire, you will receive 70% of all ad revenue from other users who view your images, music, and videos on the platform. This revenue model will be much more beneficial to designers. You can experiment with the AI image and content generation tools and share your creations while earning a small income on the side. LMWR Tokens The revenue you earn from your creations will come in the form of LMWR tokens, LimeWire’s own cryptocurrency. Your earnings will be paid every month in LMWR, which you can then trade on many popular crypto exchange platforms like Kraken, ByBit, and UniSwap. You can also use your LMWR tokens to pay for prompts when using LimeWire generative AI tools. Pricing Plans You can sign up to LimeWire to use its AI tools for free. You will receive 10 credits to use and generate up to 20 AI images per day. You will also receive 50% of the ad revenue share. However, you will get more benefits with premium plans. Basic plan: For $9.99 per month, you will get 1,000 credits per month, up to 2 ,000 image generations, early access to new AI models, and 50% ad revenue share Advanced plan: For $29 per month, you will get 3750 credits per month, up to 7500 image generations, early access to new AI models, and 60% ad revenue share Pro plan: For $49 per month, you will get 5,000 credits per month, up to 10,000 image generations, early access to new AI models, and 70% ad revenue share Pro Plus plan: For $99 per month, you will get 11,250 credits per month, up to 2 2,500 image generations, early access to new AI models, and 70% ad revenue share With all premium plans, you will receive a Pro profile badge, full creation history, faster image generation, and no ads. Sign Up Now To Get Free Credits Conclusion In conclusion, LimeWire emerges as a democratizing force in the creative landscape, providing an inclusive platform where anyone can unleash their artistic potential and effortlessly share their work. With the integration of AI, LimeWire eliminates traditional barriers, empowering designers, musicians, and artists to publish their creations and earn revenue with just a few clicks. The ongoing commitment of LimeWire to innovation is evident in its plans to enhance generative AI tools with new features and models. The upcoming expansion to include music and video generation tools holds the promise of unlocking even more possibilities for creators. It sparks anticipation about the diverse and innovative ways in which artists will leverage these tools to produce and publish their own unique creations. For those eager to explore, LimeWire's AI tools are readily accessible for free, providing an opportunity to experiment and delve into the world of generative art. As LimeWire continues to evolve, creators are encouraged to stay tuned for the launch of its forthcoming AI music and video generation tools, promising a future brimming with creative potential and endless artistic exploration",
         "en",
         "{'MISC': ['AI Image', 'AI content', 'AI model', 'AI music and video generation tools in the near future', 'AI tools', 'AI tools but also brings', 'AI tools with new features and models', 'AI-focused content for sharing with fans and followers', 'AI-generated images', 'After creating your content', 'An intriguing feature follows', 'As of the present', 'As we', 'Basic', 'Beyond providing a space for content creation and sharing', 'By opting for', 'ByBit', 'Content As', 'Creators can choose to share their posts exclusively with their premium subscribers.', 'Creators can choose to share their work freely with the public or opt for', 'Customization options', 'Earn Revenue From Your Content Additionally', \"Fans have the opportunity to subscribe to creators' pages\", 'For those eager to explore', 'If you choose to share the post only with your premium subscribers', 'It sparks anticipation about the diverse and innovative ways in which artists will leverage these tools to produce and publish their own', 'It will automatically mint your creation as an NFT on the Polygon or', \"Let's unravel the distinctive features\", 'LimeWire', 'LimeWire Studio as', 'LimeWire acknowledges the importance of exclusivity', 'LimeWire is actively developing its proprietary', 'LimeWire we discuss today is not the file-sharing application of the past but has re-emerged as an entirely new entity', 'LimeWire’s own cryptocurrency', 'Much like other tools in the generative AI', 'Non-Fungible Token', 'Sign Up Now To Get Free Credits', 'Soulja Boy', 'Stable', 'Supporting advanced models such as Stable', 'The ongoing commitment of LimeWire to innovation is', 'The platform also', \"The platform'\", 'The upcoming expansion to', 'This', 'This platform not only stands out from the multitude of', 'This revamped', 'UniSwap', 'Users can initiate the creative process with prompts as simple as', 'Users have the flexibility to effortlessly switch between various AI', 'When you', 'Within this creative hub', 'You can', 'You can also choose whether to make it public or', 'You can also use your LMWR', 'You will also receive', 'You will receive 10 credits to use and generate up to 20 AI images per day', 'Your earnings will be paid every month in LMWR', 'adding', 'adding a rewarding element to the creative process', 'all while enjoying the advantages of a free and accessible service', 'and artists to publish their creations and earn revenue', 'and no ads', 'and the exciting', 'and videos on the platform', 'anyone can', 'benefits for creators', 'creating an intimate and personalized experience within the LimeWire community', 'creators are encouraged to stay tuned for the launch of its forthcoming AI music and video generation tools', 'each time their content is traded', 'early access to new AI models', 'fresh approach to content generation', 'granting', 'immersing themselves in the creative journey and gaining ownership of digital collectibles that hold tradeable value within the LimeWire community', 'model', 'music and video generation tools holds the promise of unlocking even more possibilities for creators', 'our aim is to uncover its features', 'providing', 'providing an opportunity to experiment and delve into the world of generative art', 'release', 'securing its authenticity and ownership in the decentralized realm', 'signaling ongoing innovation and enhancements', 'space for engagement and interaction', 'step imbues', 'such as Deadmau5', 'tailoring the output to their artistic vision', 'the content becomes discoverable by anyone', 'the platform allows you the option to publish your content', 'these monetization strategies in more detail to provide', 'toolkit for users to delve into the realm of generative AI art', 'up to 2', 'videos, and images', \"we'll\", 'with their audience and distribute their digital creations', 'you can earn ad revenue from your content creations as well'], 'ORG': ['LMWR', \"LimeWire'\", 'NFT', 'NFTs', 'Notably', 'Pro', 'and musicians', 'has undergone', 'musicians', 'utilizing either the Polygon'], 'PER': ['Furthermore', 'However', 'aiming to broaden its', 'empowering designers', 'even acclaimed', 'providing', 'you can choose to publish the content', 'you will get 1,000', 'you will get 11,250 credits per month', 'you will get 3750 credits per month', 'you will get 5,000 credits per month', 'you will get more benefits with premium plans', 'you will receive'], 'LOC': ['Alternatively', 'fostering']}",
         "[-0.11648961901664734, -0.05739957094192505, 0.006911072414368391, 0.05119143798947334, 0.12570032477378845, -0.01356538850814104, -0.018814342096447945, -0.0406440868973732, 0.05418295040726662, 0.0021316679194569588, -0.00931799877434969, 0.011577388271689415, 0.07500966638326645, 0.012562080286443233, -0.043065156787633896, 0.024815721437335014, -0.02331247553229332, -0.005848783999681473, -0.06248309463262558, -0.06581705063581467, -0.04670890420675278, -0.040063753724098206, 0.04646884277462959, -0.08127108216285706, 0.06022022292017937, 0.058243509382009506, -0.023979319259524345, -0.05751321092247963, 0.03985656797885895, -0.05352841690182686, 0.07190171629190445, -0.03232651948928833, 0.02078038454055786, 0.033929869532585144, -0.004333093296736479, 0.0053141191601753235, -0.026332901790738106, 0.0025487379170954227, -0.051937174052000046, -0.04050254449248314, 0.018679192289710045, -0.027766944840550423, -0.02661859802901745, 0.0022239552345126867, 0.001006523729301989, 0.05775272846221924, 0.011550843715667725, -0.007743966765701771, 0.04065306857228279, 0.02800506167113781, -0.06546194106340408, -0.06128966063261032, -0.0102633535861969, 0.03249141201376915, -0.003388850949704647, -0.00890127569437027, 0.024515971541404724, 0.03917096182703972, -0.006500404328107834, 0.03168713301420212, 0.03272351622581482, -0.013511456549167633, 0.020465046167373657, -0.025638654828071594, 0.07296990603208542, -0.015266938135027885, 0.02390131913125515, 0.07960258424282074, 0.05984935909509659, -0.12082453817129135, 0.005795470904558897, 0.09691092371940613, -0.0292118601500988, 0.12113281339406967, 0.008062666282057762, 0.0026191556826233864, 0.03407132998108864, 0.06884732842445374, -0.03558839485049248, -0.0909009724855423, 0.003776386845856905, 0.0097407978028059, 0.00955751072615385, 0.023973695933818817, -0.06698242574930191, 0.029215533286333084, 0.008601566776633263, 0.01282260101288557, -0.033521007746458054, -0.00012484400940593332, -0.08199460804462433, 0.06149538978934288, 0.10077279061079025, -0.06822225451469421, 0.09039750695228577, 0.028325527906417847, -0.03993314132094383, -0.07679232209920883, -0.031152674928307533, -0.0003958115994464606, -0.022526340559124947, 0.023787228390574455, -0.008029092103242874, -0.09918191283941269, 0.09517883509397507, 0.012746077962219715, 0.07630826532840729, -0.009942256845533848, 0.026618102565407753, 0.026364382356405258, 0.03369443118572235, 0.01627538725733757, -0.008426266722381115, -0.10413245111703873, 0.06292612850666046, 0.016344841569662094, -0.12946686148643494, 0.11605406552553177, 0.029627881944179535, 0.018929222598671913, 0.06993402540683746, 0.0028009717352688313, -0.0811702087521553, -0.017121467739343643, -0.011385245248675346, -0.008504655212163925, -0.07030755281448364, 1.886651902680463e-33, 0.028352970257401466, 0.026065370067954063, 0.008554250001907349, 0.07575249671936035, 0.09405017644166946, -0.07401209324598312, -0.023970788344740868, 0.043675292283296585, -0.15272782742977142, -0.010579006746411324, 0.013458279892802238, 0.02261469140648842, -0.08936191350221634, 0.12294530123472214, 0.06616193056106567, -0.038818880915641785, -0.05355650186538696, -0.010692059993743896, 0.044853247702121735, 0.013809360563755035, -0.040034931153059006, -0.07099008560180664, 0.014963966794312, 0.056857477873563766, -0.02184177003800869, -0.013795331120491028, 0.07094212621450424, -0.08419537544250488, 0.13129210472106934, -0.04377623274922371, -0.11249200254678726, -0.007898240350186825, 0.05469584837555885, -0.047492124140262604, -0.06023065000772476, -0.04048532620072365, -0.058206506073474884, -0.022185558453202248, -0.05239265412092209, 0.07791449129581451, 0.010809799656271935, -0.016561215743422508, -0.05955347418785095, -0.02054940164089203, -0.06904498487710953, -0.0034932908602058887, 0.025313423946499825, 0.007405335083603859, -0.01564144343137741, 0.0009052875102497637, 0.03857804834842682, 0.02364257723093033, 0.09113363921642303, 0.021511351689696312, -0.01096275169402361, -0.037043020129203796, 0.020794762298464775, -0.025643547996878624, 0.03429488465189934, -0.045771628618240356, 0.07113151997327805, 0.06772717088460922, -0.02908467687666416, 0.04415375739336014, -0.017303092405200005, -0.0026861662045121193, 0.15578490495681763, 0.06713440269231796, 0.0646325945854187, 0.04224752262234688, -0.07239893078804016, -0.01447195466607809, -0.011686932295560837, -0.03489764407277107, -0.0030219689942896366, -0.07482081651687622, -0.021509533748030663, -0.05926337465643883, 0.04881318658590317, -0.020167894661426544, -0.13322071731090546, -0.02432584948837757, -0.017986824735999107, -0.00916898064315319, -0.047157492488622665, 0.008194449357688427, -0.015006588771939278, -0.0398724265396595, -0.06333037465810776, 0.01592506282031536, -0.0006091516697779298, 0.019305700436234474, 0.020751530304551125, 0.0728660300374031, -0.01474919356405735, -8.189555266163641e-34, 0.010836397297680378, -0.004965349566191435, -0.08195473998785019, -0.006753281224519014, 0.017754502594470978, -0.03152192011475563, -0.05683683604001999, -0.012054300867021084, 0.006013788282871246, -0.012279943563044071, -0.04596275836229324, 0.025505302473902702, -0.032807160168886185, -0.0818297266960144, 0.02985602617263794, -0.07774168998003006, 0.018458278849720955, -0.030057275667786598, -0.10392660647630692, 0.019895685836672783, -0.0008636206621304154, 0.07743904739618301, -0.0024538764264434576, -0.022188017144799232, -0.014889605343341827, 0.045239463448524475, 0.023244230076670647, 0.0371396504342556, 0.026904970407485962, 0.006662716157734394, 0.05873052775859833, -0.027785649523139, -0.06117238849401474, -0.11987683176994324, 0.007021273486316204, 0.005449461285024881, 0.08439481258392334, 0.02290176786482334, -0.0663607195019722, 0.053256839513778687, -0.002222200157120824, -0.004511247389018536, -0.05071214213967323, 0.027712199836969376, -0.057690490037202835, -0.008261362090706825, -0.05704156309366226, 0.05088337883353233, -0.013758474960923195, 0.06000097095966339, 0.041407521814107895, -0.056148089468479156, -0.019092140719294548, -0.07117217034101486, 0.021994242444634438, -0.024027137085795403, -0.05169638991355896, 0.08083273470401764, 0.006289432756602764, 0.06375454366207123, -0.0034952189307659864, -0.0939546748995781, -0.09344356507062912, 0.030978169292211533, -0.04286539927124977, 0.04318429157137871, 0.02343204990029335, 0.04860018566250801, -0.05337578430771828, 0.05968400835990906, 0.050201576203107834, -0.02042459510266781, 0.02982967160642147, 0.05784353241324425, 0.0019491021521389484, 0.05433935672044754, 0.060581181198358536, 0.022451797500252724, 0.020283589139580727, -0.03828459978103638, -0.027250997722148895, 0.0569191500544548, 0.01799742504954338, 0.04766673967242241, 0.06963607668876648, -0.0017450726591050625, -0.06549401581287384, 0.02529693767428398, 0.033059585839509964, 0.05655241385102272, -0.017912045121192932, 0.03257576376199722, -0.08827908337116241, 0.06397940963506699, -0.04680967703461647, -3.9920760031009195e-08, -0.013872024603188038, -0.015998097136616707, -0.045099858194589615, 0.029612362384796143, 0.016584664583206177, 0.03814864903688431, -0.01896730437874794, 0.054542426019907, 0.0094619020819664, -0.016927270218729973, 0.05199160426855087, -0.07184214144945145, -0.06110915169119835, -0.03321995958685875, 0.008086029440164566, 0.024035973474383354, -0.006834950298070908, 0.04584537819027901, -0.0031604536343365908, -0.05647572875022888, 0.037195127457380295, 0.015533309429883957, -0.021474625915288925, -0.05621170252561569, -0.008560980670154095, -0.06450505554676056, 0.024584688246250153, -0.0012931874953210354, -0.05758336931467056, 0.033672768622636795, 0.05655425414443016, 0.026332683861255646, 0.02386174164712429, 0.023177199065685272, 0.05054619908332825, 0.05266245827078819, -0.04917995259165764, 0.027225006371736526, -0.056273117661476135, -0.03665272146463394, 0.08232465386390686, 0.0896366536617279, 0.034306351095438004, -0.060310471802949905, -0.057285845279693604, -0.05704082176089287, 0.034253958612680435, -0.003830907167866826, 0.009016362018883228, 0.01663084328174591, -0.08826842159032822, -0.06994251906871796, 0.08035705983638763, 0.106254942715168, 0.11961908638477325, 0.006683277897536755, 0.011889597401022911, 0.019374791532754898, 0.10164682567119598, 0.10151847451925278, 0.06518568843603134, 0.03651226684451103, 0.05562666803598404, 0.01183710340410471]",
         "0.16"
        ],
        [
         "14",
         "34",
         "Top 10 Best PLR(Private Label Rights)  Websites | Which One You Should Join in 2022?",
         "Content creation is one of the biggest struggles for many marketers and business owners. It often requires both time and financial resources, especially if you plan to hire a writer. Today, we have a fantastic opportunity to use other people's products by purchasing Private Label Rights. To find a good PLR website, first, determine the type of products you want to acquire. One way to do this is to choose among membership sites or PLR product stores. Following are 10 great sites that offer products in both categories. What are PLR websites? Private Label Rights (PLR) products are digital products that can be in the form of an ebook, software, online course videos, value-packed articles, etc. You can use these products with some adjustments to sell as your own under your own brand and keep all the money and profit yourself without wasting your time on product creation. The truth is that locating the best website for PLR materials can be a time-consuming and expensive exercise. That’s why we have researched, analyzed, and ranked the best 10 websites: 1. PLR.me PLR.me is of the best places to get PLR content in 2021-2022. It offers a content marketing system that comes with courses, brandable tools, and more. It is the most trusted PLR website, among other PLR sites. The PLR.me platform features smart digital caching PLR tools for health and wellness professionals. The PLR.me platform, which was built on advanced caching technology, has been well-received by big brands such as Toronto Sun and Entrepreneur. The best thing about this website is its content marketing automation tools. Pricing Pay-as-you-go Plan – $22 100 Monthly Plan – $99/month 400 Annual Plan – $379/year 800 Annual Plan – $579/year 2500 Annual Plan – $990/year Pros Access over 15,940+ ready-to-use PLR coaching resources. Content marketing and sliding tools are provided by the site. You can create courses, products, webinars, emails, and nearly anything else you can dream of. You can cancel your subscription anytime. Cons Compared to other top PLR sites, this one is a bit more expensive. 2. InDigitalWorks InDigitalWorks is a leading private label rights membership website established in 2008. As of now, it has more than 100,000 members from around the globe have joined the platform. The site offers thousands of ready-to-be-sold digital products for online businesses in every single niche possible. InDigitalWorks features hundreds of electronic books, software applications, templates, graphics, videos that you can sell right away. Pricing: 3 Months Plan – $39 1 Year Plan – $69 Lifetime Plan – $79 Pros IndigitalWorks promotes new authors by providing them with 200 free products for download. Largest and most reputable private label rights membership site. 20000+ digital products 137 training videos provided by experts to help beginners set up and grow their online presence for free. 10 GB of web hosting will be available on a reliable server. Cons Fewer people are experiencing the frustration of not getting the help they need. 3. BuyQualityPLR BuyQualityPLR’s website is a Top PLR of 2021-2022! It's a source for major Internet Marketing Products and Resources. Whether you’re an Affiliate Marketer, Product Creator, Course Seller, BuyQualityPLR can assist you in the right direction. You will find several eBooks and digital products related to the Health and Fitness niche, along with a series of Security-based products. If you search for digital products, Resell Rights Products, Private Label Rights Products, or Internet Marketing Products, BuyQualityPLR is among the best websites for your needs. Pricing Free PLR articles packs, ebooks, and other digital products are available Price ranges from 3.99$ to 99.9$ Pros Everything on this site is written by professionals The quick download features available Doesn't provide membership. Offers thousand of PLR content in many niches Valuable courses available Cons You can't buy all content because it doesn't provide membership 4. IDPLR The IDPLR website has helped thousands of internet marketers since 2008. This website follows a membership approach and allows you to gain access to thousands of PLR products in different niches. The best thing about this site is the quality of the products, which is extremely impressive. This is the best PLR website of 2021-2022, offering over 200k+ high-quality articles. It also gives you graphics, templates, ebooks, and audio. Pricing 3 Months ACCESS: $39 1 YEAR ACCESS: $69 LIFETIME ACCESS: $79 Pros You will have access to over 12,590 PLR products. You will get access to training tutorials and Courses in a Gold membership. 10 GB of web hosting will be available on a reliable server. You will receive 3D eCover Software It offers an unlimited download limit Most important, you will get a 30 day money-back guarantee Cons: A few products are available for free membership. 5. PLRMines PLRmines is a leading digital product library for private label rights products. The site provides useful information on products that you can use to grow your business, as well as licenses for reselling the content. You can either purchase a membership or get access through a free trial, and you can find unlimited high-quality resources via the site's paid or free membership. Overall, the site is an excellent resource for finding outstanding private label rights content. Pricing Lifetime membership: $97 Pros 4000+ ebooks from top categories Members have access to more than 660 instructional videos covering all kinds of topics in a membership area. You will receive outstanding graphics that are ready to use. They also offer a variety of helpful resources and tools, such as PLR blogs, WordPress themes, and plugins Cons The free membership won't give you much value. 6. Super-Resell Super-Resell is another remarkable provider of PLR material. The platform was established in 2009 and offers valuable PLR content to users. Currently, the platform offers standard lifetime memberships and monthly plans at an affordable price. Interested users can purchase up to 10,000 products with digital rights or rights of re-sale. Super-Resell offers a wide range of products such as readymade websites, article packs, videos, ebooks, software, templates, and graphics, etc. Pricing 6 Months Membership: $49.90 Lifetime membership: $129 Pros It offers you products that come with sales pages and those without sales pages. You'll find thousands of digital products that will help your business grow. Daily News update Cons The company has set up an automatic renewal system. This can result in costs for you even though you are not using the service. 7. Unstoppable PLR UnStoppablePLR was launched in 2006 by Aurelius Tjin, an internet marketer. Over the last 15 years, UnStoppablePLR has provided massive value to users by offering high-quality PLR content. The site is one of the best PLR sites because of its affordability and flexibility. Pricing Regular Price: $29/Month Pros You’ll get 30 PLR articles in various niches for free. 100% money-back guarantee. Members get access to community It gives you access to professionally designed graphics and much more. Cons People often complain that not enough PLR products are released each month. 8. Resell Rights Weekly Resell Rights Weekly, a private label rights (PLR) website, provides exceptional PLR content. It is among the top free PLR websites that provide free membership. You will get 728+ PLR products completely free and new products every single week. The Resell Rights Weekly gives you free instant access to all products and downloads the ones you require. Pricing Gold Membership: $19.95/Month Pros Lots of products available free of cost Free access to the members forum Cons The prices for the products at this PLR site are very low quality compared to other websites that sell the same items. 9. MasterResellRights MasterResellRights was established in 2006, and it has helped many successful entrepreneurs. Once you join MasterResellRights, you will get access to more than 10,000 products and services from other members. It is one of the top PLR sites that provide high-quality PLR products to members across the globe. You will be able to access a lot of other membership privileges at no extra price. The website also provides PLR, MRR, and RR license products. Pricing ⦁ One Month Membership: $19.97 ⦁ Three Month Membership: $47.00 Pros ⦁ Access more than 10,000 high-quality, PLR articles in different niches. ⦁ Get daily fresh new updates ⦁ Users get 8 GB of hosting space ⦁ You can pay using PayPal Cons ⦁ Only members have access to the features of this site. 10. BigProductStore BigProductStore is a popular private label rights website that offers tens of thousands of digital products. These include software, videos, video courses, eBooks, and many others that you can resell, use as you want, or sell and keep 100% of the profit. The PLR website updates its product list daily. It currently offers over 10,000 products. The site offers original content for almost every niche and when you register as a member, you can access the exclusive products section where you can download a variety of high-quality, unique, and exclusive products. Pricing Monthly Plan: $19.90/Month 27% off One-Time-Payment: $98.50 50% off Monthly Ultimate: $29.90/Month 36% off One-Time-Payment Ultimate: $198.50 50% off Pros You can use PLR products to generate profits, give them as bonuses for your affiliate promotion campaign, or rebrand them and create new unique products. Lifetime memberships for PLR products can save you money if you’re looking for a long-term solution to bulk goods. The website is updated regularly with fresh, quality content. Cons Product descriptions may not provide much detail, so it can be difficult to know just what you’re downloading. Some product categories such as WP Themes and articles are outdated.",
         "Content creation is one of the biggest struggles for many marketers and business owners. It often requires both time and financial resources, especially if you plan to hire a writer.\n\nToday, we have a fantastic opportunity to use other people's products by purchasing Private Label Rights.\n\n\n\nTo find a good PLR website, first, determine the type of products you want to acquire. One way to do this is to choose among membership sites or PLR product stores. Following are 10 great sites that offer products in both categories.\n\n\n\nWhat are PLR websites?\n\nPrivate Label Rights (PLR) products are digital products that can be in the form of an ebook, software, online course videos, value-packed articles, etc. You can use these products with some adjustments to sell as your own under your own brand and keep all the money and profit yourself without wasting your time on product creation.\n\nThe truth is that locating the best website for PLR materials can be a time-consuming and expensive exercise. That’s why we have researched, analyzed, and ranked the best 10 websites:\n\n1. PLR.me\n\nPLR.me is of the best places to get PLR content in 2021-2022. It offers a content marketing system that comes with courses, brandable tools, and more. It is the most trusted PLR website, among other PLR sites. The PLR.me platform features smart digital caching PLR tools for health and wellness professionals. The PLR.me platform, which was built on advanced caching technology, has been well-received by big brands such as Toronto Sun and Entrepreneur. The best thing about this website is its content marketing automation tools.\n\n\n\nPricing\n\nPay-as-you-go Plan – $22\n\n100 Monthly Plan – $99/month\n\n400 Annual Plan – $379/year\n\n800 Annual Plan – $579/year\n\n2500 Annual Plan – $990/year\n\nPros\n\nAccess over 15,940+ ready-to-use PLR coaching resources.\n\nContent marketing and sliding tools are provided by the site.\n\nYou can create courses, products, webinars, emails, and nearly anything else you can dream of.\n\nYou can cancel your subscription anytime.\n\nCons\n\nCompared to other top PLR sites, this one is a bit more expensive.\n\n2. InDigitalWorks\n\nInDigitalWorks is a leading private label rights membership website established in 2008. As of now, it has more than 100,000 members from around the globe have joined the platform. The site offers thousands of ready-to-be-sold digital products for online businesses in every single niche possible. InDigitalWorks features hundreds of electronic books, software applications, templates, graphics, videos that you can sell right away.\n\n\n\nPricing:\n\n3 Months Plan – $39\n\n1 Year Plan – $69\n\nLifetime Plan – $79\n\nPros\n\nIndigitalWorks promotes new authors by providing them with 200 free products for download.\n\nLargest and most reputable private label rights membership site.\n\n20000+ digital products\n\n137 training videos provided by experts to help beginners set up and grow their online presence for free.\n\n10 GB of web hosting will be available on a reliable server.\n\nCons\n\nFewer people are experiencing the frustration of not getting the help they need.\n\n3. BuyQualityPLR\n\nBuyQualityPLR’s website is a Top PLR of 2021-2022! It's a source for major Internet Marketing Products and Resources. Whether you’re an Affiliate Marketer, Product Creator, Course Seller, BuyQualityPLR can assist you in the right direction. You will find several eBooks and digital products related to the Health and Fitness niche, along with a series of Security-based products. If you search for digital products, Resell Rights Products, Private Label Rights Products, or Internet Marketing Products, BuyQualityPLR is among the best websites for your needs.\n\n\n\nPricing\n\nFree PLR articles packs, ebooks, and other digital products are available\n\nPrice ranges from 3.99$ to 99.9$\n\nPros\n\nEverything on this site is written by professionals\n\nThe quick download features available\n\nDoesn't provide membership.\n\nOffers thousand of PLR content in many niches\n\nValuable courses available\n\nCons\n\nYou can't buy all content because it doesn't provide membership\n\n4. IDPLR\n\nThe IDPLR website has helped thousands of internet marketers since 2008. This website follows a membership approach and allows you to gain access to thousands of PLR products in different niches. The best thing about this site is the quality of the products, which is extremely impressive.\n\nThis is the best PLR website of 2021-2022, offering over 200k+ high-quality articles. It also gives you graphics, templates, ebooks, and audio.\n\n\n\nPricing\n\n3 Months ACCESS: $39\n\n1 YEAR ACCESS: $69\n\nLIFETIME ACCESS: $79\n\nPros\n\nYou will have access to over 12,590 PLR products.\n\nYou will get access to training tutorials and Courses in a Gold membership.\n\n10 GB of web hosting will be available on a reliable server.\n\nYou will receive 3D eCover Software\n\nIt offers an unlimited download limit\n\nMost important, you will get a 30 day money-back guarantee\n\nCons:\n\nA few products are available for free membership.\n\n5. PLRMines\n\nPLRmines is a leading digital product library for private label rights products. The site provides useful information on products that you can use to grow your business, as well as licenses for reselling the content. You can either purchase a membership or get access through a free trial, and you can find unlimited high-quality resources via the site's paid or free membership. Overall, the site is an excellent resource for finding outstanding private label rights content.\n\n\n\nPricing\n\nLifetime membership: $97\n\nPros\n\n4000+ ebooks from top categories\n\nMembers have access to more than 660 instructional videos covering all kinds of topics in a membership area.\n\nYou will receive outstanding graphics that are ready to use.\n\nThey also offer a variety of helpful resources and tools, such as PLR blogs, WordPress themes, and plugins\n\nCons\n\nThe free membership won't give you much value.\n\n6. Super-Resell\n\nSuper-Resell is another remarkable provider of PLR material. The platform was established in 2009 and offers valuable PLR content to users. Currently, the platform offers standard lifetime memberships and monthly plans at an affordable price. Interested users can purchase up to 10,000 products with digital rights or rights of re-sale. Super-Resell offers a wide range of products such as readymade websites, article packs, videos, ebooks, software, templates, and graphics, etc.\n\n\n\nPricing\n\n6 Months Membership: $49.90\n\nLifetime membership: $129\n\nPros\n\nIt offers you products that come with sales pages and those without sales pages.\n\nYou'll find thousands of digital products that will help your business grow.\n\nDaily News update\n\nCons\n\nThe company has set up an automatic renewal system. This can result in costs for you even though you are not using the service.\n\n7. Unstoppable PLR\n\nUnStoppablePLR was launched in 2006 by Aurelius Tjin, an internet marketer. Over the last 15 years, UnStoppablePLR has provided massive value to users by offering high-quality PLR content. The site is one of the best PLR sites because of its affordability and flexibility.\n\n\n\nPricing\n\nRegular Price: $29/Month\n\nPros\n\nYou’ll get 30 PLR articles in various niches for free.\n\n100% money-back guarantee.\n\nMembers get access to community\n\nIt gives you access to professionally designed graphics and much more.\n\nCons\n\nPeople often complain that not enough PLR products are released each month.\n\n8. Resell Rights Weekly\n\nResell Rights Weekly, a private label rights (PLR) website, provides exceptional PLR content. It is among the top free PLR websites that provide free membership. You will get 728+ PLR products completely free and new products every single week. The Resell Rights Weekly gives you free instant access to all products and downloads the ones you require.\n\n\n\nPricing\n\nGold Membership: $19.95/Month\n\nPros\n\nLots of products available free of cost\n\nFree access to the members forum\n\nCons\n\nThe prices for the products at this PLR site are very low quality compared to other websites that sell the same items.\n\n9. MasterResellRights\n\nMasterResellRights was established in 2006, and it has helped many successful entrepreneurs. Once you join MasterResellRights, you will get access to more than 10,000 products and services from other members. It is one of the top PLR sites that provide high-quality PLR products to members across the globe. You will be able to access a lot of other membership privileges at no extra price. The website also provides PLR, MRR, and RR license products.\n\n\n\nPricing\n\n⦁ One Month Membership: $19.97\n\n⦁ Three Month Membership: $47.00\n\n\n\nPros\n\n⦁ Access more than 10,000 high-quality, PLR articles in different niches.\n\n⦁ Get daily fresh new updates\n\n⦁ Users get 8 GB of hosting space\n\n⦁ You can pay using PayPal\n\n\n\nCons\n\n⦁ Only members have access to the features of this site.\n\n\n\n10. BigProductStore\n\nBigProductStore is a popular private label rights website that offers tens of thousands of digital products. These include software, videos, video courses, eBooks, and many others that you can resell, use as you want, or sell and keep 100% of the profit.\n\nThe PLR website updates its product list daily. It currently offers over 10,000 products.\n\nThe site offers original content for almost every niche and when you register as a member, you can access the exclusive products section where you can download a variety of high-quality, unique, and exclusive products.\n\n\n\nPricing\n\nMonthly Plan: $19.90/Month 27% off\n\nOne-Time-Payment: $98.50 50% off\n\nMonthly Ultimate: $29.90/Month 36% off\n\nOne-Time-Payment Ultimate: $198.50 50% off\n\nPros\n\nYou can use PLR products to generate profits, give them as bonuses for your affiliate promotion campaign, or rebrand them and create new unique products.\n\nLifetime memberships for PLR products can save you money if you’re looking for a long-term solution to bulk goods.\n\nThe website is updated regularly with fresh, quality content.\n\nCons",
         "2022-02-26T13:36:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/02/top-10-best-plrprivate-label-rights.html",
         "2025-07-26T05:41:35.875474",
         "Content creation is one of the biggest struggles for many marketers and business owners. It often requires both time and financial resources, especially if you plan to hire a writer. Today, we have a fantastic opportunity to use other people's products by purchasing Private Label Rights. To find a good PLR website, first, determine the type of products you want to acquire. One way to do this is to choose among membership sites or PLR product stores. Following are 10 great sites that offer products in both categories. What are PLR websites? Private Label Rights (PLR) products are digital products that can be in the form of an ebook, software, online course videos, value-packed articles, etc. You can use these products with some adjustments to sell as your own under your own brand and keep all the money and profit yourself without wasting your time on product creation. The truth is that locating the best website for PLR materials can be a time-consuming and expensive exercise. That’s why we have researched, analyzed, and ranked the best 10 websites: 1. PLR.me PLR.me is of the best places to get PLR content in 2021-2022. It offers a content marketing system that comes with courses, brandable tools, and more. It is the most trusted PLR website, among other PLR sites. The PLR.me platform features smart digital caching PLR tools for health and wellness professionals. The PLR.me platform, which was built on advanced caching technology, has been well-received by big brands such as Toronto Sun and Entrepreneur. The best thing about this website is its content marketing automation tools. Pricing Pay-as-you-go Plan – $22 100 Monthly Plan – $99/month 400 Annual Plan – $379/year 800 Annual Plan – $579/year 2500 Annual Plan – $990/year Pros Access over 15,940+ ready-to-use PLR coaching resources. Content marketing and sliding tools are provided by the site. You can create courses, products, webinars, emails, and nearly anything else you can dream of. You can cancel your subscription anytime. Cons Compared to other top PLR sites, this one is a bit more expensive. 2. InDigitalWorks InDigitalWorks is a leading private label rights membership website established in 2008. As of now, it has more than 100,000 members from around the globe have joined the platform. The site offers thousands of ready-to-be-sold digital products for online businesses in every single niche possible. InDigitalWorks features hundreds of electronic books, software applications, templates, graphics, videos that you can sell right away. Pricing: 3 Months Plan – $39 1 Year Plan – $69 Lifetime Plan – $79 Pros IndigitalWorks promotes new authors by providing them with 200 free products for download. Largest and most reputable private label rights membership site. 20000+ digital products 137 training videos provided by experts to help beginners set up and grow their online presence for free. 10 GB of web hosting will be available on a reliable server. Cons Fewer people are experiencing the frustration of not getting the help they need. 3. BuyQualityPLR BuyQualityPLR’s website is a Top PLR of 2021-2022! It's a source for major Internet Marketing Products and Resources. Whether you’re an Affiliate Marketer, Product Creator, Course Seller, BuyQualityPLR can assist you in the right direction. You will find several eBooks and digital products related to the Health and Fitness niche, along with a series of Security-based products. If you search for digital products, Resell Rights Products, Private Label Rights Products, or Internet Marketing Products, BuyQualityPLR is among the best websites for your needs. Pricing Free PLR articles packs, ebooks, and other digital products are available Price ranges from 3.99$ to 99.9$ Pros Everything on this site is written by professionals The quick download features available Doesn't provide membership. Offers thousand of PLR content in many niches Valuable courses available Cons You can't buy all content because it doesn't provide membership 4. IDPLR The IDPLR website has helped thousands of internet marketers since 2008. This website follows a membership approach and allows you to gain access to thousands of PLR products in different niches. The best thing about this site is the quality of the products, which is extremely impressive. This is the best PLR website of 2021-2022, offering over 200k+ high-quality articles. It also gives you graphics, templates, ebooks, and audio. Pricing 3 Months ACCESS: $39 1 YEAR ACCESS: $69 LIFETIME ACCESS: $79 Pros You will have access to over 12,590 PLR products. You will get access to training tutorials and Courses in a Gold membership. 10 GB of web hosting will be available on a reliable server. You will receive 3D eCover Software It offers an unlimited download limit Most important, you will get a 30 day money-back guarantee Cons: A few products are available for free membership. 5. PLRMines PLRmines is a leading digital product library for private label rights products. The site provides useful information on products that you can use to grow your business, as well as licenses for reselling the content. You can either purchase a membership or get access through a free trial, and you can find unlimited high-quality resources via the site's paid or free membership. Overall, the site is an excellent resource for finding outstanding private label rights content. Pricing Lifetime membership: $97 Pros 4000+ ebooks from top categories Members have access to more than 660 instructional videos covering all kinds of topics in a membership area. You will receive outstanding graphics that are ready to use. They also offer a variety of helpful resources and tools, such as PLR blogs, WordPress themes, and plugins Cons The free membership won't give you much value. 6. Super-Resell Super-Resell is another remarkable provider of PLR material. The platform was established in 2009 and offers valuable PLR content to users. Currently, the platform offers standard lifetime memberships and monthly plans at an affordable price. Interested users can purchase up to 10,000 products with digital rights or rights of re-sale. Super-Resell offers a wide range of products such as readymade websites, article packs, videos, ebooks, software, templates, and graphics, etc. Pricing 6 Months Membership: $49.90 Lifetime membership: $129 Pros It offers you products that come with sales pages and those without sales pages. You'll find thousands of digital products that will help your business grow. Daily News update Cons The company has set up an automatic renewal system. This can result in costs for you even though you are not using the service. 7. Unstoppable PLR UnStoppablePLR was launched in 2006 by Aurelius Tjin, an internet marketer. Over the last 15 years, UnStoppablePLR has provided massive value to users by offering high-quality PLR content. The site is one of the best PLR sites because of its affordability and flexibility. Pricing Regular Price: $29/Month Pros You’ll get 30 PLR articles in various niches for free. 100% money-back guarantee. Members get access to community It gives you access to professionally designed graphics and much more. Cons People often complain that not enough PLR products are released each month. 8. Resell Rights Weekly Resell Rights Weekly, a private label rights (PLR) website, provides exceptional PLR content. It is among the top free PLR websites that provide free membership. You will get 728+ PLR products completely free and new products every single week. The Resell Rights Weekly gives you free instant access to all products and downloads the ones you require. Pricing Gold Membership: $19.95/Month Pros Lots of products available free of cost Free access to the members forum Cons The prices for the products at this PLR site are very low quality compared to other websites that sell the same items. 9. MasterResellRights MasterResellRights was established in 2006, and it has helped many successful entrepreneurs. Once you join MasterResellRights, you will get access to more than 10,000 products and services from other members. It is one of the top PLR sites that provide high-quality PLR products to members across the globe. You will be able to access a lot of other membership privileges at no extra price. The website also provides PLR, MRR, and RR license products. Pricing ⦁ One Month Membership: $19.97 ⦁ Three Month Membership: $47.00 Pros ⦁ Access more than 10,000 high-quality, PLR articles in different niches. ⦁ Get daily fresh new updates ⦁ Users get 8 GB of hosting space ⦁ You can pay using PayPal Cons ⦁ Only members have access to the features of this site. 10. BigProductStore BigProductStore is a popular private label rights website that offers tens of thousands of digital products. These include software, videos, video courses, eBooks, and many others that you can resell, use as you want, or sell and keep 100% of the profit. The PLR website updates its product list daily. It currently offers over 10,000 products. The site offers original content for almost every niche and when you register as a member, you can access the exclusive products section where you can download a variety of high-quality, unique, and exclusive products. Pricing Monthly Plan: $19.90/Month 27% off One-Time-Payment: $98.50 50% off Monthly Ultimate: $29.90/Month 36% off One-Time-Payment Ultimate: $198.50 50% off Pros You can use PLR products to generate profits, give them as bonuses for your affiliate promotion campaign, or rebrand them and create new unique products. Lifetime memberships for PLR products can save you money if you’re looking for a long-term solution to bulk goods. The website is updated regularly with fresh, quality content. Cons",
         "en",
         "{'MISC': ['ACCESS', 'As of now', 'BigProductStore is', 'Cons: A few products are available for free membership', 'Content creation is one of the biggest struggles for many marketers and business', 'Content marketing and sliding tools are provided by the site', 'Currently', \"Doesn't provide membership\", 'Following are 10 great sites that offer products in both categories', 'GB of web', 'Get daily fresh new updates ⦁ Users get 8 GB of hosting space ⦁ You can pay using PayPal Cons ⦁ Only members have access to the features of this site', 'If you search for digital products', 'InDigitalWorks features', 'Internet Marketing Products', 'Internet Marketing Products and Resources', 'It', 'It also gives you graphics', 'It currently', 'It is among the top free PLR websites that provide free membership', 'It is one of the top PLR sites that provide high-quality PLR products to members across the globe', 'It is the most trusted PLR website', 'It often requires both time and financial', \"It'\", 'Largest and most reputable private label rights membership site', 'Members get access to community', 'Members have access to more than 660 instructional', 'Month Pros', 'Monthly Ultimate', 'Most', 'Offers thousand of PLR', 'One way to do this is to choose among membership sites or', 'One-Time-Payment', 'One-Time-Payment Ultimate', 'Over the last 15 years', 'Overall', 'Pricing', 'Pricing 3 Months', 'Pricing Free PLR', 'Pricing Gold Membership', 'Pricing Lifetime', 'Pricing Pay-as-you-go', 'Pricing Regular', 'Pricing ⦁ One', 'Pricing: 3 Months', 'Private Label Rights', 'Pros Access over', 'Pros Everything on this site is written by professionals', 'Pros It offers you products that come with sales pages and those without sales pages', 'Pros ⦁ Access more than 10,000 high-quality', 'Resell Rights Weekly', 'That’s why we have researched', 'The PLR.me platform', 'The PLR.me platform features smart', 'The best thing about this site is the quality of the products', 'The best thing about this website is its content marketing automation tools', 'The quick download features', 'The truth is that locating the best website for PLR materials can be a time-consuming and expensive exercise', 'The website also provides', 'The website is updated regularly with fresh', 'They also offer', 'This is the best PLR website of 2021-2022', 'Three Month Membership', 'To find a good PLR website', 'Top PLR of 2021-2022!', 'UnStoppablePLR has provided massive value to users by offering high', 'What are PLR websites', 'WordPress', 'YEAR ACCESS', 'Year Plan', 'You can', 'You can create courses', 'You can either purchase', 'You can use these products with some adjustments to sell as your own under your own brand and keep all the money and profit yourself without wasting your time', 'You will be able to access', 'You will find several eBooks and digital products related to the Health and Fitness niche', 'You will get 728', 'You will get access to training tutorials and Courses in a Gold', 'You will receive 3D eCover Software It', 'You will receive outstanding graphics that are ready to', \"You'll find thousands of digital products that will help your business grow\", 'along with', 'and RR', \"and plugins Cons The free membership won't give you much value\", 'and ranked the best', 'as well as licenses for reselling the content', 'brandable tools', 'content for almost every niche and when you', 'eBooks, and many others that you can resell', 'free and new products every single week', 'has been well-received by big brands such as Toronto Sun and Entrepreneur', 'lifetime memberships and monthly plans at an affordable price', 'rebrand them and create new', 'that can be in the form of an ebook', \"the site'\", 'the type of products you', 'videos', \"we have a fantastic opportunity to use other people'\", 'with digital rights or rights of re-sale', 'you can access the'], 'ORG': ['Cons People often complain that not enough PLR products are released each month', 'Cons The prices for the products at this PLR site are', \"Cons You can't buy all content because it doesn't provide membership 4\", 'Daily News update Cons The company has set up an automatic', 'Lifetime', 'Lifetime Plan', 'Lifetime memberships for PLR', 'MRR', 'MasterResellRights', 'Month Pros You’ll get 30 PLR articles in various niches for free', 'Monthly Plan', 'PLR', 'Pricing Monthly Plan', 'Private Label Rights Products', 'Product Creator', 'Pros IndigitalWorks', 'Pros You can', 'Pros You will have access to over 12,590', 'Resell Rights Products', 'The Resell Rights Weekly gives you free instant access to all products and downloads the ones you require', 'These', 'Today', 'software', 'software applications'], 'LOC': ['BigProductStore', 'IDPLR', 'Month', 'PLR.me', 'PLRMines PLRmines is'], 'PER': ['Aurelius Tjin', 'BuyQualityPLR’', 'Cons Compared', 'Cons Fewer people', 'Course Seller', 'Interested', 'Once you', 'Price', 'Super-Resell', 'Super-Resell Super-Resell is another', 'you will get', 'you will get access to more than 10,000 products and services from other members']}",
         "[-0.08022269606590271, -0.12545782327651978, -0.031646084040403366, -0.022159239277243614, 0.03463359922170639, 0.0649426132440567, -0.0427577830851078, 0.07500160485506058, 0.024797797203063965, -0.03175978362560272, 0.046100083738565445, 0.047670576721429825, 0.07575640827417374, 0.06232687085866928, 0.05184333026409149, -0.025211382657289505, 0.04580137878656387, -0.001198165467940271, 0.027091460302472115, -0.0482243113219738, 0.0478302501142025, 0.057764556258916855, 0.06432236731052399, -0.007263130974024534, -0.04925386607646942, -0.0001726465270621702, -0.022703072056174278, 0.005262961611151695, 0.1160321980714798, -0.08924311399459839, 0.08658252656459808, 0.037023790180683136, 0.03923124447464943, -0.03552733734250069, 0.018213266506791115, 0.02299157716333866, -0.005501985549926758, -0.056969355791807175, -0.016950849443674088, 0.004431614652276039, 0.009919787757098675, -0.06828107684850693, -0.09245800226926804, -0.021688690409064293, 0.05461050197482109, 0.009069402702152729, 0.0861029326915741, 0.018163271248340607, -0.018311718478798866, 0.08304958790540695, 0.008922109380364418, -0.0023125747684389353, -0.0560491718351841, -0.09792008996009827, -0.019190575927495956, -0.04334630072116852, -0.0027628671377897263, -0.0447203703224659, -0.008314782753586769, -0.059821441769599915, -0.01644154265522957, -0.08839412778615952, -0.0064863404259085655, -0.017547644674777985, -0.0037851317320019007, 0.023966513574123383, 0.03862912580370903, 0.1302788108587265, -0.026203753426671028, -0.05402638763189316, -0.03093937411904335, -0.03233333304524422, -0.005324958823621273, 0.09940558671951294, 0.03267941623926163, -0.04450880363583565, 0.08877846598625183, -0.013967374339699745, -0.09885542094707489, 0.027450069785118103, 0.003920707385987043, 0.05208783224225044, -0.037418168038129807, 0.045193519443273544, -0.1703519970178604, -0.057808902114629745, 0.07120566070079803, 0.06312701106071472, 0.016137121245265007, -0.015939146280288696, 0.041505198925733566, 0.012409214861690998, 0.008109715767204762, 0.007888788357377052, -0.035552773624658585, 0.025143606588244438, -0.03794923797249794, -0.02470693737268448, 0.0949457660317421, -0.05746014788746834, -0.010878999717533588, -0.041214678436517715, 0.03785233199596405, -0.11009424924850464, -0.09194321185350418, 0.002610971452668309, 0.028107017278671265, 0.06382233649492264, 0.036111973226070404, 0.09981189668178558, -0.05188264325261116, 0.07771047949790955, -0.13758262991905212, -0.000501928327139467, 0.06128918007016182, 0.004119217395782471, -0.0538264736533165, -0.0005322935758158565, 0.14276587963104248, -0.030588412657380104, -0.047701410949230194, 0.04907038435339928, 0.05487142875790596, 0.0007261988939717412, 0.006879989989101887, -0.06622428447008133, -0.0680994838476181, 2.9950286484776673e-33, -0.0016022213967517018, 0.07513969391584396, 0.026975471526384354, -0.01538125704973936, 0.017623379826545715, 0.030161406844854355, 0.08663332462310791, 0.0730089396238327, -0.06371518224477768, 0.012511874549090862, 0.04968544840812683, 0.025959130376577377, -0.051945317536592484, 0.038390759378671646, 0.049997806549072266, -0.08743949234485626, 0.028020739555358887, -0.020512402057647705, 0.029217392206192017, -0.03456586226820946, 0.0032420328352600336, -0.029507625848054886, 0.061965689063072205, 0.02303013578057289, -0.013930832035839558, -0.03901219367980957, -0.032864611595869064, -0.030121443793177605, 0.0705772191286087, -0.06195496395230293, -0.005787694826722145, -0.06473716348409653, 0.06873799860477448, -0.04083757475018501, 0.007860497571527958, -0.017374053597450256, -0.09564468264579773, -0.027012581005692482, 0.0501348152756691, 0.04808695986866951, -0.07002072036266327, 0.019385963678359985, -0.04386452957987785, 0.06326417624950409, 0.07131313532590866, 0.028904149308800697, -0.04814551770687103, 0.009648550301790237, 0.019684916362166405, 0.016118532046675682, -0.04847892373800278, -0.029382120817899704, -0.01376019511371851, 0.00934666395187378, -0.051991529762744904, 0.037872131913900375, -0.04820314794778824, -0.07325436174869537, -0.02886848710477352, -0.0713232085108757, 0.027955124154686928, 0.09168844670057297, 0.011271219700574875, -0.011923556216061115, -0.022787585854530334, -0.021550515666604042, 0.030347559601068497, -0.06870024651288986, 0.04565020650625229, 0.0005987435579299927, 0.02220303565263748, 0.018540669232606888, -0.0022766771726310253, -0.06663912534713745, 0.022493932396173477, -0.00916069746017456, -0.05422045662999153, 0.04244698956608772, 0.0025227477308362722, 0.048034634441137314, 0.028055304661393166, 0.06832369416952133, 0.004942828789353371, 0.0033858183305710554, -0.058229830116033554, -0.012409767135977745, 0.01687815971672535, -0.08274861425161362, -0.0024881826248019934, 0.049627963453531265, 0.05678781494498253, 0.013423280790448189, -0.05180833116173744, 0.03248417750000954, 0.006135425064712763, -3.44701522624746e-33, 0.0024060364812612534, -0.10681315511465073, 0.09446348249912262, 0.11166202276945114, 0.04683805629611015, -0.010891519486904144, -0.04569162055850029, 0.0539352111518383, 0.05217910185456276, -0.03387221321463585, -0.05608837679028511, 0.0007434684666804969, 0.0053956471383571625, 0.005603837314993143, -0.08272749930620193, 0.018328366801142693, -0.02840535342693329, -0.0020262578036636114, -0.05492660403251648, -0.0004465435049496591, -0.008552339859306812, 0.05544999614357948, -0.03745027631521225, 0.025355344638228416, 0.06238073855638504, -0.022374428808689117, -0.02216275967657566, 0.04506860673427582, 0.034622497856616974, 0.00561545742675662, -0.02494414523243904, -0.10629906505346298, -0.003054054919630289, -0.002009684918448329, -0.04577580839395523, -0.09872082620859146, 0.012531347572803497, 0.084342360496521, -0.0005823788233101368, 0.03551312908530235, 0.021482577547430992, 0.06168272718787193, -0.0251211728900671, -0.041453901678323746, -0.11206725239753723, -0.03726431727409363, -0.008928748778998852, -0.023248182609677315, 0.1003238707780838, -0.036105602979660034, -0.027037248015403748, 0.006795914378017187, 0.010693894699215889, -0.056994110345840454, 0.05603356659412384, -0.03502669557929039, -0.06350936740636826, -0.03740205615758896, -0.010661469772458076, -0.006816281005740166, -0.011581801809370518, 0.04835527390241623, -0.058455973863601685, 0.09237634390592575, 0.018039634451270103, -0.08909359574317932, 0.07561159133911133, 0.021412700414657593, -0.14998266100883484, 0.01861128956079483, 0.010408762842416763, -0.03194664046168327, 0.007497074548155069, -0.031928785145282745, -0.08592580258846283, 0.06904458999633789, -0.018540438264608383, 0.016280166804790497, -0.028094330802559853, -0.02492675930261612, 0.01283387653529644, 0.025763975456357002, -0.06914320588111877, 0.0400279238820076, 0.06650301814079285, 0.01964397355914116, 0.04261722043156624, -0.05488743260502815, -0.036897141486406326, -0.034729450941085815, -0.03900109604001045, 0.008146299980580807, 0.010757491923868656, 0.13966254889965057, 0.012193003669381142, -5.1437336168191905e-08, 0.02113579586148262, -0.09031391888856888, -0.03481321781873703, 0.05166666954755783, -0.08672161400318146, 0.012088567018508911, 0.03403284028172493, -0.02938646450638771, -0.013301223516464233, 0.07847757637500763, -0.002856235485523939, -0.10357651859521866, -0.02663772739470005, 0.04202505573630333, 0.07005679607391357, 0.04882464557886124, 0.09383486956357956, -0.009451795369386673, 0.0352628231048584, -0.05315925180912018, 0.006103172432631254, -0.03764638304710388, 0.06173265352845192, -0.016063394024968147, 0.02180648222565651, 0.07484152913093567, 0.0505574531853199, -0.03133971616625786, -0.008274701423943043, -0.011585385538637638, 0.005434588994830847, -0.016844838857650757, 0.06867942214012146, 0.0008051526383496821, 0.076786108314991, -0.02538280189037323, -0.026552433148026466, 0.021842146292328835, -0.050477080047130585, 0.08673238754272461, 0.038880977779626846, 0.04175112769007683, 0.03499528765678406, -0.009276903234422207, 0.06634250283241272, -0.012270839884877205, -0.043642472475767136, -0.042201749980449677, 0.0011164135066792369, 0.0067832195200026035, -0.06139786168932915, -0.039675794541835785, 0.024710917845368385, -0.06849872320890427, 0.03208005428314209, 0.06736456602811813, -0.014398891478776932, 0.06224364787340164, 0.02952175959944725, 0.10035969316959381, 0.003507004352286458, -0.04476552829146385, 0.003635632572695613, 0.008331753313541412]",
         "0.174"
        ],
        [
         "15",
         "296",
         "'Outrageous' dramatizes the lives of the Mitford sisters",
         "The six British sisters are the subject of a new Britbox series. In 1989, Jessica Mitford talked with Terry Gross about her relationship with the Communist Party and her book about the death industry.",
         "'Outrageous' dramatizes the lives of the Mitford sisters\n\nThe six British sisters are the subject of a new Britbox series. In 1989, Jessica Mitford talked with Terry Gross about her relationship with the Communist Party and her book about the death industry.\n\nDAVID BIANCULLI, HOST:\n\nThis is FRESH AIR. I'm David Bianculli, professor of television studies at Rowan University. Jessica Mitford was famous for several reasons. One reason was her investigative books, including her best-known one, \"The American Way Of Death,\" published in 1963. It revealed how the funeral industry was financially taking advantage of grief-stricken Americans. It was a bestseller and led to congressional hearings on the industry. Another reason Mitford was famous was that she was committed to radical causes throughout her life. In the 1950s, as a former member of the Communist Party, she refused to give any information to the House Un-American Activities Committee.\n\nMitford grew up in the English countryside, the daughter of a lord, which gets to yet another source of her notoriety. She was one of England's most unusual groups of sisters. There were six Mitford girls, including Unity, who briefly was romantically involved with Hitler, Diana, who married Oswald Mosley, the head of Britain's Union of Fascists, and Nancy, who became a popular novelist. The sisters are now the subject of a new BritBox drama series titled \"Outrageous.\" In my recent review of the TV show, I called it and the Mitford sisters fascinating. Jessica Mitford died in 1996. Terry Gross spoke with her seven years earlier in 1989.\n\n(SOUNDBITE OF ARCHIVED NPR CONTENT)\n\nTERRY GROSS: Jessica Mitford, welcome to FRESH AIR.\n\nJESSICA MITFORD: Thanks.\n\nGROSS: There's so much I want to talk with you about your life. Let's start kind of way back (laughter)...\n\nMITFORD: How far?\n\nGROSS: ...In your childhood. When you were a young girl from a prosperous family growing up in the English countryside, reading pacifist and leftist literature and getting very excited about it, what was the initial appeal to you of it?\n\nMITFORD: Well, you know, I've thought this over since. I believe, actually, that one is very much the product of one's own time. I mean, the '60s people were a product of their time, weren't they? Now, I was a '30s person. In other words, I was born in 1917. So by 1930, I was about 13 years old, reading everything I could lay hands on, like most children, and sort of fascinated with the growing politics all around me. It was the Depression in England - tremendous poverty, huge areas called, you know, unemployable areas - and then there was fascism rising abroad. So these things made me think.\n\nGROSS: You're talking about how you think of yourself as being a product of your time. But it's fascinating how, as a product of your time, you became a leftist, yet two of your sisters became fascists. And it's really so hard to imagine sisters in the same family growing up so different. Do you have any explanation for it?\n\nMITFORD: I never have been able to figure it out myself, frankly. I've been asked that a lot, lots of times.\n\nGROSS: I'm sure you have.\n\nMITFORD: Yeah. But, I mean, the thing is, though, that some say it's sibling rivalry, which I don't believe really. I really don't think so. I don't think we were jealous of each other. It was just that I happened to see things differently from the beginning.\n\nGROSS: Did you - because you were so opposed to fascism, did you find yourself hating your sisters when they became fascists?\n\nMITFORD: Not really. That's the odd thing. I was always deeply fond of my sister Unity. I mean, she was one of my very favorite people in the world. And what I did realize was that our divergent views politically were going to inevitably lead to a huge, well, end of friendship, in fact, which in fact they did.\n\nGROSS: You kept a running-away account when you were young...\n\nMITFORD: Yeah.\n\nGROSS: ...Money so that you could run away from home. But what you ended up using your running-away account for was to try to go to Spain...\n\nMITFORD: Right.\n\nGROSS: ...With the man who you later married.\n\nMITFORD: That's it, yeah. And there was just the right amount, 50 pounds.\n\nGROSS: And this was during the Spanish Civil War.\n\nMITFORD: Yeah.\n\nGROSS: And you already knew which side (laughter)...\n\nMITFORD: Oh, yeah.\n\nGROSS: ...You were on. You kind of went from this quiet, rural country life, the daughter of a lord, to suddenly being a political radical, involved in a revolution, a young married woman married to someone who was also from a wealthy background. Your husband was the nephew of Winston Churchill.\n\nMITFORD: Right. Yes.\n\nGROSS: I wonder if you started to see your own families as the opposition.\n\nMITFORD: Whether I ever saw them?\n\nGROSS: If you saw them as the opposition...\n\nMITFORD: Oh, if I saw them as the opposition.\n\nGROSS: ...In the political...\n\nMITFORD: Oh.\n\nGROSS: ...Battles you were waging.\n\nMITFORD: Absolutely. Yeah. See, both my parents went completely on the side of Hitler, which was very surprising. You know, we were brought up in the shadow of the first world war, in a way. And in those days, you see, the Huns, they were the filthy Huns who had killed uncle Clem (ph) and numerous other relations in the first world war - people, of course, that I never knew 'cause I was just born during that time. And then all of a sudden, that - Hitler became a tremendous star. He did away with the labor unions, with the Communist Party. He was doing away with the Jews. And you can't discount the amount of antisemitism that goes on in the English upper class.\n\nGROSS: Jessica Mitford is my guest. You lost your first husband in action in 1941...\n\nMITFORD: Right. Yeah.\n\nGROSS: ...During the war. He was 23 years old. You, just before that, lost your baby who...\n\nMITFORD: Yes.\n\nGROSS: ...Died of measles, I read it was.\n\nMITFORD: The one that - born in Rotherhithe Street. Right.\n\nGROSS: You were young. You were in your 20s. Did you despair at that point that your life was over? I think it must've been so hard to suffer those two losses at such a young age.\n\nMITFORD: Well, also, by then, I had another baby born in 1941, Dinky - Constancia Romilly - who now lives in Atlanta. She's a nurse there, in fact. And, I mean, that was ages ago. She's now 48, absolutely ancient. I can't believe it. But anyhow - so she was my great standby and steadfast friend. And anyhow, you know, when you're young, I suppose life goes on, and especially if you've got a baby to look after and support. And so I got various jobs with the government and other places, you know.\n\nGROSS: Let's move ahead a little bit.\n\nMITFORD: Yeah.\n\nGROSS: You wrote about your membership in the Communist Party in your book, \"A Fine Old Conflict.\" What got you to join when you did?\n\nMITFORD: Well, you see, in the first place, I'd always been a terrific supporter of the Communist Party in England ever since I was about 15 because if you sort of studied the times, in those days, you know, well, the Communists were in the forefront of the fight for the rights of unemployed, I mean, and an end to things like the means test, which was a rotten sort of Tory ploy to prevent the unemployed from collecting unemployed insurance or welfare. And then they were also in the forefront of the fight against fascism, both in Germany and Italy, but in Spain above all. It was the Communists who recruited all the young people who went - who flocked from all over the world into the International Brigade, of which Esmond Romilly was one, and that's how I met him. And then we sort of ran off to Spain together, you know. So that was sort of the progression of that.\n\nAnd then - but we never actually joined the party, Esmond and I, in those days. After Esmond was killed, I stayed in Washington with my baby, Dinky - Constancia Romilly. So then I remarried, in 1943, Bob Treuhaft, a lawyer who I met in the OPA, where I was working. And that was in San Francisco. We moved out to San Francisco. And there, again, the Communist Party, in those years, seemed to me the absolute sort of loadstar or the kind of backbone really, if you like, of all progressive left-wing movements, the ones - the steadfast supporters of rights of Black people, that kind of thing. And this is what made us determined to join. So we did join in 1943 and remained members, in fact, until '58, which was quite a longish time.\n\nGROSS: What got you to leave in 1958?\n\nMITFORD: Well, by 1958, in the first place, the Khrushchev report about the crimes of Stalin had come out, and as a consequence of that, an awful lot of people flocked out of the CP. Not - I didn't at the time. That was in 1956, in fact. And then came the invasion of Hungary, and then came Czechoslovakia and so on, and more and more people flocked out. It was getting to be a waste of time. I'd be better off working with people in the main - in the movements on campuses, for instance, in the '60s and in the Black community.\n\nGROSS: So many people were harassed during the McCarthy period, and so many lives were ruined. I'm thinking that it must've been hard to harass someone like you, someone who had been outspoken all of her life and who had already, like, a reputation for eccentricity because of her family. I mean, did you feel like, what can you do to hurt me?\n\nMITFORD: Well, I did it a little bit. Yeah. I'll tell you what I really felt, which is that the hell with them sort of thing. I mean, we were subpoenaed. Bob Treuhaft, my husband...\n\nGROSS: Your husband, yeah.\n\nMITFORD: ...And I were both subpoenaed. And I was subpoenaed by not only the main House Committee on Un-American Activities, but also the local version of the same, the California committee and so on. And, well, I mean, what could you do? Actually, I - when I went, when I was subpoenaed by the main House committee, I was among a hundred people. There were sort of huge headlines in the Chronicle and other papers - 100 Bay Reds subpoenaed. Well, of course, if I hadn't been one of those, I'd have been rather miffed.\n\nGROSS: (Laughter).\n\nMITFORD: Do you know the feeling? Sort of rather annoyed. But anyhow, I was one, but they never finally called me. But what I found out was that they were bound to pay per diem - or was it? No. It wasn't per diem. It was travel allowance, so much a mile. And since we lived in Oakland, I put in for $40 for travel allowance for the week that I was forced to be there and then turned over the check to the Communist Party. I hoped to annoy them somehow, you know.\n\nBIANCULLI: Jessica Mitford speaking to Terry Gross in 1989. More after a break. This is FRESH AIR.\n\n(SOUNDBITE OF MUSIC)\n\nBIANCULLI: This is FRESH AIR. Let's get back to Terry's 1989 interview with author and activist Jessica Mitford. She and her aristocratic sisters are the subjects of the new BritBox drama series titled \"Outrageous.\"\n\n(SOUNDBITE OF ARCHIVED NPR CONTENT)\n\nGROSS: In your memoir about your coming-of-age...\n\nMITFORD: Yeah.\n\nGROSS: ...called \"Daughters And Rebels,\" you wrote that you - you confessed that you were guiltily looking forward to being a debutante.\n\nMITFORD: Yeah.\n\nGROSS: Now, I don't know if you ever had that experience or not, but certainly you became a very well-known leftist and left that society world. Your father wrote you out of his will...\n\nMITFORD: Yeah.\n\nGROSS: ...I think because you had named one of your children after Lenin. You called him Nicholas.\n\nMITFORD: (Laughter) Yeah.\n\nGROSS: Do you ever have any regrets about leaving wealth and privilege?\n\nMITFORD: No. In fact, you know, when that happened, which is in '58, I happened to be in Mexico at the time, and to the horror of the landlady where I was staying, 'cause she somehow thought she was going to have to pay for the calls. There were phone calls from everywhere - from the London Evening Standard, from Canada, from all over the United States. What is your reaction to being cut out of your father's will? And I said, I have no reaction. I think people have every right to leave their money as they wish. And I wasn't expecting any, you know? And the sort of - the deflated journalists - you know how they hate that kind of bland answer. Anyhow...\n\nGROSS: This could have been, I guess, a big thing if you...\n\nMITFORD: If I was like, bah, you know, it's all screamed away or something, you know.\n\nGROSS: But you had just assumed that you would...\n\nMITFORD: Oh, of course. So I never expected it.\n\nGROSS: And that when you make the decision to live your life as you do...\n\nMITFORD: Yeah.\n\nGROSS: ...You can't have it both ways.\n\nMITFORD: Right.\n\nGROSS: That was the effective...\n\nMITFORD: Of course. Exactly. You said it.\n\nGROSS: Jessica Mitford, let's talk a little bit about your writing. You're best known for the book \"The American Way Of Death,\" your expose of the funeral industry. What led you to want to expose the horrors of the funeral industry and how they would get people when they were weak and take them for whatever they could.\n\nMITFORD: Well, it is rather weird, I admit. You know, it's an odd subject, indeed. I think the thing is that Bob Treuhaft, my husband - who was a lawyer in Oakland - was representing numerous trade unions. And along about the middle 1950s, he began to notice, to his fury, that every time a union member died - the breadwinner of a family - the hard-fought-for union benefits meant to go to the widow and children would wind up being the price of the funeral. So he started organizing the Bay Area Funeral Society, a nonprofit thing, which I thought was rather boring, frankly. I mean, I said, well, look, we're robbed every day in the supermarkets...\n\nGROSS: (Laughter).\n\nMITFORD: ...And by the landlords and things. So why pick on the wretched undertakers - until I began reading the trade magazines.\n\nGROSS: Oh, what did you see in there?\n\nMITFORD: Oh, God. Well, the titles would lead you on - Mortuary Management, Casket And Sunnyside - one - Casket And Sunnyside - and my favorite title of all, you know, which really makes you think - Concept: The Journal Of Creative Ideas For Cemeteries. Well, I mean, you know, if you saw those, wouldn't you be reading them like mad? I did. And I found therein a whole wonder world of the mortuary that I'd never known existed. You know, I hadn't known, for instance, that you could have a choice of foam rubber or whatchamacallit - inner spring mattress for your eternal sealer casket and that kind of thing. I started sending away for samples, and it was all so delightful. So then I started writing that book.\n\nGROSS: Did you go undercover and pose as someone who had a deceased loved one so that you could shop for funeral arrangements...\n\nMITFORD: Yeah, I did.\n\nGROSS: ...To see what it was like?\n\nMITFORD: I did quite a bit of that. That was one of the best parts of it, especially Forest Lawn in Los Angeles. That was tremendous fun.\n\nGROSS: What was the experience there like?\n\nMITFORD: Well, I mean, I went there. Actually, I went with a young man who is an American fellow who was teaching English history or something in one of the colleges there in Los Angeles. And so we made up that he was my nephew, and I was his English aunt, and my sister was dying or something, you see. And we wanted to make preneed arrangements. So I said we wanted to see everything. But in those days, by the way, Forest Lawn was - there was a price war on. a\\And Forest Lawn was advertising on billboards, funerals from $145, you see, which sounded very reasonable. So I said to the grief therapist - they're not salesmen, you know. They're grief therapists. I said to the grief therapist, well, we want to see everything and the nature of all the coffins and I can choose the best - most appropriate.\n\nSo the first one we came to was $16,500. Now, you have to realize we're talking in the late 19 - no, the early 1960s. So you can double that or triple it or whatever for the inflation, what it - and I must say, it was rather magnificent, you know. And I looked at it longingly. And then I said, well, could we see the $145 one? And so, you know, he took ages finding it. It was all hidden away somewhere. And, my dear, it was purple. It had a purple...\n\nGROSS: (Laughter).\n\nMITFORD: ...Really hideous. And I said - I looked at it, and I said, my sister wouldn't be caught dead in that sort of thing, you know?\n\nGROSS: (Laughter).\n\nMITFORD: And so, then we kind of went along and saw all the different plots and blah, blah. And it was great fun.\n\nGROSS: After writing \"The American Way Of Death,\" did you find yourself in the position of having to genuinely prepare somebody's funeral and having to shop for real in the funeral industry?\n\nMITFORD: I have, once or twice. But my favorite thing in that line, there was a man called Howard Gossage - extremely well known in San Francisco - but he died many years ago. He was a wonderful - he was an ad man, advertising writer. And when he was - oh, he did all those marvelous things in The New Yorker about the getaway car. I mean, it's all years old. I don't know if people remember it. But he was much more than that. He was a brilliant and funny fellow in all ways. So he was dying of leukemia, and we knew he was dying and not expected to live.\n\nSo one morning about 4, 5 a.m., his brother-in-law rang up and - who I hadn't met. And he said, Howard died in the middle of the night. And his last words to me was, when I go - and I think it'll be very soon now - be sure to get hold of Jessica because she knows how to nose out the cheapest coffin in this whole town.\n\nGROSS: (Laughter).\n\nMITFORD: So you know how when somebody dies, and the survivors, you know - you always sort of say - or people say, well, what can I - can I do anything? And the answer is no, obviously. But in this case, yes was the answer. So I went and collected the widow, who was a beautiful young actress. And together, we went - and my God, I got one for $150 all in, you know? And he was a rich man. And he would have been considered a super prize for the undertakers.\n\nGROSS: Now, there was a casket named after you after your book came out, right?\n\nMITFORD: Yeah (laughter).\n\nGROSS: A kind of bargain basement, budget kind of casket.\n\nMITFORD: Well, I know. It was such a marvelous idea, sort of industrialist in the Middle West had plans and specifications for the Jessica Mitford casket, which was going to be sort of made of plastic, I think, or something like that.\n\nGROSS: Did they really make it?\n\nMITFORD: I'm not sure. I never actually saw one. My sister Nancy said, oh, well, we all know that you get 10% royalties on those Mitfords.\n\n(LAUGHTER)\n\nGROSS: Jessica Mitford, it's been such a pleasure to have you here. I thank you very, very much for joining me.\n\nMITFORD: Well, thank you. I've loved every minute.\n\nBIANCULLI: Jessica Mitford speaking to Terry Gross in 1989. Jessica Mitford and her sisters are the subject of the new BritBox drama series titled \"Outrageous.\" She died in 1996 at age 78. Coming up, I review \"Dexter: Resurrection,\" the newest entry in the \"Dexter\" TV series, about a serial killer who hunts and kills other serial killers. This is FRESH AIR.\n\nCopyright © 2025 NPR. All rights reserved. Visit our website terms of use and permissions pages at www.npr.org for further information.\n\nAccuracy and availability of NPR transcripts may vary. Transcript text may be revised to correct errors or match updates to audio. Audio on npr.org may be edited after its original broadcast or publication. The authoritative record of NPR’s programming is the audio record.",
         "2025-07-25T18:07:04",
         "https://www.npr.org/rss/rss.php?id=1001",
         "https://www.npr.org/2025/07/25/g-s1-79463/outrageous-dramatizes-the-lives-of-the-mitford-sisters",
         "2025-07-26T05:53:43.289025",
         "'Outrageous' dramatizes the lives of the Mitford sisters The six British sisters are the subject of a new Britbox series. In 1989, Jessica Mitford talked with Terry Gross about her relationship with the Communist Party and her book about the death industry. DAVID BIANCULLI, HOST: This is FRESH AIR. I'm David Bianculli, professor of television studies at Rowan University. Jessica Mitford was famous for several reasons. One reason was her investigative books, including her best-known one, \"The American Way Of Death,\" published in 1963. It revealed how the funeral industry was financially taking advantage of grief-stricken Americans. It was a bestseller and led to congressional hearings on the industry. Another reason Mitford was famous was that she was committed to radical causes throughout her life. In the 1950s, as a former member of the Communist Party, she refused to give any information to the House Un-American Activities Committee. Mitford grew up in the English countryside, the daughter of a lord, which gets to yet another source of her notoriety. She was one of England's most unusual groups of sisters. There were six Mitford girls, including Unity, who briefly was romantically involved with Hitler, Diana, who married Oswald Mosley, the head of Britain's Union of Fascists, and Nancy, who became a popular novelist. The sisters are now the subject of a new BritBox drama series titled \"Outrageous.\" In my recent review of the TV show, I called it and the Mitford sisters fascinating. Jessica Mitford died in 1996. Terry Gross spoke with her seven years earlier in 1989. (SOUNDBITE OF ARCHIVED NPR CONTENT) TERRY GROSS: Jessica Mitford, welcome to FRESH AIR. JESSICA MITFORD: Thanks. GROSS: There's so much I want to talk with you about your life. Let's start kind of way back (laughter)... MITFORD: How far? GROSS: ...In your childhood. When you were a young girl from a prosperous family growing up in the English countryside, reading pacifist and leftist literature and getting very excited about it, what was the initial appeal to you of it? MITFORD: Well, you know, I've thought this over since. I believe, actually, that one is very much the product of one's own time. I mean, the '60s people were a product of their time, weren't they? Now, I was a '30s person. In other words, I was born in 1917. So by 1930, I was about 13 years old, reading everything I could lay hands on, like most children, and sort of fascinated with the growing politics all around me. It was the Depression in England - tremendous poverty, huge areas called, you know, unemployable areas - and then there was fascism rising abroad. So these things made me think. GROSS: You're talking about how you think of yourself as being a product of your time. But it's fascinating how, as a product of your time, you became a leftist, yet two of your sisters became fascists. And it's really so hard to imagine sisters in the same family growing up so different. Do you have any explanation for it? MITFORD: I never have been able to figure it out myself, frankly. I've been asked that a lot, lots of times. GROSS: I'm sure you have. MITFORD: Yeah. But, I mean, the thing is, though, that some say it's sibling rivalry, which I don't believe really. I really don't think so. I don't think we were jealous of each other. It was just that I happened to see things differently from the beginning. GROSS: Did you - because you were so opposed to fascism, did you find yourself hating your sisters when they became fascists? MITFORD: Not really. That's the odd thing. I was always deeply fond of my sister Unity. I mean, she was one of my very favorite people in the world. And what I did realize was that our divergent views politically were going to inevitably lead to a huge, well, end of friendship, in fact, which in fact they did. GROSS: You kept a running-away account when you were young... MITFORD: Yeah. GROSS: ...Money so that you could run away from home. But what you ended up using your running-away account for was to try to go to Spain... MITFORD: Right. GROSS: ...With the man who you later married. MITFORD: That's it, yeah. And there was just the right amount, 50 pounds. GROSS: And this was during the Spanish Civil War. MITFORD: Yeah. GROSS: And you already knew which side (laughter)... MITFORD: Oh, yeah. GROSS: ...You were on. You kind of went from this quiet, rural country life, the daughter of a lord, to suddenly being a political radical, involved in a revolution, a young married woman married to someone who was also from a wealthy background. Your husband was the nephew of Winston Churchill. MITFORD: Right. Yes. GROSS: I wonder if you started to see your own families as the opposition. MITFORD: Whether I ever saw them? GROSS: If you saw them as the opposition... MITFORD: Oh, if I saw them as the opposition. GROSS: ...In the political... MITFORD: Oh. GROSS: ...Battles you were waging. MITFORD: Absolutely. Yeah. See, both my parents went completely on the side of Hitler, which was very surprising. You know, we were brought up in the shadow of the first world war, in a way. And in those days, you see, the Huns, they were the filthy Huns who had killed uncle Clem (ph) and numerous other relations in the first world war - people, of course, that I never knew 'cause I was just born during that time. And then all of a sudden, that - Hitler became a tremendous star. He did away with the labor unions, with the Communist Party. He was doing away with the Jews. And you can't discount the amount of antisemitism that goes on in the English upper class. GROSS: Jessica Mitford is my guest. You lost your first husband in action in 1941... MITFORD: Right. Yeah. GROSS: ...During the war. He was 23 years old. You, just before that, lost your baby who... MITFORD: Yes. GROSS: ...Died of measles, I read it was. MITFORD: The one that - born in Rotherhithe Street. Right. GROSS: You were young. You were in your 20s. Did you despair at that point that your life was over? I think it must've been so hard to suffer those two losses at such a young age. MITFORD: Well, also, by then, I had another baby born in 1941, Dinky - Constancia Romilly - who now lives in Atlanta. She's a nurse there, in fact. And, I mean, that was ages ago. She's now 48, absolutely ancient. I can't believe it. But anyhow - so she was my great standby and steadfast friend. And anyhow, you know, when you're young, I suppose life goes on, and especially if you've got a baby to look after and support. And so I got various jobs with the government and other places, you know. GROSS: Let's move ahead a little bit. MITFORD: Yeah. GROSS: You wrote about your membership in the Communist Party in your book, \"A Fine Old Conflict.\" What got you to join when you did? MITFORD: Well, you see, in the first place, I'd always been a terrific supporter of the Communist Party in England ever since I was about 15 because if you sort of studied the times, in those days, you know, well, the Communists were in the forefront of the fight for the rights of unemployed, I mean, and an end to things like the means test, which was a rotten sort of Tory ploy to prevent the unemployed from collecting unemployed insurance or welfare. And then they were also in the forefront of the fight against fascism, both in Germany and Italy, but in Spain above all. It was the Communists who recruited all the young people who went - who flocked from all over the world into the International Brigade, of which Esmond Romilly was one, and that's how I met him. And then we sort of ran off to Spain together, you know. So that was sort of the progression of that. And then - but we never actually joined the party, Esmond and I, in those days. After Esmond was killed, I stayed in Washington with my baby, Dinky - Constancia Romilly. So then I remarried, in 1943, Bob Treuhaft, a lawyer who I met in the OPA, where I was working. And that was in San Francisco. We moved out to San Francisco. And there, again, the Communist Party, in those years, seemed to me the absolute sort of loadstar or the kind of backbone really, if you like, of all progressive left-wing movements, the ones - the steadfast supporters of rights of Black people, that kind of thing. And this is what made us determined to join. So we did join in 1943 and remained members, in fact, until '58, which was quite a longish time. GROSS: What got you to leave in 1958? MITFORD: Well, by 1958, in the first place, the Khrushchev report about the crimes of Stalin had come out, and as a consequence of that, an awful lot of people flocked out of the CP. Not - I didn't at the time. That was in 1956, in fact. And then came the invasion of Hungary, and then came Czechoslovakia and so on, and more and more people flocked out. It was getting to be a waste of time. I'd be better off working with people in the main - in the movements on campuses, for instance, in the '60s and in the Black community. GROSS: So many people were harassed during the McCarthy period, and so many lives were ruined. I'm thinking that it must've been hard to harass someone like you, someone who had been outspoken all of her life and who had already, like, a reputation for eccentricity because of her family. I mean, did you feel like, what can you do to hurt me? MITFORD: Well, I did it a little bit. Yeah. I'll tell you what I really felt, which is that the hell with them sort of thing. I mean, we were subpoenaed. Bob Treuhaft, my husband... GROSS: Your husband, yeah. MITFORD: ...And I were both subpoenaed. And I was subpoenaed by not only the main House Committee on Un-American Activities, but also the local version of the same, the California committee and so on. And, well, I mean, what could you do? Actually, I - when I went, when I was subpoenaed by the main House committee, I was among a hundred people. There were sort of huge headlines in the Chronicle and other papers - 100 Bay Reds subpoenaed. Well, of course, if I hadn't been one of those, I'd have been rather miffed. GROSS: (Laughter). MITFORD: Do you know the feeling? Sort of rather annoyed. But anyhow, I was one, but they never finally called me. But what I found out was that they were bound to pay per diem - or was it? No. It wasn't per diem. It was travel allowance, so much a mile. And since we lived in Oakland, I put in for $40 for travel allowance for the week that I was forced to be there and then turned over the check to the Communist Party. I hoped to annoy them somehow, you know. BIANCULLI: Jessica Mitford speaking to Terry Gross in 1989. More after a break. This is FRESH AIR. (SOUNDBITE OF MUSIC) BIANCULLI: This is FRESH AIR. Let's get back to Terry's 1989 interview with author and activist Jessica Mitford. She and her aristocratic sisters are the subjects of the new BritBox drama series titled \"Outrageous.\" (SOUNDBITE OF ARCHIVED NPR CONTENT) GROSS: In your memoir about your coming-of-age... MITFORD: Yeah. GROSS: ...called \"Daughters And Rebels,\" you wrote that you - you confessed that you were guiltily looking forward to being a debutante. MITFORD: Yeah. GROSS: Now, I don't know if you ever had that experience or not, but certainly you became a very well-known leftist and left that society world. Your father wrote you out of his will... MITFORD: Yeah. GROSS: ...I think because you had named one of your children after Lenin. You called him Nicholas. MITFORD: (Laughter) Yeah. GROSS: Do you ever have any regrets about leaving wealth and privilege? MITFORD: No. In fact, you know, when that happened, which is in '58, I happened to be in Mexico at the time, and to the horror of the landlady where I was staying, 'cause she somehow thought she was going to have to pay for the calls. There were phone calls from everywhere - from the London Evening Standard, from Canada, from all over the United States. What is your reaction to being cut out of your father's will? And I said, I have no reaction. I think people have every right to leave their money as they wish. And I wasn't expecting any, you know? And the sort of - the deflated journalists - you know how they hate that kind of bland answer. Anyhow... GROSS: This could have been, I guess, a big thing if you... MITFORD: If I was like, bah, you know, it's all screamed away or something, you know. GROSS: But you had just assumed that you would... MITFORD: Oh, of course. So I never expected it. GROSS: And that when you make the decision to live your life as you do... MITFORD: Yeah. GROSS: ...You can't have it both ways. MITFORD: Right. GROSS: That was the effective... MITFORD: Of course. Exactly. You said it. GROSS: Jessica Mitford, let's talk a little bit about your writing. You're best known for the book \"The American Way Of Death,\" your expose of the funeral industry. What led you to want to expose the horrors of the funeral industry and how they would get people when they were weak and take them for whatever they could. MITFORD: Well, it is rather weird, I admit. You know, it's an odd subject, indeed. I think the thing is that Bob Treuhaft, my husband - who was a lawyer in Oakland - was representing numerous trade unions. And along about the middle 1950s, he began to notice, to his fury, that every time a union member died - the breadwinner of a family - the hard-fought-for union benefits meant to go to the widow and children would wind up being the price of the funeral. So he started organizing the Bay Area Funeral Society, a nonprofit thing, which I thought was rather boring, frankly. I mean, I said, well, look, we're robbed every day in the supermarkets... GROSS: (Laughter). MITFORD: ...And by the landlords and things. So why pick on the wretched undertakers - until I began reading the trade magazines. GROSS: Oh, what did you see in there? MITFORD: Oh, God. Well, the titles would lead you on - Mortuary Management, Casket And Sunnyside - one - Casket And Sunnyside - and my favorite title of all, you know, which really makes you think - Concept: The Journal Of Creative Ideas For Cemeteries. Well, I mean, you know, if you saw those, wouldn't you be reading them like mad? I did. And I found therein a whole wonder world of the mortuary that I'd never known existed. You know, I hadn't known, for instance, that you could have a choice of foam rubber or whatchamacallit - inner spring mattress for your eternal sealer casket and that kind of thing. I started sending away for samples, and it was all so delightful. So then I started writing that book. GROSS: Did you go undercover and pose as someone who had a deceased loved one so that you could shop for funeral arrangements... MITFORD: Yeah, I did. GROSS: ...To see what it was like? MITFORD: I did quite a bit of that. That was one of the best parts of it, especially Forest Lawn in Los Angeles. That was tremendous fun. GROSS: What was the experience there like? MITFORD: Well, I mean, I went there. Actually, I went with a young man who is an American fellow who was teaching English history or something in one of the colleges there in Los Angeles. And so we made up that he was my nephew, and I was his English aunt, and my sister was dying or something, you see. And we wanted to make preneed arrangements. So I said we wanted to see everything. But in those days, by the way, Forest Lawn was - there was a price war on. a\\And Forest Lawn was advertising on billboards, funerals from $145, you see, which sounded very reasonable. So I said to the grief therapist - they're not salesmen, you know. They're grief therapists. I said to the grief therapist, well, we want to see everything and the nature of all the coffins and I can choose the best - most appropriate. So the first one we came to was $16,500. Now, you have to realize we're talking in the late 19 - no, the early 1960s. So you can double that or triple it or whatever for the inflation, what it - and I must say, it was rather magnificent, you know. And I looked at it longingly. And then I said, well, could we see the $145 one? And so, you know, he took ages finding it. It was all hidden away somewhere. And, my dear, it was purple. It had a purple... GROSS: (Laughter). MITFORD: ...Really hideous. And I said - I looked at it, and I said, my sister wouldn't be caught dead in that sort of thing, you know? GROSS: (Laughter). MITFORD: And so, then we kind of went along and saw all the different plots and blah, blah. And it was great fun. GROSS: After writing \"The American Way Of Death,\" did you find yourself in the position of having to genuinely prepare somebody's funeral and having to shop for real in the funeral industry? MITFORD: I have, once or twice. But my favorite thing in that line, there was a man called Howard Gossage - extremely well known in San Francisco - but he died many years ago. He was a wonderful - he was an ad man, advertising writer. And when he was - oh, he did all those marvelous things in The New Yorker about the getaway car. I mean, it's all years old. I don't know if people remember it. But he was much more than that. He was a brilliant and funny fellow in all ways. So he was dying of leukemia, and we knew he was dying and not expected to live. So one morning about 4, 5 a.m., his brother-in-law rang up and - who I hadn't met. And he said, Howard died in the middle of the night. And his last words to me was, when I go - and I think it'll be very soon now - be sure to get hold of Jessica because she knows how to nose out the cheapest coffin in this whole town. GROSS: (Laughter). MITFORD: So you know how when somebody dies, and the survivors, you know - you always sort of say - or people say, well, what can I - can I do anything? And the answer is no, obviously. But in this case, yes was the answer. So I went and collected the widow, who was a beautiful young actress. And together, we went - and my God, I got one for $150 all in, you know? And he was a rich man. And he would have been considered a super prize for the undertakers. GROSS: Now, there was a casket named after you after your book came out, right? MITFORD: Yeah (laughter). GROSS: A kind of bargain basement, budget kind of casket. MITFORD: Well, I know. It was such a marvelous idea, sort of industrialist in the Middle West had plans and specifications for the Jessica Mitford casket, which was going to be sort of made of plastic, I think, or something like that. GROSS: Did they really make it? MITFORD: I'm not sure. I never actually saw one. My sister Nancy said, oh, well, we all know that you get 10% royalties on those Mitfords. (LAUGHTER) GROSS: Jessica Mitford, it's been such a pleasure to have you here. I thank you very, very much for joining me. MITFORD: Well, thank you. I've loved every minute. BIANCULLI: Jessica Mitford speaking to Terry Gross in 1989. Jessica Mitford and her sisters are the subject of the new BritBox drama series titled \"Outrageous.\" She died in 1996 at age 78. Coming up, I review \"Dexter: Resurrection,\" the newest entry in the \"Dexter\" TV series, about a serial killer who hunts and kills other serial killers. This is FRESH AIR. Copyright © 2025 NPR. All rights reserved. Visit our website terms of use and permissions pages at www.npr.org for further information. Accuracy and availability of NPR transcripts may vary. Transcript text may be revised to correct errors or match updates to audio. Audio on npr.org may be edited after its original broadcast or publication. The authoritative record of NPR’s programming is the audio record.",
         "en",
         "{'ORG': ['Accuracy and availability of NPR transcripts may vary', 'American Activities Committee', 'American Way Of Death', 'Audio', 'Bay Area Funeral Society', 'British sisters are the subject of a new Britbox', 'Casket And Sunnyside', 'Daughters And Rebels', 'It was', 'MITFORD', 'Mitfords', 'NPR', 'NPR CONTENT', 'No. In fact', \"Outrageous' dramatizes\", 'Yes', 'You', 'and funny fellow in all ways', 'and my', 'at Rowan University', 'for instance', 'frankly', 'she', 'the Communist Party', 'with the Communist Party'], 'PER': ['After Esmond was killed', 'Bob Treuhaft', 'Clem', 'Coming', 'David Bianculli', 'He was', 'He was a wonderful', 'He was doing away with the Jews', 'House committee', 'Howard died in the middle of the night', 'I believe', \"I don't think we were jealous of each other\", 'I happened to be in Mexico at the time', 'I mean', \"I really don't think so\", 'I thank you very', 'I was among', 'Jessica Mitford', 'Mitford', 'Now', 'Oswald Mosley', 'Terry Gross spoke with her seven years earlier in 1989', 'Transcript', 'bah', 'did you feel like', 'frankly', 'funerals from', \"his brother-in-law rang up and - who I hadn't\", 'if you saw those', 'lawyer who I', 'that you could have', 'there was a man called Howard', 'views politically were going to inevitably lead to a huge', 'well', \"weren't they\", \"which I don't believe really\", 'which was', \"wouldn't you be reading them like mad?\", 'yes was the answer', 'yet two of your sisters became fascists.', 'you became a leftist', 'you know', 'you know - you always', 'you know.', 'you see'], 'MISC': ['...During the war', 'A Fine Old Conflict', 'Absolutely', 'After writing \"The American Way Of Death', 'All rights reserved', 'And I said', 'And I was subpoenaed', 'And I were both subpoenaed', 'And along about the middle 1950s', 'And by the landlords and things', 'And he said', 'And he would have been considered', 'And his last words to me was', 'And in those days', 'And it was great fun', \"And it's really so hard to imagine sisters in the same family growing up so different\", 'And so', 'And so we made up that he was my nephew', 'And that was in San Francisco', 'And that when you make the decision to live your life as you do', 'And then I said', 'And then all of a sudden', 'And there', 'And this was during the Spanish Civil War', 'And together, we went', 'And when he was - oh', 'And you already knew which side', 'BIANCULLI', 'Battles you were waging', 'But in those days', \"But it's fascinating how\", 'But my favorite thing in that line', 'Creative Ideas For Cemeteries', 'Czechoslovakia and so', 'Dexter: Resurrection', 'Diana', 'Did they really make it', 'Did you', 'Did you despair at that point that your life was over?', 'Did you go undercover and pose as someone who had', 'Do you ever have any regrets about leaving wealth and privilege', 'Do you have any explanation for it', 'Do you know the feeling', 'Esmond and I', 'Exactly', 'Forest Lawn in Los Angeles', 'Forest Lawn was - there was', 'Forest Lawn was advertising on billboards', 'GROSS', 'God', 'HOST: This is FRESH AIR', 'He did away with the labor unions', 'He was 23 years old', 'House Committee on Un', 'How far?', 'Huns', 'Huns who had killed', 'I called it and the Mitford', \"I can't believe it.\", 'I did it a little bit', \"I don't know if people\", \"I don't know if you ever had that experience or not\", 'I got one for', 'I guess', 'I had another baby born in 1941', \"I hadn't been one of those\", \"I hadn't known\", 'I have', 'I have no reaction', 'I know', 'I mean', 'I never actually saw one', 'I never have been able to figure it out myself', 'I read it was', 'I said to the grief', 'I started sending away for samples', 'I stayed in Washington with my baby', 'I suppose life goes on', 'I think', 'I think because you had named one of your children after Lenin', \"I think it must've been so hard to suffer those two losses at such a young age\", 'I think people have every right to leave their money as they wish.', 'I think the thing is that Bob Treuhaft', 'I was born in 1917', 'I was one', 'I went there', 'I went with a young man who is an American fellow who was teaching English', 'I wonder if you started to see your own families as the opposition', \"I'\", \"I'd always been a terrific\", \"I'd have been rather miffed\", \"I'll\", \"I've been asked that a lot\", \"I've thought this over since\", 'If I was like', 'If you saw', 'In other words', 'It had a purple', 'It revealed how the funeral industry was financially taking advantage of grief', 'It was all hidden away somewhere.', 'It was getting to be a waste of time', 'It was just that I happened to see things differently from the beginning', 'It was the Communists who recruited all the young people who went', 'It was the Depression in England - tremendous poverty', 'It was travel allowance', 'LAUGHTER', 'Laughter', \"Let's get back to Terry'\", \"Let's move ahead a little bit\", \"Let's start kind of way back\", 'MITFORD', 'MITFORD: And so', 'Money so that you could run away from home', 'More after', 'My', 'NPR’', 'Nancy said, oh', 'Not really', 'Now', 'Oh', 'One reason was her investigative books', 'Really hideous', 'Right', 'SOUNDBITE OF', 'SOUNDBITE OF MUSIC', 'She and her aristocratic sisters are the subjects of the new BritBox', 'She died in 1996 at age', \"She was one of England'\", \"She'\", 'So I never expected it', 'So I said to the grief therapist', 'So I said we wanted to see everything', 'So I went and collected the widow', 'So many people were harassed during the McCarthy period', 'So one morning about 4', 'So the first one we came to was', 'So these things made me think', 'So why pick on the wretched undertakers', 'So you can double that or triple it or whatever for the inflation', 'So you know how when somebody dies', 'Sort of rather annoyed', 'Spain above all', 'TERRY', 'Thanks', 'That was one of the best parts of it', 'That was the effective', \"That's it, yeah.\", \"That's the odd thing\", 'The authoritative record of', 'The sisters are now the subject of a new BritBox', 'There were phone calls from everywhere - from the London Evening Standard', 'There were six Mitford girls', 'There were sort of huge headlines in the Chronicle and other papers', 'This could have been', 'This is FRESH AIR', 'To see what it was like', 'Tory ploy to prevent the unemployed from collecting', 'Unity', 'Visit our website', 'We moved out to San Francisco', 'Well', 'What got you to join when you did', 'What got you to leave in 1958', \"What is your reaction to being cut out of your father's will?\", 'What led you to want to expose the horrors of the funeral industry and how they would get people when they were weak and take them for whatever they could', 'What was the experience there like', 'When you were a young', 'Whether I ever saw them', 'With the man who you later married', 'Yeah', 'You called him Nicholas', \"You can't have it both ways\", 'You kept a running-away account when you were young', 'You kind of went from this quiet', 'You know', \"You know, it's an odd subject\", 'You know, we were brought up in the shadow of the first world war', 'You lost your first husband in action in 1941', 'You said it', 'You were', 'You were in your 20s', 'You were young', 'You wrote about your membership in the Communist Party in your book', 'Your father wrote you out of his will', 'Your husband was the nephew of Winston Churchill', 'Your husband, yeah', \"actually, that one is very much the product of one's own time\", 'and I was his English aunt', 'and as', 'and more and more people flocked out', 'and so many lives were ruined', \"and that's how I\", 'and we knew he was dying and not expected to live', 'big thing if you', 'both in Germany and Italy', 'could we see the', 'end of friendship', 'fascinated with the growing politics all around', 'including Unity', 'including her best-known one', \"it's all screamed away or something\", \"it's all years old\", \"it's been such\", 'just before that', 'like most children', 'longish time', 'lost your baby who', 'may be revised to correct errors', 'member of the Communist Party', 'my husband', 'of industrialist in the Middle West had plans and specifications for the Jessica Mitford casket', 'of loadstar or the kind of backbone really', 'of the Communist Party in England ever since I was about 15 because if you', 'of their time', 'or something like that', 'price war on', 'reading pacifist and leftist literature and getting very excited about it', 'review of the TV show', 'she was one of my very favorite people in the world.', 'speaking to Terry Gross', 'spring mattress for your eternal sealer casket and that kind of thing', \"that I never knew 'cause\", 'that kind of thing', 'the Communists were in the forefront of the fight for the rights of unemployed', 'the Khrushchev report', 'the daughter of', 'the early 1960s', \"the head of Britain's Union of Fascists\", 'the ones', 'the side of Hitler', 'the thing is', 'then we kind of went along and saw all the different plots and blah', 'unemployable areas', 'very much for joining', 'we all know that you get 10', 'we want to see everything and the nature of all the coffins and I', \"we're robbed every day in the supermarkets\", 'welcome to FRESH AIR', 'what can I', 'what can you do to hurt', 'what could you do?', 'what it - and I must say', 'what was the initial appeal to you of it', 'when I go', 'when I was subpoenaed', 'which I thought was rather boring', 'who hunts and kills other serial killers', \"whole wonder world of the mortuary that I'd never known existed\", \"wouldn't be caught dead in that sort of thing\", \"you have to realize we're talking in the late 19 - no\", 'you know?', 'you see', 'you see, in the first place', 'you see.', 'young married woman married to someone who was also from'], 'LOC': ['Anyhow', 'Atlanta', 'Canada', 'Dinky', 'I', \"I'\", 'Los Angeles', 'MITFORD', 'Now', 'Yeah', 'and Nancy', 'indeed', 'lawyer in Oakland', 'the California committee and so']}",
         "[0.004021747969090939, -0.1298867166042328, -0.030253376811742783, 0.005167231895029545, 0.022921007126569748, 0.026559647172689438, 0.046175651252269745, -0.03908229246735573, -0.04720915108919144, 0.02345469407737255, 0.08767001330852509, 0.11713987588882446, 0.007346474565565586, -0.054990530014038086, -0.08094022423028946, 0.08490076661109924, 0.018208809196949005, 0.025035984814167023, -0.1089092493057251, 0.053515639156103134, -0.0031991004943847656, 0.00922053586691618, 0.031600479036569595, 0.028048131614923477, -0.0036945606116205454, -0.07753206789493561, 0.007211377378553152, -0.023210793733596802, -0.04869550094008446, 0.04667581990361214, -0.11599482595920563, 0.06266571581363678, -0.04069909825921059, 0.007542521692812443, 0.10243091732263565, -0.0050725387409329414, 0.10131704807281494, 0.026349516585469246, 0.029486849904060364, -0.015539613552391529, -0.026949718594551086, -0.07940253615379333, -0.0011197755811735988, -0.013225793838500977, -0.04270220920443535, 0.004241875372827053, -0.03842641040682793, 0.05371459573507309, 0.041510358452796936, -0.01718173921108246, -0.049609698355197906, 0.08932547271251678, 0.030702274292707443, -0.04858708381652832, 0.028669338673353195, -0.058267053216695786, -0.0520700141787529, 0.014271870255470276, -0.029761312529444695, -0.03350868821144104, -0.09814174473285675, -0.01519287284463644, 0.014039534144103527, -0.0347139835357666, -0.03122648596763611, 0.053522706031799316, -0.000681219797115773, 0.0039871674962341785, 0.09180927276611328, 0.008475316688418388, -0.03111416846513748, 0.002888015005737543, -0.02116929553449154, -0.003567052073776722, -0.06598931550979614, 0.03274453803896904, 0.10702504962682724, -0.09529563784599304, -0.0843241959810257, 0.050522580742836, -0.01135928463190794, -0.09365841746330261, 0.16285042464733124, -0.04779854789376259, 0.013370978645980358, -0.07243776321411133, -0.010981333442032337, -0.00477853836491704, -0.007707439828664064, 0.0884285494685173, -0.08442901074886322, 0.00609378470107913, 0.018237097188830376, -0.013403143733739853, 0.06499310582876205, -0.022557487711310387, 0.06025434657931328, -0.014489907771348953, 0.00013738257985096425, 0.04233240336179733, -0.05014750733971596, 0.014877691864967346, -0.02688828483223915, -0.008659658953547478, 0.01115428563207388, -0.11838874220848083, 0.00135282170958817, 0.02783028781414032, 0.04017438739538193, 0.02091911807656288, -0.005997940432280302, -0.05227842181921005, -0.00304072885774076, -0.006446288898587227, 0.07143669575452805, -0.022884855046868324, 0.05091478303074837, 0.023194439709186554, -0.009575659409165382, -0.03218574821949005, 0.08366391062736511, 0.07528015971183777, -0.11427213251590729, 0.08452724665403366, -0.005200114566832781, -0.038705579936504364, -0.02226133830845356, -1.561606408842992e-33, -0.01751970872282982, 0.06986410915851593, -0.014151127077639103, 0.07536554336547852, -0.058581605553627014, 0.03195929899811745, -0.0035222081933170557, -0.020404260605573654, 0.036070626229047775, 0.006629438139498234, 0.0262766070663929, 0.011426019482314587, -0.04151707887649536, -0.058184441179037094, -0.04435678571462631, 0.014604256488382816, -0.05843402072787285, 0.046049270778894424, 0.06877733767032623, -0.0074562751688063145, 0.0387800969183445, 0.07936295121908188, -0.012799959629774094, -0.031179502606391907, -0.10209736227989197, -0.00252712145447731, 0.07466677576303482, 0.04356890171766281, -0.03506965935230255, 0.012359878979623318, 0.0016339265275746584, -0.008380703628063202, 0.03982066363096237, -0.03006872721016407, -0.004986360669136047, 0.007278457283973694, -0.05657175928354263, -0.02250066213309765, 0.04277046024799347, 0.1156492605805397, -0.07651299238204956, 0.04756270349025726, 0.045706987380981445, -0.06126983463764191, -0.05054178461432457, 0.09231939911842346, 0.014111032709479332, -0.0471576452255249, 0.052149366587400436, -0.042568888515233994, -0.0399710051715374, 0.0029281426686793566, 0.015877731144428253, -0.03552118316292763, 0.0073968954384326935, 0.01504016388207674, -0.038475118577480316, -0.023736217990517616, -0.0022540390491485596, -0.06484386324882507, -0.04792133346199989, -0.020243115723133087, -0.01643155701458454, 0.07060333341360092, -0.00460704555734992, 0.01055310107767582, -0.06859435141086578, -0.09870723634958267, -0.02180083841085434, 0.031802404671907425, -0.07181170582771301, 0.09712450206279755, 0.08496853709220886, -0.03925414755940437, -0.0751706212759018, 0.032740380614995956, 0.013050098903477192, -0.03305456414818764, -0.02411220408976078, 0.002422590972855687, 0.0722307562828064, 0.05741415172815323, 0.062082771211862564, 0.017674969509243965, -0.061556581407785416, -0.055045127868652344, -0.08118873089551926, 0.05364153906702995, -0.00360748334787786, -0.020934931933879852, 0.006293326150625944, -0.05780715122818947, -0.03598470613360405, -0.014087767340242863, -0.010702223517000675, -2.0935069496725226e-33, 0.012484566308557987, -0.09412560611963272, -0.02234373241662979, 0.01528770849108696, 0.018407613039016724, 0.04940716549754143, -0.10782275348901749, -0.012160052545368671, 0.12189929932355881, 0.011982200667262077, 0.023470360785722733, -0.05613851547241211, 0.014320408925414085, 0.03462013602256775, 0.005210984498262405, -0.08105284720659256, 0.05729538947343826, -0.06800007820129395, -0.015534874983131886, 0.012008195742964745, -0.08971324563026428, 0.06471104919910431, -0.08378878235816956, -0.06212582811713219, 0.020059270784258842, 0.02263033203780651, -0.0014281129697337747, -0.0032938835211098194, -0.0036261514760553837, -0.019248854368925095, 0.018045561388134956, 0.08749349415302277, 0.049289051443338394, 0.03494776785373688, 0.06093896925449371, -0.0030466916505247355, -0.07266481220722198, 0.020082896575331688, 0.01718919910490513, -0.07998616248369217, 0.010965581983327866, 0.02996799349784851, 0.004855375271290541, -0.04296601191163063, 0.09818516671657562, -0.06855262070894241, 0.0524635836482048, -0.01074092835187912, 0.06473317742347717, 0.0039535025134682655, -0.10130786895751953, -0.021055100485682487, -0.02211916074156761, -0.0006756088696420193, 0.03476575389504433, 0.030284643173217773, -0.0072826966643333435, -0.05067923292517662, 0.07904741168022156, 0.02574649080634117, 0.00041476995102129877, -0.0015078899450600147, 0.0012053648242726922, -0.012778003700077534, -0.07526390254497528, -0.021300194784998894, -0.03383341804146767, -0.12466650456190109, -0.0017852712189778686, 0.016403788700699806, -0.04417463019490242, 0.0036498447880148888, 0.010703975334763527, 0.005162146408110857, -0.0027503431774675846, 0.03707468882203102, -0.038966380059719086, -0.0035746763460338116, -0.08198211342096329, 0.025121597573161125, 0.006435119081288576, -0.014297274872660637, -0.0007280493155121803, 0.05277804285287857, 0.04190254211425781, 0.06915813684463501, -0.0009647789411246777, 0.11259728670120239, 0.0033896088134497404, -0.054076727479696274, 0.005778435152024031, -0.1379188895225525, 0.03337705507874489, -0.04334265738725662, -0.11036579310894012, -5.5198718484916753e-08, 0.037927091121673584, 0.049077924340963364, -0.03449181839823723, -0.026764094829559326, -0.1284843534231186, 0.056356169283390045, 0.07397212088108063, 0.08517242223024368, -0.026563813909888268, 0.02845802716910839, 0.011118861846625805, 0.05462978035211563, -0.02902163751423359, -0.031759750097990036, -0.0005593466339632869, -0.04909566417336464, 0.022125987336039543, -0.03826366737484932, 0.003022230928763747, -0.0011525676818564534, -0.021171852946281433, -0.06767965853214264, 0.06223370134830475, -0.05234120786190033, -0.04229135066270828, 0.04705768823623657, 0.08587358146905899, 0.011363268829882145, -0.029410380870103836, -0.02510276436805725, -0.09742269665002823, 0.004825741518288851, -0.03953300416469574, 0.07293885201215744, -0.05405726656317711, -0.0067100077867507935, 0.022832997143268585, 0.06417355686426163, -0.0506119579076767, 0.07641804218292236, 0.076746366918087, -0.018100876361131668, 0.007075381465256214, 0.010487612336874008, 0.1117243766784668, -0.03203596919775009, 0.029561325907707214, -0.07513504475355148, 0.0683508962392807, 0.07875771075487137, 0.0042869229800999165, 0.011711904779076576, -0.020484179258346558, 0.014577483758330345, 0.06220708414912224, 0.06739293783903122, -0.005366070196032524, -0.014894329011440277, -0.05722873657941818, 0.037896692752838135, 0.005363883916288614, -0.008833861909806728, -0.0027319558430463076, -0.027941027656197548]",
         "0.148"
        ],
        [
         "16",
         "23",
         "Top 10 AI Tools That Will Transform Your Content Creation in 2025",
         "Looking to level up your content creation game in 2025? You're in the right place! The digital landscape has evolved dramatically, and AI tools have become essential for creators who want to stay ahead of the curve. In this guide, I'll show you the top 10 AI tools that are revolutionizing content creation and making creators' lives easier. Why You Need These AI Tools in 2025 Content creation has become more demanding than ever. Whether you're a social media influencer, marketer, or business owner, keeping up with the constant need for fresh, engaging content can be overwhelming. That's where AI tools come in – they're not just fancy tech, they're your secret weapon for creating better content faster. Let's Dive Into the Top 10 AI Tools for 2025 1. ChatGPT : Content Ideation and Scriptwriting What Makes It Special: ChatGPT has evolved into a comprehensive content creation assistant by combining advanced language understanding with specialized content optimization features. Its ability to generate, edit, and optimize content while maintaining brand voice and industry expertise makes it an essential tool for creators who need to produce high-quality written content at scale. Key Features: Advanced content generation SEO optimization Brand voice maintenance Research capabilities Multi-format adaptation Pricing: Free tier available Plus: $20/month Pro: $200/month Perfect For: Content writers, marketers, and businesses needing consistent, high-quality written content. 2. Canva Magic Studio : Visual Design and Social Media Content Creation What Makes It Special: Canva Magic Studio has transformed the graphic design landscape by combining its user-friendly interface with powerful AI capabilities. The platform's ability to understand design principles and automatically generate on-brand content while maintaining professional aesthetics makes it accessible for beginners while providing enough sophistication for professional designers. Key Features: AI design generation Brand kit integration Magic resize Animation tools Template library Pricing: Free tier available Pro: $6.50/user/month Teams: $5/user/month Perfect For: Small businesses, social media managers, and anyone needing quick, professional-looking designs. 3. RunwayML : AI Video Generator What Makes It Special: RunwayML stands out as the ultimate video creation powerhouse by combining professional-grade effects with user-friendly AI technology. Its game-changing ability to manipulate video content – from changing weather effects with a text prompt to removing objects seamlessly in real-time – makes it indispensable for creators who want to produce high-quality video content without getting bogged down by technical complexities. Key Features: Advanced video generation & editing Real-time visual effects Smart motion tracking Green screen effects without actual green screen AI-powered editing suite Pricing: Free tier available Standard: $12/month Pro: $28/month Unlimited: $76/month Enterprise: Custom Price Perfect For: Video creators, YouTubers, and social media managers who want to create professional-quality videos quickly. 4. MidJourney : AI Art Generation What Makes It Special: Midjourney V6 has redefined AI image generation by mastering the nuances of professional photography and artistic style. Its ability to understand and execute complex creative directions – from specific lighting conditions to branded visual styles – while maintaining consistent quality across multiple generations makes it the go-to tool for creators who need stunning visuals that align perfectly with their brand identity. Key Features: Photorealistic image generation Advanced style control Quick generation time Commercial usage rights Strong community support Pricing: Basic: $10/month Standard: $30/month Pro: $60/month Mega: $120/month Perfect For: Social media managers, digital marketers, and anyone needing professional-quality visuals consistently. 5. Synthesia : AI Avatar-Based Video Creation What Makes It Special: Synthesia has transformed video creation by making it possible to create professional-looking AI avatar videos in minutes. Its ability to generate natural-looking presentations in multiple languages with synchronized lip movements and gestures makes it invaluable for creators who need to produce video content at scale without the traditional filming process. Key Features: AI avatar Video creation Multi-language support Custom avatar options Professional templates Script to video conversion Pricing: Free tier available Starter: $18/month Creator: $64/month Enterprise: Custom pricing Perfect For: Businesses and educators creating training videos, presentations, and multilingual content. 6. Descript : Podcast and Video Editing with Transcription Features What Makes It Special: Descript has transformed audio and video editing by making it as simple as editing a text document. Its innovative approach to media editing, combined with powerful AI features like automatic transcription and filler word removal, makes professional-quality editing accessible to creators of all skill levels. Key Features: Text-based video editing Automatic transcription Filler word removal Screen recording Collaborative editing Pricing: Hobbyist: $12/month Creator: $24/month Business: $40/month Enterprise: Custom pricing Perfect For: Podcasters, video creators, and teams needing efficient audio/video editing solutions. 7. ElevenLabs : AI VOICE GENERATION What Makes It Special: ElevenLabs has revolutionized voice synthesis by achieving unprecedented levels of natural speech quality and emotional expression. Its ability to clone voices accurately and generate multiple languages with proper accents and inflections makes it the ultimate tool for creators who need professional-quality voiceovers without the traditional recording process or voice actor limitations. Key Features: Ultra-realistic voice synthesis Voice cloning capability Multi-language support Emotion control Real-time generation Pricing: Free tier available Starter: $5/month Creator: $11/month Pro: $99/month Scale: $330/month Business: $1321/month Enterprise: Custom pricing Perfect For: Podcasters, video creators, and content creators needing professional voiceovers in multiple languages. 8. Tribescaler : Viral Content and Headline Optimization What Makes It Special: Tribescaler brings a scientific approach to viral content creation by combining trend analysis with content optimization. Its powerful AI engine analyzes successful content patterns across platforms and provides actionable insights to help creators craft content that's more likely to go viral, while maintaining authenticity and audience engagement. Key Features: Viral content prediction Trend analysis Content optimization Performance tracking Multi-platform scheduling Pricing: Free tier available Pro: $49/month Perfect For: Content creators and social media managers focused on maximizing reach and engagement. 9. Clickable : Automated Ad Creation and Optimization What Makes It Special: Clickable revolutionizes ad creation by seamlessly blending data-driven insights with creative automation. Its ability to analyze brand assets and automatically generate platform-optimized ad variations while maintaining brand voice transforms the tedious process of ad creation into a streamlined, results-driven workflow that consistently delivers high-performing content. Key Features: Automated ad creation Multi-platform optimization Built-in A/B testing Performance analytics Template library Perfect For: Digital marketers and businesses looking to scale their ad production efficiently. 10. Copy AI What Makes It Special: CopyAI has established itself as a powerhouse in AI-powered copywriting by offering specialized content generation for various marketing formats. Its sophisticated understanding of marketing psychology and brand voice, combined with its ability to generate compelling copy across multiple formats and industries, makes it invaluable for marketers and content creators who need to produce engaging, conversion-focused content at scale. Key Features: Advanced marketing copy generation Multiple content type templates Brand voice customization Multilingual support A/B testing variations Pricing: Free tier available Pro: $49/month Advanced: $249/month Enterprise: Custom pricing Perfect For: Marketing teams, copywriters, and businesses needing high-converting marketing copy across multiple channels. Conclusion The AI tools listed here are revolutionizing the content creation landscape in 2025, making it easier than ever to produce high-quality, engaging, and impactful content. By integrating these tools into your workflow, you can save time, unleash your creativity, and achieve better results. AI doesn't replace creativity; it amplifies it. As a content creator, your unique voice and vision are irreplaceable. These tools serve as enablers, helping you focus on what you do best—creating. Explore, experiment, and innovate. The future of content creation is here, and it's brimming with possibilities. Embrace these technologies, stay ahead of the curve, and watch your creative potential soar. The only limit is your imagination! Note: All features and pricing information are subject to change. Please verify current details with the respective platforms, Also this article contain affiliate links which means we make a small comission if yo buy any premium plan from our links Pricing updated on 01/02/ 2025",
         "Top 10 AI Tools That Will Transform Your Content Creation in 2025\n\n\n\n\n\nLooking to level up your content creation game in 2025? You're in the right place! The digital landscape has evolved dramatically, and AI tools have become essential for creators who want to stay ahead of the curve. In this guide, I'll show you the top 10 AI tools that are revolutionizing content creation and making creators' lives easier.\n\nWhy You Need These AI Tools in 2025\n\nContent creation has become more demanding than ever. Whether you're a social media influencer, marketer, or business owner, keeping up with the constant need for fresh, engaging content can be overwhelming. That's where AI tools come in – they're not just fancy tech, they're your secret weapon for creating better content faster.\n\nLet's Dive Into the Top 10 AI Tools for 2025\n\n\n\n\n\n1. ChatGPT : Content Ideation and Scriptwriting\n\nWhat Makes It Special: ChatGPT has evolved into a comprehensive content creation assistant by combining advanced language understanding with specialized content optimization features. Its ability to generate, edit, and optimize content while maintaining brand voice and industry expertise makes it an essential tool for creators who need to produce high-quality written content at scale.\n\nKey Features:\n\nAdvanced content generation\n\nSEO optimization\n\nBrand voice maintenance\n\nResearch capabilities\n\nMulti-format adaptation\n\nPricing:\n\nFree tier available\n\nPlus: $20/month\n\nPro: $200/month\n\nPerfect For: Content writers, marketers, and businesses needing consistent, high-quality written content.\n\n2. Canva Magic Studio : Visual Design and Social Media Content Creation\n\nWhat Makes It Special: Canva Magic Studio has transformed the graphic design landscape by combining its user-friendly interface with powerful AI capabilities. The platform's ability to understand design principles and automatically generate on-brand content while maintaining professional aesthetics makes it accessible for beginners while providing enough sophistication for professional designers.\n\nKey Features:\n\nAI design generation\n\nBrand kit integration\n\nMagic resize\n\nAnimation tools\n\nTemplate library\n\nPricing:\n\nFree tier available\n\nPro: $6.50/user/month\n\nTeams: $5/user/month\n\nPerfect For: Small businesses, social media managers, and anyone needing quick, professional-looking designs.\n\n3. RunwayML : AI Video Generator\n\nWhat Makes It Special: RunwayML stands out as the ultimate video creation powerhouse by combining professional-grade effects with user-friendly AI technology. Its game-changing ability to manipulate video content – from changing weather effects with a text prompt to removing objects seamlessly in real-time – makes it indispensable for creators who want to produce high-quality video content without getting bogged down by technical complexities.\n\nKey Features:\n\nAdvanced video generation & editing\n\nReal-time visual effects\n\nSmart motion tracking\n\nGreen screen effects without actual green screen\n\nAI-powered editing suite\n\nPricing:\n\nFree tier available\n\nStandard: $12/month\n\nPro: $28/month\n\nUnlimited: $76/month\n\nEnterprise: Custom Price\n\nPerfect For: Video creators, YouTubers, and social media managers who want to create professional-quality videos quickly.\n\n4. MidJourney : AI Art Generation\n\nWhat Makes It Special: Midjourney V6 has redefined AI image generation by mastering the nuances of professional photography and artistic style. Its ability to understand and execute complex creative directions – from specific lighting conditions to branded visual styles – while maintaining consistent quality across multiple generations makes it the go-to tool for creators who need stunning visuals that align perfectly with their brand identity.\n\nKey Features:\n\nPhotorealistic image generation\n\nAdvanced style control\n\nQuick generation time\n\nCommercial usage rights\n\nStrong community support\n\nPricing:\n\nBasic: $10/month\n\nStandard: $30/month\n\nPro: $60/month\n\nMega: $120/month\n\nPerfect For: Social media managers, digital marketers, and anyone needing professional-quality visuals consistently.\n\n5. Synthesia : AI Avatar-Based Video Creation\n\nWhat Makes It Special: Synthesia has transformed video creation by making it possible to create professional-looking AI avatar videos in minutes. Its ability to generate natural-looking presentations in multiple languages with synchronized lip movements and gestures makes it invaluable for creators who need to produce video content at scale without the traditional filming process.\n\nKey Features:\n\nAI avatar Video creation\n\nMulti-language support\n\nCustom avatar options\n\nProfessional templates\n\nScript to video conversion\n\nPricing:\n\nFree tier available\n\nStarter: $18/month\n\nCreator: $64/month\n\nEnterprise: Custom pricing\n\nPerfect For: Businesses and educators creating training videos, presentations, and multilingual content.\n\n6. Descript : Podcast and Video Editing with Transcription Features\n\nWhat Makes It Special: Descript has transformed audio and video editing by making it as simple as editing a text document. Its innovative approach to media editing, combined with powerful AI features like automatic transcription and filler word removal, makes professional-quality editing accessible to creators of all skill levels.\n\nKey Features:\n\nText-based video editing\n\nAutomatic transcription\n\nFiller word removal\n\nScreen recording\n\nCollaborative editing\n\nPricing:\n\nHobbyist: $12/month\n\nCreator: $24/month\n\nBusiness: $40/month\n\nEnterprise: Custom pricing\n\nPerfect For: Podcasters, video creators, and teams needing efficient audio/video editing solutions.\n\n7. ElevenLabs : AI VOICE GENERATION\n\nWhat Makes It Special: ElevenLabs has revolutionized voice synthesis by achieving unprecedented levels of natural speech quality and emotional expression. Its ability to clone voices accurately and generate multiple languages with proper accents and inflections makes it the ultimate tool for creators who need professional-quality voiceovers without the traditional recording process or voice actor limitations.\n\nKey Features:\n\nUltra-realistic voice synthesis\n\nVoice cloning capability\n\nMulti-language support\n\nEmotion control\n\nReal-time generation\n\nPricing:\n\nFree tier available\n\nStarter: $5/month\n\nCreator: $11/month\n\nPro: $99/month\n\nScale: $330/month\n\nBusiness: $1321/month\n\nEnterprise: Custom pricing\n\nPerfect For: Podcasters, video creators, and content creators needing professional voiceovers in multiple languages.\n\n8. Tribescaler : Viral Content and Headline Optimization\n\nWhat Makes It Special: Tribescaler brings a scientific approach to viral content creation by combining trend analysis with content optimization. Its powerful AI engine analyzes successful content patterns across platforms and provides actionable insights to help creators craft content that's more likely to go viral, while maintaining authenticity and audience engagement.\n\nKey Features:\n\nViral content prediction\n\nTrend analysis\n\nContent optimization\n\nPerformance tracking\n\nMulti-platform scheduling\n\nPricing:\n\nFree tier available\n\nPro: $49/month\n\nPerfect For: Content creators and social media managers focused on maximizing reach and engagement.\n\n9. Clickable : Automated Ad Creation and Optimization\n\nWhat Makes It Special: Clickable revolutionizes ad creation by seamlessly blending data-driven insights with creative automation. Its ability to analyze brand assets and automatically generate platform-optimized ad variations while maintaining brand voice transforms the tedious process of ad creation into a streamlined, results-driven workflow that consistently delivers high-performing content.\n\nKey Features:\n\nAutomated ad creation\n\nMulti-platform optimization\n\nBuilt-in A/B testing\n\nPerformance analytics\n\nTemplate library\n\nPerfect For: Digital marketers and businesses looking to scale their ad production efficiently.\n\nWhat Makes It Special: CopyAI has established itself as a powerhouse in AI-powered copywriting by offering specialized content generation for various marketing formats. Its sophisticated understanding of marketing psychology and brand voice, combined with its ability to generate compelling copy across multiple formats and industries, makes it invaluable for marketers and content creators who need to produce engaging, conversion-focused content at scale.\n\nKey Features:\n\nAdvanced marketing copy generation\n\nMultiple content type templates\n\nBrand voice customization\n\nMultilingual support\n\nA/B testing variations\n\nPricing:\n\nFree tier available\n\nPro: $49/month\n\nAdvanced: $249/month\n\nEnterprise: Custom pricing\n\nPerfect For: Marketing teams, copywriters, and businesses needing high-converting marketing copy across multiple channels.\n\nConclusion\n\nThe AI tools listed here are revolutionizing the content creation landscape in 2025, making it easier than ever to produce high-quality, engaging, and impactful content. By integrating these tools into your workflow, you can save time, unleash your creativity, and achieve better results.\n\nAI doesn't replace creativity; it amplifies it. As a content creator, your unique voice and vision are irreplaceable. These tools serve as enablers, helping you focus on what you do best—creating. Explore, experiment, and innovate. The future of content creation is here, and it's brimming with possibilities.\n\nEmbrace these technologies, stay ahead of the curve, and watch your creative potential soar. The only limit is your imagination!\n\nNote:\n\nAll features and pricing information are subject to change. Please verify current details with the respective platforms, Also this article contain affiliate links which means we make a small comission if yo buy any premium plan from our links\n\nPricing updated on 01/02/ 2025",
         "2025-01-02T09:26:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2025/01/top-10-ai-tools-that-will-transform.html",
         "2025-07-26T05:41:35.751418",
         "Top 10 AI Tools That Will Transform Your Content Creation in 2025 Looking to level up your content creation game in 2025? You're in the right place! The digital landscape has evolved dramatically, and AI tools have become essential for creators who want to stay ahead of the curve. In this guide, I'll show you the top 10 AI tools that are revolutionizing content creation and making creators' lives easier. Why You Need These AI Tools in 2025 Content creation has become more demanding than ever. Whether you're a social media influencer, marketer, or business owner, keeping up with the constant need for fresh, engaging content can be overwhelming. That's where AI tools come in – they're not just fancy tech, they're your secret weapon for creating better content faster. Let's Dive Into the Top 10 AI Tools for 2025 1. ChatGPT : Content Ideation and Scriptwriting What Makes It Special: ChatGPT has evolved into a comprehensive content creation assistant by combining advanced language understanding with specialized content optimization features. Its ability to generate, edit, and optimize content while maintaining brand voice and industry expertise makes it an essential tool for creators who need to produce high-quality written content at scale. Key Features: Advanced content generation SEO optimization Brand voice maintenance Research capabilities Multi-format adaptation Pricing: Free tier available Plus: $20/month Pro: $200/month Perfect For: Content writers, marketers, and businesses needing consistent, high-quality written content. 2. Canva Magic Studio : Visual Design and Social Media Content Creation What Makes It Special: Canva Magic Studio has transformed the graphic design landscape by combining its user-friendly interface with powerful AI capabilities. The platform's ability to understand design principles and automatically generate on-brand content while maintaining professional aesthetics makes it accessible for beginners while providing enough sophistication for professional designers. Key Features: AI design generation Brand kit integration Magic resize Animation tools Template library Pricing: Free tier available Pro: $6.50/user/month Teams: $5/user/month Perfect For: Small businesses, social media managers, and anyone needing quick, professional-looking designs. 3. RunwayML : AI Video Generator What Makes It Special: RunwayML stands out as the ultimate video creation powerhouse by combining professional-grade effects with user-friendly AI technology. Its game-changing ability to manipulate video content – from changing weather effects with a text prompt to removing objects seamlessly in real-time – makes it indispensable for creators who want to produce high-quality video content without getting bogged down by technical complexities. Key Features: Advanced video generation & editing Real-time visual effects Smart motion tracking Green screen effects without actual green screen AI-powered editing suite Pricing: Free tier available Standard: $12/month Pro: $28/month Unlimited: $76/month Enterprise: Custom Price Perfect For: Video creators, YouTubers, and social media managers who want to create professional-quality videos quickly. 4. MidJourney : AI Art Generation What Makes It Special: Midjourney V6 has redefined AI image generation by mastering the nuances of professional photography and artistic style. Its ability to understand and execute complex creative directions – from specific lighting conditions to branded visual styles – while maintaining consistent quality across multiple generations makes it the go-to tool for creators who need stunning visuals that align perfectly with their brand identity. Key Features: Photorealistic image generation Advanced style control Quick generation time Commercial usage rights Strong community support Pricing: Basic: $10/month Standard: $30/month Pro: $60/month Mega: $120/month Perfect For: Social media managers, digital marketers, and anyone needing professional-quality visuals consistently. 5. Synthesia : AI Avatar-Based Video Creation What Makes It Special: Synthesia has transformed video creation by making it possible to create professional-looking AI avatar videos in minutes. Its ability to generate natural-looking presentations in multiple languages with synchronized lip movements and gestures makes it invaluable for creators who need to produce video content at scale without the traditional filming process. Key Features: AI avatar Video creation Multi-language support Custom avatar options Professional templates Script to video conversion Pricing: Free tier available Starter: $18/month Creator: $64/month Enterprise: Custom pricing Perfect For: Businesses and educators creating training videos, presentations, and multilingual content. 6. Descript : Podcast and Video Editing with Transcription Features What Makes It Special: Descript has transformed audio and video editing by making it as simple as editing a text document. Its innovative approach to media editing, combined with powerful AI features like automatic transcription and filler word removal, makes professional-quality editing accessible to creators of all skill levels. Key Features: Text-based video editing Automatic transcription Filler word removal Screen recording Collaborative editing Pricing: Hobbyist: $12/month Creator: $24/month Business: $40/month Enterprise: Custom pricing Perfect For: Podcasters, video creators, and teams needing efficient audio/video editing solutions. 7. ElevenLabs : AI VOICE GENERATION What Makes It Special: ElevenLabs has revolutionized voice synthesis by achieving unprecedented levels of natural speech quality and emotional expression. Its ability to clone voices accurately and generate multiple languages with proper accents and inflections makes it the ultimate tool for creators who need professional-quality voiceovers without the traditional recording process or voice actor limitations. Key Features: Ultra-realistic voice synthesis Voice cloning capability Multi-language support Emotion control Real-time generation Pricing: Free tier available Starter: $5/month Creator: $11/month Pro: $99/month Scale: $330/month Business: $1321/month Enterprise: Custom pricing Perfect For: Podcasters, video creators, and content creators needing professional voiceovers in multiple languages. 8. Tribescaler : Viral Content and Headline Optimization What Makes It Special: Tribescaler brings a scientific approach to viral content creation by combining trend analysis with content optimization. Its powerful AI engine analyzes successful content patterns across platforms and provides actionable insights to help creators craft content that's more likely to go viral, while maintaining authenticity and audience engagement. Key Features: Viral content prediction Trend analysis Content optimization Performance tracking Multi-platform scheduling Pricing: Free tier available Pro: $49/month Perfect For: Content creators and social media managers focused on maximizing reach and engagement. 9. Clickable : Automated Ad Creation and Optimization What Makes It Special: Clickable revolutionizes ad creation by seamlessly blending data-driven insights with creative automation. Its ability to analyze brand assets and automatically generate platform-optimized ad variations while maintaining brand voice transforms the tedious process of ad creation into a streamlined, results-driven workflow that consistently delivers high-performing content. Key Features: Automated ad creation Multi-platform optimization Built-in A/B testing Performance analytics Template library Perfect For: Digital marketers and businesses looking to scale their ad production efficiently. What Makes It Special: CopyAI has established itself as a powerhouse in AI-powered copywriting by offering specialized content generation for various marketing formats. Its sophisticated understanding of marketing psychology and brand voice, combined with its ability to generate compelling copy across multiple formats and industries, makes it invaluable for marketers and content creators who need to produce engaging, conversion-focused content at scale. Key Features: Advanced marketing copy generation Multiple content type templates Brand voice customization Multilingual support A/B testing variations Pricing: Free tier available Pro: $49/month Advanced: $249/month Enterprise: Custom pricing Perfect For: Marketing teams, copywriters, and businesses needing high-converting marketing copy across multiple channels. Conclusion The AI tools listed here are revolutionizing the content creation landscape in 2025, making it easier than ever to produce high-quality, engaging, and impactful content. By integrating these tools into your workflow, you can save time, unleash your creativity, and achieve better results. AI doesn't replace creativity; it amplifies it. As a content creator, your unique voice and vision are irreplaceable. These tools serve as enablers, helping you focus on what you do best—creating. Explore, experiment, and innovate. The future of content creation is here, and it's brimming with possibilities. Embrace these technologies, stay ahead of the curve, and watch your creative potential soar. The only limit is your imagination! Note: All features and pricing information are subject to change. Please verify current details with the respective platforms, Also this article contain affiliate links which means we make a small comission if yo buy any premium plan from our links Pricing updated on 01/02/ 2025",
         "en",
         "{'MISC': ['A', 'AI Avatar', 'AI Video Generator What Makes It Special: RunwayML stands out as the ultimate video', 'All features and pricing information are subject to change', 'Also this article', 'Automated Ad', 'Brand', 'Brand kit integration', 'Brand voice maintenance', 'By integrating these tools into your workflow', 'Canva Magic Studio', 'ChatGPT', 'ChatGPT has evolved into', 'Conclusion', 'Content Ideation and Scriptwriting What Makes It Special:', 'Creator', 'Custom Price Perfect For: Video creators', 'Custom pricing Perfect', 'Custom pricing Perfect For:', 'Descript', 'ElevenLabs', 'Embrace these technologies', 'Enterprise', 'Filler word removal Screen recording Collaborative editing Pricing: Hobbyist', 'Green screen', \"I'll show you the top 10 AI tools that are revolutionizing content creation and making creators' lives easier\", \"Let's Dive Into the Top 10 AI Tools for\", 'Marketing teams', 'Mega', 'Midjourney V6 has redefined AI', 'Multi-language', 'Multi-platform', 'Multi-platform scheduling Pricing', 'Multilingual', 'Multiple', 'Perfect For: Content creators and social media managers focused', 'Perfect For: Content writers', 'Perfect For: Digital marketers and businesses looking to scale their ad', 'Perfect For: Social media managers', 'Please verify', 'Podcast and Video Editing with', 'Podcasters', 'Pricing', 'Pricing updated on', 'Pricing:', 'Pricing: Basic', 'Pro', 'Professional', 'Quick generation time Commercial', 'Scale', 'Script to video', 'Smart', 'Standard', 'Starter', 'Synthesia', 'Teams', \"That's where AI tools come in – they're not just fancy tech\", 'The', 'The only limit is your imagination!', \"The platform's ability to understand design principles\", 'These tools', 'Top 10 AI Tools That Will Transform Your Content Creation in 2025 Looking to level up your content', 'Trend analysis', 'Ultra-realistic', 'Unlimited', 'Video', 'Viral Content and Headline Optimization What Makes It Special: Tribescaler brings', 'Visual Design and Social Media Content Creation What Makes', 'Voice cloning capability', 'What Makes', 'What Makes It Special: CopyAI has established itself as', 'What Makes It Special: ElevenLabs has revolutionized voice synthesis by achieving', 'Why You Need These', 'and AI tools have become essential for creators who want to stay ahead of the curve', 'and achieve better results', 'and content creators needing professional voiceovers in multiple languages', 'and impactful', 'and multilingual content', 'and teams needing', 'and watch your creative potential', 'by combining advanced language understanding with specialized content optimization features', 'creativity', 'details with the respective platforms', 'edit', 'game-changing ability to manipulate', 'high-quality written content', 'keeping up with the constant need for fresh', 'makes it indispensable for creators who want to produce high-quality video content without getting bogged down by technical complexities', 'makes it invaluable for marketers and content creators who need', 'makes professional', 'perfectly with their brand identity', 'powerful AI', 'stay ahead of the curve', \"they're your secret weapon for creating better content faster\", 'unleash your creativity', 'voiceovers without the traditional', 'while maintaining', 'while maintaining authenticity and audience engagement', 'with powerful AI features like automatic transcription and filler word removal', 'you can save time'], 'ORG': ['Advanced', 'Advanced video generation & editing Real', 'Business', 'Businesses and educators creating training videos', 'Custom', 'Key Features', 'Key Features: Text', 'Performance', 'Photorealistic', 'YouTubers', 'and anyone needing quick'], 'LOC': ['B', 'MidJourney', 'with'], 'PER': ['Synthesia', 'Tribescaler', 'Viral', 'helping you focus on what you do best—creating', 'with']}",
         "[-0.08463621884584427, -0.11200868338346481, 0.060577813535928726, 0.013500114902853966, 0.05140026658773422, 0.003949744161218405, -0.033138543367385864, 0.029526079073548317, -0.005645273718982935, 0.033261701464653015, -0.090791255235672, 0.022662492468953133, -0.002592761069536209, 0.04866679385304451, 0.001667219796217978, 0.044427044689655304, 0.03989202156662941, -0.07949982583522797, -0.04083532467484474, -0.1485244482755661, 0.015262997709214687, 0.06705326586961746, 0.06325109302997589, -0.05758168548345566, 0.024832546710968018, 0.047228068113327026, -0.02241041511297226, -0.09640704095363617, 0.03728586807847023, -0.009702708572149277, 0.04803316295146942, 0.019940124824643135, 0.01868215948343277, -0.001054255524650216, -0.09869701415300369, 0.06494282186031342, 0.022026196122169495, -0.0355779193341732, 0.07751969993114471, -0.0480460599064827, -0.037583112716674805, -0.09466182440519333, -0.02824217826128006, -0.048230692744255066, 0.12816838920116425, 0.011338887736201286, -0.0412602461874485, -0.023670798167586327, -0.020940007641911507, 0.08490288257598877, -0.11475754529237747, -0.03234079107642174, 0.006610207259654999, -0.0030836642254143953, -0.04929616302251816, 0.016203368082642555, 0.018796823918819427, 0.03183208778500557, 0.030543265864253044, -0.0501818023622036, 0.024011312052607536, -0.06874502450227737, 0.043519578874111176, -0.018387142568826675, 0.006340287625789642, -0.01538819819688797, 0.015163240022957325, 0.027161406353116035, -0.009071744047105312, -0.004995816852897406, -0.004355745390057564, 0.03921934589743614, -0.01596972718834877, 0.05326047167181969, 0.02432389371097088, -0.0010613526683300734, 0.035743843764066696, -0.06314459443092346, 0.0029993513599038124, -0.066963329911232, 0.036561205983161926, 0.00798578280955553, 0.022032445296645164, 0.021906934678554535, -0.1195250153541565, -0.021106494590640068, 0.019470173865556717, 0.032263658940792084, -0.007529963739216328, 0.06442153453826904, -0.009099097922444344, 0.01774667762219906, 0.08910656720399857, -0.004704535007476807, 0.027022462338209152, 0.03459352254867554, -0.06785687059164047, -0.11418246477842331, -0.05180448293685913, -0.011948812752962112, -0.050737135112285614, 0.026276780292391777, 0.0006353958742693067, -0.09100991487503052, -0.018021710216999054, -0.011540758423507214, 0.08979667723178864, -0.03226189687848091, -0.010561997070908546, 0.0015780183020979166, -0.02045900747179985, 0.021911120042204857, -0.021036479622125626, -0.0817619264125824, 0.11494772881269455, -0.0005812665913254023, 0.02620011195540428, 0.05469505488872528, 0.09232161194086075, 0.057935625314712524, 0.022238552570343018, 0.04637303575873375, -0.043956492096185684, 0.06489142030477524, 0.04050317406654358, 0.055237919092178345, -0.045357294380664825, 5.158912261262928e-33, 0.05823128670454025, 0.04868846386671066, 0.04681279510259628, 0.12516669929027557, 0.015192428603768349, 0.010551410727202892, 0.040246669203042984, 0.03715522959828377, -0.07297024130821228, -0.027524231001734734, -0.04002749174833298, 0.05829766020178795, -0.09945973008871078, 0.06183195114135742, 0.0866275355219841, -0.12509888410568237, -0.023979000747203827, 0.015304562635719776, 0.028521403670310974, -0.028085757046937943, -0.01622799225151539, -0.055543627589941025, 0.04437096416950226, 0.05698249489068985, 0.04537399858236313, 0.048398617655038834, 0.07311321794986725, -0.09559368342161179, -0.011012701317667961, -0.02792116068303585, -0.11377137154340744, -0.002978601260110736, -0.007786538917571306, -0.0026164224836975336, -0.013190300203859806, -0.008859251625835896, -0.09428486227989197, -0.04131084308028221, -0.0018843442667275667, 0.09033216536045074, -0.022801650688052177, 0.013651146553456783, -0.013934951275587082, -0.05174938961863518, 0.0024753219913691282, 0.0059755658730864525, 0.0057673584669828415, 0.0007612326880916953, 0.015629688277840614, 0.016303304582834244, -0.03187476843595505, 0.053611382842063904, 0.04900037497282028, -0.008413653820753098, 0.02383558824658394, -0.07214359939098358, -0.009320812299847603, -0.05114595219492912, 0.07277587056159973, -0.005095457658171654, 0.057520948350429535, 0.0004973431350663304, -0.06586474180221558, 0.05057878792285919, 0.06359672546386719, 0.05092670023441315, 0.11811655014753342, 0.050075363367795944, 0.025252623483538628, 0.003099106252193451, 0.004154282156378031, 0.011655803769826889, -0.01728931814432144, -0.02690301649272442, -0.022368310019373894, 0.037334099411964417, -0.010082622058689594, -0.12751290202140808, 0.061368659138679504, -0.002900755498558283, -0.04006817564368248, 0.035144735127687454, 0.004074217285960913, -0.06454595178365707, 0.07327818125486374, -0.06494882702827454, 0.0016703841974958777, -0.03007516637444496, 0.0379638597369194, 0.013224582187831402, -0.0283643938601017, -0.014472252689301968, 0.03257034346461296, 0.09594275802373886, -0.031924013048410416, -3.375685861697579e-33, -0.01820768229663372, -0.05052202567458153, -0.1078503355383873, 0.08798401802778244, -0.010328126139938831, -0.028502779081463814, -0.0252518430352211, -0.011353973299264908, 0.057298120111227036, -0.055708594620227814, 0.0024987736251205206, -0.0457664355635643, 0.02591649442911148, -0.017376739531755447, 0.018401967361569405, -0.058637771755456924, -0.01438648346811533, -0.10107676684856415, -0.025339147076010704, 0.003240256104618311, 0.08055233955383301, 0.05662144348025322, -0.08465882390737534, -0.005991068668663502, 0.05357414111495018, -0.005602925084531307, -0.023190530017018318, 0.04591023921966553, 0.018061580136418343, 0.00984017364680767, -0.02435622364282608, 0.0014526295708492398, 0.020001791417598724, 0.032973818480968475, 0.022241005674004555, 0.004985807463526726, 0.09228315949440002, -0.042545292526483536, -0.04346323013305664, 0.05613446235656738, 0.07841449975967407, 0.010441924445331097, -0.07150714844465256, -0.010149223729968071, -0.07558153569698334, 0.07516226917505264, -0.09475960582494736, 0.06869757920503616, -0.035778604447841644, 0.016272740438580513, 0.024226922541856766, -0.022151276469230652, -0.03734162449836731, -0.10028267651796341, -0.00711440434679389, -0.042728815227746964, -0.01054321974515915, 0.01956593245267868, -0.01488118339329958, 0.022253239527344704, -0.05161559581756592, 0.0628572478890419, 0.0494471900165081, 0.01259660441428423, -0.003928705118596554, -0.043099142611026764, 0.05125453695654869, 0.09620723128318787, -0.08918845653533936, -0.05502939969301224, 0.040476180613040924, -0.07159379869699478, 0.01607263833284378, -0.033541060984134674, -0.05020585283637047, 0.0238258708268404, 0.0574805811047554, -0.010290829464793205, 0.04060882702469826, -0.050041791051626205, 0.026445986703038216, 0.04772840067744255, -0.011229101568460464, 0.005584956146776676, 0.056874487549066544, 0.10632597655057907, -0.02936221845448017, 0.04610104113817215, 0.015761148184537888, 0.08102148771286011, -0.05604800581932068, 0.01696815900504589, -0.057448334991931915, 0.10686149448156357, -0.06390762329101562, -4.906774719870555e-08, -0.022437475621700287, -0.04599849134683609, -0.03274354711174965, 0.044419821351766586, 0.034606028348207474, 0.030823949724435806, -0.031791578978300095, 0.07171238213777542, 0.02274073287844658, -0.003079432062804699, 0.06851793825626373, -0.06032005324959755, 0.02596266008913517, 0.02654113806784153, 0.07563545554876328, 0.0005875273491255939, -0.05653174966573715, -0.0426618866622448, 0.027679946273565292, -0.06831701844930649, 0.06456702947616577, 0.0033810569439083338, 0.0036707764957100153, -0.06633828580379486, -0.01732165738940239, -0.09296014904975891, -0.030002431944012642, -0.00685462960973382, -0.02535952627658844, 0.04544997960329056, 0.01163190696388483, -0.022478414699435234, -0.010142544284462929, -0.0021059890277683735, 0.10523562133312225, 0.0045519545674324036, -0.009440647438168526, -0.017611173912882805, -0.05401366204023361, 0.02532186172902584, 0.07232500612735748, 0.09542687237262726, -0.010061867535114288, -0.04974357783794403, -0.017179779708385468, -0.09885260462760925, -0.05175591632723808, -0.09318459033966064, 0.05023821070790291, -0.06578109413385391, -0.08727884292602539, 3.7382615118985996e-05, 0.007068839855492115, 0.04932721331715584, 0.11617951840162277, 0.062434133142232895, 0.0031565427780151367, 0.02840697206556797, 0.022416800260543823, 0.10449661314487457, 0.0010527786798775196, 0.035340484231710434, 0.019085882231593132, -0.01481475867331028]",
         "0.193"
        ],
        [
         "17",
         "27",
         "Beginner Guide to CJ Affiliate (Commission Junction) in 2022",
         "Image by vectorjuice on Freepik In this CJ Affiliate guide, I will share with you everything you need to get started on the platform, I will give you an in-depth look at the network and how it works. You will learn how to earn money with the platform. If you're not interested, I'll share some of the best CJ affiliate programs and alternatives. By the end of this post, I will also answer some of the FAQs on the platform and give my quick CJ review. Sounds Good So let’s start What is CJ Affiliate? Commission Junction is an online advertising company that offers affiliate programs for various retailers. Since 1998, it has been known as one of the oldest and most popular affiliate networks. Commission Junction has consistently ranked among the top 10 affiliate networks With in-depth data analysis and an unmatched understanding of clients needs, CJ has established itself as a leader in performance marketing. For Advertiser: CJ provides advertisers with a variety of tracking, management, and payment options. As an affiliate network, CJ can help you launch multiple affiliate programs from a centralized network. CJ's experienced team of account managers is available to help at every step—from program set-up to optimization. For Publishers: CJ offers a variety of well-paying affiliate programs. You can find affiliate programs in almost every niche at CJ. With CJ, you can also find promotional tools such as banners and product feeds, which help you promote your website. The reporting tools are unparalleled and provide granular data that can assist you in fine-tuning your campaigns for maximum results. Requirements First things first, CJ is free to join! If you are new to the world of affiliate marketing, don't worry—you'll be able to join right away. The requirements for joining CJ are almost similar to other networks. For example, you must have a blog or social media follower. Isn't it obvious? Let's explore the details. High-quality, unique content. Non-gated content, of course. Site privacy policy. No software, coupon/deal, or incentive models Your traffic must be from US and Canada. The main traffic source must not be paid 10K+ monthly trafic on your website. How Does CJ Affiliate Work? Between advertisers and publishers, CJ Affiliate acts as a middleman.. Advertisers sign up on CJ to promote their products or services, while publishers sign up on CJ to find and join affiliate programs to make money. CJ then tracks the sales or leads generated by the publisher and pays them a commission according to the terms of the affiliate program. CJ provides a win-win situation for both sides: advertisers get more sales and publishers make money. In order to free up both parties to concentrate on their job, CJ also handles payments and other technical issues. Now that you know how CJ works, let's learn more about how to sign up and start making money with it. How to Start Making Money Online Using CJ Affiliate To get started using CJ's affiliate network, you'll need to register for an account. To do this, you must have a website or social media profile with relevant content and an audience from the US or Canada. Create a CJ account, complete the application process, and then wait for approval. You shouldn't worry CJ is not strict as other network in approving applications. Here's how you can signup for Cj Visit cj.com to register as a publisher. Fill in information such as your nationality, email, password, and more. Verify your email address now. You will be transferred right away to your CJ Account Manager, which contains crucial data including network statistics and performance summaries. Now from the Account menu, head to Network Profile. And to sign up for any affiliate programme offered on CJ, complete this profile separately. When applying for CJ, you need to share these two pieces of information Description of the website (include statistics for your site and more) Promotion methods (Traffic sources) The process of setting up a CJ Affiliate account is a way for you to prove to CJ and the merchants that you're a serious affiliate marketer. Your CJ account is complete once you've added or edited your payment information; now you need to add or edit your tax certificates if required. You are now prepared to start making money on CJ Affiliate program apply for product when approved start promting and earn commissions on every sale. Click on \"Advertisers\" and then select a category to go to your niche advertiser area. You can apply for it by clicking the 'Join the Program' button and analysing three months' earnings per click and overall earnings! After you're approved, you'll get links from all over the Internet. After you've completed the steps above, you can share your affiliate links in your blog post. You can view performance reports for your affiliate links by visiting the CJ account dashboard. Click \"Clients\" to see details about clicks, sales, and commissions earned by each client. With CJ, you can make money promoting great products and services in any niche imaginable! So start joining CJ programs now and watch your business grow. Best CJ Affiliate Programs in 2022 On CJ, you can find thousands of affiliate programs in almost any niche. Some of the top affiliate programs enlisted on CJ include: Contabo VPS Fiverr Hostinger Godaddy Namecheap You'll find a lot of programs to join at CJ, depending on your niche. Just enter your keywords in the search bar, and CJ will show you all the relevant programs that match your criteria. You can further filter the results by commission type, category, or country. A Quick CJ Affiliate Review: Is It Good Enough? CJ Affiliate is one of the oldest and most well-known affiliate networks. The platform has been around for over 20 years and has a massive network of advertisers and publishers. The features on CJ Affiliate are easy to use, and it offers advertisers a wide range of tracking, management, and payment options. CJ offers some great features for publishers too—promotional tools like banners, links, and social media are available to help boost your site's visibility. The only downside is that CJ has a bit of a learning curve, and the approval process can be strict. But overall, CJ Affiliate is an excellent platform for advertisers and publishers. Top Alternatives and Competitors CJ Affiliate is a great place to earn an income from affiliate marketing. It offers a wide range of features and options for advertisers and publishers. But if CJ doesn't work for you, plenty of other options are available. Here are some of the top competitors and alternatives in the market today: ShareASale AWIN Impact Rakuten Marketing PartnerStack Partnerize ClickBank Here are some of the best CJ Affiliate alternatives that you can try. Each platform has its own set of features, so make sure to choose one that best suits your needs. Regardless of which CJ alternative you choose, remember that quality content is key to success as a publisher, so ensure to focus on providing high-value, engaging content to your readers. Frequently Asked Questions About Cj Affiliate Marketplace Is the Cj AffilIs late Network legit? CJ Affiliate is a legitimate affiliate platform that has earned the trust of many marketers because of its vast network of advertisers and publishers. How much do CJ affiliates make? It's not just about CJ; it's about how much effort you put into making money. It is possible to earn a few dollars to a few thousand dollars How much does it cost to join Cj? Joining CJ is free of charge. There are no monthly or annual fees. You only pay when you make a sale, and CJ takes a commission of 5-10%. What are the payment methods accepted by Cj? You can receive payment via direct deposit or check, as well as through Payoneer. CJ pays out within 20 days of the end of the month if your account has at least $50 worth of deposits ($100 for those outside America). How to get approved for CJ affiliate? CJ is friendly to both beginners and advanced affiliates. You need a website or social media profile with a solid organic traffic source and make yourself known using your profile description. Be honest, and you'll get approved for CJ's affiliate network. How to find programs on CJ affiliates? CJ affiliate offers a straightforward and user-friendly interface. All you need is to log in to your CJ account and click on ‘Advertisers' from the menu. Depending on your niche, you can then search for any affiliate program on CJ What are the Pros of CJ Affiliate for advertisers? CJ Affiliate is one of the most advanced affiliate programs available, providing advertisers with a range of features and options including advanced tracking, management, and payment options. The platform is also easy to use and provides promotional tools like coupons, banners, and widgets that can help increase our sales. Final Saying Choosing Commission Junction as your affiliate program isn't easy. CJ is a big company and they have a wide range of affiliates, big and small. They offer everything from banner ads to text links and so much more. The sheer amount of choices can seem intimidating at first, especially to new Affiliates, which is why we've put together this simple guide for people looking for a successful CJ affiliate program to join. If you have any questions feel free to ask in the comments.",
         "In this CJ Affiliate guide, I will share with you everything you need to get started on the platform, I will give you an in-depth look at the network and how it works.\n\n\n\n\n\nYou will learn how to earn money with the platform. If you're not interested, I'll share some of the best CJ affiliate programs and alternatives. By the end of this post, I will also answer some of the FAQs on the platform and give my quick CJ review.\n\n\n\n\n\nSounds Good So let’s start\n\nWhat is CJ Affiliate?\n\nCommission Junction is an online advertising company that offers affiliate programs for various retailers. Since 1998, it has been known as one of the oldest and most popular affiliate networks.\n\n\n\n\n\nCommission Junction has consistently ranked among the top 10 affiliate networks\n\n\n\n\n\nWith in-depth data analysis and an unmatched understanding of clients needs, CJ has established itself as a leader in performance marketing.\n\n\n\n\n\nFor Advertiser:\n\nCJ provides advertisers with a variety of tracking, management, and payment options. As an affiliate network, CJ can help you launch multiple affiliate programs from a centralized network.\n\nCJ's experienced team of account managers is available to help at every step—from program set-up to optimization.\n\n\n\n\n\nFor Publishers:\n\nCJ offers a variety of well-paying affiliate programs. You can find affiliate programs in almost every niche at CJ. With CJ, you can also find promotional tools such as banners and product feeds, which help you promote your website.\n\n\n\n\n\nThe reporting tools are unparalleled and provide granular data that can assist you in fine-tuning your campaigns for maximum results.\n\n\n\n\n\nRequirements\n\n\n\n\n\nFirst things first, CJ is free to join! If you are new to the world of affiliate marketing, don't worry—you'll be able to join right away.\n\n\n\n\n\nThe requirements for joining CJ are almost similar to other networks. For example, you must have a blog or social media follower.\n\n\n\n\n\nIsn't it obvious? Let's explore the details.\n\n\n\n\n\nHigh-quality, unique content.\n\nNon-gated content, of course.\n\nSite privacy policy.\n\nNo software, coupon/deal, or incentive models\n\nYour traffic must be from US and Canada.\n\nThe main traffic source must not be paid\n\n10K+ monthly trafic on your website.\n\n\n\n\n\nHow Does CJ Affiliate Work?\n\n\n\n\n\nBetween advertisers and publishers, CJ Affiliate acts as a middleman.. Advertisers sign up on CJ to promote their products or services, while publishers sign up on CJ to find and join affiliate programs to make money. CJ then tracks the sales or leads generated by the publisher and pays them a commission according to the terms of the affiliate program.\n\n\n\n\n\nCJ provides a win-win situation for both sides: advertisers get more sales and publishers make money.\n\n\n\n\n\nIn order to free up both parties to concentrate on their job, CJ also handles payments and other technical issues. Now that you know how CJ works, let's learn more about how to sign up and start making money with it.\n\n\n\n\n\nHow to Start Making Money Online Using CJ Affiliate\n\n\n\n\n\nTo get started using CJ's affiliate network, you'll need to register for an account. To do this, you must have a website or social media profile with relevant content and an audience from the US or Canada.\n\n\n\n\n\nCreate a CJ account, complete the application process, and then wait for approval. You shouldn't worry CJ is not strict as other network in approving applications.\n\n\n\n\n\nHere's how you can signup for Cj\n\n\n\n\n\nVisit cj.com to register as a publisher. Fill in information such as your nationality, email, password, and more. Verify your email address now. You will be transferred right away to your CJ Account Manager, which contains crucial data including network statistics and performance summaries. Now from the Account menu, head to Network Profile. And to sign up for any affiliate programme offered on CJ, complete this profile separately.\n\n\n\n\n\nWhen applying for CJ, you need to share these two pieces of information\n\nDescription of the website (include statistics for your site and more) Promotion methods (Traffic sources)\n\n\n\n\n\nThe process of setting up a CJ Affiliate account is a way for you to prove to CJ and the merchants that you're a serious affiliate marketer. Your CJ account is complete once you've added or edited your payment information; now you need to add or edit your tax certificates if required. You are now prepared to start making money on CJ Affiliate program apply for product when approved start promting and earn commissions on every sale.\n\n\n\n\n\nClick on \"Advertisers\" and then select a category to go to your niche advertiser area. You can apply for it by clicking the 'Join the Program' button and analysing three months' earnings per click and overall earnings! After you're approved, you'll get links from all over the Internet.\n\n\n\n\n\nAfter you've completed the steps above, you can share your affiliate links in your blog post. You can view performance reports for your affiliate links by visiting the CJ account dashboard. Click \"Clients\" to see details about clicks, sales, and commissions earned by each client.\n\n\n\n\n\nWith CJ, you can make money promoting great products and services in any niche imaginable! So start joining CJ programs now and watch your business grow.\n\n\n\n\n\nBest CJ Affiliate Programs in 2022\n\n\n\n\n\nOn CJ, you can find thousands of affiliate programs in almost any niche. Some of the top affiliate programs enlisted on CJ include:\n\n\n\n\n\nContabo VPS\n\nFiverr\n\nHostinger\n\nGodaddy\n\nNamecheap\n\n\n\n\n\nYou'll find a lot of programs to join at CJ, depending on your niche. Just enter your keywords in the search bar, and CJ will show you all the relevant programs that match your criteria. You can further filter the results by commission type, category, or country.\n\n\n\n\n\nA Quick CJ Affiliate Review: Is It Good Enough?\n\n\n\n\n\nCJ Affiliate is one of the oldest and most well-known affiliate networks. The platform has been around for over 20 years and has a massive network of advertisers and publishers. The features on CJ Affiliate are easy to use, and it offers advertisers a wide range of tracking, management, and payment options.\n\n\n\n\n\nCJ offers some great features for publishers too—promotional tools like banners, links, and social media are available to help boost your site's visibility. The only downside is that CJ has a bit of a learning curve, and the approval process can be strict. But overall, CJ Affiliate is an excellent platform for advertisers and publishers.\n\n\n\n\n\n\n\n\n\nTop Alternatives and Competitors\n\n\n\n\n\nCJ Affiliate is a great place to earn an income from affiliate marketing. It offers a wide range of features and options for advertisers and publishers. But if CJ doesn't work for you, plenty of other options are available. Here are some of the top competitors and alternatives in the market today:\n\n\n\n\n\nShareASale\n\nAWIN\n\nImpact\n\nRakuten Marketing\n\nPartnerStack\n\nPartnerize\n\nClickBank\n\n\n\n\n\nHere are some of the best CJ Affiliate alternatives that you can try. Each platform has its own set of features, so make sure to choose one that best suits your needs. Regardless of which CJ alternative you choose, remember that quality content is key to success as a publisher, so ensure to focus on providing high-value, engaging content to your readers.\n\n\n\n\n\nFrequently Asked Questions About Cj Affiliate Marketplace\n\n\n\n\n\nIs the Cj AffilIs late Network legit?\n\n\n\n\n\nCJ Affiliate is a legitimate affiliate platform that has earned the trust of many marketers because of its vast network of advertisers and publishers.\n\n\n\n\n\nHow much do CJ affiliates make?\n\n\n\n\n\nIt's not just about CJ; it's about how much effort you put into making money. It is possible to earn a few dollars to a few thousand dollars\n\n\n\n\n\nHow much does it cost to join Cj?\n\n\n\n\n\nJoining CJ is free of charge. There are no monthly or annual fees. You only pay when you make a sale, and CJ takes a commission of 5-10%.\n\n\n\n\n\nWhat are the payment methods accepted by Cj?\n\n\n\n\n\nYou can receive payment via direct deposit or check, as well as through Payoneer. CJ pays out within 20 days of the end of the month if your account has at least $50 worth of deposits ($100 for those outside America).\n\n\n\n\n\nHow to get approved for CJ affiliate?\n\n\n\n\n\nCJ is friendly to both beginners and advanced affiliates. You need a website or social media profile with a solid organic traffic source and make yourself known using your profile description. Be honest, and you'll get approved for CJ's affiliate network.\n\n\n\n\n\nHow to find programs on CJ affiliates?\n\n\n\n\n\nCJ affiliate offers a straightforward and user-friendly interface. All you need is to log in to your CJ account and click on ‘Advertisers' from the menu. Depending on your niche, you can then search for any affiliate program on CJ\n\n\n\n\n\nWhat are the Pros of CJ Affiliate for advertisers?\n\n\n\n\n\nCJ Affiliate is one of the most advanced affiliate programs available, providing advertisers with a range of features and options including advanced tracking, management, and payment options.\n\n\n\n\n\nThe platform is also easy to use and provides promotional tools like coupons, banners, and widgets that can help increase our sales.\n\n\n\n\n\nFinal Saying\n\n\n\n\n\nChoosing Commission Junction as your affiliate program isn't easy. CJ is a big company and they have a wide range of affiliates, big and small. They offer everything from banner ads to text links and so much more. The sheer amount of choices can seem intimidating at first, especially to new Affiliates, which is why we've put together this simple guide for people looking for a successful CJ affiliate program to join. If you have any questions feel free to ask in the comments.",
         "2022-09-10T08:57:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/09/cj-affiliate-ultimate-guide-to.html",
         "2025-07-26T05:41:35.799545",
         "In this CJ Affiliate guide, I will share with you everything you need to get started on the platform, I will give you an in-depth look at the network and how it works. You will learn how to earn money with the platform. If you're not interested, I'll share some of the best CJ affiliate programs and alternatives. By the end of this post, I will also answer some of the FAQs on the platform and give my quick CJ review. Sounds Good So let’s start What is CJ Affiliate? Commission Junction is an online advertising company that offers affiliate programs for various retailers. Since 1998, it has been known as one of the oldest and most popular affiliate networks. Commission Junction has consistently ranked among the top 10 affiliate networks With in-depth data analysis and an unmatched understanding of clients needs, CJ has established itself as a leader in performance marketing. For Advertiser: CJ provides advertisers with a variety of tracking, management, and payment options. As an affiliate network, CJ can help you launch multiple affiliate programs from a centralized network. CJ's experienced team of account managers is available to help at every step—from program set-up to optimization. For Publishers: CJ offers a variety of well-paying affiliate programs. You can find affiliate programs in almost every niche at CJ. With CJ, you can also find promotional tools such as banners and product feeds, which help you promote your website. The reporting tools are unparalleled and provide granular data that can assist you in fine-tuning your campaigns for maximum results. Requirements First things first, CJ is free to join! If you are new to the world of affiliate marketing, don't worry—you'll be able to join right away. The requirements for joining CJ are almost similar to other networks. For example, you must have a blog or social media follower. Isn't it obvious? Let's explore the details. High-quality, unique content. Non-gated content, of course. Site privacy policy. No software, coupon/deal, or incentive models Your traffic must be from US and Canada. The main traffic source must not be paid 10K+ monthly trafic on your website. How Does CJ Affiliate Work? Between advertisers and publishers, CJ Affiliate acts as a middleman.. Advertisers sign up on CJ to promote their products or services, while publishers sign up on CJ to find and join affiliate programs to make money. CJ then tracks the sales or leads generated by the publisher and pays them a commission according to the terms of the affiliate program. CJ provides a win-win situation for both sides: advertisers get more sales and publishers make money. In order to free up both parties to concentrate on their job, CJ also handles payments and other technical issues. Now that you know how CJ works, let's learn more about how to sign up and start making money with it. How to Start Making Money Online Using CJ Affiliate To get started using CJ's affiliate network, you'll need to register for an account. To do this, you must have a website or social media profile with relevant content and an audience from the US or Canada. Create a CJ account, complete the application process, and then wait for approval. You shouldn't worry CJ is not strict as other network in approving applications. Here's how you can signup for Cj Visit cj.com to register as a publisher. Fill in information such as your nationality, email, password, and more. Verify your email address now. You will be transferred right away to your CJ Account Manager, which contains crucial data including network statistics and performance summaries. Now from the Account menu, head to Network Profile. And to sign up for any affiliate programme offered on CJ, complete this profile separately. When applying for CJ, you need to share these two pieces of information Description of the website (include statistics for your site and more) Promotion methods (Traffic sources) The process of setting up a CJ Affiliate account is a way for you to prove to CJ and the merchants that you're a serious affiliate marketer. Your CJ account is complete once you've added or edited your payment information; now you need to add or edit your tax certificates if required. You are now prepared to start making money on CJ Affiliate program apply for product when approved start promting and earn commissions on every sale. Click on \"Advertisers\" and then select a category to go to your niche advertiser area. You can apply for it by clicking the 'Join the Program' button and analysing three months' earnings per click and overall earnings! After you're approved, you'll get links from all over the Internet. After you've completed the steps above, you can share your affiliate links in your blog post. You can view performance reports for your affiliate links by visiting the CJ account dashboard. Click \"Clients\" to see details about clicks, sales, and commissions earned by each client. With CJ, you can make money promoting great products and services in any niche imaginable! So start joining CJ programs now and watch your business grow. Best CJ Affiliate Programs in 2022 On CJ, you can find thousands of affiliate programs in almost any niche. Some of the top affiliate programs enlisted on CJ include: Contabo VPS Fiverr Hostinger Godaddy Namecheap You'll find a lot of programs to join at CJ, depending on your niche. Just enter your keywords in the search bar, and CJ will show you all the relevant programs that match your criteria. You can further filter the results by commission type, category, or country. A Quick CJ Affiliate Review: Is It Good Enough? CJ Affiliate is one of the oldest and most well-known affiliate networks. The platform has been around for over 20 years and has a massive network of advertisers and publishers. The features on CJ Affiliate are easy to use, and it offers advertisers a wide range of tracking, management, and payment options. CJ offers some great features for publishers too—promotional tools like banners, links, and social media are available to help boost your site's visibility. The only downside is that CJ has a bit of a learning curve, and the approval process can be strict. But overall, CJ Affiliate is an excellent platform for advertisers and publishers. Top Alternatives and Competitors CJ Affiliate is a great place to earn an income from affiliate marketing. It offers a wide range of features and options for advertisers and publishers. But if CJ doesn't work for you, plenty of other options are available. Here are some of the top competitors and alternatives in the market today: ShareASale AWIN Impact Rakuten Marketing PartnerStack Partnerize ClickBank Here are some of the best CJ Affiliate alternatives that you can try. Each platform has its own set of features, so make sure to choose one that best suits your needs. Regardless of which CJ alternative you choose, remember that quality content is key to success as a publisher, so ensure to focus on providing high-value, engaging content to your readers. Frequently Asked Questions About Cj Affiliate Marketplace Is the Cj AffilIs late Network legit? CJ Affiliate is a legitimate affiliate platform that has earned the trust of many marketers because of its vast network of advertisers and publishers. How much do CJ affiliates make? It's not just about CJ; it's about how much effort you put into making money. It is possible to earn a few dollars to a few thousand dollars How much does it cost to join Cj? Joining CJ is free of charge. There are no monthly or annual fees. You only pay when you make a sale, and CJ takes a commission of 5-10%. What are the payment methods accepted by Cj? You can receive payment via direct deposit or check, as well as through Payoneer. CJ pays out within 20 days of the end of the month if your account has at least $50 worth of deposits ($100 for those outside America). How to get approved for CJ affiliate? CJ is friendly to both beginners and advanced affiliates. You need a website or social media profile with a solid organic traffic source and make yourself known using your profile description. Be honest, and you'll get approved for CJ's affiliate network. How to find programs on CJ affiliates? CJ affiliate offers a straightforward and user-friendly interface. All you need is to log in to your CJ account and click on ‘Advertisers' from the menu. Depending on your niche, you can then search for any affiliate program on CJ What are the Pros of CJ Affiliate for advertisers? CJ Affiliate is one of the most advanced affiliate programs available, providing advertisers with a range of features and options including advanced tracking, management, and payment options. The platform is also easy to use and provides promotional tools like coupons, banners, and widgets that can help increase our sales. Final Saying Choosing Commission Junction as your affiliate program isn't easy. CJ is a big company and they have a wide range of affiliates, big and small. They offer everything from banner ads to text links and so much more. The sheer amount of choices can seem intimidating at first, especially to new Affiliates, which is why we've put together this simple guide for people looking for a successful CJ affiliate program to join. If you have any questions feel free to ask in the comments.",
         "en",
         "{'MISC': [\"Advertisers' from the menu\", \"After you're approved\", \"After you've completed the steps above\", 'All you need is to log in to your CJ account and click', 'And to sign up for any affiliate programme', 'Be honest', 'Best CJ Affiliate', 'Between advertisers and publishers', 'But overall', 'By the end of this post', 'CJ What are the Pros of CJ Affiliate for advertisers', 'CJ is free to join!', 'CJ to find and join affiliate programs to make money', 'CJ to promote their products or services', 'Click', 'Contabo VPS Fiverr', 'Create', 'Description of the website', 'Fill in information such as your nationality', 'For Advertiser', 'For Publishers', 'Here are some of the top competitors and alternatives in the market today', \"Here's how you can signup for Cj Visit cj.com to register as\", 'How Does CJ Affiliate Work', 'How much do CJ', 'How much does it cost to join Cj?', \"How to Start Making Money Online Using CJ Affiliate To get started using CJ'\", 'How to find programs on CJ', 'How to get approved for CJ', 'I will also answer some of the FAQs on the platform and give my quick CJ review', 'I will give you an in-depth look at the network and how it works', 'I will share with you everything you need to get started on the platform', \"I'll share some of the best CJ affiliate programs and alternatives\", 'If you are new to the world of affiliate marketing', 'If you have any questions feel free to ask in the comments', 'In this CJ Affiliate guide', \"Isn'\", 'It', 'It Good Enough', 'It is possible to earn', \"It's not just about CJ\", 'Joining CJ is free of', 'Non-gated content', 'Now from the Account menu', 'Now that you know how CJ works', 'Partnerize ClickBank', 'Rakuten Marketing', 'Regardless of which CJ alternative you choose', 'Saying Choosing Commission', 'ShareASale', 'Since 1998', 'So start joining CJ programs now and watch your business grow', 'Some of the top affiliate', 'Sounds Good So let’', 'The', 'The only downside is that CJ has', 'The platform has been around for over 20 years and has', 'The platform is also easy to use and provides', 'The process of setting up', 'The requirements for joining CJ are almost similar to other networks', 'To do this', 'Top Alternatives and Competitors', 'Traffic', 'Verify your', 'What are the payment methods', 'What is CJ Affiliate', 'When applying for CJ', 'With CJ', 'With in-depth data analysis and an unmatched understanding of clients needs', 'You are now prepared to start making money', 'You can', 'You can find affiliate programs in almost every niche at CJ', 'You can further filter the results by commission', 'You can receive payment', 'You can view performance reports for your affiliate links by visiting the CJ account dashboard', 'You need', 'You only pay when you make', \"You shouldn't worry CJ is not strict as other network in approving applications\", 'You will be transferred right away to your CJ Account Manager', 'You will learn how to earn money with the platform', \"Your CJ account is complete once you've added or edited your payment information\", 'Your traffic must be from US and Canada', 'and the approval process can be strict', 'as well as through Payoneer', 'big and small', \"don't worry—you'll be able to join right away\", 'especially to new Affiliates', 'head to Network Profile', 'it has been known as one of the oldest and most', \"it's about how much effort you put into making money\", 'now you need to add or', 'plenty of other options are available', 'statistics for your site and more', 'the application process', 'tools are unparalleled and provide granular data that can assist you in fine-tuning your campaigns for maximum results', 'tools like banners', 'tools like coupons', 'win-win situation for both sides', 'you can also find promotional', 'you can share your affiliate links in your blog post', 'you need to share these two pieces of information', \"you'll get links from all over the Internet\", \"you'll need to register for an account\"], 'PER': ['CJ Affiliate', 'CJ Affiliate is one of the oldest and most well-known affiliate networks', \"CJ doesn't work for you\", 'CJ has established itself as', 'CJ is friendly to both beginners and advanced', 'CJ offers some great features for publishers too—promotional', 'CJ provides', 'CJ then', 'They', 'middleman', 'providing advertisers with', 'you must have'], 'LOC': ['CJ', \"CJ'\", 'Canada', 'Depending', 'advertisers with', 'and CJ takes', 'and CJ will show you all the', 'and user-friendly interface', 'depending on your niche', 'wide range of tracking'], 'ORG': ['Advertisers', 'Advertisers\" and then select', \"CJ Affiliate account is a way for you to prove to CJ and the merchants that you're\", 'CJ Affiliate are easy to', 'CJ Affiliate program', 'CJ account', 'CJ also handles payments and other technical', 'CJ can help you launch multiple affiliate programs from a centralized network', 'For', 'No software', 'Promotion methods', 'Quick CJ Affiliate Review:', 'and it', \"and social media are available to help boost your site'\", 'with']}",
         "[-0.03824789822101593, -0.10725513100624084, -0.08788809925317764, 0.009985818527638912, -0.04541797935962677, 0.06486354768276215, 0.03738320991396904, 0.05122560262680054, -0.0619044192135334, -0.056090619415044785, -0.01798209547996521, 0.001039354014210403, 0.07463611662387848, 0.03086564503610134, 0.055928584188222885, 0.010700228624045849, 0.12337014824151993, 0.02468426153063774, -0.006596758030354977, -0.09898405522108078, -0.09148973226547241, -0.0661998763680458, -0.01430972758680582, -0.07113204896450043, -0.022618265822529793, -0.04434911906719208, 0.061025429517030716, -0.0048037366941571236, -0.1090577095746994, -0.043835338205099106, -0.016047628596425056, -0.008767182938754559, 0.039642542600631714, 0.025220029056072235, -0.0038516782224178314, -0.037210773676633835, -0.06550853699445724, -0.0039739483036100864, 0.0488453134894371, 0.031902674585580826, -0.020343614742159843, 0.015624974854290485, -0.056672029197216034, -0.012891632504761219, 0.015761401504278183, -0.07827962189912796, -0.04198451340198517, 0.09723646938800812, 0.0040868292562663555, 0.06540235877037048, 0.008973612450063229, -0.08126985281705856, 0.029305340722203255, -0.015673764050006866, -0.028666498139500618, 0.012086202390491962, -0.07527151703834534, 0.05769200995564461, -0.017104852944612503, -0.00792130921036005, 0.11109741032123566, -0.009755216538906097, -0.018699152395129204, 0.013965915888547897, -0.0323033407330513, -0.08983985334634781, 0.007698392029851675, 0.1361456960439682, -0.016563482582569122, -0.1482609510421753, -0.037700340151786804, -0.05083015188574791, -0.06444054841995239, 0.008906775154173374, 0.014317009598016739, 0.004337780177593231, 0.09383061528205872, 0.0069904751144349575, 0.04223361238837242, -0.058755215257406235, -0.0024110672529786825, 0.06695974618196487, -0.02963784523308277, 0.0240285936743021, -0.03544867783784866, -0.02693937160074711, 0.033694077283144, 0.0474378727376461, 0.0006304634152911603, 0.03614839166402817, 0.00529351644217968, 0.09163724631071091, -0.08043470233678818, -0.11334684491157532, 0.06414750963449478, 0.008112198673188686, -0.014306393451988697, -0.019451968371868134, 0.05213690921664238, 0.04489627107977867, 0.00706098135560751, 0.023417528718709946, 0.0318010151386261, -0.04272326081991196, -0.004249991849064827, -0.04122141748666763, 0.0030949392821639776, 0.11441595107316971, 0.12373953312635422, 0.04648364707827568, -0.08394872397184372, 0.05337827280163765, -0.10252644121646881, -0.08355394005775452, 0.015439910814166069, 0.06630221009254456, 0.0019018399761989713, 0.08508597314357758, 0.11775780469179153, 0.044281840324401855, -0.018572203814983368, 0.09046531468629837, 0.009996785782277584, 0.004718325100839138, 0.06809081882238388, 0.011095859110355377, -0.017071420326828957, 2.2515896340230116e-33, -0.10480077564716339, 0.07020595669746399, 0.03204863518476486, 0.005541965831071138, 0.019671158865094185, 0.027943696826696396, 0.014735881239175797, -0.0016980089712888002, -0.10426929593086243, -0.020488005131483078, -0.06322702765464783, 0.06121981516480446, 0.020458918064832687, 0.055644549429416656, 0.04131311923265457, -0.043507304042577744, -0.003335891989991069, -0.07022187113761902, 0.024245735257864, -0.057766884565353394, -0.0022109763231128454, -0.004825369454920292, -0.03892111778259277, 0.0771029070019722, 0.056928303092718124, -0.04216034710407257, -0.004000113811343908, 0.08738914132118225, 0.032521944493055344, 0.022291015833616257, 0.01866096258163452, 0.04109466075897217, -0.002364489482715726, 0.018856491893529892, -0.006302184425294399, 0.018462300300598145, -0.04297357797622681, -0.10681528598070145, -0.01133004855364561, -0.006053243763744831, -0.09807154536247253, -0.009295142255723476, 0.002821913454681635, -0.06983242928981781, -0.077061228454113, 0.0410085991024971, -0.046183113008737564, -0.000603561638854444, 0.06689432263374329, 0.03577831760048866, 0.020840229466557503, 0.0011982001597061753, 0.09731531143188477, -4.38594252045732e-05, 0.0007259005797095597, 0.026005445048213005, -0.008967898786067963, -0.04646426811814308, 0.0038583765272051096, -0.010668971575796604, 0.00390649912878871, -0.012582431547343731, -0.10555731505155563, 0.02423429675400257, -0.08657428622245789, 0.02143077366054058, -0.025638453662395477, -0.05510297045111656, 0.08749846369028091, 0.006487768609076738, -0.041961681097745895, 0.0629785805940628, 0.07137471437454224, -0.04092201218008995, -0.037961676716804504, 0.038161903619766235, -0.11765424907207489, 0.03944677487015724, 0.04585496336221695, 0.03206155076622963, -0.04660880193114281, -0.033183980733156204, 0.07211755961179733, -0.019206592813134193, 0.07645085453987122, -0.045827943831682205, -0.0474090650677681, 0.013556401245296001, 0.04067801311612129, 0.07531780749559402, 0.10896963626146317, 0.1305193305015564, -0.06909551471471786, 0.09948297590017319, 0.07934251427650452, -3.298512086172204e-33, 0.002868546172976494, 0.05453881248831749, 0.010014182887971401, 0.017773069441318512, -0.0077451360411942005, 0.0427858792245388, -0.025166651234030724, -0.06640724837779999, -0.014479368925094604, -0.07750820368528366, -0.06415373086929321, -0.03275085613131523, 0.022637037560343742, 0.0036769090220332146, -0.03608135133981705, -0.07643454521894455, -0.014524172991514206, 0.033984776586294174, 0.04233931750059128, 0.029316294938325882, 0.038269463926553726, 0.00021560574532486498, -0.018513092771172523, -0.12451541423797607, 0.034845467656850815, -0.013771990314126015, -0.04659401252865791, 0.06145264953374863, -0.0422460213303566, 0.05986149609088898, 0.008439738303422928, -0.06317757070064545, 0.07317470759153366, -0.019597282633185387, 0.030317800119519234, 0.045881424099206924, 0.0023135067895054817, 0.010763747617602348, -0.005998753942549229, -0.09376208484172821, 0.015100810676813126, -0.08070992678403854, -0.0078054009936749935, 0.0027820244431495667, -0.02475910075008869, -0.004593007732182741, 0.008295949548482895, 0.04298755154013634, -0.05324510484933853, -0.02846439555287361, -0.08138158917427063, 0.03419416397809982, -0.0003863247693516314, -0.012328214943408966, -0.02793935127556324, 0.07505366206169128, 0.010870193131268024, 0.031203720718622208, 0.021029498428106308, 0.03822004795074463, -0.03054240345954895, -0.02737266942858696, 0.05921585485339165, 0.1069582998752594, 0.08350568264722824, -0.0429692268371582, 0.08332409709692001, 0.05851726979017258, -0.03535034880042076, -0.05235917493700981, 0.009587885811924934, 0.0290716290473938, 0.0013759584398940206, -0.0507994070649147, -0.07617498934268951, -0.032411541789770126, -0.011567248962819576, -0.04419969394803047, -0.06445465981960297, 0.01037714071571827, 0.015593073330819607, -0.0039133247919380665, 0.048770464956760406, 0.030154425650835037, 0.026222245767712593, 0.020165234804153442, 0.033516909927129745, -0.010945402085781097, -0.0034250090830028057, 0.021636784076690674, -0.029409850016236305, -0.004850790835916996, 0.042570166289806366, 0.03854607790708542, 0.01292877271771431, -5.038159756054483e-08, -0.0725543424487114, -0.0023364287335425615, -0.04021533578634262, 0.0070258923806250095, 0.08837934583425522, -0.015568998642265797, -0.0121536860242486, 0.00668260408565402, -0.0031626084819436073, 0.08390519767999649, -0.012471928261220455, 0.015340310521423817, -0.06842100620269775, 0.02198825776576996, 0.020295636728405952, -0.07184906303882599, 0.021541878581047058, -0.010527096688747406, 0.023265769705176353, 0.02653777040541172, -0.04491102322936058, -0.014256691560149193, -0.009073560126125813, -0.021029150113463402, 0.023764120414853096, -0.01760661043226719, 0.006021845154464245, 0.1592949628829956, 0.04455609247088432, -0.05255845561623573, -0.0725887268781662, 0.03460588678717613, 0.027335170656442642, 0.02311226725578308, -0.119830422103405, -0.019603773951530457, 0.013221224769949913, 0.000779412395786494, -0.015615020878612995, -0.006226236931979656, -0.05260513722896576, -0.0022627676371484995, 0.004720119293779135, -0.022408224642276764, 0.054156217724084854, 0.04082709923386574, -0.05211300775408745, -0.04572807624936104, 0.041203148663043976, -0.06419557332992554, -0.03323066979646683, -0.014107441529631615, -0.0468253456056118, -0.05500326678156853, 0.05774558708071709, 0.0026890398003160954, -0.013605483807623386, 0.024933498352766037, 0.039381153881549835, 0.08261192589998245, -0.04334603250026703, -0.0015789228491485119, -0.025722147896885872, -0.042017679661512375]",
         "0.175"
        ],
        [
         "18",
         "36",
         "Top 7 Best Wordpress Plugin Of All Time",
         "If you are looking for the best wordpress plugins, then you are at the right place. Here is the list of best wordpress plugins that you should use in your blog to boost SEO, strong your security and know every aspects of your blog . Although creating a good content is one factor but there are many wordpress plugins that perform different actions and add on to your success. So let's start 1.Yoast SEO Those users who are serious about SEO, Yoast SEO will do the work for them to reach their goals. All they need to do is select a keyword, and the plugin will then optimize your page according to the specified keyword Yoast offers many popular SEO WordPress plugin functions. It gives you real-time page analysis to optimize your content, images, meta descriptions, titles, and kewords. Yoast also checks the length of your sentences and paragraphs, whether you’re using enough transition words or subheadings, how often you use passive voice, and so on. Yoast tells Google whether or not to index a page or a set of pages too. Let me summarize these points in bullets: Enhance the readability of your article to reduce bounce rate Optimize your articles with targetted keywords Let Google know who you are and what your site is about Improve your on-page SEO with advanced, real-time guidance and advice on keyword usage, linking, and external linking. Keep your focus keywords consistent to help rank better on Google. Preview how your page would appear in the search engine results page (SERP) Crawl your site daily to ensure Google indexes it as quickly as possible. Rate your article informing you of any mistakes you might have made so that you can fix them before publishing. Stay up-to-date with Google’s latest algorithm changes and adapt your on-page SEO as needed with smartsuggestionss from the Yoast SEO plugin. This plugin is always up-to-date. Free Version is available Pricing Premium version=$89/year that comes with extra functions, allowing you to optimize your content up to five keywords, among other benefits. 2. WP Rocket A website running WordPress can put a lot of strain on a server, which increases the chances that the website will crash and harm your business. To avoid such an unfortunate situation and ensure that all your pages load quickly, you need a caching plugin like WP Rocket. WP Rocket plugin designed to increases your website speed. Instead of waiting for pages to be saved to cache, WP Rocket turns on desired caching settings, like page cache and gzip compression. The plugin also activates other features, such as CDN support and llazy image loadding, to enhance your site speed. Features in bullets: Browser Catching Preloading the cache of pages Reducing the number of HTTP requests allows websites to load more quickly. Decreasing bandwidth usage with GZIP compression Apply optimal browser caching headers (expires) Minifying and combining JavaScript and CSS files Remove Unused CSS Deferred loading of images (LazyLoad) WebP compatibility Deferred loading of JavaScript files Delay JavaScript Execution Critical Path CSS generation and deferred loading of CSS files Database optimization WordPress Heartbeat API control DNS prefetch CDN integration Cloudflare integration Sucuri integration Easy import/export of settings Easy roll back to a previous version Pricing Single License =$49/year for one website Plus License =$99/year for 3 websites Infinite License =$249/year for unlimited websites 3.Wordfence Security Wordfence Security is a WordPress firewall and security scanner that keeps your site safe from malicious hackers, spam, and other online threats. This Plugin comes with a web application firewall (WAF) called tthread Defence Feed that helps to prevents brute force attacks by ensuring you set stronger passwords and limiting login attempts. It searches for malware and compares code, theme, and plugin files with the records in the WordPress.org repository to verify their integrity and reports changes to you. Wordfence security scanner provides you with actionable insights into your website's security status and will alert you to any potential threats, keeping it safe and secure. It also includes login security features that let you activate reCAPTCHA and two-factor authentication for your website. Features in Bullets. Scans your site for vulnerabilities. Alerts you by email when new threats are detected. Supports advanced login security measures. IP addresses may be blocked automatically if suspicious activity is detected. Pricing Premium Plan= $99/Year that comes with extra security features like the real time IP backlist and country blocking option and also support from highly qualified experts. 4. Akismet Akismet can help prevent spam from appearing on your site. Every day, it automatically checks every comment against a global database of spam to block malicious content. With Akismet, you also won’t have to worry about innocent comments being caught by the filter or false positives. You can simply tell Akismet about those and it will get better over time. It also checks your contact form submissions against its global spam database and weed out unnecessary fake information. Features in Bullets: The program automatically checks comments and filters out spam. Hidden or misleading links are often revealed in the comment body. Akismet tracks the status of each comment, allowing you to see which ones were caught by Akismet and which ones were cleared by a moderator. A spam-blocking feature that saves disk space and makes your site run faster. Moderators can view a list of comments approved by each user. Pricing Free to use for personal blog 5. Contact Form 7 Contact Form 7 is a plug-in that allows you to create contact forms that make it easy for your users to send messages to your site. The plug-in was developed by Takayuki Miyoshi and lets you create multiple contact forms on the same site; it also integrates Akismet spam filtering and lets you customize the styling and fields that you want to use in the form. The plug-in provides CAPTCHA and Ajax submitting. Features in bullets: Create and manage multiple contact forms Easily customize form fields Use simple markup to alter mail content Add Lots of third-party extensions for additional functionality Shortcode offers a way to insert content into pages or posts. Akismet spam filtering, Ajax-powered submitting, and CAPTCHA are all features of this plugin. Pricing Free to use 6. Monster Insights When you’re looking for an easy way to manage your Google Analytics-related web tracking services, Monster Insights can help. You can add, customize, and integrate Google Analytics data with ease so you’ll be able to see how every webpage performs, which online campaigns bring in the most traffic, and which content readers engage with the most. It’s same as Google Analytics It is a powerful tool to keep track of your traffic stats. With it, you can view stats for your active sessions, conversions, and bounce rates. You’ll also be able to see your total revenue, the products you sell, and how your site is performing when it comes to referrals. MonsterInsights offers a free plan that includes basic Google Analytics integration, data insights, and user activity metrics. Features in bullets: Demographics and interest reports: Anonymize the IPs of visitor See the results of how far visitors Scroll down Show the insights of multiple links to the same page and show you which links get more clicks See sessions of two related sites as a single session Google AdSense tracking Send you weekly analytics report of your blog you can download it as pdf Pricing Premium plan= $99.50/year that comes with extra features like page and post tracking, Adsense tracking, custom tracking and reports. 7. Pretty Links Pretty Links is a powerful WordPress plugin that enables you to easily cloak affiliate links on your websiteIt even allows you to easily redirect visitors based on a specific request, including permanent 301 and temporary 302/307 redirects. Pretty links also helps you to automatically shorten your url for your post and pages. You can also enable auto-linking feature to automatically add affiliate links for certain keywords Features Create clean, easy-to-remember URLs on your website (301, 302, and 307 redirects only) Random-generator or custom URL slugs Track the number of clicks Easy to understand reports View click details including ip address, remote host, browser, operating system, and referring site You can pass custom parameters to your scripts when using pretty permalinks, and still have full tracking capability. Exclude IP Addresses from Stats Cookie-based system to track your activity across clicks Create nofollow/noindex links Toggle tracking on / off on each link. Pretty Link Bookmarklet Update redirected links easily to new URLs! Pricing Beginner Plan=$79/year that can be used on 1 site Marketer Plan: $99/year – that can be used on upto 2 sites Super Affiliate Plan: $149/year – that can be use on upto 5 sites We hope you’ve found this article useful. We appreciate you reading and welcome your feedback if you have it.",
         "If you are looking for the best wordpress plugins, then you are at the right place. Here is the list of best wordpress plugins that you should use in your blog to boost SEO, strong your security and know every aspects of your blog . Although creating a good content is one factor but there are many wordpress plugins that perform different actions and add on to your success. So let's start\n\n1.Yoast SEO\n\nThose users who are serious about SEO, Yoast SEO will do the work for them to reach their goals. All they need to do is select a keyword, and the plugin will then optimize your page according to the specified keyword\n\nYoast offers many popular SEO WordPress plugin functions. It gives you real-time page analysis to optimize your content, images, meta descriptions, titles, and kewords. Yoast also checks the length of your sentences and paragraphs, whether you’re using enough transition words or subheadings, how often you use passive voice, and so on. Yoast tells Google whether or not to index a page or a set of pages too.\n\nLet me summarize these points in bullets:\n\nEnhance the readability of your article to reduce bounce rate\n\nOptimize your articles with targetted keywords\n\nLet Google know who you are and what your site is about\n\nImprove your on-page SEO with advanced, real-time guidance and advice on keyword usage, linking, and external linking.\n\nKeep your focus keywords consistent to help rank better on Google.\n\nPreview how your page would appear in the search engine results page (SERP)\n\nCrawl your site daily to ensure Google indexes it as quickly as possible.\n\nRate your article informing you of any mistakes you might have made so that you can fix them before publishing.\n\nStay up-to-date with Google’s latest algorithm changes and adapt your on-page SEO as needed with smartsuggestionss from the Yoast SEO plugin. This plugin is always up-to-date.\n\nFree Version is available\n\nPricing\n\nPremium version=$89/year that comes with extra functions, allowing you to optimize your content up to five keywords, among other benefits.\n\n\n\n\n\n2. WP Rocket\n\nA website running WordPress can put a lot of strain on a server, which increases the chances that the website will crash and harm your business. To avoid such an unfortunate situation and ensure that all your pages load quickly, you need a caching plugin like WP Rocket.\n\nWP Rocket plugin designed to increases your website speed. Instead of waiting for pages to be saved to cache, WP Rocket turns on desired caching settings, like page cache and gzip compression. The plugin also activates other features, such as CDN support and llazy image loadding, to enhance your site speed.\n\nFeatures in bullets:\n\nBrowser Catching\n\nPreloading the cache of pages\n\nReducing the number of HTTP requests allows websites to load more quickly.\n\nDecreasing bandwidth usage with GZIP compression\n\nApply optimal browser caching headers (expires)\n\nMinifying and combining JavaScript and CSS files\n\nRemove Unused CSS\n\nDeferred loading of images (LazyLoad)\n\nWebP compatibility\n\nDeferred loading of JavaScript files\n\nDelay JavaScript Execution\n\nCritical Path CSS generation and deferred loading of CSS files\n\nDatabase optimization\n\nWordPress Heartbeat API control\n\nDNS prefetch\n\nCDN integration\n\nCloudflare integration\n\nSucuri integration\n\nEasy import/export of settings\n\nEasy roll back to a previous version\n\n\n\n\n\nPricing\n\nSingle License =$49/year for one website\n\nPlus License =$99/year for 3 websites\n\nInfinite License =$249/year for unlimited websites\n\n\n\n\n\n3.Wordfence Security\n\nWordfence Security is a WordPress firewall and security scanner that keeps your site safe from malicious hackers, spam, and other online threats. This Plugin comes with a web application firewall (WAF) called tthread Defence Feed that helps to prevents brute force attacks by ensuring you set stronger passwords and limiting login attempts. It searches for malware and compares code, theme, and plugin files with the records in the WordPress.org repository to verify their integrity and reports changes to you.\n\nWordfence security scanner provides you with actionable insights into your website's security status and will alert you to any potential threats, keeping it safe and secure. It also includes login security features that let you activate reCAPTCHA and two-factor authentication for your website.\n\nFeatures in Bullets.\n\nScans your site for vulnerabilities.\n\nAlerts you by email when new threats are detected.\n\nSupports advanced login security measures.\n\nIP addresses may be blocked automatically if suspicious activity is detected.\n\nPricing\n\nPremium Plan= $99/Year that comes with extra security features like the real time IP backlist and country blocking option and also support from highly qualified experts.\n\n4. Akismet\n\nAkismet can help prevent spam from appearing on your site. Every day, it automatically checks every comment against a global database of spam to block malicious content. With Akismet, you also won’t have to worry about innocent comments being caught by the filter or false positives. You can simply tell Akismet about those and it will get better over time. It also checks your contact form submissions against its global spam database and weed out unnecessary fake information.\n\nFeatures in Bullets:\n\nThe program automatically checks comments and filters out spam.\n\nHidden or misleading links are often revealed in the comment body.\n\nAkismet tracks the status of each comment, allowing you to see which ones were caught by Akismet and which ones were cleared by a moderator.\n\nA spam-blocking feature that saves disk space and makes your site run faster.\n\nModerators can view a list of comments approved by each user.\n\nPricing\n\nFree to use for personal blog\n\n5. Contact Form 7\n\nContact Form 7 is a plug-in that allows you to create contact forms that make it easy for your users to send messages to your site. The plug-in was developed by Takayuki Miyoshi and lets you create multiple contact forms on the same site; it also integrates Akismet spam filtering and lets you customize the styling and fields that you want to use in the form. The plug-in provides CAPTCHA and Ajax submitting.\n\nFeatures in bullets:\n\nCreate and manage multiple contact forms\n\nEasily customize form fields\n\nUse simple markup to alter mail content\n\nAdd Lots of third-party extensions for additional functionality\n\nShortcode offers a way to insert content into pages or posts.\n\nAkismet spam filtering, Ajax-powered submitting, and CAPTCHA are all features of this plugin.\n\nPricing\n\nFree to use\n\n6. Monster Insights\n\nWhen you’re looking for an easy way to manage your Google Analytics-related web tracking services, Monster Insights can help. You can add, customize, and integrate Google Analytics data with ease so you’ll be able to see how every webpage performs, which online campaigns bring in the most traffic, and which content readers engage with the most. It’s same as Google Analytics\n\nIt is a powerful tool to keep track of your traffic stats. With it, you can view stats for your active sessions, conversions, and bounce rates. You’ll also be able to see your total revenue, the products you sell, and how your site is performing when it comes to referrals.\n\nMonsterInsights offers a free plan that includes basic Google Analytics integration, data insights, and user activity metrics.\n\nFeatures in bullets:\n\nDemographics and interest reports:\n\nAnonymize the IPs of visitor\n\nSee the results of how far visitors Scroll down\n\nShow the insights of multiple links to the same page and show you which links get more clicks\n\nSee sessions of two related sites as a single session\n\nGoogle AdSense tracking\n\nSend you weekly analytics report of your blog you can download it as pdf\n\nPricing\n\nPremium plan= $99.50/year that comes with extra features like page and post tracking, Adsense tracking, custom tracking and reports.\n\n7. Pretty Links\n\nPretty Links is a powerful WordPress plugin that enables you to easily cloak affiliate links on your websiteIt even allows you to easily redirect visitors based on a specific request, including permanent 301 and temporary 302/307 redirects.\n\nPretty links also helps you to automatically shorten your url for your post and pages.\n\nYou can also enable auto-linking feature to automatically add affiliate links for certain keywords\n\nFeatures\n\nCreate clean, easy-to-remember URLs on your website (301, 302, and 307 redirects only)\n\nRandom-generator or custom URL slugs\n\nTrack the number of clicks\n\nEasy to understand reports\n\nView click details including ip address, remote host, browser, operating system, and referring site\n\nYou can pass custom parameters to your scripts when using pretty permalinks, and still have full tracking capability.\n\nExclude IP Addresses from Stats\n\nCookie-based system to track your activity across clicks\n\nCreate nofollow/noindex links\n\nToggle tracking on / off on each link.\n\nPretty Link Bookmarklet\n\nUpdate redirected links easily to new URLs!\n\nPricing\n\nBeginner Plan=$79/year that can be used on 1 site\n\nMarketer Plan: $99/year – that can be used on upto 2 sites\n\nSuper Affiliate Plan: $149/year – that can be use on upto 5 sites\n\n\n\n\n\nWe hope you’ve found this article useful. We appreciate you reading and welcome your feedback if you have it.",
         "2022-02-11T09:00:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/02/top-7-best-wordpress-plugin-of-all-time.html",
         "2025-07-26T05:41:35.898394",
         "If you are looking for the best wordpress plugins, then you are at the right place. Here is the list of best wordpress plugins that you should use in your blog to boost SEO, strong your security and know every aspects of your blog . Although creating a good content is one factor but there are many wordpress plugins that perform different actions and add on to your success. So let's start 1.Yoast SEO Those users who are serious about SEO, Yoast SEO will do the work for them to reach their goals. All they need to do is select a keyword, and the plugin will then optimize your page according to the specified keyword Yoast offers many popular SEO WordPress plugin functions. It gives you real-time page analysis to optimize your content, images, meta descriptions, titles, and kewords. Yoast also checks the length of your sentences and paragraphs, whether you’re using enough transition words or subheadings, how often you use passive voice, and so on. Yoast tells Google whether or not to index a page or a set of pages too. Let me summarize these points in bullets: Enhance the readability of your article to reduce bounce rate Optimize your articles with targetted keywords Let Google know who you are and what your site is about Improve your on-page SEO with advanced, real-time guidance and advice on keyword usage, linking, and external linking. Keep your focus keywords consistent to help rank better on Google. Preview how your page would appear in the search engine results page (SERP) Crawl your site daily to ensure Google indexes it as quickly as possible. Rate your article informing you of any mistakes you might have made so that you can fix them before publishing. Stay up-to-date with Google’s latest algorithm changes and adapt your on-page SEO as needed with smartsuggestionss from the Yoast SEO plugin. This plugin is always up-to-date. Free Version is available Pricing Premium version=$89/year that comes with extra functions, allowing you to optimize your content up to five keywords, among other benefits. 2. WP Rocket A website running WordPress can put a lot of strain on a server, which increases the chances that the website will crash and harm your business. To avoid such an unfortunate situation and ensure that all your pages load quickly, you need a caching plugin like WP Rocket. WP Rocket plugin designed to increases your website speed. Instead of waiting for pages to be saved to cache, WP Rocket turns on desired caching settings, like page cache and gzip compression. The plugin also activates other features, such as CDN support and llazy image loadding, to enhance your site speed. Features in bullets: Browser Catching Preloading the cache of pages Reducing the number of HTTP requests allows websites to load more quickly. Decreasing bandwidth usage with GZIP compression Apply optimal browser caching headers (expires) Minifying and combining JavaScript and CSS files Remove Unused CSS Deferred loading of images (LazyLoad) WebP compatibility Deferred loading of JavaScript files Delay JavaScript Execution Critical Path CSS generation and deferred loading of CSS files Database optimization WordPress Heartbeat API control DNS prefetch CDN integration Cloudflare integration Sucuri integration Easy import/export of settings Easy roll back to a previous version Pricing Single License =$49/year for one website Plus License =$99/year for 3 websites Infinite License =$249/year for unlimited websites 3.Wordfence Security Wordfence Security is a WordPress firewall and security scanner that keeps your site safe from malicious hackers, spam, and other online threats. This Plugin comes with a web application firewall (WAF) called tthread Defence Feed that helps to prevents brute force attacks by ensuring you set stronger passwords and limiting login attempts. It searches for malware and compares code, theme, and plugin files with the records in the WordPress.org repository to verify their integrity and reports changes to you. Wordfence security scanner provides you with actionable insights into your website's security status and will alert you to any potential threats, keeping it safe and secure. It also includes login security features that let you activate reCAPTCHA and two-factor authentication for your website. Features in Bullets. Scans your site for vulnerabilities. Alerts you by email when new threats are detected. Supports advanced login security measures. IP addresses may be blocked automatically if suspicious activity is detected. Pricing Premium Plan= $99/Year that comes with extra security features like the real time IP backlist and country blocking option and also support from highly qualified experts. 4. Akismet Akismet can help prevent spam from appearing on your site. Every day, it automatically checks every comment against a global database of spam to block malicious content. With Akismet, you also won’t have to worry about innocent comments being caught by the filter or false positives. You can simply tell Akismet about those and it will get better over time. It also checks your contact form submissions against its global spam database and weed out unnecessary fake information. Features in Bullets: The program automatically checks comments and filters out spam. Hidden or misleading links are often revealed in the comment body. Akismet tracks the status of each comment, allowing you to see which ones were caught by Akismet and which ones were cleared by a moderator. A spam-blocking feature that saves disk space and makes your site run faster. Moderators can view a list of comments approved by each user. Pricing Free to use for personal blog 5. Contact Form 7 Contact Form 7 is a plug-in that allows you to create contact forms that make it easy for your users to send messages to your site. The plug-in was developed by Takayuki Miyoshi and lets you create multiple contact forms on the same site; it also integrates Akismet spam filtering and lets you customize the styling and fields that you want to use in the form. The plug-in provides CAPTCHA and Ajax submitting. Features in bullets: Create and manage multiple contact forms Easily customize form fields Use simple markup to alter mail content Add Lots of third-party extensions for additional functionality Shortcode offers a way to insert content into pages or posts. Akismet spam filtering, Ajax-powered submitting, and CAPTCHA are all features of this plugin. Pricing Free to use 6. Monster Insights When you’re looking for an easy way to manage your Google Analytics-related web tracking services, Monster Insights can help. You can add, customize, and integrate Google Analytics data with ease so you’ll be able to see how every webpage performs, which online campaigns bring in the most traffic, and which content readers engage with the most. It’s same as Google Analytics It is a powerful tool to keep track of your traffic stats. With it, you can view stats for your active sessions, conversions, and bounce rates. You’ll also be able to see your total revenue, the products you sell, and how your site is performing when it comes to referrals. MonsterInsights offers a free plan that includes basic Google Analytics integration, data insights, and user activity metrics. Features in bullets: Demographics and interest reports: Anonymize the IPs of visitor See the results of how far visitors Scroll down Show the insights of multiple links to the same page and show you which links get more clicks See sessions of two related sites as a single session Google AdSense tracking Send you weekly analytics report of your blog you can download it as pdf Pricing Premium plan= $99.50/year that comes with extra features like page and post tracking, Adsense tracking, custom tracking and reports. 7. Pretty Links Pretty Links is a powerful WordPress plugin that enables you to easily cloak affiliate links on your websiteIt even allows you to easily redirect visitors based on a specific request, including permanent 301 and temporary 302/307 redirects. Pretty links also helps you to automatically shorten your url for your post and pages. You can also enable auto-linking feature to automatically add affiliate links for certain keywords Features Create clean, easy-to-remember URLs on your website (301, 302, and 307 redirects only) Random-generator or custom URL slugs Track the number of clicks Easy to understand reports View click details including ip address, remote host, browser, operating system, and referring site You can pass custom parameters to your scripts when using pretty permalinks, and still have full tracking capability. Exclude IP Addresses from Stats Cookie-based system to track your activity across clicks Create nofollow/noindex links Toggle tracking on / off on each link. Pretty Link Bookmarklet Update redirected links easily to new URLs! Pricing Beginner Plan=$79/year that can be used on 1 site Marketer Plan: $99/year – that can be used on upto 2 sites Super Affiliate Plan: $149/year – that can be use on upto 5 sites We hope you’ve found this article useful. We appreciate you reading and welcome your feedback if you have it.",
         "en",
         "{'MISC': ['Add Lots of third', 'Adsense tracking', 'Akismet', 'Akismet Akismet can', 'Akismet about those and it will get better over time', 'Alerts you by email when new threats are detected', 'All they need to do is select', 'Although creating a good content is one factor but there are many wordpress plugins that perform different actions and add on to your success', 'Browser Catching Preloading the cache of pages Reducing the number of HTTP', 'CAPTCHA and Ajax submitting', 'Crawl', 'Create and manage multiple contact', 'Create nofollow/noindex links', 'DNS', 'Deferred loading of images', 'Demographics and interest reports', 'Easy', 'Easy to understand reports View', 'Enhance the readability of your article to reduce bounce rate', 'Every day', 'Features Create clean', 'Google', 'Google Analytics It is', 'Google Analytics data with ease so you’ll be able to see how every webpage', 'Google indexes it as quickly as possible', 'Google whether or not to index', 'Here is the list of best wordpress plugins that you should use in your blog to boost SEO', 'Hidden or misleading links are often revealed in the', 'IP', 'If you are looking for the best wordpress plugins', 'Infinite', 'Instead of waiting for pages to be saved to cache', 'It also', 'It also checks your', 'It gives you real-time page analysis to optimize your content', 'It searches for malware and', 'JavaScript and CSS', 'Keep your focus', 'LazyLoad', 'Let me summarize these points in bullets', 'Minifying and', 'Moderators can view', 'Monster Insights When you’re looking for an easy way to manage your Google Analytics-related web tracking services', 'Monster Insights can help', 'MonsterInsights', 'Optimize your articles with targetted', 'Plus License', 'Pretty Links Pretty Links is', 'Pretty links also helps you to automatically shorten your url', 'Preview how your page would appear in the search engine', 'Pricing', 'Pricing Beginner', 'Pricing Free to', 'Pricing Free to use for personal blog 5', 'Pricing Premium', 'Remove Unused', 'SEO as needed with smartsuggestionss from the Yoast SEO', 'SEO with advanced', 'Scroll down Show the insights of multiple links to the same page and show you which links get more clicks See', 'See the results of how far', \"So let's start\", 'Stay up-to-date with Google’s latest algorithm changes and adapt your on', 'Supports advanced login security measures', 'The plugin also activates', 'This Plugin comes with', 'To avoid such an unfortunate situation and ensure that all your pages load quickly', 'Toggle tracking', 'URLs on your website', 'WAF', 'WP Rocket A', 'WP Rocket plugin designed to increases your website speed', 'WP Rocket turns on desired caching settings', 'We appreciate you reading and welcome your feedback if you have it', 'We hope you’ve found this article useful', 'WebP', 'With Akismet', 'With it', 'WordPress', 'WordPress can', 'WordPress firewall and security', 'Wordfence security', 'Yoast', 'Yoast SEO will do the work for them to reach their goals', 'Yoast also checks the length of your sentences and paragraphs', 'You can', 'You can add', 'You can also enable auto-linking', 'You’ll also be able to see your total revenue', 'according to the specified keyword', 'allowing you to optimize your content up to five keywords', 'among other benefits', 'and still have full tracking capability', 'custom tracking and reports', 'easy-to-', 'including permanent 301 and temporary 302/307 redirects', 'it automatically checks every', 'like WP Rocket', 'like page cache and gzip', 'remote host', 'strong your security and know every aspects of your blog', 'theme, and plugin files with the records in the WordPress.org repository to verify their integrity and reports', 'then you are at the right', 'to enhance your', 'which increases the chances that the website will crash and harm your business', 'which online campaigns bring in the most traffic', 'you also won’t have to worry about innocent comments being caught by the filter or false positives', 'you need', 'you sell'], 'ORG': ['Apply', 'CDN support and llazy', 'Features', 'Features in Bullets', 'Google', 'SEO Those'], 'LOC': ['Easily', 'and kewords', 'and referring'], 'PER': ['Ajax-powered submitting, and CAPTCHA are all features', 'Rate', 'Takayuki Miyoshi', 'allowing you to see which ones were caught by Akismet and which ones were cleared by', 'whether you’re using enough transition words or subheadings']}",
         "[-0.05905281379818916, -0.03175855055451393, 0.055655915290117264, -0.0002456156362313777, 0.0012865836033597589, 0.02790767326951027, 0.014341608621180058, 0.06804444640874863, -0.03216555714607239, 0.020189573988318443, -0.022150544449687004, 0.07620636373758316, 0.01805829256772995, 0.04511559009552002, 0.03274282440543175, -0.005989160388708115, 0.057627249509096146, 0.10787683725357056, -0.08873680233955383, -0.11170181632041931, 0.04478280991315842, -0.03279625251889229, 0.04002654179930687, -0.03748314455151558, -0.02782321721315384, -0.0010428039822727442, -0.07985638827085495, -0.027270235121250153, 0.018270526081323624, -0.1310771405696869, -0.057912494987249374, -0.13180287182331085, -0.005527197383344173, 0.021035678684711456, -0.07700922340154648, -0.003608124330639839, 0.05056203901767731, -0.022878939285874367, -0.01868196576833725, -0.020549431443214417, -0.03661657124757767, -0.020068051293492317, -0.08429384976625443, 0.027918031439185143, 0.0912172719836235, -0.08075636625289917, -0.009918364696204662, -0.059081099927425385, -0.00015233622980304062, 0.053601063787937164, -0.030853891745209694, -0.03876971825957298, -0.0168447345495224, 0.02141568996012211, -0.03157183155417442, -0.06242865324020386, -0.10351762175559998, -0.06494858860969543, 0.005894002038985491, -0.09852232784032822, 0.005275033414363861, 0.012091470882296562, -0.0030609637033194304, 0.0017389793647453189, -0.013641140423715115, -0.08337769657373428, 0.033235106617212296, 0.0035370667465031147, 0.055760499089956284, 0.020694060251116753, -0.02078617550432682, 0.019810311496257782, 0.009793881326913834, 0.04648636654019356, -0.05988234281539917, -0.02551555261015892, 0.06833362579345703, -0.05118710920214653, 0.04061252623796463, 0.020835455507040024, 0.08731291443109512, 0.06789884716272354, -0.008898395113646984, 0.06010720878839493, 0.03471596911549568, -0.07325242459774017, 0.04601765051484108, -0.04895474389195442, -0.06457404047250748, 0.03527702018618584, 0.08934058994054794, -0.002058920916169882, 0.02871326170861721, -0.05623187869787216, 0.030612943693995476, 0.06843829154968262, -0.08199705183506012, -0.08616410195827484, 0.04964923486113548, 0.03563284873962402, -0.015226067043840885, -0.020063262432813644, -0.02385682985186577, -0.0064200712367892265, 0.020635666325688362, 0.011990442872047424, -0.022076338529586792, 0.022310134023427963, -0.002643887884914875, 0.07819758355617523, 0.06116396561264992, 0.053747326135635376, -0.054169267416000366, -0.029994649812579155, 0.04833298176527023, 0.0011732715647667646, -0.0028270171023905277, 0.00800132192671299, 0.09183239936828613, 0.01730482466518879, -0.009574025869369507, 0.09125027060508728, 0.04312797635793686, -0.028088923543691635, -0.053867436945438385, 0.07538533210754395, -0.03525784984230995, 7.109473587745691e-33, 0.0028280781116336584, 0.012043538503348827, -0.0778157189488411, 0.039339788258075714, -0.035125937312841415, 0.0009967359947040677, -0.0006955676362849772, 0.03405497968196869, -0.1391734778881073, -0.01216015312820673, -0.05131737142801285, 0.010366985574364662, -0.024329692125320435, 0.09086041152477264, 0.045690447092056274, -0.09267902374267578, 0.058038342744112015, -0.037416744977235794, -0.029312441125512123, -0.0709085613489151, 0.03410341590642929, -0.03673524782061577, 0.08916269242763519, 0.013137247413396835, 0.022138522937893867, -0.0865577980875969, 0.03904586285352707, -0.024571839720010757, -0.07179204374551773, -0.00027269957354292274, -0.015548900701105595, -0.06537964195013046, 0.000611696916166693, 0.018194351345300674, -0.019284091889858246, -0.046350885182619095, -0.06657803803682327, -0.02227133698761463, -0.013213667087256908, -0.029927164316177368, -0.0988101214170456, 0.0423758290708065, -0.041132695972919464, -0.02352992445230484, 0.06845255941152573, 0.10847220569849014, 0.00669088726863265, -0.017234772443771362, 0.044355910271406174, 0.07505753636360168, 0.04597926512360573, -0.01965157873928547, -0.04540574550628662, 0.11638149619102478, -0.020794648677110672, 0.02319842018187046, 0.040155839174985886, 0.01708177477121353, 0.04153238609433174, 0.04183277115225792, -0.012426854111254215, -0.07625117897987366, -0.01972353644669056, 0.011047246865928173, 0.02228509448468685, 0.07475925981998444, -0.012555724009871483, 0.04408760368824005, 0.019912386313080788, -0.004670154303312302, 0.0076156193390488625, -0.007621828466653824, 0.051621634513139725, -0.02147473581135273, -0.015390788204967976, -0.014866789802908897, 0.03561122715473175, -0.029096564278006554, -0.06793109327554703, -0.010917150415480137, 0.0021541316527873278, 0.0587041862308979, -0.015614757314324379, -0.029326073825359344, 0.029073461890220642, -0.05254649370908737, 0.031291116029024124, 0.00362161872908473, 0.010447892360389233, 0.03359018266201019, 0.015598775818943977, 0.15501344203948975, 0.02792467549443245, 0.02704535238444805, -0.11868160963058472, -6.44987872824435e-33, -0.00830299872905016, -0.01672634296119213, 0.0152083495631814, 0.059716612100601196, -0.05743076279759407, 0.003854073816910386, -0.10964769870042801, -0.006368955597281456, 0.04563327878713608, -0.07991986721754074, -0.05247948318719864, -0.02822928875684738, 0.08497335761785507, 0.060472261160612106, 0.0024554526899009943, 0.012838118709623814, -0.03684194013476372, -0.1389053463935852, -0.023937394842505455, 0.08960705250501633, -0.040376998484134674, 0.07396603375673294, -0.061475079506635666, -0.0093848193064332, 0.06713156402111053, 3.59873884008266e-05, -0.07091572880744934, 0.06370138376951218, 0.01007922738790512, 0.017336217686533928, 0.014049084857106209, 0.021252745762467384, -0.019243735820055008, -0.061896197497844696, -0.012511253356933594, 0.06602063030004501, 0.02254439704120159, 0.011031020432710648, -0.013022915460169315, 0.061308763921260834, 0.006092344410717487, 0.06812544912099838, 0.04612864926457405, -0.1009453758597374, -0.07004012167453766, 0.014530368149280548, -0.11203840374946594, 0.004090550355613232, -0.000799385248683393, 0.04412245750427246, -0.03772544860839844, -0.026003718376159668, -0.06140122562646866, 0.03633679077029228, -0.00930402334779501, -0.057970743626356125, -0.09204262495040894, -0.01647360995411873, -0.08727768808603287, 0.024310560896992683, -0.030457425862550735, 0.05857207998633385, -0.018718335777521133, 0.0414312407374382, -0.0072058723308146, -0.05537630245089531, 0.030874988064169884, -0.08134831488132477, -0.024001672863960266, 0.012716271914541721, -0.014506460167467594, 0.09428481757640839, 0.06568565964698792, -0.050642888993024826, -0.01294154953211546, 0.019926264882087708, -0.015173631720244884, -0.04707948490977287, -0.005378324072808027, -0.005730011034756899, 0.02702411636710167, 0.09328208118677139, -0.07509803026914597, -0.04804142564535141, -0.051039692014455795, 0.10500188171863556, -0.0038799960166215897, 0.038955505937337875, 0.04401075467467308, 0.023852411657571793, 0.014239809475839138, -0.05869568884372711, -0.06240781024098396, 0.11481484770774841, -0.01259894110262394, -5.7067719438919084e-08, 0.002223016694188118, -0.03941209986805916, 0.026926925405859947, 0.030664831399917603, -0.03939855843782425, 0.00834715086966753, 0.03007081337273121, 0.005281731951981783, -0.008196069858968258, -0.05321944132447243, 0.17860813438892365, 0.030242444947361946, -0.04477626457810402, 0.05938955023884773, -0.012704850174486637, -0.018566202372312546, -0.021063849329948425, 0.031750574707984924, 0.016066845506429672, -0.05846424773335457, -0.009290910325944424, 0.05915499106049538, -0.0646112710237503, 0.007093454711139202, 0.07035218179225922, 0.03521736338734627, 0.016701020300388336, 0.025520291179418564, -0.04357257857918739, -0.04199764132499695, 0.010993805713951588, 0.04633959382772446, 0.027984028682112694, -0.015369349159300327, 0.0016881221672520041, 0.034335117787122726, 0.0068632205948233604, -0.007363390643149614, -0.0832836776971817, 0.09147875010967255, 0.12080442905426025, 0.0336996391415596, 0.0448981411755085, -0.0365186408162117, -0.04676074907183647, -0.033443987369537354, 0.020831400528550148, -0.08067701011896133, 0.011456221342086792, 0.01990148425102234, 0.02237582579255104, -0.06682858616113663, 0.041024427860975266, 0.018996357917785645, 0.04114290699362755, 0.011315211653709412, -0.03019869513809681, 0.08531951159238815, 0.03787657618522644, 0.09119665622711182, -0.04004392400383949, 0.00883614644408226, 0.09132717549800873, -0.010595932602882385]",
         "0.203"
        ],
        [
         "19",
         "31",
         "ProWritingAid VS Grammarly: Which Grammar Checker is Better in (2022) ?",
         "ProWritingAid VS Grammarly: When it comes to English grammar, there are two Big Players that everyone knows of: the Grammarly and ProWritingAid. but you are wondering which one to choose so here we write a detail article which will help you to choose the best one for you so Let's start What is Grammarly? Grammarly is a tool that checks for grammatical errors, spelling, and punctuation.it gives you comprehensive feedback on your writing. You can use this tool to proofread and edit articles, blog posts, emails, etc. Grammarly also detects all types of mistakes, including sentence structure issues and misused words. It also gives you suggestions on style changes, punctuation, spelling, and grammar all are in real-time. The free version covers the basics like identifying grammar and spelling mistakes whereas the Premium version offers a lot more functionality, it detects plagiarism in your content, suggests word choice, or adds fluency to it. Features of Grammarly Spelling and Word Suggestion: Grammarly detects basic to advance grammatical errors and also help you why this is an error and suggest to you how you can improve it Create a Personal Dictionary: The Grammarly app allows you to add words to your personal dictionary so that the same mistake isn't highlighted every time you run Grammarly. Different English Style : Check to spell for American, British, Canadian, and Australian English. Plagiarism: This feature helps you detect if a text has been plagiarized by comparing it with over eight billion web pages. Wordiness: This tool will help you check your writing for long and hard-to-read sentences. It also shows you how to shorten sentences so that they are more concise. Passive Voice: The program also notifies users when passive voice is used too frequently in a document. Punctuations: This feature flags all incorrect and missing punctuation. Repetition: The tool provides recommendations for replacing the repeated word. Proposition: Grammarly identifies misplaced and confused prepositions. Plugins: It offers Microsoft Word, Microsoft Outlook, and Google Chrome plugins. What is ProWritingAid? ProWritingAid is a style and grammar checker for content creators and writers. It helps to optimize word choice, punctuation errors, and common grammar mistakes, providing detailed reports to help you improve your writing. ProWritingAid can be used as an add-on to WordPress, Gmail, and Google Docs. The software also offers helpful articles, videos, quizzes, and explanations to help improve your writing. Features of ProWriting Aid Here are some key features of ProWriting Aid: Grammar checker and spell checker: This tool helps you to find all grammatical and spelling errors. Find repeated words: The tool also allows you to search for repeated words and phrases in your content. Context-sensitive style suggestions: You can find the exact style of writing you intend and suggest if it flows well in your writing. Check the readability of your content: Pro Writing Aid helps you identify the strengths and weaknesses of your article by pointing out difficult sentences and paragraphs. Sentence Length: It also indicates the length of your sentences. Check Grammatical error: It also checks your work for any grammatical errors or typos, as well. Overused words: As a writer, you might find yourself using the same word repeatedly. ProWritingAid's overused words checker helps you avoid this lazy writing mistake. Consistency: Check your work for inconsistent usage of open and closed quotation marks. Echoes: Check your writing for uniformly repetitive words and phrases. Difference between Grammarly and Pro-Writing Aid Grammarly and ProWritingAid are well-known grammar-checking software. However, if you're like most people who can't decide which to use, here are some different points that may be helpful in your decision. Grammarly vs ProWritingAid Grammarly is a writing enhancement tool that offers suggestions for grammar, vocabulary, and syntax whereas ProWritingAid offers world-class grammar and style checking, as well as advanced reports to help you strengthen your writing. Grammarly provides Android and IOS apps whereas ProWritingAid doesn't have a mobile or IOS app. Grammarly offers important suggestions about mistakes you've made whereas ProWritingAid shows more suggestions than Grammarly but all recommendations are not accurate Grammarly has a more friendly UI/UX whereas the ProWritingAid interface is not friendly as Grammarly. Grammarly is an accurate grammar checker for non-fiction writing whereas ProWritingAid is an accurate grammar checker for fiction writers. Grammarly finds grammar and punctuation mistakes, whereas ProWritingAid identifies run-on sentences and fragments. Grammarly provides 24/7 support via submitting a ticket and sending emails. ProWritingAid’s support team is available via email, though the response time is approximately 48 hours. Grammarly offers many features in its free plan, whereas ProWritingAid offers some basic features in the free plan. Grammarly does not offer much feedback on big picture writing; ProWritingAid offers complete feedback on big picture writing. Grammarly is a better option for accuracy, whereas ProWritingAid is better for handling fragmented sentences and dialogue. It can be quite useful for fiction writers. ProWritingAid VS Grammarly: Pricing Difference ProWritingAid comes with three pricing structures. The full-year cost of ProWritingAid is $79, while its lifetime plans cost $339. You also can opt for a monthly plan of $20. Grammarly offers a Premium subscription for $30/month for a monthly plan $20/month for quarterly and $12/month for an annual subscription. The Business plan costs $12.50 per month for each member of your company. ProWritingAid vs Grammarly – Pros and Cons Grammarly Pros It allows you to fix common mistakes like grammar and spelling. Offers most features in the free plan Allows you to edit a document without affecting the formatting. Active and passive voice checker Personal dictionary Plagiarism checker (paid version) Proofread your writing and correct all punctuation, grammar, and spelling errors. Allows you to make changes to a document without altering its formatting. Helps users improve vocabulary User-friendly interface Browser extensions and MS word add-ons Available on all major devices and platforms Grammarly will also offer suggestions to improve your style. Enhance the readability of your sentence Free mobile apps Offers free version Grammarly Cons Supports only English Customer support only via email Limits to 150,000 words Subscription plans can be a bit pricey Plagiarism checker is only available in a premium plan Doesn’t offer a free trial No refund policy The free version is ideal for basic spelling and grammatical mistakes, but it does not correct advanced writing issues. Some features are not available for Mac. ProwritingAid Pros It offers more than 20 different reports to help you improve your writing. Less expensive than other grammar checkers. This tool helps you strengthen your writing style as it offers big-picture feedback. ProWritingAid has a life plan with no further payments required. Compatible with Google Docs! Prowritingaid works on both Windows and Mac. They offer more integrations than most tools. ProWritingAid Cons Editing can be a little more time-consuming when you add larger passages of text. ProWritingAid currently offers no mobile app for Android or iOS devices. Plagiarism checker is only available in premium plans. All recommendations are not accurate Summarizing the Ginger VS Grammarly: My Recommendation As both writing assistants are great in their own way, you need to choose the one that suits you best. For example, go for Grammarly if you are a non-fiction writer Go for ProWritingAid if you are a fiction writer. ProWritingAid is better at catching errors found in long-form content. However, Grammarly is more suited to short blog posts and other similar tasks. ProWritingAid helps you clean up your writing by checking for style, structure, and content while Grammarly focuses on grammar and punctuation. Grammarly has a more friendly UI/UX whereas; ProWritingAid offers complete feedback on big picture writing. Both ProWritingAid and Grammarly are awesome writing tools, without a doubt. but as per my experience, Grammarly is a winner here because Grammarly helps you to review and edit your content. Grammarly highlights all the mistakes in your writing within seconds of copying and pasting the content into Grammarly’s editor or using the software’s native feature in other text editors. Not only does it identify tiny grammatical and spelling errors, it tells you when you overlook punctuations where they are needed. And, beyond its plagiarism-checking capabilities, Grammarly helps you proofread your content. Even better, the software offers a free plan that gives you access to some of its features.",
         "ProWritingAid VS Grammarly: Which Grammar Checker is Better in (2022) ?\n\nWhen it comes to English grammar, there are two Big Players that everyone knows of: the Grammarly and ProWritingAid. but you are wondering which one to choose so here we write a detail article which will help you to choose the best one for you so Let's start\n\nWhat is Grammarly?\n\nGrammarly is a tool that checks for grammatical errors, spelling, and punctuation.it gives you comprehensive feedback on your writing. You can use this tool to proofread and edit articles, blog posts, emails, etc.\n\nGrammarly also detects all types of mistakes, including sentence structure issues and misused words. It also gives you suggestions on style changes, punctuation, spelling, and grammar all are in real-time. The free version covers the basics like identifying grammar and spelling mistakes\n\nwhereas the Premium version offers a lot more functionality, it detects plagiarism in your content, suggests word choice, or adds fluency to it.\n\n\n\n\n\nFeatures of Grammarly\n\nSpelling and Word Suggestion: Grammarly detects basic to advance grammatical errors and also help you why this is an error and suggest to you how you can improve it\n\nCreate a Personal Dictionary: The Grammarly app allows you to add words to your personal dictionary so that the same mistake isn't highlighted every time you run Grammarly.\n\nDifferent English Style : Check to spell for American, British, Canadian, and Australian English.\n\nPlagiarism: This feature helps you detect if a text has been plagiarized by comparing it with over eight billion web pages.\n\nWordiness: This tool will help you check your writing for long and hard-to-read sentences. It also shows you how to shorten sentences so that they are more concise.\n\nPassive Voice: The program also notifies users when passive voice is used too frequently in a document.\n\nPunctuations: This feature flags all incorrect and missing punctuation.\n\nRepetition: The tool provides recommendations for replacing the repeated word.\n\nProposition: Grammarly identifies misplaced and confused prepositions.\n\n\n\nPlugins: It offers Microsoft Word, Microsoft Outlook, and Google Chrome plugins.\n\n\n\n\n\nWhat is ProWritingAid?\n\nProWritingAid is a style and grammar checker for content creators and writers. It helps to optimize word choice, punctuation errors, and common grammar mistakes, providing detailed reports to help you improve your writing.\n\nProWritingAid can be used as an add-on to WordPress, Gmail, and Google Docs. The software also offers helpful articles, videos, quizzes, and explanations to help improve your writing.\n\nFeatures of ProWriting Aid\n\nHere are some key features of ProWriting Aid:\n\nGrammar checker and spell checker: This tool helps you to find all grammatical and spelling errors.\n\nFind repeated words: The tool also allows you to search for repeated words and phrases in your content.\n\nContext-sensitive style suggestions: You can find the exact style of writing you intend and suggest if it flows well in your writing.\n\nCheck the readability of your content: Pro Writing Aid helps you identify the strengths and weaknesses of your article by pointing out difficult sentences and paragraphs.\n\nSentence Length: It also indicates the length of your sentences.\n\nCheck Grammatical error: It also checks your work for any grammatical errors or typos, as well.\n\nOverused words: As a writer, you might find yourself using the same word repeatedly. ProWritingAid's overused words checker helps you avoid this lazy writing mistake.\n\nConsistency: Check your work for inconsistent usage of open and closed quotation marks.\n\nEchoes: Check your writing for uniformly repetitive words and phrases.\n\nDifference between Grammarly and Pro-Writing Aid\n\nGrammarly and ProWritingAid are well-known grammar-checking software. However, if you're like most people who can't decide which to use, here are some different points that may be helpful in your decision.\n\nGrammarly vs ProWritingAid\n\nGrammarly is a writing enhancement tool that offers suggestions for grammar, vocabulary, and syntax whereas ProWritingAid offers world-class grammar and style checking, as well as advanced reports to help you strengthen your writing.\n\nGrammarly provides Android and IOS apps whereas ProWritingAid doesn't have a mobile or IOS app.\n\nGrammarly offers important suggestions about mistakes you've made whereas ProWritingAid shows more suggestions than Grammarly but all recommendations are not accurate\n\nGrammarly has a more friendly UI/UX whereas the ProWritingAid interface is not friendly as Grammarly.\n\nGrammarly is an accurate grammar checker for non-fiction writing whereas ProWritingAid is an accurate grammar checker for fiction writers.\n\nGrammarly finds grammar and punctuation mistakes, whereas ProWritingAid identifies run-on sentences and fragments.\n\nGrammarly provides 24/7 support via submitting a ticket and sending emails. ProWritingAid’s support team is available via email, though the response time is approximately 48 hours.\n\nGrammarly offers many features in its free plan, whereas ProWritingAid offers some basic features in the free plan.\n\nGrammarly does not offer much feedback on big picture writing; ProWritingAid offers complete feedback on big picture writing.\n\nGrammarly is a better option for accuracy, whereas ProWritingAid is better for handling fragmented sentences and dialogue. It can be quite useful for fiction writers.\n\nProWritingAid VS Grammarly: Pricing Difference\n\nProWritingAid comes with three pricing structures. The full-year cost of ProWritingAid is $79, while its lifetime plans cost $339. You also can opt for a monthly plan of $20.\n\nGrammarly offers a Premium subscription for $30/month for a monthly plan $20/month for quarterly and $12/month for an annual subscription.\n\nThe Business plan costs $12.50 per month for each member of your company.\n\nProWritingAid vs Grammarly – Pros and Cons\n\nGrammarly Pros\n\nIt allows you to fix common mistakes like grammar and spelling.\n\nOffers most features in the free plan\n\nAllows you to edit a document without affecting the formatting.\n\nActive and passive voice checker\n\nPersonal dictionary\n\nPlagiarism checker (paid version)\n\nProofread your writing and correct all punctuation, grammar, and spelling errors.\n\nAllows you to make changes to a document without altering its formatting.\n\nHelps users improve vocabulary\n\nUser-friendly interface\n\nBrowser extensions and MS word add-ons\n\nAvailable on all major devices and platforms\n\nGrammarly will also offer suggestions to improve your style.\n\nEnhance the readability of your sentence\n\nFree mobile apps\n\nOffers free version\n\nGrammarly Cons\n\nSupports only English\n\nCustomer support only via email\n\nLimits to 150,000 words\n\nSubscription plans can be a bit pricey\n\nPlagiarism checker is only available in a premium plan\n\nDoesn’t offer a free trial\n\nNo refund policy\n\nThe free version is ideal for basic spelling and grammatical mistakes, but it does not correct advanced writing issues.\n\nSome features are not available for Mac.\n\nProwritingAid Pros\n\nIt offers more than 20 different reports to help you improve your writing.\n\nLess expensive than other grammar checkers.\n\nThis tool helps you strengthen your writing style as it offers big-picture feedback.\n\nProWritingAid has a life plan with no further payments required.\n\nCompatible with Google Docs!\n\nProwritingaid works on both Windows and Mac.\n\nThey offer more integrations than most tools.\n\nProWritingAid Cons\n\nEditing can be a little more time-consuming when you add larger passages of text.\n\nProWritingAid currently offers no mobile app for Android or iOS devices.\n\nPlagiarism checker is only available in premium plans.\n\nAll recommendations are not accurate\n\nSummarizing the Ginger VS Grammarly: My Recommendation\n\nAs both writing assistants are great in their own way, you need to choose the one that suits you best.\n\nFor example, go for Grammarly if you are a non-fiction writer\n\nGo for ProWritingAid if you are a fiction writer.\n\nProWritingAid is better at catching errors found in long-form content. However, Grammarly is more suited to short blog posts and other similar tasks.\n\nProWritingAid helps you clean up your writing by checking for style, structure, and content while Grammarly focuses on grammar and punctuation.\n\nGrammarly has a more friendly UI/UX whereas; ProWritingAid offers complete feedback on big picture writing.\n\nBoth ProWritingAid and Grammarly are awesome writing tools, without a doubt. but as per my experience, Grammarly is a winner here because Grammarly helps you to review and edit your content. Grammarly highlights all the mistakes in your writing within seconds of copying and pasting the content into Grammarly’s editor or using the software’s native feature in other text editors.\n\nNot only does it identify tiny grammatical and spelling errors, it tells you when you overlook punctuations where they are needed. And, beyond its plagiarism-checking capabilities, Grammarly helps you proofread your content. Even better, the software offers a free plan that gives you access to some of its features.",
         "2022-03-13T15:04:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/03/prowritingaid-vs-grammarly-which.html",
         "2025-07-26T05:41:35.842673",
         "ProWritingAid VS Grammarly: Which Grammar Checker is Better in (2022) ? When it comes to English grammar, there are two Big Players that everyone knows of: the Grammarly and ProWritingAid. but you are wondering which one to choose so here we write a detail article which will help you to choose the best one for you so Let's start What is Grammarly? Grammarly is a tool that checks for grammatical errors, spelling, and punctuation.it gives you comprehensive feedback on your writing. You can use this tool to proofread and edit articles, blog posts, emails, etc. Grammarly also detects all types of mistakes, including sentence structure issues and misused words. It also gives you suggestions on style changes, punctuation, spelling, and grammar all are in real-time. The free version covers the basics like identifying grammar and spelling mistakes whereas the Premium version offers a lot more functionality, it detects plagiarism in your content, suggests word choice, or adds fluency to it. Features of Grammarly Spelling and Word Suggestion: Grammarly detects basic to advance grammatical errors and also help you why this is an error and suggest to you how you can improve it Create a Personal Dictionary: The Grammarly app allows you to add words to your personal dictionary so that the same mistake isn't highlighted every time you run Grammarly. Different English Style : Check to spell for American, British, Canadian, and Australian English. Plagiarism: This feature helps you detect if a text has been plagiarized by comparing it with over eight billion web pages. Wordiness: This tool will help you check your writing for long and hard-to-read sentences. It also shows you how to shorten sentences so that they are more concise. Passive Voice: The program also notifies users when passive voice is used too frequently in a document. Punctuations: This feature flags all incorrect and missing punctuation. Repetition: The tool provides recommendations for replacing the repeated word. Proposition: Grammarly identifies misplaced and confused prepositions. Plugins: It offers Microsoft Word, Microsoft Outlook, and Google Chrome plugins. What is ProWritingAid? ProWritingAid is a style and grammar checker for content creators and writers. It helps to optimize word choice, punctuation errors, and common grammar mistakes, providing detailed reports to help you improve your writing. ProWritingAid can be used as an add-on to WordPress, Gmail, and Google Docs. The software also offers helpful articles, videos, quizzes, and explanations to help improve your writing. Features of ProWriting Aid Here are some key features of ProWriting Aid: Grammar checker and spell checker: This tool helps you to find all grammatical and spelling errors. Find repeated words: The tool also allows you to search for repeated words and phrases in your content. Context-sensitive style suggestions: You can find the exact style of writing you intend and suggest if it flows well in your writing. Check the readability of your content: Pro Writing Aid helps you identify the strengths and weaknesses of your article by pointing out difficult sentences and paragraphs. Sentence Length: It also indicates the length of your sentences. Check Grammatical error: It also checks your work for any grammatical errors or typos, as well. Overused words: As a writer, you might find yourself using the same word repeatedly. ProWritingAid's overused words checker helps you avoid this lazy writing mistake. Consistency: Check your work for inconsistent usage of open and closed quotation marks. Echoes: Check your writing for uniformly repetitive words and phrases. Difference between Grammarly and Pro-Writing Aid Grammarly and ProWritingAid are well-known grammar-checking software. However, if you're like most people who can't decide which to use, here are some different points that may be helpful in your decision. Grammarly vs ProWritingAid Grammarly is a writing enhancement tool that offers suggestions for grammar, vocabulary, and syntax whereas ProWritingAid offers world-class grammar and style checking, as well as advanced reports to help you strengthen your writing. Grammarly provides Android and IOS apps whereas ProWritingAid doesn't have a mobile or IOS app. Grammarly offers important suggestions about mistakes you've made whereas ProWritingAid shows more suggestions than Grammarly but all recommendations are not accurate Grammarly has a more friendly UI/UX whereas the ProWritingAid interface is not friendly as Grammarly. Grammarly is an accurate grammar checker for non-fiction writing whereas ProWritingAid is an accurate grammar checker for fiction writers. Grammarly finds grammar and punctuation mistakes, whereas ProWritingAid identifies run-on sentences and fragments. Grammarly provides 24/7 support via submitting a ticket and sending emails. ProWritingAid’s support team is available via email, though the response time is approximately 48 hours. Grammarly offers many features in its free plan, whereas ProWritingAid offers some basic features in the free plan. Grammarly does not offer much feedback on big picture writing; ProWritingAid offers complete feedback on big picture writing. Grammarly is a better option for accuracy, whereas ProWritingAid is better for handling fragmented sentences and dialogue. It can be quite useful for fiction writers. ProWritingAid VS Grammarly: Pricing Difference ProWritingAid comes with three pricing structures. The full-year cost of ProWritingAid is $79, while its lifetime plans cost $339. You also can opt for a monthly plan of $20. Grammarly offers a Premium subscription for $30/month for a monthly plan $20/month for quarterly and $12/month for an annual subscription. The Business plan costs $12.50 per month for each member of your company. ProWritingAid vs Grammarly – Pros and Cons Grammarly Pros It allows you to fix common mistakes like grammar and spelling. Offers most features in the free plan Allows you to edit a document without affecting the formatting. Active and passive voice checker Personal dictionary Plagiarism checker (paid version) Proofread your writing and correct all punctuation, grammar, and spelling errors. Allows you to make changes to a document without altering its formatting. Helps users improve vocabulary User-friendly interface Browser extensions and MS word add-ons Available on all major devices and platforms Grammarly will also offer suggestions to improve your style. Enhance the readability of your sentence Free mobile apps Offers free version Grammarly Cons Supports only English Customer support only via email Limits to 150,000 words Subscription plans can be a bit pricey Plagiarism checker is only available in a premium plan Doesn’t offer a free trial No refund policy The free version is ideal for basic spelling and grammatical mistakes, but it does not correct advanced writing issues. Some features are not available for Mac. ProwritingAid Pros It offers more than 20 different reports to help you improve your writing. Less expensive than other grammar checkers. This tool helps you strengthen your writing style as it offers big-picture feedback. ProWritingAid has a life plan with no further payments required. Compatible with Google Docs! Prowritingaid works on both Windows and Mac. They offer more integrations than most tools. ProWritingAid Cons Editing can be a little more time-consuming when you add larger passages of text. ProWritingAid currently offers no mobile app for Android or iOS devices. Plagiarism checker is only available in premium plans. All recommendations are not accurate Summarizing the Ginger VS Grammarly: My Recommendation As both writing assistants are great in their own way, you need to choose the one that suits you best. For example, go for Grammarly if you are a non-fiction writer Go for ProWritingAid if you are a fiction writer. ProWritingAid is better at catching errors found in long-form content. However, Grammarly is more suited to short blog posts and other similar tasks. ProWritingAid helps you clean up your writing by checking for style, structure, and content while Grammarly focuses on grammar and punctuation. Grammarly has a more friendly UI/UX whereas; ProWritingAid offers complete feedback on big picture writing. Both ProWritingAid and Grammarly are awesome writing tools, without a doubt. but as per my experience, Grammarly is a winner here because Grammarly helps you to review and edit your content. Grammarly highlights all the mistakes in your writing within seconds of copying and pasting the content into Grammarly’s editor or using the software’s native feature in other text editors. Not only does it identify tiny grammatical and spelling errors, it tells you when you overlook punctuations where they are needed. And, beyond its plagiarism-checking capabilities, Grammarly helps you proofread your content. Even better, the software offers a free plan that gives you access to some of its features.",
         "en",
         "{'MISC': ['Active and passive voice checker Personal dictionary', 'All recommendations are not accurate Summarizing the Ginger VS Grammarly', 'Allows you to', 'Allows you to make changes to', \"Android and IOS apps whereas ProWritingAid doesn't have\", 'As', 'Available on all major devices and platforms', 'Both ProWritingAid and Grammarly are awesome writing tools', 'Browser extensions and MS word add', 'Check Grammatical error: It also checks your work for any grammatical errors or typos', 'Check the readability of your content', 'Check your work for inconsistent', 'Check your writing for uniformly repetitive', 'Compatible with', 'Cons Editing can be a little more time-consuming when you add', 'Different English Style : Check to spell for American', 'Enhance the readability of your sentence Free mobile', 'Even better', 'Features of ProWriting', 'Find repeated words:', 'Gmail', 'Go for ProWritingAid if you are a fiction', 'Google Chrome plugins', 'Google Docs', 'Grammar checker and spell checker:', 'Grammarly', 'Grammarly will also', 'IOS', 'It', 'It also gives you suggestions on style changes', 'It also shows you how to shorten sentences', 'It can be quite useful for fiction writers', 'It helps to optimize word', 'Microsoft Outlook', 'Microsoft Word', 'My Recommendation As', 'Not only does it', 'Offers most features', 'Overused words:', \"Personal Dictionary: The Grammarly app allows you to add words to your personal dictionary so that the same mistake isn't highlighted every time you run Grammarly\", 'Plagiarism', 'Plagiarism checker', 'Plagiarism checker is only', 'Plugins:', 'Premium subscription for', 'Pro Writing Aid helps you identify the strengths and weaknesses of your article', 'ProWriting Aid', 'Proofread', 'Prowritingaid works on both Windows and Mac', 'Sentence Length: It also indicates the length of your sentences', 'Some features are not available for Mac', 'Spelling and Word', 'The free version covers the basics like identifying grammar', 'The free version is ideal for basic spelling and grammatical mistakes', 'The full-year cost of ProWritingAid is $79', 'The software also', 'This tool helps you strengthen your writing style', 'This tool will help you check your writing for long and hard-to-read sentences', 'What is Grammarly', 'What is ProWritingAid?', 'Which Grammar Checker is Better in', 'WordPress', 'You also can opt for a monthly plan of', 'You can find the exact style of writing you intend and suggest if it flows well in your writing', 'You can use this tool to proofread and edit articles', 'all incorrect and missing punctuation', 'and explanations to help improve your writing', 'and grammar all are in real-time', 'app for Android', 'as well', 'but it does not correct advanced writing issues', 'checker for fiction writers', 'editors', 'go for Grammarly if you are a non-fiction', 'has a life plan with no further payments required', 'has been plagiarized by comparing it with over eight billion web pages', 'iOS', 'it tells you when you overlook punctuations where they are needed', 'or using the software’', 'providing detailed reports to help you improve your writing', 's overused words', 'submitting', 'though the response time is approximately 48 hours', 'whereas ProWritingAid', 'whereas ProWritingAid is better for handling fragmented sentences and', 'without a doubt', 'without affecting the formatting', 'without altering its formatting', 'world-class grammar and style checking', 'you need to choose the one that suits you best'], 'ORG': ['Australian English', 'British', 'Echoes', 'Features of', 'For', 'Helps', \"ProWritingAid'\", 'Pros and', 'The Business', 'Voice', 'spelling', 'the software', 'tiny grammatical and spelling errors'], 'LOC': ['Canadian', 'Consistency', 'Plagiarism', 'ProWritingAid’', 'Repetition', 'and punctuation.it gives you comprehensive feedback on your writing'], 'PER': ['Grammarly', 'Grammarly also detects all types of mistakes', 'Grammarly detects basic to advance grammatical errors and also help you why this is an error and suggest to you how you can improve it Create', 'Grammarly does not offer much', 'Grammarly has', 'Grammarly helps you proofread your content', 'Grammarly vs ProWritingAid', 'However', 'They', 'Wordiness', 'it detects plagiarism in your content', 'punctuation errors', 'videos', 'you might find yourself using the same word repeatedly']}",
         "[-0.01520246546715498, -0.050049301236867905, -0.029023200273513794, 0.014658099040389061, 0.056928884238004684, -0.0048858667723834515, -0.0038938005454838276, 0.07371224462985992, -0.014052757062017918, 0.0415453240275383, 0.020910978317260742, 0.08771711587905884, 0.04353702440857887, -0.03416265919804573, 0.021383799612522125, -0.02243008464574814, 0.021826889365911484, -0.0005037065129727125, -0.08514455705881119, -0.07934768497943878, 0.00037138338666409254, 0.02601483091711998, 0.005511387251317501, 0.0011470739264041185, -0.003169846720993519, 0.003305880120024085, -0.07459330558776855, -0.007738862186670303, -0.025233710184693336, -0.043766144663095474, -0.06691785901784897, 0.019963376224040985, 0.01736288331449032, -0.05785651132464409, 0.005254879128187895, -0.009936723858118057, 0.01753189228475094, 0.023330776020884514, -0.0265406034886837, -0.09468169510364532, -0.06860636919736862, -0.05738770216703415, -0.06517408043146133, -0.01466153934597969, 0.0325508713722229, -0.025431327521800995, 0.02369806542992592, 0.011920263059437275, -0.02654389478266239, 0.09905640780925751, -0.02003655768930912, -0.048482466489076614, 0.03767756000161171, 0.030512001365423203, -0.0286477729678154, 0.026079857721924782, -0.08315034210681915, 0.04294048994779587, -0.01703003980219364, -0.10145800560712814, -0.06399799883365631, 0.012073541060090065, -0.04165126383304596, 0.03253345191478729, 0.0014579251874238253, -0.0005426192656159401, 0.07562139630317688, 0.020148560404777527, -0.01804582215845585, 0.010067042894661427, -0.10077562183141708, 0.03799009323120117, 0.011556094512343407, 0.1253848373889923, 0.015210379846394062, 0.02947644516825676, 0.017909355461597443, -0.06558695435523987, 0.03358300402760506, -0.08903058618307114, 0.03289945051074028, -0.01679041050374508, -0.03030308336019516, 0.01826026663184166, 0.03345236927270889, -0.03299801051616669, 0.1077546626329422, 0.002418333664536476, 0.03659304976463318, -0.03137897700071335, 0.05575067549943924, -0.020481500774621964, 0.10209541767835617, -0.06075957044959068, -0.03455570712685585, 0.01163658406585455, -0.06840381026268005, -0.0174351055175066, -0.028343619778752327, 0.024449974298477173, 0.00433521531522274, -0.006575338542461395, -0.008187606930732727, -0.08183881640434265, -0.012410466559231281, 0.02077125571668148, 0.038095902651548386, 0.05256006494164467, 0.10713598132133484, 0.010422796942293644, 0.0005138569395057857, 0.014176440425217152, -0.03587089478969574, -0.027425676584243774, 0.049204327166080475, 0.016662107780575752, -0.037896331399679184, 0.07697788625955582, 0.11983560025691986, 0.011434350162744522, -0.030754607170820236, 0.02604544721543789, 0.006805592682212591, -0.02363448776304722, 0.07999308407306671, -0.04842888191342354, 0.050009142607450485, 1.8615872407140625e-33, 0.02328738383948803, 0.08249377459287643, -0.08654425293207169, -0.010577225126326084, 0.013506630435585976, -0.007652857806533575, -0.056637175381183624, 0.05272359400987625, -0.04529833793640137, -0.04531332105398178, 0.1046229749917984, -0.04986448585987091, -0.007429677993059158, 0.09043051302433014, 0.11428370326757431, 0.003235356416553259, 0.04065997526049614, -0.02663169428706169, -0.013747596181929111, 0.08748289942741394, 0.02891530655324459, -0.016883352771401405, 0.039111848920583725, -0.08888249099254608, -0.020483678206801414, -0.07383124530315399, 0.09998660534620285, 0.06106293946504593, 0.03177947551012039, 0.02151578478515148, -0.02600119262933731, -0.15533971786499023, -0.015455903485417366, -0.0021240233909338713, -0.023195601999759674, -0.0799981951713562, -0.04225002974271774, -0.07533267885446548, 0.007189310155808926, -0.035029686987400055, -0.09223763644695282, -0.02658211626112461, -0.011616007424890995, 0.007359757088124752, 0.04079246148467064, 0.07642562687397003, -0.023018039762973785, 0.08333998173475266, 0.050571683794260025, -0.002713801572099328, 0.033164963126182556, 0.03152279928326607, -0.026507075875997543, 0.049505751579999924, -0.05162839964032173, 0.08866098523139954, 0.020660707727074623, -0.01461248192936182, 0.025231804698705673, 0.012893835082650185, 0.06700020283460617, 0.061056606471538544, 0.018500206992030144, -0.02624783292412758, -0.005838490556925535, 0.06536340713500977, -0.057715658098459244, 0.03327655792236328, 0.011468672193586826, -0.052976083010435104, -0.10980205982923508, -0.05759564787149429, -0.004450737498700619, 0.09215158224105835, -0.006478251423686743, -0.03456585854291916, 0.057408127933740616, -0.014409137889742851, -0.007119222078472376, 0.028318587690591812, -0.0928407832980156, 0.03710446134209633, 0.019220765680074692, 0.05169818177819252, -0.05098675936460495, -0.07519353926181793, -0.029454579576849937, 0.04101967811584473, 0.021837912499904633, 0.015669407323002815, 0.11248207837343216, 0.00028732477221637964, 0.027298031374812126, 0.02055050991475582, -0.04178740084171295, -3.986191342424612e-33, -0.03429246321320534, -0.03783915564417839, -0.007355075795203447, 0.13627658784389496, -0.10535667836666107, -0.04712271690368652, -0.07813241332769394, 0.023238545283675194, 0.09800039231777191, -0.1182299479842186, -0.020585622638463974, 0.008748459629714489, -0.06565724313259125, -0.002978432457894087, 0.012983232736587524, -0.025611748918890953, -0.028465334326028824, -0.04781092330813408, -0.02027176506817341, -0.005691810976713896, 0.08693010360002518, 0.10052234679460526, -0.03668269142508507, 0.015640094876289368, -0.05143234133720398, -0.010575519874691963, -0.05927813798189163, 0.08753759413957596, -0.05444202199578285, 0.023763375356793404, -0.02246064506471157, 0.08623319119215012, -0.03178434818983078, -0.04848896339535713, -0.0610702708363533, -0.012707248330116272, -0.001357751665636897, -0.0037621716037392616, -0.009504486806690693, 0.03258970379829407, 0.04782618209719658, 0.06244916841387749, 0.007962829433381557, -0.022611575201153755, 0.009789127856492996, 0.015784690156579018, -0.05902129039168358, -0.06399687379598618, 0.10261210799217224, 0.11538699269294739, -0.020873935893177986, 0.021119432523846626, -0.06286460906267166, -0.0025309640914201736, 0.006131565663963556, 0.0026194609235972166, 0.03364940360188484, -0.08737533539533615, -0.073427714407444, -0.03572741895914078, -0.10742711275815964, 0.07181251794099808, 0.056515924632549286, 0.04281452298164368, 0.06344128400087357, -0.0791405513882637, 0.03244215250015259, -0.03693672642111778, 0.07938475906848907, -0.019753223285079002, -0.010571150109171867, -0.04466106742620468, -0.037368983030319214, 0.009637040086090565, -0.0533490814268589, 0.07123146951198578, 0.06695866584777832, -0.006849678233265877, -0.04356924444437027, -0.0236491896212101, 0.05617055296897888, -0.002917269943282008, -0.047613851726055145, -0.013963035307824612, -0.0378941148519516, 0.03678862750530243, -0.02756691910326481, 0.04293689504265785, 0.018762405961751938, 0.042198099195957184, 0.014978503808379173, -0.0029273375403136015, 0.019589576870203018, 0.020640213042497635, -0.06297411769628525, -4.924675423012559e-08, 0.0028687254525721073, -0.05388769507408142, 0.023078665137290955, -0.005887189880013466, -0.009294464252889156, -0.05930008366703987, -0.012946118600666523, 0.022181933745741844, 0.010794040746986866, -0.1013759896159172, 0.005574121605604887, -0.008041572757065296, -0.12471865862607956, -0.12096256017684937, -0.037955984473228455, 0.08780436962842941, -0.023638971149921417, 0.05640392377972603, -0.10977164655923843, 0.01076764427125454, -0.012866063974797726, -0.045395731925964355, -0.1285674124956131, 0.03278788924217224, -0.013894205912947655, 0.03305395320057869, 0.021542411297559738, 0.028875013813376427, -0.05376336723566055, -0.003409069497138262, 0.003168428083881736, 0.04200784116983414, 0.019189421087503433, -0.02474665269255638, 0.0132673354819417, 0.022382328286767006, 0.06298411637544632, 0.02649291791021824, -0.007151633035391569, 0.0925150141119957, 0.06976775825023651, -0.0029639287386089563, 0.02098984271287918, -0.0036110614892095327, 0.05874426290392876, -0.060424353927373886, 0.0007518809288740158, -0.08554218709468842, -0.01402635034173727, -0.0711703971028328, 0.0035943281836807728, -0.05387473106384277, 0.055348556488752365, -0.03882840275764465, -0.017984608188271523, 0.07417155802249908, -0.056455228477716446, 0.013265763409435749, 0.04738248884677887, 0.04666348174214363, 0.07496880739927292, 0.043323028832674026, 0.07744408398866653, -0.022446976974606514]",
         "0.174"
        ],
        [
         "20",
         "30",
         "What is Blockchain: Everything You Need to Know (2022)",
         "If you want to pay online, you need to register an account and provide credit card information. If you don't have a credit card, you can pay with bank transfer. With the rise of cryptocurrencies, these methods may become old. Imagine a world in which you can do transactions and many other things without having to give your personal information. A world in which you don’t need to rely on banks or governments anymore. Sounds amazing, right? That’s exactly what blockchain technology allows us to do. It’s like your computer’s hard drive. blockchain is a technology that lets you store data in digital blocks, which are connected together like links in a chain. Blockchain technology was originally invented in 1991 by two mathematicians, Stuart Haber and W. Scot Stornetta. They first proposed the system to ensure that timestamps could not be tampered with. A few years later, in 1998, software developer Nick Szabo proposed using a similar kind of technology to secure a digital payments system he called “Bit Gold.” However, this innovation was not adopted until Satoshi Nakamoto claimed to have invented the first Blockchain and Bitcoin. So, What is Blockchain? A blockchain is a distributed database shared between the nodes of a computer network. It saves information in digital format. Many people first heard of blockchain technology when they started to look up information about bitcoin. Blockchain is used in cryptocurrency systems to ensure secure, decentralized records of transactions. Blockchain allowed people to guarantee the fidelity and security of a record of data without the need for a third party to ensure accuracy. To understand how a blockchain works, Consider these basic steps: Blockchain collects information in “blocks”. A block has a storage capacity, and once it's used up, it can be closed and linked to a previously served block. Blocks form chains, which are called “Blockchains.” More information will be added to the block with the most content until its capacity is full. The process repeats itself. Each block in the chain has an exact timestamp and can't be changed. Let’s get to know more about the blockchain. How does blockchain work? Blockchain records digital information and distributes it across the network without changing it. The information is distributed among many users and stored in an immutable, permanent ledger that can't be changed or destroyed. That's why blockchain is also called \"Distributed Ledger Technology\" or DLT. Here’s how it works: Someone or a computer will transacts The transaction is transmitted throughout the network. A network of computers can confirm the transaction. When it is confirmed a transaction is added to a block The blocks are linked together to create a history. And that’s the beauty of it! The process may seem complicated, but it’s done in minutes with modern technology. And because technology is advancing rapidly, I expect things to move even more quickly than ever. A new transaction is added to the system. It is then relayed to a network of computers located around the world. The computers then solve equations to ensure the authenticity of the transaction. Once a transaction is confirmed, it is placed in a block after the confirmation. All of the blocks are chained together to create a permanent history of every transaction. How are Blockchains used? Even though blockchain is integral to cryptocurrency, it has other applications. For example, blockchain can be used for storing reliable data about transactions. Many people confuse blockchain with cryptocurrencies like bitcoin and ethereum. Blockchain already being adopted by some big-name companies, such as Walmart, AIG, Siemens, Pfizer, and Unilever. For example, IBM's Food Trust uses blockchain to track food's journey before reaching its final destination. Although some of you may consider this practice excessive, food suppliers and manufacturers adhere to the policy of tracing their products because bacteria such as E. coli and Salmonella have been found in packaged foods. In addition, there have been isolated cases where dangerous allergens such as peanuts have accidentally been introduced into certain products. Tracing and identifying the sources of an outbreak is a challenging task that can take months or years. Thanks to the Blockchain, however, companies now know exactly where their food has been—so they can trace its location and prevent future outbreaks. Blockchain technology allows systems to react much faster in the event of a hazard. It also has many other uses in the modern world. What is Blockchain Decentralization? Blockchain technology is safe, even if it’s public. People can access the technology using an internet connection. Have you ever been in a situation where you had all your data stored at one place and that one secure place got compromised? Wouldn't it be great if there was a way to prevent your data from leaking out even when the security of your storage systems is compromised? Blockchain technology provides a way of avoiding this situation by using multiple computers at different locations to store information about transactions. If one computer experiences problems with a transaction, it will not affect the other nodes. Instead, other nodes will use the correct information to cross-reference your incorrect node. This is called “Decentralization,” meaning all the information is stored in multiple places. Blockchain guarantees your data's authenticity—not just its accuracy, but also its irreversibility. It can also be used to store data that are difficult to register, like legal contracts, state identifications, or a company's product inventory. Pros and Cons of Blockchain Blockchain has many advantages and disadvantages. Pros Accuracy is increased because there is no human involvement in the verification process. One of the great things about decentralization is that it makes information harder to tamper with. Safe, private, and easy transactions Provides a banking alternative and safe storage of personal information Cons Data storage has limits. The regulations are always changing, as they differ from place to place. It has a risk of being used for illicit activities Frequently Asked Questions About Blockchain I’ll answer the most frequently asked questions about blockchain in this section. Is Blockchain a cryptocurrency? Blockchain is not a cryptocurrency but a technology that makes cryptocurrencies possible. It's a digital ledger that records every transaction seamlessly. Is it possible for Blockchain to be hacked? Yes, blockchain can be theoretically hacked, but it is a complicated task to be achieved. A network of users constantly reviews it, which makes hacking the blockchain difficult. What is the most prominent blockchain company? Coinbase Global is currently the biggest blockchain company in the world. The company runs a commendable infrastructure, services, and technology for the digital currency economy. Who owns Blockchain? Blockchain is a decentralized technology. It’s a chain of distributed ledgers connected with nodes. Each node can be any electronic device. Thus, one owns blockhain. What is the difference between Bitcoin and Blockchain technology? Bitcoin is a cryptocurrency, which is powered by Blockchain technology while Blockchain is a distributed ledger of cryptocurrency What is the difference between Blockchain and a Database? Generally a database is a collection of data which can be stored and organized using a database management system. The people who have access to the database can view or edit the information stored there. The client-server network architecture is used to implement databases. whereas a blockchain is a growing list of records, called blocks, stored in a distributed system. Each block contains a cryptographic hash of the previous block, timestamp and transaction information. Modification of data is not allowed due to the design of the blockchain. The technology allows decentralized control and eliminates risks of data modification by other parties. Final Saying Blockchain has a wide spectrum of applications and, over the next 5-10 years, we will likely see it being integrated into all sorts of industries. From finance to healthcare, blockchain could revolutionize the way we store and share data. Although there is some hesitation to adopt blockchain systems right now, that won't be the case in 2022-2023 (and even less so in 2026). Once people become more comfortable with the technology and understand how it can work for them, owners, CEOs and entrepreneurs alike will be quick to leverage blockchain technology for their own gain. Hope you like this article if you have any question let me know in the comments section FOLLOW US ON TWITTER Follow @AdilAhmad_c",
         "If you want to pay online, you need to register an account and provide credit card information. If you don't have a credit card, you can pay with bank transfer. With the rise of cryptocurrencies, these methods may become old.\n\nImagine a world in which you can do transactions and many other things without having to give your personal information. A world in which you don’t need to rely on banks or governments anymore. Sounds amazing, right? That’s exactly what blockchain technology allows us to do.\n\nIt’s like your computer’s hard drive. blockchain is a technology that lets you store data in digital blocks, which are connected together like links in a chain.\n\nBlockchain technology was originally invented in 1991 by two mathematicians, Stuart Haber and W. Scot Stornetta. They first proposed the system to ensure that timestamps could not be tampered with.\n\nA few years later, in 1998, software developer Nick Szabo proposed using a similar kind of technology to secure a digital payments system he called “Bit Gold.” However, this innovation was not adopted until Satoshi Nakamoto claimed to have invented the first Blockchain and Bitcoin.\n\nSo, What is Blockchain?\n\nA blockchain is a distributed database shared between the nodes of a computer network. It saves information in digital format. Many people first heard of blockchain technology when they started to look up information about bitcoin.\n\nBlockchain is used in cryptocurrency systems to ensure secure, decentralized records of transactions.\n\nBlockchain allowed people to guarantee the fidelity and security of a record of data without the need for a third party to ensure accuracy.\n\nTo understand how a blockchain works, Consider these basic steps:\n\nBlockchain collects information in “blocks”.\n\nA block has a storage capacity, and once it's used up, it can be closed and linked to a previously served block.\n\nBlocks form chains, which are called “Blockchains.”\n\nMore information will be added to the block with the most content until its capacity is full. The process repeats itself.\n\nEach block in the chain has an exact timestamp and can't be changed.\n\nLet’s get to know more about the blockchain.\n\nHow does blockchain work?\n\nBlockchain records digital information and distributes it across the network without changing it. The information is distributed among many users and stored in an immutable, permanent ledger that can't be changed or destroyed. That's why blockchain is also called \"Distributed Ledger Technology\" or DLT.\n\nHere’s how it works:\n\nSomeone or a computer will transacts\n\nThe transaction is transmitted throughout the network.\n\nA network of computers can confirm the transaction.\n\nWhen it is confirmed a transaction is added to a block\n\nThe blocks are linked together to create a history.\n\nAnd that’s the beauty of it! The process may seem complicated, but it’s done in minutes with modern technology. And because technology is advancing rapidly, I expect things to move even more quickly than ever.\n\nA new transaction is added to the system. It is then relayed to a network of computers located around the world. The computers then solve equations to ensure the authenticity of the transaction.\n\nOnce a transaction is confirmed, it is placed in a block after the confirmation. All of the blocks are chained together to create a permanent history of every transaction.\n\nHow are Blockchains used?\n\nEven though blockchain is integral to cryptocurrency, it has other applications. For example, blockchain can be used for storing reliable data about transactions. Many people confuse blockchain with cryptocurrencies like bitcoin and ethereum.\n\nBlockchain already being adopted by some big-name companies, such as Walmart, AIG, Siemens, Pfizer, and Unilever. For example, IBM's Food Trust uses blockchain to track food's journey before reaching its final destination.\n\nAlthough some of you may consider this practice excessive, food suppliers and manufacturers adhere to the policy of tracing their products because bacteria such as E. coli and Salmonella have been found in packaged foods. In addition, there have been isolated cases where dangerous allergens such as peanuts have accidentally been introduced into certain products.\n\nTracing and identifying the sources of an outbreak is a challenging task that can take months or years. Thanks to the Blockchain, however, companies now know exactly where their food has been—so they can trace its location and prevent future outbreaks.\n\nBlockchain technology allows systems to react much faster in the event of a hazard. It also has many other uses in the modern world.\n\nWhat is Blockchain Decentralization?\n\nBlockchain technology is safe, even if it’s public. People can access the technology using an internet connection.\n\nHave you ever been in a situation where you had all your data stored at one place and that one secure place got compromised? Wouldn't it be great if there was a way to prevent your data from leaking out even when the security of your storage systems is compromised?\n\nBlockchain technology provides a way of avoiding this situation by using multiple computers at different locations to store information about transactions. If one computer experiences problems with a transaction, it will not affect the other nodes.\n\nInstead, other nodes will use the correct information to cross-reference your incorrect node. This is called “Decentralization,” meaning all the information is stored in multiple places.\n\nBlockchain guarantees your data's authenticity—not just its accuracy, but also its irreversibility. It can also be used to store data that are difficult to register, like legal contracts, state identifications, or a company's product inventory.\n\nPros and Cons of Blockchain\n\nBlockchain has many advantages and disadvantages.\n\nPros\n\nAccuracy is increased because there is no human involvement in the verification process.\n\nOne of the great things about decentralization is that it makes information harder to tamper with.\n\nSafe, private, and easy transactions\n\nProvides a banking alternative and safe storage of personal information\n\nCons\n\nData storage has limits.\n\nThe regulations are always changing, as they differ from place to place.\n\nIt has a risk of being used for illicit activities\n\nFrequently Asked Questions About Blockchain\n\nI’ll answer the most frequently asked questions about blockchain in this section.\n\nIs Blockchain a cryptocurrency?\n\nBlockchain is not a cryptocurrency but a technology that makes cryptocurrencies possible. It's a digital ledger that records every transaction seamlessly.\n\nIs it possible for Blockchain to be hacked?\n\nYes, blockchain can be theoretically hacked, but it is a complicated task to be achieved. A network of users constantly reviews it, which makes hacking the blockchain difficult.\n\nWhat is the most prominent blockchain company?\n\nCoinbase Global is currently the biggest blockchain company in the world. The company runs a commendable infrastructure, services, and technology for the digital currency economy.\n\nWho owns Blockchain?\n\nBlockchain is a decentralized technology. It’s a chain of distributed ledgers connected with nodes. Each node can be any electronic device. Thus, one owns blockhain.\n\nWhat is the difference between Bitcoin and Blockchain technology?\n\nBitcoin is a cryptocurrency, which is powered by Blockchain technology while Blockchain is a distributed ledger of cryptocurrency\n\nWhat is the difference between Blockchain and a Database?\n\nGenerally a database is a collection of data which can be stored and organized using a database management system. The people who have access to the database can view or edit the information stored there. The client-server network architecture is used to implement databases. whereas a blockchain is a growing list of records, called blocks, stored in a distributed system. Each block contains a cryptographic hash of the previous block, timestamp and transaction information. Modification of data is not allowed due to the design of the blockchain. The technology allows decentralized control and eliminates risks of data modification by other parties.\n\nFinal Saying\n\nBlockchain has a wide spectrum of applications and, over the next 5-10 years, we will likely see it being integrated into all sorts of industries. From finance to healthcare, blockchain could revolutionize the way we store and share data. Although there is some hesitation to adopt blockchain systems right now, that won't be the case in 2022-2023 (and even less so in 2026). Once people become more comfortable with the technology and understand how it can work for them, owners, CEOs and entrepreneurs alike will be quick to leverage blockchain technology for their own gain. Hope you like this article if you have any question let me know in the comments section\n\nFOLLOW US ON TWITTER",
         "2022-04-18T05:49:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/04/what-is-blockchain-everything-you-need.html",
         "2025-07-26T05:41:35.832954",
         "If you want to pay online, you need to register an account and provide credit card information. If you don't have a credit card, you can pay with bank transfer. With the rise of cryptocurrencies, these methods may become old. Imagine a world in which you can do transactions and many other things without having to give your personal information. A world in which you don’t need to rely on banks or governments anymore. Sounds amazing, right? That’s exactly what blockchain technology allows us to do. It’s like your computer’s hard drive. blockchain is a technology that lets you store data in digital blocks, which are connected together like links in a chain. Blockchain technology was originally invented in 1991 by two mathematicians, Stuart Haber and W. Scot Stornetta. They first proposed the system to ensure that timestamps could not be tampered with. A few years later, in 1998, software developer Nick Szabo proposed using a similar kind of technology to secure a digital payments system he called “Bit Gold.” However, this innovation was not adopted until Satoshi Nakamoto claimed to have invented the first Blockchain and Bitcoin. So, What is Blockchain? A blockchain is a distributed database shared between the nodes of a computer network. It saves information in digital format. Many people first heard of blockchain technology when they started to look up information about bitcoin. Blockchain is used in cryptocurrency systems to ensure secure, decentralized records of transactions. Blockchain allowed people to guarantee the fidelity and security of a record of data without the need for a third party to ensure accuracy. To understand how a blockchain works, Consider these basic steps: Blockchain collects information in “blocks”. A block has a storage capacity, and once it's used up, it can be closed and linked to a previously served block. Blocks form chains, which are called “Blockchains.” More information will be added to the block with the most content until its capacity is full. The process repeats itself. Each block in the chain has an exact timestamp and can't be changed. Let’s get to know more about the blockchain. How does blockchain work? Blockchain records digital information and distributes it across the network without changing it. The information is distributed among many users and stored in an immutable, permanent ledger that can't be changed or destroyed. That's why blockchain is also called \"Distributed Ledger Technology\" or DLT. Here’s how it works: Someone or a computer will transacts The transaction is transmitted throughout the network. A network of computers can confirm the transaction. When it is confirmed a transaction is added to a block The blocks are linked together to create a history. And that’s the beauty of it! The process may seem complicated, but it’s done in minutes with modern technology. And because technology is advancing rapidly, I expect things to move even more quickly than ever. A new transaction is added to the system. It is then relayed to a network of computers located around the world. The computers then solve equations to ensure the authenticity of the transaction. Once a transaction is confirmed, it is placed in a block after the confirmation. All of the blocks are chained together to create a permanent history of every transaction. How are Blockchains used? Even though blockchain is integral to cryptocurrency, it has other applications. For example, blockchain can be used for storing reliable data about transactions. Many people confuse blockchain with cryptocurrencies like bitcoin and ethereum. Blockchain already being adopted by some big-name companies, such as Walmart, AIG, Siemens, Pfizer, and Unilever. For example, IBM's Food Trust uses blockchain to track food's journey before reaching its final destination. Although some of you may consider this practice excessive, food suppliers and manufacturers adhere to the policy of tracing their products because bacteria such as E. coli and Salmonella have been found in packaged foods. In addition, there have been isolated cases where dangerous allergens such as peanuts have accidentally been introduced into certain products. Tracing and identifying the sources of an outbreak is a challenging task that can take months or years. Thanks to the Blockchain, however, companies now know exactly where their food has been—so they can trace its location and prevent future outbreaks. Blockchain technology allows systems to react much faster in the event of a hazard. It also has many other uses in the modern world. What is Blockchain Decentralization? Blockchain technology is safe, even if it’s public. People can access the technology using an internet connection. Have you ever been in a situation where you had all your data stored at one place and that one secure place got compromised? Wouldn't it be great if there was a way to prevent your data from leaking out even when the security of your storage systems is compromised? Blockchain technology provides a way of avoiding this situation by using multiple computers at different locations to store information about transactions. If one computer experiences problems with a transaction, it will not affect the other nodes. Instead, other nodes will use the correct information to cross-reference your incorrect node. This is called “Decentralization,” meaning all the information is stored in multiple places. Blockchain guarantees your data's authenticity—not just its accuracy, but also its irreversibility. It can also be used to store data that are difficult to register, like legal contracts, state identifications, or a company's product inventory. Pros and Cons of Blockchain Blockchain has many advantages and disadvantages. Pros Accuracy is increased because there is no human involvement in the verification process. One of the great things about decentralization is that it makes information harder to tamper with. Safe, private, and easy transactions Provides a banking alternative and safe storage of personal information Cons Data storage has limits. The regulations are always changing, as they differ from place to place. It has a risk of being used for illicit activities Frequently Asked Questions About Blockchain I’ll answer the most frequently asked questions about blockchain in this section. Is Blockchain a cryptocurrency? Blockchain is not a cryptocurrency but a technology that makes cryptocurrencies possible. It's a digital ledger that records every transaction seamlessly. Is it possible for Blockchain to be hacked? Yes, blockchain can be theoretically hacked, but it is a complicated task to be achieved. A network of users constantly reviews it, which makes hacking the blockchain difficult. What is the most prominent blockchain company? Coinbase Global is currently the biggest blockchain company in the world. The company runs a commendable infrastructure, services, and technology for the digital currency economy. Who owns Blockchain? Blockchain is a decentralized technology. It’s a chain of distributed ledgers connected with nodes. Each node can be any electronic device. Thus, one owns blockhain. What is the difference between Bitcoin and Blockchain technology? Bitcoin is a cryptocurrency, which is powered by Blockchain technology while Blockchain is a distributed ledger of cryptocurrency What is the difference between Blockchain and a Database? Generally a database is a collection of data which can be stored and organized using a database management system. The people who have access to the database can view or edit the information stored there. The client-server network architecture is used to implement databases. whereas a blockchain is a growing list of records, called blocks, stored in a distributed system. Each block contains a cryptographic hash of the previous block, timestamp and transaction information. Modification of data is not allowed due to the design of the blockchain. The technology allows decentralized control and eliminates risks of data modification by other parties. Final Saying Blockchain has a wide spectrum of applications and, over the next 5-10 years, we will likely see it being integrated into all sorts of industries. From finance to healthcare, blockchain could revolutionize the way we store and share data. Although there is some hesitation to adopt blockchain systems right now, that won't be the case in 2022-2023 (and even less so in 2026). Once people become more comfortable with the technology and understand how it can work for them, owners, CEOs and entrepreneurs alike will be quick to leverage blockchain technology for their own gain. Hope you like this article if you have any question let me know in the comments section FOLLOW US ON TWITTER",
         "en",
         "{'MISC': ['All of the blocks are chained together to create', 'Although some of you may consider this practice', 'And that’s the beauty of it!', 'Bitcoin is a cryptocurrency', 'Blockchain allowed people to guarantee the fidelity and security of', 'Blockchain is used in cryptocurrency systems', 'Blockchain records digital information and distributes it across the network without changing it', 'Cons Data', 'Consider these basic steps', 'Distributed Ledger Technology', 'Each node can be any electronic device', 'Final Saying Blockchain has a wide spectrum of applications and', 'From finance to healthcare', 'Have you ever been in', 'Hope you like', 'How are Blockchains used?', 'How does blockchain work', 'I expect things to move even more quickly than ever', 'If one computer experiences problems with', 'If you want to pay online', 'Instead', 'Is Blockchain', 'Is it possible for Blockchain to be hacked', 'It also has many other uses in the modern world', 'It can also be used to store data that are difficult to register', 'It has a risk of being used for illicit activities Frequently Asked', \"It'\", 'It’', 'It’s like your computer’', 'Let’s get to know more about the blockchain', 'Many people', 'Many people first heard of blockchain technology when they started to look up information about bitcoin', 'Modification of data is not allowed due to the design of the blockchain', 'More information will be added to the block with the most content until its capacity is full', 'Once', 'Once people become more comfortable with the technology and understand how it can work for them', 'One of the great things about decentralization is that it makes', 'Questions About Blockchain I’ll answer the most frequently', 'So', 'Someone or', 'Thanks to the Blockchain', \"That'\", 'That’', 'The', 'The blocks are linked together to create', 'The people', 'The process repeats itself', 'The regulations are always changing', 'They first proposed the system to ensure', 'This is called “Decentralization', 'Thus', 'To understand how', 'Tracing and identifying the sources of an outbreak is', 'What is Blockchain', 'What is Blockchain Decentralization', 'What is the difference between Bitcoin and Blockchain technology', 'What is the difference between Blockchain and a Database', 'What is the most', 'When it is', 'With the rise of cryptocurrencies', \"Wouldn't it be great if there was a way to prevent your data from leaking out even when the security of your storage systems is compromised\", 'and easy transactions', \"and once it's used up\", 'and technology for the digital currency economy', 'hard drive', 'it’', 'like legal contracts', 'right?', 'suppliers and manufacturers adhere to the policy of tracing their products because bacteria such as E. coli and Salmonella have been found in packaged foods', 'which are connected together like links in', 'world in which you can do transactions and many other things without having to give your personal information', 'world in which you don’t need to rely on banks or', 'you can pay with bank transfer', 'you need to', '” meaning all the information is stored in multiple places'], 'PER': ['Blockchain', 'Blockchain already being', 'Blockchain is not', 'Blocks', 'Here’', \"If you don't have\", 'Nick Szabo', 'Sounds amazing', 'Stuart Haber and W. Scot Stornetta', 'blockchain could revolutionize the way we store and share data', 'however', 'not just its accuracy', 'until Satoshi', 'whereas'], 'ORG': ['AIG', 'Blockchain and Bitcoin', 'CEOs and entrepreneurs alike will be quick to leverage blockchain technology for their own gain', 'Coinbase Global is currently the biggest blockchain company in the world', 'FOLLOW US ON TWITTER', 'Food Trust', 'For', \"IBM'\", 'Pros and Cons of Blockchain Blockchain', 'Safe', 'Siemens', 'The company', 'Who owns Blockchain', 'Yes', 'reviews it', 'software'], 'LOC': ['For', 'Generally', 'Pfizer', 'and Unilever', 'called blocks', \"your data's authenticity\"]}",
         "[-0.06078806519508362, 0.044517211616039276, -0.015088620595633984, 0.01045915950089693, -0.021350525319576263, -0.0025724805891513824, 0.04148519039154053, 0.07800526171922684, 0.09000035375356674, -0.019619889557361603, -0.04140466824173927, 0.03045491687953472, -0.029840124770998955, -0.015668362379074097, -0.011982429772615433, -0.06741834431886673, -0.02568460814654827, -0.0211025420576334, 0.009880122728645802, -0.03150331228971481, -0.004090678412467241, 0.009932137094438076, -0.03076920472085476, 0.04323443025350571, -0.031504735350608826, 0.0010084871901199222, 0.0005477183731272817, -0.05914847180247307, -0.04161238297820091, -0.0012396170059219003, 0.006930855102837086, -0.010253028012812138, 0.05680857598781586, 0.009762274101376534, -0.14832356572151184, -0.02390448935329914, 0.11962773650884628, 0.03268472105264664, -0.04026570916175842, -0.02821330353617668, -0.004158094059675932, -0.0766240581870079, 0.054424263536930084, -0.0072311279363930225, 0.028638388961553574, 0.022897420451045036, 0.040381450206041336, 0.048805370926856995, -0.05870966240763664, 0.011119253002107143, -0.0060944692231714725, 0.03515198454260826, 0.035063691437244415, 0.04919370636343956, -0.04035341367125511, -0.010593662038445473, 0.11339203268289566, 0.01432231068611145, 0.041290026158094406, -0.06726886332035065, 0.005339448340237141, -0.028414631262421608, 0.06940731406211853, 0.019872242584824562, 0.06122154742479324, 0.04291325807571411, -0.024683356285095215, 0.10712415724992752, 6.973086419748142e-05, 0.016393719241023064, -0.006775031331926584, 0.0036839835811406374, -0.012074695900082588, 0.036145132035017014, 0.023055238649249077, -0.09176970273256302, 0.07378340512514114, 0.0429571196436882, 0.02250945195555687, 0.1094449833035469, -0.027966130524873734, -0.02160179428756237, 0.05355837941169739, 0.0008893161430023611, -0.08669689297676086, 0.015977198258042336, -0.049002546817064285, 0.05277321860194206, 0.014119616709649563, -0.1701219081878662, 0.07139630615711212, 0.030802415683865547, -0.03673965856432915, -0.04841064661741257, 0.09165317565202713, -0.09617577493190765, 0.0484430156648159, 0.010105174966156483, 0.025716692209243774, -0.014097805134952068, 0.05857069417834282, 0.002921751467511058, 0.03168267384171486, -0.007298212964087725, 0.06746569275856018, 0.07876116037368774, 0.05496368184685707, 0.04745941236615181, 0.07444988936185837, -0.04008989781141281, -0.08036183565855026, -0.05870386213064194, -0.0550733357667923, -0.05549507215619087, -0.014611543156206608, -0.014940256252884865, -0.11430279910564423, 0.044702306389808655, 0.02881775051355362, 0.05210607498884201, 0.043083030730485916, 0.021108658984303474, -0.08937256038188934, -0.08673926442861557, 0.04356985539197922, -0.020722702145576477, 0.03933614864945412, 3.740056784357841e-33, 0.020674973726272583, -7.769094372633845e-05, 0.05897486209869385, -0.02459615282714367, 0.027609841898083687, 0.005141122732311487, -0.007031300570815802, 0.018985804170370102, -0.005352988373488188, 0.026938943192362785, 0.06286334246397018, -0.09748416393995285, 0.013745422475039959, 0.09244026988744736, 0.06928501278162003, -0.015955209732055664, -0.07157418876886368, -0.1263842135667801, 0.16549214720726013, 0.03797794133424759, 0.05842297524213791, -0.02061331272125244, 0.07237900793552399, -0.0019266331801190972, 9.78585085249506e-05, -0.0035719946026802063, -0.040987279266119, -0.009966826997697353, 0.09309487789869308, -0.02906016819179058, 0.03192739933729172, -0.03340313956141472, 0.011236208491027355, 0.017199764028191566, 0.06616470962762833, 0.009925001300871372, 0.0210911612957716, -0.07027745246887207, 0.059477582573890686, -0.08698426187038422, 0.0026310801040381193, -0.032573550939559937, -0.02232632413506508, -0.010701047256588936, -0.012357696890830994, 0.0018678033957257867, 0.06502345949411392, -0.012016243301331997, -0.0623830184340477, 0.025639109313488007, -0.0008907605079002678, 0.06730078905820847, -0.04495619609951973, -0.054805610328912735, -0.03732215240597725, 0.00032404347439296544, -0.029825428500771523, -0.06313897669315338, -0.005474893841892481, -0.014350366778671741, 0.021038420498371124, -0.07793666422367096, 0.034500107169151306, 0.006417672615498304, -0.06951075792312622, 0.022502021864056587, 0.10680203884840012, -0.0341092012822628, 0.03401115536689758, 0.0037823019083589315, 0.00828675925731659, -0.022006070241332054, -0.04983455687761307, -0.0054430426098406315, 0.01872476190328598, 0.058097243309020996, 0.02076634392142296, -0.039678752422332764, -0.08120415359735489, 0.05800984427332878, -0.027885491028428078, -0.06337744742631912, 0.020781690254807472, 0.041234686970710754, 0.04881032556295395, 0.05320385843515396, 0.0020531711634248495, 0.03671379014849663, 0.020816398784518242, -0.07682385295629501, -0.012214569374918938, -0.06449712812900543, 0.014053565450012684, 0.004461027681827545, 0.07874912768602371, -5.3290874764055166e-33, -0.025501171126961708, -0.07224595546722412, -0.020886335521936417, 0.019605126231908798, 0.014330700971186161, -0.061040595173835754, -0.04982832074165344, 0.0049126832745969296, -0.01617683656513691, 0.04353974759578705, -0.028966180980205536, 0.015309710055589676, -0.022151067852973938, -0.01812961883842945, 0.03131575882434845, -0.025871779769659042, -0.05817922204732895, -0.0565384216606617, -0.017228765413165092, -0.059597138315439224, 0.05172636732459068, -0.04292941838502884, -0.04523560777306557, -0.0044760750606656075, 0.009248650632798672, 0.013458595611155033, -0.10467838495969772, -0.037776749581098557, 0.07038471847772598, 0.09082012623548508, -0.021584516391158104, -0.074195496737957, -0.009405412711203098, -0.07126567512750626, -0.02025098167359829, 0.06806338578462601, -0.003783171297982335, 0.044440317898988724, -0.027864869683980942, -0.09674123674631119, -0.021940795704722404, -0.018512429669499397, -0.024973277002573013, -0.02998928725719452, -0.050534967333078384, 0.01633831113576889, -0.07665363699197769, 0.10551979392766953, -0.04210740700364113, -0.03283517807722092, 0.06964773684740067, 0.05128844082355499, 0.038899410516023636, -0.06805092841386795, -0.051728758960962296, 0.0574694499373436, -0.0021632094867527485, 0.04241607338190079, 0.0027167575899511576, 0.04007849097251892, -0.03937743604183197, -0.07126081734895706, -0.002771374536678195, 0.07314209640026093, -0.01458609290421009, -0.02253575436770916, 0.04559794440865517, 0.02577044814825058, -0.060613956302404404, -0.046045366674661636, -0.011609151028096676, 0.031516194343566895, -0.026897279545664787, 0.010094980709254742, -0.01708873361349106, 0.04314355179667473, 0.01033210288733244, -0.023662906140089035, -0.08369438350200653, 0.039206989109516144, 0.0740465596318245, -0.011656847782433033, 0.0695519968867302, -0.0515458770096302, 0.042489610612392426, -0.030146921053528786, 0.0332694947719574, -0.04833180829882622, -0.07514441758394241, -0.13940152525901794, -0.03984925523400307, -0.03659290820360184, -0.0867362767457962, 0.06455174088478088, -0.08862476795911789, -5.808068692658708e-08, -0.006267509888857603, -0.0681910514831543, 0.0258924663066864, -0.03484950214624405, -0.027078889310359955, -0.0005413701292127371, 0.0937337800860405, 0.013480426743626595, -0.06258915364742279, 0.00948736909776926, -0.07754162698984146, 0.03049098141491413, -0.019933205097913742, -0.0070774732157588005, 0.09974472969770432, 0.03335508704185486, 0.043473999947309494, -0.05649488419294357, -0.00996951200067997, 0.018965929746627808, 0.05873339995741844, -0.11323270201683044, -0.08396697789430618, 0.007231556810438633, 0.08691178262233734, 0.021818378940224648, 0.11349008977413177, 0.06458663940429688, 0.030661461874842644, 0.04654713347554207, 0.03928207978606224, -0.005303635727614164, 0.01811487041413784, 0.04136386886239052, 0.04662161320447922, -0.036506690084934235, 0.014115183614194393, -0.012194179929792881, -0.02371617965400219, -0.06400548666715622, -0.05127532407641411, 0.04638690501451492, 0.04350007325410843, -0.039177510887384415, -0.05355006828904152, -0.04485663026571274, -0.08579663187265396, 0.031720809638500214, 0.0052101402543485165, 0.06180299445986748, -0.012942230328917503, 0.0010968029964715242, 0.10910846292972565, 0.00670835142955184, 0.025756394490599632, -0.0514165423810482, 0.08230534940958023, -0.014319391921162605, 0.030427508056163788, 0.09142038971185684, 0.11116279661655426, -0.04651778191328049, 0.04927801713347435, -0.048818837851285934]",
         "0.19"
        ],
        [
         "21",
         "32",
         "Sellfy Review 2022: How Good Is This Ecommerce Platform?",
         "Are you searching for an ecomerce platform to help you build an online store and sell products? In this Sellfy review, we'll talk about how this eCommerce platform can let you sell digital products while keeping full control of your marketing. And the best part? Starting your business can be done in just five minutes. Let us then talk about the Sellfy platform and all the benefits it can bring to your business. What is Sellfy? Sellfy is an eCommerce solution that allows digital content creators, including writers, illustrators, designers, musicians, and filmmakers, to sell their products online. Sellfy provides a customizable storefront where users can display their digital products and embed \"Buy Now\" buttons on their website or blog. Sellfy product pages enable users to showcase their products from different angles with multiple images and previews from Soundcloud, Vimeo, and YouTube. Files of up to 2GB can be uploaded to Sellfy, and the company offers unlimited bandwidth and secure file storage. Users can also embed their entire store or individual project widgets in their site, with the ability to preview how widgets will appear before they are displayed. Features Sellfy includes: Online Store Sellfy is a powerful e-commerce platform that helps you personalize your online storefront. You can add your logo, change colors, revise navigation, and edit the layout of your store. Sellfy also allows you to create a full shopping cart so customers can purchase multiple items. And Sellfy gives you the ability to set your language or let customers see a translated version of your store based on their location. Sellfy gives you the option to host your store directly on its platform, add a custom domain to your store, and use it as an embedded storefront on your website. Sellfy also optimizes its store offerings for mobile devices, allowing for a seamless checkout experience. Product hosting Sellfy allows creators to host all their products and sell all of their digital products on one platform. Sellfy also does not place storage limits on your store but recommends that files be no larger than 5GB. Creators can sell both standard and subscription-based products in any file format that is supported by the online marketplace. Customers can purchase products instantly after making a purchase – there is no waiting period. You can organize your store by creating your product categories, sorting by any characteristic you choose. Your title, description, and the image will be included on each product page. In this way, customers can immediately evaluate all of your products. You can offer different pricing options for all of your products, including \"pay what you want,\" in which the price is entirely up to the customer. This option allows you to give customers control over the cost of individual items (without a minimum price) or to set pricing minimums—a good option if you're in a competitive market or when you have higher-end products. You can also offer set prices per product as well as free products to help build your store's popularity. Sellfy is ideal for selling digital content, such as ebooks. But it does not allow you to copyrighted material (that you don't have rights to distribute). Embed options Sellfy offers several ways to share your store, enabling you to promote your business on different platforms. Sellfy lets you integrate it with your existing website using \"buy now\" buttons, embed your entire storefront, or embed certain products so you can reach more people. Sellfy also enables you to connect with your Facebook page and YouTube channel, maximizing your visibility. Payments and security Sellfy is a simple online platform that allows customers to buy your products directly through your store. Sellfy has two payment processing options: PayPal and Stripe. You will receive instant payments with both of these processors, and your customer data is protected by Sellfy's secure (PCI-compliant) payment security measures. In addition to payment security, Sellfy provides anti-fraud tools to help protect your products including PDF stamping, unique download links, and limited download attempts. Marketing and analytics tools The Sellfy platform includes marketing and analytics tools to help you manage your online store. You can send email product updates and collect newsletter subscribers through the platform. With Sellfy, you can also offer discount codes and product upsells, as well as create and track Facebook and Twitter ads for your store. The software's analytics dashboard will help you track your best-performing products, generated revenue, traffic channels, top locations, and overall store performance. Integrations To expand functionality and make your e-commerce store run more efficiently, Sellfy offers several integrations. Google Analytics and Webhooks, as well as integrations with Patreon and Facebook Live Chat, are just a few of the options available. Sellfy allows you to connect to Zapier, which gives you access to hundreds of third-party apps, including tools like Mailchimp, Trello, Salesforce, and more. Pricing and Premium Plan Features Get Sellfy 14 day free trail from here Free Plan Price: $0 The free plan comes with: Up to 10 products Print-on-demand products Physical products Starter Plan Price: $19/month Starter plan comes with: Everything is Free, plus: Unlimited products Digital products Subscription products Connect your domain 2,000 email credits Business Plan Price: $49/month The business plan comes with: Everything in Starter, plus: Remove \"Sellfy\" branding Store design migration Cart abandonment Product upselling 10,000 email credits Premium Plan Price: $99/month The premium plan comes with: Everything in Business, plus: Product migration Priority support 50,000 email credits Sellfy Review: Pros and Cons Sellfy has its benefits and downsides, but fortunately, the pros outweigh the cons. Pros It takes only a few minutes to set up an online store and begin selling products. You can sell your products on a single storefront, even if you are selling multiple product types. Sellfy supports selling a variety of product types, including physical items, digital goods, subscriptions, and print-on-demand products. Sellfy offers a free plan for those who want to test out the features before committing to a paid plan. You get paid the same day you make a sale. Sellfy doesn't delay your funds as some other payment processors do. Print-on-demand services are available directly from your store, so you can sell merchandise to fans without setting up an integration. You can conduct all store-related activities via the mobile app and all online stores have mobile responsive designs. Everything you need to make your website is included, including a custom domain name hosting, security for your files, and the ability to customize your store The file security features can help you protect your digital property by allowing you to put PDF stamps, set download limits, and SSL encryption. Sellfy provides unlimited support. Sellfy provides simple and intuitive tax and VAT configuration settings. Marketing strategies include coupons, email marketing, upselling, tracking pixels, and cart abandonment. Cons Although the free plan is helpful, but it limits you to only 10 products. Payment plans often require an upgrade if you exceed a certain sales amount per year. The storefront designs are clean, but they're not unique templates for creating a completely different brand image. Sellfy's branding is removed from your hosted product when you upgrade to the $49 per month Business plan. The free plan does not allow for selling digital or subscription products. Conclusion In this article, we have taken a look at some of the biggest benefits associated with using sellfy for eCommerce. Once you compare these benefits to what you get with other platforms such as Shopify, you should find that it is worth your time to consider sellfy for your business. After reading this article all of your questions will be solved but if you have still some questions let me know in the comment section below, I will be happy to answer your questions. Note: This article contains affiliate links which means we make a small commission if you buy sellfy premium plan from our link.",
         "Are you searching for an ecomerce platform to help you build an online store and sell products?\n\nIn this Sellfy review, we'll talk about how this eCommerce platform can let you sell digital products while keeping full control of your marketing.\n\nAnd the best part? Starting your business can be done in just five minutes.\n\nLet us then talk about the Sellfy platform and all the benefits it can bring to your business.\n\nWhat is Sellfy?\n\nSellfy is an eCommerce solution that allows digital content creators, including writers, illustrators, designers, musicians, and filmmakers, to sell their products online. Sellfy provides a customizable storefront where users can display their digital products and embed \"Buy Now\" buttons on their website or blog. Sellfy product pages enable users to showcase their products from different angles with multiple images and previews from Soundcloud, Vimeo, and YouTube. Files of up to 2GB can be uploaded to Sellfy, and the company offers unlimited bandwidth and secure file storage. Users can also embed their entire store or individual project widgets in their site, with the ability to preview how widgets will appear before they are displayed.\n\nFeatures\n\nSellfy includes:\n\nOnline Store\n\nSellfy is a powerful e-commerce platform that helps you personalize your online storefront. You can add your logo, change colors, revise navigation, and edit the layout of your store. Sellfy also allows you to create a full shopping cart so customers can purchase multiple items. And Sellfy gives you the ability to set your language or let customers see a translated version of your store based on their location.\n\nSellfy gives you the option to host your store directly on its platform, add a custom domain to your store, and use it as an embedded storefront on your website. Sellfy also optimizes its store offerings for mobile devices, allowing for a seamless checkout experience.\n\nProduct hosting\n\nSellfy allows creators to host all their products and sell all of their digital products on one platform. Sellfy also does not place storage limits on your store but recommends that files be no larger than 5GB. Creators can sell both standard and subscription-based products in any file format that is supported by the online marketplace. Customers can purchase products instantly after making a purchase – there is no waiting period.\n\nYou can organize your store by creating your product categories, sorting by any characteristic you choose. Your title, description, and the image will be included on each product page. In this way, customers can immediately evaluate all of your products. You can offer different pricing options for all of your products, including \"pay what you want,\" in which the price is entirely up to the customer. This option allows you to give customers control over the cost of individual items (without a minimum price) or to set pricing minimums—a good option if you're in a competitive market or when you have higher-end products. You can also offer set prices per product as well as free products to help build your store's popularity.\n\nSellfy is ideal for selling digital content, such as ebooks. But it does not allow you to copyrighted material (that you don't have rights to distribute).\n\nEmbed options\n\nSellfy offers several ways to share your store, enabling you to promote your business on different platforms. Sellfy lets you integrate it with your existing website using \"buy now\" buttons, embed your entire storefront, or embed certain products so you can reach more people. Sellfy also enables you to connect with your Facebook page and YouTube channel, maximizing your visibility.\n\nPayments and security\n\nSellfy is a simple online platform that allows customers to buy your products directly through your store. Sellfy has two payment processing options: PayPal and Stripe. You will receive instant payments with both of these processors, and your customer data is protected by Sellfy's secure (PCI-compliant) payment security measures. In addition to payment security, Sellfy provides anti-fraud tools to help protect your products including PDF stamping, unique download links, and limited download attempts.\n\nMarketing and analytics tools\n\nThe Sellfy platform includes marketing and analytics tools to help you manage your online store. You can send email product updates and collect newsletter subscribers through the platform. With Sellfy, you can also offer discount codes and product upsells, as well as create and track Facebook and Twitter ads for your store. The software's analytics dashboard will help you track your best-performing products, generated revenue, traffic channels, top locations, and overall store performance.\n\nIntegrations\n\nTo expand functionality and make your e-commerce store run more efficiently, Sellfy offers several integrations. Google Analytics and Webhooks, as well as integrations with Patreon and Facebook Live Chat, are just a few of the options available. Sellfy allows you to connect to Zapier, which gives you access to hundreds of third-party apps, including tools like Mailchimp, Trello, Salesforce, and more.\n\nPricing and Premium Plan Features\n\nGet Sellfy 14 day free trail from here\n\nFree Plan\n\nPrice: $0\n\nThe free plan comes with:\n\nUp to 10 products\n\nPrint-on-demand products\n\nPhysical products\n\nStarter Plan\n\nPrice: $19/month\n\nStarter plan comes with:\n\nEverything is Free, plus:\n\nUnlimited products\n\nDigital products\n\nSubscription products\n\nConnect your domain\n\n2,000 email credits\n\nBusiness Plan\n\nPrice: $49/month\n\nThe business plan comes with:\n\nEverything in Starter, plus:\n\nRemove \"Sellfy\" branding\n\nStore design migration\n\nCart abandonment\n\nProduct upselling\n\n10,000 email credits\n\nPremium Plan\n\nPrice: $99/month\n\nThe premium plan comes with:\n\nEverything in Business, plus:\n\nProduct migration\n\nPriority support\n\n50,000 email credits\n\nSellfy Review: Pros and Cons\n\nSellfy has its benefits and downsides, but fortunately, the pros outweigh the cons.\n\nPros\n\nIt takes only a few minutes to set up an online store and begin selling products.\n\nYou can sell your products on a single storefront, even if you are selling multiple product types.\n\nSellfy supports selling a variety of product types, including physical items, digital goods, subscriptions, and print-on-demand products.\n\n\n\n\n\nSellfy offers a free plan for those who want to test out the features before committing to a paid plan.\n\nYou get paid the same day you make a sale. Sellfy doesn't delay your funds as some other payment processors do.\n\nPrint-on-demand services are available directly from your store, so you can sell merchandise to fans without setting up an integration.\n\nYou can conduct all store-related activities via the mobile app and all online stores have mobile responsive designs.\n\nEverything you need to make your website is included, including a custom domain name hosting, security for your files, and the ability to customize your store\n\nThe file security features can help you protect your digital property by allowing you to put PDF stamps, set download limits, and SSL encryption.\n\nSellfy provides unlimited support.\n\nSellfy provides simple and intuitive tax and VAT configuration settings.\n\nMarketing strategies include coupons, email marketing, upselling, tracking pixels, and cart abandonment.\n\nCons\n\nAlthough the free plan is helpful, but it limits you to only 10 products.\n\nPayment plans often require an upgrade if you exceed a certain sales amount per year.\n\nThe storefront designs are clean, but they're not unique templates for creating a completely different brand image.\n\nSellfy's branding is removed from your hosted product when you upgrade to the $49 per month Business plan.\n\nThe free plan does not allow for selling digital or subscription products.\n\nConclusion\n\nIn this article, we have taken a look at some of the biggest benefits associated with using sellfy for eCommerce. Once you compare these benefits to what you get with other platforms such as Shopify, you should find that it is worth your time to consider sellfy for your business. After reading this article all of your questions will be solved but if you have still some questions let me know in the comment section below, I will be happy to answer your questions.\n\nNote: This article contains affiliate links which means we make a small commission if you buy sellfy premium plan from our link.",
         "2022-03-12T11:54:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/03/sellfy-review-2022-how-good-is-this.html",
         "2025-07-26T05:41:35.854060",
         "Are you searching for an ecomerce platform to help you build an online store and sell products? In this Sellfy review, we'll talk about how this eCommerce platform can let you sell digital products while keeping full control of your marketing. And the best part? Starting your business can be done in just five minutes. Let us then talk about the Sellfy platform and all the benefits it can bring to your business. What is Sellfy? Sellfy is an eCommerce solution that allows digital content creators, including writers, illustrators, designers, musicians, and filmmakers, to sell their products online. Sellfy provides a customizable storefront where users can display their digital products and embed \"Buy Now\" buttons on their website or blog. Sellfy product pages enable users to showcase their products from different angles with multiple images and previews from Soundcloud, Vimeo, and YouTube. Files of up to 2GB can be uploaded to Sellfy, and the company offers unlimited bandwidth and secure file storage. Users can also embed their entire store or individual project widgets in their site, with the ability to preview how widgets will appear before they are displayed. Features Sellfy includes: Online Store Sellfy is a powerful e-commerce platform that helps you personalize your online storefront. You can add your logo, change colors, revise navigation, and edit the layout of your store. Sellfy also allows you to create a full shopping cart so customers can purchase multiple items. And Sellfy gives you the ability to set your language or let customers see a translated version of your store based on their location. Sellfy gives you the option to host your store directly on its platform, add a custom domain to your store, and use it as an embedded storefront on your website. Sellfy also optimizes its store offerings for mobile devices, allowing for a seamless checkout experience. Product hosting Sellfy allows creators to host all their products and sell all of their digital products on one platform. Sellfy also does not place storage limits on your store but recommends that files be no larger than 5GB. Creators can sell both standard and subscription-based products in any file format that is supported by the online marketplace. Customers can purchase products instantly after making a purchase – there is no waiting period. You can organize your store by creating your product categories, sorting by any characteristic you choose. Your title, description, and the image will be included on each product page. In this way, customers can immediately evaluate all of your products. You can offer different pricing options for all of your products, including \"pay what you want,\" in which the price is entirely up to the customer. This option allows you to give customers control over the cost of individual items (without a minimum price) or to set pricing minimums—a good option if you're in a competitive market or when you have higher-end products. You can also offer set prices per product as well as free products to help build your store's popularity. Sellfy is ideal for selling digital content, such as ebooks. But it does not allow you to copyrighted material (that you don't have rights to distribute). Embed options Sellfy offers several ways to share your store, enabling you to promote your business on different platforms. Sellfy lets you integrate it with your existing website using \"buy now\" buttons, embed your entire storefront, or embed certain products so you can reach more people. Sellfy also enables you to connect with your Facebook page and YouTube channel, maximizing your visibility. Payments and security Sellfy is a simple online platform that allows customers to buy your products directly through your store. Sellfy has two payment processing options: PayPal and Stripe. You will receive instant payments with both of these processors, and your customer data is protected by Sellfy's secure (PCI-compliant) payment security measures. In addition to payment security, Sellfy provides anti-fraud tools to help protect your products including PDF stamping, unique download links, and limited download attempts. Marketing and analytics tools The Sellfy platform includes marketing and analytics tools to help you manage your online store. You can send email product updates and collect newsletter subscribers through the platform. With Sellfy, you can also offer discount codes and product upsells, as well as create and track Facebook and Twitter ads for your store. The software's analytics dashboard will help you track your best-performing products, generated revenue, traffic channels, top locations, and overall store performance. Integrations To expand functionality and make your e-commerce store run more efficiently, Sellfy offers several integrations. Google Analytics and Webhooks, as well as integrations with Patreon and Facebook Live Chat, are just a few of the options available. Sellfy allows you to connect to Zapier, which gives you access to hundreds of third-party apps, including tools like Mailchimp, Trello, Salesforce, and more. Pricing and Premium Plan Features Get Sellfy 14 day free trail from here Free Plan Price: $0 The free plan comes with: Up to 10 products Print-on-demand products Physical products Starter Plan Price: $19/month Starter plan comes with: Everything is Free, plus: Unlimited products Digital products Subscription products Connect your domain 2,000 email credits Business Plan Price: $49/month The business plan comes with: Everything in Starter, plus: Remove \"Sellfy\" branding Store design migration Cart abandonment Product upselling 10,000 email credits Premium Plan Price: $99/month The premium plan comes with: Everything in Business, plus: Product migration Priority support 50,000 email credits Sellfy Review: Pros and Cons Sellfy has its benefits and downsides, but fortunately, the pros outweigh the cons. Pros It takes only a few minutes to set up an online store and begin selling products. You can sell your products on a single storefront, even if you are selling multiple product types. Sellfy supports selling a variety of product types, including physical items, digital goods, subscriptions, and print-on-demand products. Sellfy offers a free plan for those who want to test out the features before committing to a paid plan. You get paid the same day you make a sale. Sellfy doesn't delay your funds as some other payment processors do. Print-on-demand services are available directly from your store, so you can sell merchandise to fans without setting up an integration. You can conduct all store-related activities via the mobile app and all online stores have mobile responsive designs. Everything you need to make your website is included, including a custom domain name hosting, security for your files, and the ability to customize your store The file security features can help you protect your digital property by allowing you to put PDF stamps, set download limits, and SSL encryption. Sellfy provides unlimited support. Sellfy provides simple and intuitive tax and VAT configuration settings. Marketing strategies include coupons, email marketing, upselling, tracking pixels, and cart abandonment. Cons Although the free plan is helpful, but it limits you to only 10 products. Payment plans often require an upgrade if you exceed a certain sales amount per year. The storefront designs are clean, but they're not unique templates for creating a completely different brand image. Sellfy's branding is removed from your hosted product when you upgrade to the $49 per month Business plan. The free plan does not allow for selling digital or subscription products. Conclusion In this article, we have taken a look at some of the biggest benefits associated with using sellfy for eCommerce. Once you compare these benefits to what you get with other platforms such as Shopify, you should find that it is worth your time to consider sellfy for your business. After reading this article all of your questions will be solved but if you have still some questions let me know in the comment section below, I will be happy to answer your questions. Note: This article contains affiliate links which means we make a small commission if you buy sellfy premium plan from our link.",
         "en",
         "{'MISC': ['After reading this article all of your questions will be solved but if you have still some questions let me know in the comment section below', 'Analytics and Webhooks', 'And the best', 'Are you searching for an ecomerce platform to help you build an online store and sell products', \"But it does not allow you to copyrighted material (that you don't have rights to distribute\", 'Buy Now', 'Connect your', 'Cons Although the free plan is helpful', 'Embed', 'Everything in Business', 'Everything in Starter', 'Everything is Free', 'Everything you need to make your website is', 'Facebook Live Chat', 'Facebook and Twitter ads for your store', 'Files of up to 2GB can be uploaded to Sellfy', 'I will be happy to answer your questions', 'In this Sellfy review', 'In this way', 'Integrations To expand functionality and make your e-commerce store run more efficiently', 'Let us then', 'Marketing', 'Marketing and analytics tools The Sellfy platform', 'Online Store Sellfy is', 'PCI-compliant', 'PayPal and Stripe', 'Payments and security Sellfy is', 'Physical', 'Pricing and Premium Plan Features Get', 'Priority', 'SSL', 'Salesforce', 'Sellfy', 'Sellfy 14 day free trail from here Free Plan Price', 'Sellfy allows creators to host all their products and sell all of their digital products', 'Sellfy allows you to connect to Zapier', 'Sellfy also allows you to create a full shopping cart so customers can purchase multiple items', 'Sellfy also does not', 'Sellfy also enables you to connect with your Facebook', 'Sellfy also optimizes its store offerings for mobile devices', \"Sellfy doesn't delay your funds as some other payment processors do\", 'Sellfy gives you the option to host your store', 'Sellfy has two payment processing options', 'Sellfy is an eCommerce solution that allows digital content creators', 'Sellfy is ideal for selling digital content', 'Sellfy provides', 'Shopify', 'Starter', 'Starter Plan Price', 'Starting your business can be done in just five minutes', 'Subscription products', 'The', 'The file security features can help you protect your digital property', 'The free plan comes with: Up to 10 products', 'The free plan does not allow for selling digital or', 'The storefront designs are clean', 'Trello', 'Users can also embed', 'What is Sellfy', 'With Sellfy', 'You can', \"You can also offer set prices per product as well as free products to help build your store'\", 'You can sell', 'You get paid the same day you make', 'You will receive instant payments with both of these processors', 'YouTube', 'Your title', 'add', 'allowing for a seamless checkout experience', 'and overall store performance', 'and use it as an embedded storefront on your website', 'credits Premium Plan Price', 'customers can immediately evaluate all of your products', 'illustrators', 'including PDF stamping', 'including tools like Mailchimp', 'including writers', 'security for your files', 'sellfy for your business', 'subscriptions', 'the pros outweigh the cons', 'to sell their products online', 'upselling', 'we have taken', \"we'll talk about how this eCommerce platform can let you sell digital products while keeping full control of your marketing\", 'with the ability to preview how widgets will appear before they are displayed', 'you can also'], 'PER': ['Once you', 'and filmmakers', 'even if you are selling multiple', 'including', 'so you can sell'], 'ORG': ['Digital', 'Features', 'Pros and Cons Sellfy has its benefits and downsides', 'Sellfy Review', 'Store design migration Cart', 'Unlimited products', 'Vimeo', 'and the company', 'credits Business', 'goods', 'unlimited bandwidth and secure file storage', 'upsells'], 'LOC': ['Product', 'Remove', 'Sellfy', 'and print-on-demand products', \"and your customer data is protected by Sellfy'\"]}",
         "[-0.0362698994576931, -0.0642918273806572, -0.04321671277284622, 0.01176941953599453, 0.06999882310628891, 0.07824806123971939, 0.016717344522476196, 0.06671755760908127, -0.03247077763080597, -0.02607647515833378, -0.001740047475323081, 0.07637237757444382, 0.023543134331703186, 0.03100111149251461, 0.10070400685071945, -0.0160825252532959, 0.03673116862773895, 0.011198311112821102, -0.08458660542964935, -0.03227313235402107, -0.005425719544291496, -0.0034465226344764233, -0.004870587959885597, 0.008027779869735241, -0.05940061807632446, -0.03815355896949768, -0.06642018258571625, 0.004619109444320202, -0.002868169452995062, -0.07914403825998306, 0.05135033279657364, -0.05298713967204094, 0.05150342360138893, 0.040756918489933014, -0.05203051120042801, -0.021034570410847664, 0.02153676189482212, -0.05154728516936302, -0.0652623325586319, -0.04760151356458664, -0.007075876463204622, -0.07159540802240372, -0.15422369539737701, 0.05180244892835617, 0.07450930774211884, 0.0051775663159787655, 0.026158355176448822, 0.09456903487443924, 0.053695421665906906, 0.01619604043662548, -0.022306757047772408, -0.058682944625616074, -0.009093432687222958, -0.021071864292025566, -0.10195300728082657, 0.016246067360043526, 0.021969551220536232, -0.021566975861787796, -1.4307688616099767e-05, -0.0468960739672184, 0.11241838335990906, -0.10605324804782867, 0.046849124133586884, 0.001551732886582613, 0.008349332958459854, 0.03138025477528572, -0.0011038602096959949, 0.06023617461323738, -0.046820204704999924, -0.029669368639588356, -0.021018866449594498, -0.03933859243988991, -0.023070521652698517, 0.11654190719127655, -0.0013474943116307259, -0.110907644033432, 0.10560265928506851, -0.03256138414144516, 0.004633389413356781, 0.06739487498998642, 0.01713463105261326, 0.01983504556119442, -0.06328588724136353, -0.03566945344209671, -0.08391675353050232, -0.03172798454761505, 0.05472590774297714, 0.03682667389512062, 0.003366330172866583, -0.03084423393011093, -0.003768361872062087, 0.06462733447551727, -0.057674240320920944, -0.02264995127916336, 0.02014545537531376, -0.09337668865919113, 0.012313787825405598, 0.01831640675663948, 0.043639931827783585, 0.014270476065576077, -0.02392994984984398, 0.02155514620244503, 0.06417075544595718, -0.11339664459228516, -0.03677215427160263, -0.05212114006280899, -0.019758040085434914, 0.13986721634864807, -0.017764486372470856, 0.050347950309515, -0.07151152193546295, -0.02731902524828911, -0.04679533839225769, -0.0006739152013324201, 0.06248435005545616, 0.04803790524601936, -0.06787949055433273, 0.03341693431138992, 0.11244630068540573, -0.03905963897705078, 0.0792771652340889, 0.07352886348962784, 0.058063529431819916, -0.047612082213163376, 0.016617070883512497, -0.005931388586759567, -0.027762416750192642, 5.138034746908355e-33, 0.018107371404767036, 0.015179084613919258, -0.02474405989050865, 0.02426542155444622, 0.006313891150057316, 0.07708912342786789, 0.032569561153650284, 0.04308668151497841, -0.11587643623352051, 0.06399229913949966, 0.028632372617721558, 0.05922242999076843, -0.0070748161524534225, 0.13210533559322357, 0.0391620397567749, -0.07254818081855774, 0.01787753961980343, -0.02937031351029873, 0.11280207335948944, -0.05095848813652992, 0.023729262873530388, -0.05573772266507149, -0.03828555345535278, 0.07261145114898682, -0.029473694041371346, -0.0759727731347084, 0.023143738508224487, 0.07026670128107071, 0.10145799815654755, -0.017851296812295914, -0.038165025413036346, -0.06050378084182739, -0.022603165358304977, 0.0012801727280020714, -0.06171996891498566, -0.07915634661912918, -0.07274442166090012, -0.13640369474887848, 0.13877882063388824, -0.0005447571165859699, -0.0992647185921669, 0.004211415071040392, -0.016710521653294563, 0.02669973112642765, -0.03742096945643425, 0.07554276287555695, -0.031230850145220757, -0.020759768784046173, -0.010970738716423512, 0.06032839044928551, -0.007763087283819914, -0.006845514290034771, 0.030993200838565826, 0.019444428384304047, -0.050233833491802216, -0.029998240992426872, -0.011285599321126938, -0.07161732763051987, 0.013994316570460796, -0.061728887259960175, -0.021500684320926666, -0.01744132488965988, -0.005629047751426697, -0.06660246104001999, -0.11308693140745163, -0.015302632935345173, 0.08886923640966415, -0.004183524288237095, -0.0011681976029649377, -0.038072001188993454, -0.05254339054226875, 0.013390584848821163, 0.06647605448961258, -0.07691853493452072, 0.015607219189405441, 0.009919981472194195, -0.040632203221321106, 0.04339822381734848, -0.007705510128289461, 0.029100673273205757, -0.007033153437077999, -0.004359373822808266, 0.03601858764886856, 0.06628287583589554, -0.0049280524253845215, -0.027171585708856583, -0.0253289844840765, -0.0023164567537605762, -0.06349850445985794, -0.03396221250295639, -0.02907460927963257, 0.07572368532419205, -0.03796697407960892, 0.03520752862095833, 0.05255556106567383, -4.394547794324705e-33, 0.004419013857841492, -0.0691806972026825, -0.09157949686050415, 0.10963664948940277, 0.013922437094151974, 0.023691197857260704, -0.0376262366771698, 0.021665124222636223, 0.008152136579155922, -0.051990482956171036, -0.04164085164666176, -0.050247564911842346, -0.004239798057824373, -0.007416449021548033, -0.07307253032922745, 0.016479114070534706, -0.005600468721240759, -0.05382704362273216, 0.036347005516290665, -0.044121481478214264, -0.002406330546364188, 0.0053780414164066315, -0.018939638510346413, 0.0014122790889814496, 0.037117838859558105, 0.007720463443547487, -0.012411676347255707, 0.06665195524692535, 0.042212434113025665, 0.007537783123552799, 0.03668685629963875, -0.08779343962669373, 0.03149055317044258, 0.009580285288393497, 0.027410538867115974, -0.001146788359619677, -0.0034181843511760235, -0.022887246683239937, 0.05441773682832718, 0.020886080339550972, 0.033880993723869324, 0.04382554814219475, 0.02853797934949398, -0.05811357498168945, -0.060943279415369034, 0.026637287810444832, -0.007631544955074787, -0.02328931912779808, 0.0406462736427784, -0.008506988175213337, 0.0037263461854308844, 0.11592522263526917, -0.008397262543439865, -0.08535220474004745, -0.03853178769350052, -0.00020217087876517326, -0.015948418527841568, 0.021462073549628258, -0.052091266959905624, 0.07973344624042511, 0.0017465614946559072, 0.046961553394794464, 0.06388358771800995, -0.016133971512317657, -0.005899396724998951, -0.05885738506913185, 0.07874070852994919, 0.03324228525161743, -0.04309112951159477, 0.021047493442893028, 0.0017411013832315803, 0.053489185869693756, -0.019790250808000565, -0.07151945680379868, -0.11718405038118362, 0.00957073550671339, -0.005084269214421511, -0.011116509325802326, 0.01698417030274868, -0.028351619839668274, -0.015618482604622841, 0.05884169414639473, 0.11228577047586441, -0.00824565440416336, 0.027419893071055412, -0.009781862609088421, -0.0606483556330204, -0.0009854813106358051, -0.005408141296356916, -0.04809476062655449, -0.04720800369977951, -0.0017729609971866012, -0.0605996735394001, 0.1256835162639618, 0.06362508237361908, -5.2957762619598725e-08, 0.05711528658866882, -0.020851410925388336, 0.06235933303833008, 0.02729067951440811, -0.023139650002121925, -0.002304882276803255, 0.10157713294029236, 0.02492942288517952, 0.01586812362074852, -0.023100854828953743, 0.037491459399461746, -0.07664014399051666, -0.056023694574832916, 0.04763450846076012, 0.04571783170104027, -0.0016556524205952883, 0.0410611629486084, -0.02977144718170166, 0.022986166179180145, 0.012464330531656742, 0.07273226231336594, -0.03930196538567543, 8.559679554309696e-05, 0.015278429724276066, 0.018604205921292305, 0.03832090273499489, 0.07366596907377243, 0.06241854652762413, 0.012322814203798771, -0.04721749946475029, -0.0015835869126021862, -0.00014661814202554524, 0.03410404175519943, 0.04778020828962326, 0.030810251832008362, -0.08061959594488144, -0.06375107914209366, 0.013166560791432858, -0.08947230130434036, 0.07284484803676605, -0.031434446573257446, -0.03537941724061966, 0.01525124255567789, -0.0035809860564768314, -0.01941162906587124, -0.0411798469722271, -0.03622592240571976, -0.07631571590900421, 0.0066948686726391315, 0.04228086397051811, -0.0170664694160223, 0.01585027575492859, 0.0611569844186306, 0.01164170354604721, -0.01645752415060997, 0.05022833123803139, -0.014142577536404133, 0.038279108703136444, 0.0771402046084404, 0.13343365490436554, -0.06269521266222, -0.06005103513598442, 0.055974081158638, 0.01681370474398136]",
         "0.186"
        ],
        [
         "22",
         "29",
         "Most Frequently Asked Questions About Affiliate Marketing",
         "There are lots of questions floating around about how affiliate marketing works, what to do and what not to do when it comes to setting up a business. With so much uncertainty surrounding both personal and business aspects of affiliate marketing. In this post, we will answer the most frequently asked question about affiliate marketing 1. What is affiliate marketing? Affiliate marketing is a way to make money by promoting the products and services of other people and companies. You don't need to create your product or service, just promote existing ones. That's why it's so easy to get started with affiliate marketing. You can even get started with no budget at all! 2. What is an affiliate program? An affiliate program is a package of information you create for your product, which is then made available to potential publishers. The program will typically include details about the product and its retail value, commission levels, and promotional materials. Many affiliate programs are managed via an affiliate network like ShareASale, which acts as a platform to connect publishers and advertisers, but it is also possible to offer your program directly. 3. What is an affiliate network and how do affiliate networks make money? Affiliate networks connect publishers to advertisers. Affiliate networks make money by charging fees to the merchants who advertise with them; these merchants are known as advertisers. The percentage of each sale that the advertiser pays is negotiated between the merchant and the affiliate network. 4. What's the difference between affiliate marketing and dropshipping? Dropshipping is a method of selling that allows you to run an online store without having to stock products. You advertise the products as if you owned them, but when someone makes an order, you create a duplicate order with the distributor at a reduced price. The distributor takes care of the post and packaging on your behalf. As affiliate marketing is based on referrals and this type of drop shipping requires no investment in inventory when a customer buys through the affiliate link, no money exchanges hands. 5. Can affiliate marketing and performance marketing be considered the same thing? Performance marketing is a method of marketing that pays for performance, like when a sale is made or an ad is clicked This can include methods like PPC (pay-per-click) or display advertising. Affiliate marketing is one form of performance marketing where commissions are paid out to affiliates on a performance basis when they click on their affiliate link and make a purchase or action. 6. Is it possible to promote affiliate offers on mobile devices? Smartphones are essentially miniature computers, so publishers can display the same websites and offers that are available on a PC. But mobiles also offer specific tools not available on computers, and these can be used to good effect for publishers. Publishers can optimize their ads for mobile users by making them easy to access by this audience. Publishers can also make good use of text and instant messaging to promote their offers. As the mobile market is predicted to make up 80% of traffic in the future, publishers who do not promote on mobile devices are missing out on a big opportunity. 7. Where do I find qualified publishers? The best way to find affiliate publishers is on reputable networks like ShareASale Cj(Commission Junction), Awin, and Impact radius. These networks have a strict application process and compliance checks, which means that all affiliates are trustworthy. 8. What is an affiliate disclosure statement? An affiliate disclosure statement discloses to the reader that there may be affiliate links on a website, for which a commission may be paid to the publisher if visitors follow these links and make purchases. 9. Does social media activity play a significant role in affiliate marketing? Publishers promote their programs through a variety of means, including blogs, websites, email marketing, and pay-per-click ads. Social media has a huge interactive audience, making this platform a good source of potential traffic. 10. What is a super affiliate? A super affiliate is an affiliate partner who consistently drives a large majority of sales from any program they promote, compared to other affiliate partners involved in that program. Affiliates make a lot of money from affiliate marketing Pat Flynn earned more than $50000 in 2013 from affiliate marketing. 11. How do we track publisher sales activity? Publishers can be identified by their publisher ID, which is used in tracking cookies to determine which publishers generate sales. The activity is then viewed within a network's dashboard. 12. Could we set up an affiliate program in multiple countries? Because the Internet is so widespread, affiliate programs can be promoted in any country. Affiliate strategies that are set internationally need to be tailored to the language of the targeted country. 13. How can affiliate marketing help my business? Affiliate marketing can help you grow your business in the following ways: It allows you to save time and money on marketing, which frees you up to focus on other aspects of your business. You get access to friendly marketers who are eager to help you succeed. It also helps you to promote your products by sharing links and banners with a new audience. It offers high ROI(Return on investment) and is cost-effective. 14. How do I find quality publishers? One of the best ways to work with qualified affiliates is to hire an affiliate marketing agency that works with all the networks. Affiliates are carefully selected and go through a rigorous application process to be included in the network. 15. How Can we Promote Affiliate Links? Affiliate marketing is generally associated with websites, but there are other ways to promote your affiliate links, including: A website or blog Through email marketing and newsletter Social media, like Facebook, Instagram, or Twitter. Leave a comment on blogs or forums. Write an e-book or other digital product. Youtube 16. Do you have to pay to sign up for an affiliate program? To build your affiliate marketing business, you don't have to invest money in the beginning. You can sign up for free with any affiliate network and start promoting their brands right away. 17. What is a commission rate? Commission rates are typically based on a percentage of the total sale and in some cases can also be a flat fee for each transaction. The rates are set by the merchant. Who manages your affiliate program? Some merchants run their affiliate programs internally, while others choose to contract out management to a network or an external agency. 18. What is a cookie? Cookies are small pieces of data that work with web browsers to store information such as user preferences, login or registration data, and shopping cart contents. When someone clicks on your affiliate link, a cookie is placed on the user's computer or mobile device. That cookie is used to remember the link or ad that the visitor clicked on. Even if the user leaves your site and comes back a week later to make a purchase, you will still get credit for the sale and receive a commission it depends on the site cookies duration 19. How long do cookies last? The merchant determines the duration of a cookie, also known as its “cookie life.” The most common length for an affiliate program is 30 days. If someone clicks on your affiliate link, you’ll be paid a commission if they purchase within 30 days of the click. Final Saying Most new affiliates are eager to begin their affiliate marketing business. Unfortunately, there is a lot of bad information out there that can lead inexperienced affiliates astray. Hopefully, the answer to your question will provide clarity on how affiliate marketing works and the pitfalls you can avoid. Most importantly, keep in mind that success in affiliate marketing takes some time. Don't be discouraged if you're not immediately making sales or earning money. It takes most new affiliates months to make a full-time income.",
         "There are lots of questions floating around about how affiliate marketing works, what to do and what not to do when it comes to setting up a business. With so much uncertainty surrounding both personal and business aspects of affiliate marketing. In this post, we will answer the most frequently asked question about affiliate marketing\n\n1. What is affiliate marketing?\n\nAffiliate marketing is a way to make money by promoting the products and services of other people and companies. You don't need to create your product or service, just promote existing ones. That's why it's so easy to get started with affiliate marketing. You can even get started with no budget at all!\n\n\n\n\n\n2. What is an affiliate program?\n\nAn affiliate program is a package of information you create for your product, which is then made available to potential publishers. The program will typically include details about the product and its retail value, commission levels, and promotional materials. Many affiliate programs are managed via an affiliate network like ShareASale, which acts as a platform to connect publishers and advertisers, but it is also possible to offer your program directly.\n\n3. What is an affiliate network and how do affiliate networks make money?\n\nAffiliate networks connect publishers to advertisers. Affiliate networks make money by charging fees to the merchants who advertise with them; these merchants are known as advertisers. The percentage of each sale that the advertiser pays is negotiated between the merchant and the affiliate network.\n\n4. What's the difference between affiliate marketing and dropshipping?\n\nDropshipping is a method of selling that allows you to run an online store without having to stock products. You advertise the products as if you owned them, but when someone makes an order, you create a duplicate order with the distributor at a reduced price. The distributor takes care of the post and packaging on your behalf. As affiliate marketing is based on referrals and this type of drop shipping requires no investment in inventory when a customer buys through the affiliate link, no money exchanges hands.\n\n5. Can affiliate marketing and performance marketing be considered the same thing?\n\nPerformance marketing is a method of marketing that pays for performance, like when a sale is made or an ad is clicked This can include methods like PPC (pay-per-click) or display advertising. Affiliate marketing is one form of performance marketing where commissions are paid out to affiliates on a performance basis when they click on their affiliate link and make a purchase or action.\n\n6. Is it possible to promote affiliate offers on mobile devices?\n\nSmartphones are essentially miniature computers, so publishers can display the same websites and offers that are available on a PC. But mobiles also offer specific tools not available on computers, and these can be used to good effect for publishers. Publishers can optimize their ads for mobile users by making them easy to access by this audience. Publishers can also make good use of text and instant messaging to promote their offers. As the mobile market is predicted to make up 80% of traffic in the future, publishers who do not promote on mobile devices are missing out on a big opportunity.\n\n7. Where do I find qualified publishers?\n\nThe best way to find affiliate publishers is on reputable networks like ShareASale Cj(Commission Junction), Awin, and Impact radius. These networks have a strict application process and compliance checks, which means that all affiliates are trustworthy.\n\n8. What is an affiliate disclosure statement?\n\nAn affiliate disclosure statement discloses to the reader that there may be affiliate links on a website, for which a commission may be paid to the publisher if visitors follow these links and make purchases.\n\n9. Does social media activity play a significant role in affiliate marketing?\n\nPublishers promote their programs through a variety of means, including blogs, websites, email marketing, and pay-per-click ads. Social media has a huge interactive audience, making this platform a good source of potential traffic.\n\n10. What is a super affiliate?\n\nA super affiliate is an affiliate partner who consistently drives a large majority of sales from any program they promote, compared to other affiliate partners involved in that program. Affiliates make a lot of money from affiliate marketing Pat Flynn earned more than $50000 in 2013 from affiliate marketing.\n\n11. How do we track publisher sales activity?\n\nPublishers can be identified by their publisher ID, which is used in tracking cookies to determine which publishers generate sales. The activity is then viewed within a network's dashboard.\n\n12. Could we set up an affiliate program in multiple countries?\n\nBecause the Internet is so widespread, affiliate programs can be promoted in any country. Affiliate strategies that are set internationally need to be tailored to the language of the targeted country.\n\n13. How can affiliate marketing help my business?\n\nAffiliate marketing can help you grow your business in the following ways:\n\nIt allows you to save time and money on marketing, which frees you up to focus on other aspects of your business.\n\nYou get access to friendly marketers who are eager to help you succeed.\n\nIt also helps you to promote your products by sharing links and banners with a new audience.\n\nIt offers high ROI(Return on investment) and is cost-effective.\n\n14. How do I find quality publishers?\n\nOne of the best ways to work with qualified affiliates is to hire an affiliate marketing agency that works with all the networks. Affiliates are carefully selected and go through a rigorous application process to be included in the network.\n\n15. How Can we Promote Affiliate Links?\n\nAffiliate marketing is generally associated with websites, but there are other ways to promote your affiliate links, including:\n\nA website or blog\n\nThrough email marketing and newsletter\n\nSocial media, like Facebook, Instagram, or Twitter.\n\nLeave a comment on blogs or forums.\n\nWrite an e-book or other digital product.\n\nYoutube\n\n16. Do you have to pay to sign up for an affiliate program?\n\nTo build your affiliate marketing business, you don't have to invest money in the beginning. You can sign up for free with any affiliate network and start promoting their brands right away.\n\n17. What is a commission rate?\n\nCommission rates are typically based on a percentage of the total sale and in some cases can also be a flat fee for each transaction. The rates are set by the merchant.\n\nWho manages your affiliate program?\n\nSome merchants run their affiliate programs internally, while others choose to contract out management to a network or an external agency.\n\n18. What is a cookie?\n\nCookies are small pieces of data that work with web browsers to store information such as user preferences, login or registration data, and shopping cart contents. When someone clicks on your affiliate link, a cookie is placed on the user's computer or mobile device. That cookie is used to remember the link or ad that the visitor clicked on. Even if the user leaves your site and comes back a week later to make a purchase, you will still get credit for the sale and receive a commission it depends on the site cookies duration\n\n19. How long do cookies last?\n\nThe merchant determines the duration of a cookie, also known as its “cookie life.” The most common length for an affiliate program is 30 days. If someone clicks on your affiliate link, you’ll be paid a commission if they purchase within 30 days of the click.\n\nFinal Saying\n\nMost new affiliates are eager to begin their affiliate marketing business. Unfortunately, there is a lot of bad information out there that can lead inexperienced affiliates astray. Hopefully, the answer to your question will provide clarity on how affiliate marketing works and the pitfalls you can avoid. Most importantly, keep in mind that success in affiliate marketing takes some time. Don't be discouraged if you're not immediately making sales or earning money. It takes most new affiliates months to make a full-time income.",
         "2022-06-01T13:03:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/06/most-frequently-asked-questions-about.html",
         "2025-07-26T05:41:35.820188",
         "There are lots of questions floating around about how affiliate marketing works, what to do and what not to do when it comes to setting up a business. With so much uncertainty surrounding both personal and business aspects of affiliate marketing. In this post, we will answer the most frequently asked question about affiliate marketing 1. What is affiliate marketing? Affiliate marketing is a way to make money by promoting the products and services of other people and companies. You don't need to create your product or service, just promote existing ones. That's why it's so easy to get started with affiliate marketing. You can even get started with no budget at all! 2. What is an affiliate program? An affiliate program is a package of information you create for your product, which is then made available to potential publishers. The program will typically include details about the product and its retail value, commission levels, and promotional materials. Many affiliate programs are managed via an affiliate network like ShareASale, which acts as a platform to connect publishers and advertisers, but it is also possible to offer your program directly. 3. What is an affiliate network and how do affiliate networks make money? Affiliate networks connect publishers to advertisers. Affiliate networks make money by charging fees to the merchants who advertise with them; these merchants are known as advertisers. The percentage of each sale that the advertiser pays is negotiated between the merchant and the affiliate network. 4. What's the difference between affiliate marketing and dropshipping? Dropshipping is a method of selling that allows you to run an online store without having to stock products. You advertise the products as if you owned them, but when someone makes an order, you create a duplicate order with the distributor at a reduced price. The distributor takes care of the post and packaging on your behalf. As affiliate marketing is based on referrals and this type of drop shipping requires no investment in inventory when a customer buys through the affiliate link, no money exchanges hands. 5. Can affiliate marketing and performance marketing be considered the same thing? Performance marketing is a method of marketing that pays for performance, like when a sale is made or an ad is clicked This can include methods like PPC (pay-per-click) or display advertising. Affiliate marketing is one form of performance marketing where commissions are paid out to affiliates on a performance basis when they click on their affiliate link and make a purchase or action. 6. Is it possible to promote affiliate offers on mobile devices? Smartphones are essentially miniature computers, so publishers can display the same websites and offers that are available on a PC. But mobiles also offer specific tools not available on computers, and these can be used to good effect for publishers. Publishers can optimize their ads for mobile users by making them easy to access by this audience. Publishers can also make good use of text and instant messaging to promote their offers. As the mobile market is predicted to make up 80% of traffic in the future, publishers who do not promote on mobile devices are missing out on a big opportunity. 7. Where do I find qualified publishers? The best way to find affiliate publishers is on reputable networks like ShareASale Cj(Commission Junction), Awin, and Impact radius. These networks have a strict application process and compliance checks, which means that all affiliates are trustworthy. 8. What is an affiliate disclosure statement? An affiliate disclosure statement discloses to the reader that there may be affiliate links on a website, for which a commission may be paid to the publisher if visitors follow these links and make purchases. 9. Does social media activity play a significant role in affiliate marketing? Publishers promote their programs through a variety of means, including blogs, websites, email marketing, and pay-per-click ads. Social media has a huge interactive audience, making this platform a good source of potential traffic. 10. What is a super affiliate? A super affiliate is an affiliate partner who consistently drives a large majority of sales from any program they promote, compared to other affiliate partners involved in that program. Affiliates make a lot of money from affiliate marketing Pat Flynn earned more than $50000 in 2013 from affiliate marketing. 11. How do we track publisher sales activity? Publishers can be identified by their publisher ID, which is used in tracking cookies to determine which publishers generate sales. The activity is then viewed within a network's dashboard. 12. Could we set up an affiliate program in multiple countries? Because the Internet is so widespread, affiliate programs can be promoted in any country. Affiliate strategies that are set internationally need to be tailored to the language of the targeted country. 13. How can affiliate marketing help my business? Affiliate marketing can help you grow your business in the following ways: It allows you to save time and money on marketing, which frees you up to focus on other aspects of your business. You get access to friendly marketers who are eager to help you succeed. It also helps you to promote your products by sharing links and banners with a new audience. It offers high ROI(Return on investment) and is cost-effective. 14. How do I find quality publishers? One of the best ways to work with qualified affiliates is to hire an affiliate marketing agency that works with all the networks. Affiliates are carefully selected and go through a rigorous application process to be included in the network. 15. How Can we Promote Affiliate Links? Affiliate marketing is generally associated with websites, but there are other ways to promote your affiliate links, including: A website or blog Through email marketing and newsletter Social media, like Facebook, Instagram, or Twitter. Leave a comment on blogs or forums. Write an e-book or other digital product. Youtube 16. Do you have to pay to sign up for an affiliate program? To build your affiliate marketing business, you don't have to invest money in the beginning. You can sign up for free with any affiliate network and start promoting their brands right away. 17. What is a commission rate? Commission rates are typically based on a percentage of the total sale and in some cases can also be a flat fee for each transaction. The rates are set by the merchant. Who manages your affiliate program? Some merchants run their affiliate programs internally, while others choose to contract out management to a network or an external agency. 18. What is a cookie? Cookies are small pieces of data that work with web browsers to store information such as user preferences, login or registration data, and shopping cart contents. When someone clicks on your affiliate link, a cookie is placed on the user's computer or mobile device. That cookie is used to remember the link or ad that the visitor clicked on. Even if the user leaves your site and comes back a week later to make a purchase, you will still get credit for the sale and receive a commission it depends on the site cookies duration 19. How long do cookies last? The merchant determines the duration of a cookie, also known as its “cookie life.” The most common length for an affiliate program is 30 days. If someone clicks on your affiliate link, you’ll be paid a commission if they purchase within 30 days of the click. Final Saying Most new affiliates are eager to begin their affiliate marketing business. Unfortunately, there is a lot of bad information out there that can lead inexperienced affiliates astray. Hopefully, the answer to your question will provide clarity on how affiliate marketing works and the pitfalls you can avoid. Most importantly, keep in mind that success in affiliate marketing takes some time. Don't be discouraged if you're not immediately making sales or earning money. It takes most new affiliates months to make a full-time income.",
         "en",
         "{'ORG': ['Affiliate networks connect', 'Commission rates', 'Leave', 'Social media has a huge interactive', 'Who', 'and Impact radius', 'for which', 'works'], 'MISC': ['Affiliates are carefully selected and go through a rigorous', 'An', 'As the mobile market is predicted to make', 'Awin', 'Because the Internet is so widespread', 'Cookies are small pieces of data that work with web browsers to store information such as', 'Do you have to pay to sign up for an', \"Don't be discouraged if you're not immediately making sales or\", 'Dropshipping is a method of selling that allows you to run an online store without having to stock products', 'Even if the user leaves your site and comes back', 'Final Saying Most new affiliates are eager to begin their affiliate marketing business', 'How Can we Promote Affiliate Links', 'ID', 'In this post', 'Is it possible to', 'It allows you to save time and money on marketing', 'It also helps you to promote your products by sharing links and banners with', 'It offers high ROI(Return', 'It takes most new affiliates months to make', 'Most', 'One of the best ways to work with', 'PC', 'Performance marketing is a method of marketing that pays for performance', 'Publishers can be identified by their', 'Publishers promote their programs through a variety of means', 'ShareASale', 'Smartphones are', 'Some merchants', 'That cookie is used to remember the link or ad that the visitor', \"That's why it's so easy to get started with affiliate marketing\", 'The', \"The activity is then viewed within a network's dashboard\", 'The best way to find affiliate', 'The distributor takes care of the post and packaging on your behalf', 'The rates are set by the merchant', 'These networks have', 'This can include methods like PPC', 'Through email marketing and newsletter Social', 'To build your affiliate marketing business', 'Twitter', 'What is', 'What is a cookie?', 'What is affiliate marketing', \"What's the difference between affiliate marketing and dropshipping\", 'Where do I find', 'With so much uncertainty surrounding', 'Write an e-book or', 'You advertise the products as if you owned them', 'You can even get started with no budget at all!', 'You can sign up for free with any affiliate network and start promoting', \"You don't need to create your product or\", 'You get access to friendly marketers who are eager to help you succeed', 'Youtube 16', 'and pay-per-click ads', 'and promotional materials', 'levels', 'like Facebook', 'like when a sale is made or an ad is clicked', 'link', 'make', 'making this platform a good source of potential', 'messaging to promote their', 'these merchants are known as advertisers', 'what to do and what not to do when it comes to setting up', 'which frees you up to focus on other aspects of your business', 'while others choose to contract out management to a network or', 'will provide clarity on how affiliate marketing works and the pitfalls you can avoid', 'you’ll be paid'], 'PER': ['Pat Flynn', 'just', 'you create', \"you don't have to\", 'you will still get credit for the sale and receive'], 'LOC': ['An', 'Hopefully', 'Instagram']}",
         "[0.025052685290575027, -0.10273487865924835, -0.02134210430085659, 0.016612935811281204, 0.02818135730922222, 0.045438237488269806, 0.03368154540657997, 0.04817405715584755, -0.011836608871817589, -0.05667911842465401, 0.04980586841702461, 0.001977408304810524, 0.1213134303689003, -0.038321420550346375, -0.0011526604648679495, -0.06078089028596878, 0.06822168827056885, -0.025644907727837563, -0.10401629656553268, -0.049638982862234116, -0.006194510497152805, -0.04094679281115532, 0.0005452996701933444, -0.011775259859859943, -0.04960738494992256, 0.0034773254301398993, 0.018434803932905197, -0.011751261539757252, -0.04346933215856552, -0.026768097653985023, 0.07412104308605194, -0.08125021308660507, 0.06202975660562515, -0.0017634379910305142, -0.04329805448651314, -0.058633748441934586, -0.04804312437772751, -0.03969871252775192, -0.005651369225233793, 0.08979467302560806, -0.019460324198007584, -0.05581999197602272, -0.125798761844635, -0.010626733303070068, 0.025393657386302948, -0.05189422890543938, 0.008021896705031395, 0.06122022122144699, -0.05555298924446106, 0.056890614330768585, 0.030880454927682877, -0.006692550145089626, 0.008688061498105526, -0.041994355618953705, -0.028923146426677704, -0.05375269055366516, -0.04786664992570877, 0.03916193172335625, -0.039072394371032715, -0.02742948569357395, 0.039792489260435104, -0.031214887276291847, 0.0021897563710808754, 0.010719140991568565, -0.057807207107543945, -0.03337782248854637, 0.02530917525291443, 0.05469903349876404, -0.010688276030123234, -0.1303335279226303, 0.006004698574542999, -0.02348451502621174, -0.039466600865125656, 0.07720787823200226, 0.024295896291732788, -0.079661525785923, 0.1173873096704483, 0.03359159082174301, 0.02696976624429226, 0.03581629693508148, -0.01757388934493065, 0.039586689323186874, -0.019471120089292526, 0.027657167986035347, -0.05725675821304321, 0.009977182373404503, 0.02795279026031494, 0.05215655639767647, -0.04965437203645706, 0.025630328804254532, -0.043778251856565475, 0.05734378099441528, -0.06826207786798477, -0.0715462788939476, 0.1649296134710312, 0.0861617848277092, -0.03892543911933899, -0.04315594583749771, 0.03711210563778877, -0.06080279499292374, -0.004419885575771332, -0.030853141099214554, 0.03923799842596054, -0.03565952554345131, -0.006365848705172539, -0.024335872381925583, -0.0302286259829998, 0.03992698714137077, 0.04705126956105232, 0.10265529900789261, -0.07682476937770844, -0.001460295170545578, 0.0027986825443804264, -0.04066519811749458, 0.08879586309194565, 0.07427717745304108, -0.044709693640470505, 0.06303076446056366, 0.033824216574430466, 0.04384038969874382, 0.002879152540117502, 0.04954896867275238, 0.08446298539638519, -0.019945332780480385, 0.0315849669277668, -0.02063855715095997, -0.05015953257679939, 4.596631068936395e-33, -0.045149799436330795, 0.02249196544289589, -0.03249790146946907, 0.03134524077177048, -0.03743470832705498, 0.0020384667441248894, 0.004858965519815683, 0.03837867081165314, -0.03529885783791542, 0.06191053241491318, -0.00178941257763654, 0.034242257475852966, 0.03945746272802353, 0.15164773166179657, 0.045096851885318756, 0.01993178017437458, 0.06178072467446327, -0.07235384732484818, 0.0012356159277260303, -0.030559159815311432, 0.02873942442238331, -0.015924770385026932, 0.043203990906476974, 0.06974369287490845, -0.0034839115105569363, -0.06137670949101448, -0.04910626634955406, 0.01830156147480011, 0.02629893831908703, -0.023151881992816925, -0.029043903574347496, 0.0014213841641321778, 0.019896121695637703, -0.06230743229389191, -0.09582126140594482, -0.02958989329636097, 0.02901245281100273, -0.1064162626862526, 0.019352154806256294, -0.01704535447061062, -0.09827487915754318, -0.00979173369705677, -0.031252555549144745, 0.0022003452759236097, 0.022968992590904236, 0.03523824363946915, -0.0002933234500233084, 0.003367870580404997, 0.07545679062604904, 0.00720248045399785, 0.08808770030736923, -0.009629677049815655, 0.11619396507740021, -0.04623420163989067, 0.013417274691164494, 0.047943342477083206, -0.018139241263270378, -0.06259637326002121, -0.0388188473880291, -0.022111620754003525, 0.015198255889117718, -0.08634693920612335, 0.04875209555029869, 0.006599989254027605, -0.06180523708462715, 0.01703225076198578, 0.027864065021276474, 0.0341733954846859, 0.05060368776321411, 0.0009870427893474698, -0.043085455894470215, 0.010759065859019756, -0.03482332080602646, -0.007265071384608746, 0.031790751963853836, 0.09378018975257874, -0.04656147584319115, 0.006384916137903929, 0.026077404618263245, 0.09560947865247726, -0.03143820911645889, -0.00030579473241232336, 0.03357844427227974, 0.022818829864263535, -0.022007986903190613, -0.028469473123550415, 0.006680043414235115, 0.005396454595029354, 0.05409587547183037, -0.015993831679224968, 0.15792246162891388, 0.06529895961284637, -0.0956968441605568, 0.051238562911748886, 0.14535079896450043, -5.600047005793716e-33, 0.035347189754247665, 0.0966382548213005, -0.03894571587443352, -0.03683939203619957, -0.012661503627896309, 0.051227010786533356, -0.05901670828461647, -0.02771490253508091, -0.01864744909107685, -0.09796752780675888, -0.1156836524605751, -0.02595163881778717, -0.026029665023088455, -0.042892709374427795, -0.06740240007638931, -0.06474876403808594, 0.024052787572145462, 0.04135951027274132, 0.03772693872451782, -0.0002901938569266349, -0.015441486611962318, -0.0012764922576025128, -0.04168437421321869, -0.16360166668891907, 0.04293259233236313, -0.026676323264837265, -0.03108861856162548, 0.04395283758640289, 0.006307990290224552, 0.08767902851104736, 0.04440290853381157, -0.01664053462445736, 0.08679432421922684, -0.05367216095328331, 0.022865161299705505, 0.13175196945667267, -0.01125257182866335, -0.01803159900009632, -0.017759177833795547, -0.16873815655708313, 0.015303539112210274, -0.01064052153378725, 0.07981719821691513, -0.048728328198194504, -0.04695962369441986, -0.008056145161390305, 0.01491808146238327, -0.019093789160251617, -0.04714951664209366, -0.03501993790268898, -0.019730249419808388, 0.01069923210889101, 0.041749726980924606, -0.011636067181825638, -0.01792662963271141, 0.017864380031824112, 0.0044607981108129025, 0.08007200062274933, 0.038618844002485275, -0.011795486323535442, -0.05343474820256233, 0.0567990243434906, 0.04350589960813522, 0.0714464858174324, -0.082188181579113, -0.043441880494356155, 0.09245748817920685, -0.01609441637992859, -0.060803525149822235, -0.05323770269751549, -0.008805522695183754, 0.0834544375538826, -0.005142007488757372, -0.03583969548344612, -0.09583350270986557, 0.08008255809545517, -0.03361360356211662, -0.017527621239423752, -0.04522554203867912, -0.04442335665225983, 0.06460236012935638, -0.007425118703395128, 0.0020677032880485058, -0.05089240148663521, -0.05055054649710655, -0.015662986785173416, 0.02691701427102089, 0.018096499145030975, -0.004622052889317274, -0.029817819595336914, -0.019626719877123833, 0.005102480296045542, 0.0023743414785712957, 0.07258119434118271, 0.029856545850634575, -5.447314777029533e-08, -0.038769982755184174, -0.00888653751462698, 0.028673620894551277, 0.028626058250665665, 0.00458857137709856, 0.05819781869649887, 0.05058996379375458, 0.018664531409740448, 0.030126694589853287, 0.01683584600687027, -0.06749881058931351, 0.00941046979278326, -0.07401195913553238, -0.00985143892467022, 0.06574619561433792, 0.017149783670902252, 0.028728177770972252, -0.03250490128993988, 0.049375228583812714, 0.009253374300897121, -0.029367851093411446, -0.053542837500572205, -0.03344777598977089, -0.02728319726884365, 0.06421159207820892, -0.021545007824897766, 0.008602894842624664, 0.10222914069890976, -0.0005999603308737278, -0.01481853798031807, -0.017873162403702736, -0.04444298520684242, -0.0008443031110800803, 0.01842617616057396, -0.11085115373134613, -0.022129863500595093, 0.027988383546471596, -0.05529830604791641, -0.014011744409799576, -0.002363472478464246, -0.02758128009736538, 0.029504237696528435, 0.03607892990112305, -0.07370700687170029, -0.03768422454595566, 0.013347252272069454, -0.041022367775440216, -0.058244738727808, 0.03335633501410484, 0.02195863425731659, 0.04469941183924675, -0.03297053650021553, 0.04218139126896858, -0.10141577571630478, -0.015831222757697105, -0.0049438271671533585, -0.0028332271613180637, 0.043578870594501495, 0.09236760437488556, 0.0766594409942627, -0.0642537772655487, -0.0056402250193059444, 0.0414208360016346, -0.04432797059416771]",
         "0.179"
        ],
        [
         "23",
         "573",
         "Optimize for Impact: How to Stay Ahead of Gen AI and Thrive as a Data Scientist",
         "The data scientists who survive won't be the ones who code better than ChatGPT—they'll be the ones who think strategically The post Optimize for Impact: How to Stay Ahead of Gen AI and Thrive as a Data Scientist appeared first on Towards Data Science .",
         "This article is an excerpt from my upcoming book about how data scientists can not just survive the AI wave, but use it to level up their careers. If you’d like to hear when it’s ready, please join the waitlist here!\n\nthat junior and even mid-level data scientists take pride in—the stuff that makes them feel smart, technical, and irreplaceable—is now baseline automation. The uncomfortable question isn’t whether AI can do these things as good as a human, it’s whether a human is still adding value by doing them himself. AI is already good enough for most of the routine work that fills a typical data scientist’s day; and in business, good enough at 10% the cost and 1% the time usually wins.\n\nMost Data Scientists are Still Optimizing for Accuracy\n\nClinging to your familiar workflows isn’t just inefficient, it’s soon to be a career risk. While you’re perfecting your pandas syntax, your peers are learning to ask better questions, influence real business decisions, and optimize for impact. They’re not trying to outrun the robots; they’re doing the work robots can’t do.\n\nMost data scientists are trained for academic rigor. In school or in Kaggle competitions, we got neat and tidy data sets, and set out to build ML models with incrementally better accuracy. We’d been trained to chase clean answers, statistical significance, and low error rates. Once we got our first job, we discovered that clean data rarely exists, and the first 90% of each project would be spent just setting up our data.\n\nGen AI is forcing data scientists into another similar shift of mindset. Much of the work that has been our bread-and-butter can be done by AI now; maybe not as good as we could do it, but certainly good enough, and much faster at that. This isn’t a threat though, it’s an opportunity. What your manager is thinking, or maybe your manager’s manager, is that business impact > technical precision. Delivering a perfect visualization or insight isn’t enough anymore. If you’re not driving decisions, then you are replaceable.\n\nThe Shift from Outputs to Outcomes\n\nTo thrive in this new AI era, data scientists must become more strategic. They must start to think like a product manager thinks. This is what I mean by “optimize for impact.” Start with the decision, not the deliverable, and work backward. Focus on actionability, even at the expense of exhaustiveness. Communicate tradeoffs, interpretations, and recommendations with each piece of work.\n\nPMs start from the business goal, and then start working towards a decision. As a data scientist, I would often start from the data and ask what questions I could answer with it—this isn’t the way forward anymore. A PM is a ruthless prioritizer: What actually moves the needle? What won’t get done if we spend time on this? A PM thinks in terms of tradeoffs, constraints, and leverage; they care more about impact than elegance. Data is a tool, not the destination.\n\nI’ve identified five concrete changes of mindset that every data scientist can learn from PMs. A data scientist who becomes proficient in these skills will become defensible from encroachment by AI. This isn’t necessarily a playbook to a promotion to Staff+ levels (although it can be—there is a lot of overlap), but a framework to capitalize on AI’s weaknesses.\n\nFive Tactical Actions to Start Optimizing for Impact\n\n1. Start with the Decision, Not the Data\n\nMost data scientists open a new project by pulling a dataset. It’s comforting to poke around the numbers, explore the shape of the data, and see what interesting trends emerge; it gives the satisfying feeling (or more accurately, the illusion) of progress at the start of an ambiguous project. But this is how you end up with dashboards no one looks at and models that never get used. If you want your work to matter, you need to start with three questions:\n\nWhat decision will this inform?\n\nWhat action might it change?\n\nWhat happens if we do nothing?\n\nImagine you’re asked to analyze a user drop-off funnel. A junior data scientist might build a beautiful funnel chart, break it down by platform and region, and maybe even segment it by monthly cohorts. But then what? What decision does that analysis support? What action can the team take? The better question might have been: “What would we do differently if we learned that Android users drop off more?” Maybe the right decision is whether to invest engineering time in fixing the Android onboarding flow. That’s the business context you need before writing a single line of SQL.\n\nBefore you run your first query, align with your stakeholders on the decision they’re trying to make. If your analysis doesn’t lead to a decision, it’s wasted time. Start at the end and work backward. The key is actionability.\n\nWhy it differentiates you from AI: LLMs can analyze data, but they can’t understand org dynamics, anticipate political resistance, or choose which battles are worth fighting. That’s judgment—human territory.\n\n2. Prioritize Projects That Move the Roadmap\n\nData scientists often fall into the trap of chasing interesting questions. But interesting is not the same as important. I once spent two weeks writing a 50-page analysis documenting user activity in an emerging line of behaviors; but although everyone in the org read it, no one did anything. I was proud of the result, but it wasn’t actionable. That was a wake-up call.\n\nIf you want to be indispensable, get close to the roadmap. What are the 2–3 bets the company is making this quarter? What’s the PM losing sleep over? What open question is blocking the next big initiative? Anchor your projects to these. If your work ties directly to a team’s goals, it’s far more likely to drive action—and far more likely to be seen by leadership.\n\nA strategic project has five key characteristics:\n\nFirst, it influences a key product or business decision. This isn’t just about providing data to inform a decision, it’s about providing data that actually changes what gets decided. Strategic projects surface insights that make stakeholders think, “We need to reconsider our approach here.”\n\nSecond, it’s tied to roadmap planning or resourcing. Strategic work feeds into quarterly planning cycles, annual budgeting processes, or major product launches. It’s the analysis that gets referenced in leadership meetings when teams are deciding what to build next.\n\nThird, it surfaces tradeoffs or uncertainty in product direction. Strategic projects don’t just confirm what everyone already believes. They reveal hidden assumptions, quantify difficult tradeoffs, or expose blind spots in the team’s thinking. They make the invisible visible.\n\nFourth, it generates reusable artifacts. Strategic projects create metrics, models, frameworks, or insights that get leveraged by other teams or in future decisions. They’re not one-time analyses that disappear into the ether.\n\nFifth, it raises the ceiling of decision-making for others. Strategic work elevates conversations from tactical (“Should we change the button color?”) to strategic (“What does user engagement actually mean for our business?”).\n\nSmart data scientists don’t just answer interesting questions. They answer valuable ones. The difference between a junior analyst and a strategic data scientist is their ability to identify work that actually matters; work that influences decisions, changes minds, and moves the business forward.\n\nWhy it differentiates you from AI: AI can surface insights, but only you can see the product landscape, navigate tradeoffs, and strategically insert yourself where real leverage lives.\n\n3. Define Metrics that Reflect the Business and Incentivize the Right Behaviors\n\nEvery metric encodes assumptions, priorities, and tradeoffs. The question isn’t “what can we measure?” but “what should we optimize for?” This distinction separates strategic data scientists from tactical ones. Tactical data scientists take metrics as given. “Marketing wants to improve conversion rates? Great, let’s measure conversion rates.” Strategic data scientists ask deeper questions: “What does the business actually care about? What behaviors do we want to encourage? What could backfire if we optimize for this?” Many shady subscription services (in)famously work to drive down cancellations… by making it harder to cancel. That’s not insight, it’s misaligned incentives.\n\nIt’s your job to define metrics that guide good decisions. That means starting from the business objective and working backward. What does success actually look like? What behavior do we want to encourage? What leading indicator can we use to detect problems early? And what’s the dark side of optimizing for this metric?\n\nSort your metrics into four layers. North Star metrics define long-term success and align the entire company—like YouTube tracking Weekly Active Creators to center their mission around content production. Supporting metrics break down and drive movement in the north star, surfacing where strategic action is most needed—like creator retention or uploads per creator. Guardrail metrics prevent unintended harm while optimizing, ensuring quality and trust stay intact even under aggressive growth. And operational metrics keep the system running day-to-day—essential for execution, but not where strategy lives.\n\nMost data scientists will be devising the supporting metrics—these are the ones which provide signal in an experiment. A great supporting metric does three things: reflects reality, influences behavior, and is sensitive to change. Getting this right means working closely with PMs, engineers, and ops to understand the full system.\n\nWhy it differentiates you from AI: AI can optimize a number, but only you can question whether it’s the right number. Defining success is a political, strategic, and human act influenced by the nuance of your specific business.\n\n4. Match the Analytical Approach to the Decision Risk and Value\n\nBefore you write a single line of code or draft an experimental design, step back and ask four strategic questions: How fast do we need an answer? How wrong can we afford to be? What constraints do we face? And what decision hangs on this analysis? These questions—timeline, precision, feasibility, and impact—form a mental model for choosing the right analytical approach for the situation at hand.\n\nTimeline is often the dominant constraint. If leadership needs a decision by Friday, you’re not running a gold-standard experiment. You’re using historical data, descriptive metrics, or synthetic comparisons to make an informed call fast.\n\nPrecision is about risk tolerance: bet-the-company decisions require rigorous testing and large samples; a button color change might only need a directional signal. Don’t over-engineer when stakes are low—and don’t under-engineer when stakes are high.\n\nFeasibility reminds us that real-world analytics happens under constraints—traffic, tooling, org politics, data access. But those constraints aren’t blockers; they’re design parameters. Your workaround could become your competitive advantage.\n\nAnd finally, Impact is about ruthless prioritization. Your most sophisticated methods should support your most strategic decisions. If an analysis won’t affect what gets built, funded, or killed, you’re either wasting time or avoiding a harder conversation.\n\nThere is no “best” method in the abstract. The best method is the one that fits your constraints and drives the decision forward. To match method to moment, ask yourself: What’s the cost of a false positive? A false negative? What decision will this analysis inform, and how reversible is that decision? A one-way door needs rigor. A two-way door needs speed. If it’s a million-dollar bet, get tight estimates. If it’s a UX tweak, ship it and monitor over the next week or two.\n\nGood analysis isn’t just accurate—it’s appropriately scoped for the decision it supports.\n\nWhy it differentiates you from AI: AI can calculate statistical significance, but it can’t weigh business risk or adjust for what’s at stake. You’re not just running tests, you’re managing consequences and you need business context from your experience.\n\n5. Turn Insights Into Action, Not Just Understanding\n\nThe biggest sin in data science isn’t being wrong—it’s being irrelevant. A clever model or rich insight means nothing if it doesn’t change what the business does next. I’ve been guilty of this: presenting a polished analysis, getting polite nods, and walking away thinking I’d done my job. But the real test is whether your work moves someone to act.\n\nThis means your work needs to come with a point of view. If you’re only showing what happened, then you’re not completing the task. You also need to recommend what to do next. Be clear about tradeoffs, risks, and confidence levels. Show how this insight ties to a decision the team is facing right now. Even better, co-create the action plan with your stakeholder before you ever open a slide deck.\n\nOne trick: write the recommendation slide before you start the analysis. If you can’t imagine what action would result from your work, don’t do it. Data science is only as valuable as the decisions it enables.\n\nWhy it differentiates you from AI: AI can find patterns. You connect them to strategy, urgency, and ownership—then get people to actually act. That’s what drives impact.\n\nStrategy is Your New Job\n\nYou have a choice to make. You can continue doing the same type of work you’ve always done, hoping that someone else will recognize your value and give you opportunities for strategic impact. Or you can proactively develop strategic capabilities, position yourself for high-impact work, and help define what the future of data science looks like.\n\nThe first path is comfortable but risky. The second path is challenging but rewarding.\n\nThe five mindset shifts we’ve discussed aren’t just survival tactics. They’re career accelerators. Data scientists who master these skills don’t just become AI-proof; they become indispensable strategic partners who drive real business outcomes (and prime promotion candidates!).\n\nStart small, but start now. Pick one project this quarter and apply the decision-first framework. Choose one metric you’re currently tracking and ask whether it’s driving the right behaviors. Take one analysis you’ve completed and ask yourself: “What action should we take based on this?”\n\nBuilding strategic capabilities takes time. You won’t become a strategic data scientist overnight, and you shouldn’t expect to. But every month you spend developing business acumen, every quarter you spend building cross-functional relationships, every year you spend taking on more strategic work will compound over and over.\n\nThe AI revolution is already here. The question isn’t whether your role will change, but whether you’ll lead that change or let it happen to you. Your technical foundation is solid. Now it’s time to build strategic thinking on top of it. The future belongs to data scientists who can do both—and the future starts with your next project.\n\nDid this post ignite your curiosity about becoming a more strategic data scientist? Join the waitlist for The Strategic Data Scientist: How to Level Up and Thrive in the Age of AI. Learn the frameworks, mindsets, and tactics Strategic Data Scientists use to drive impact without managing people; and discover how to work with AI as a strategic co-pilot, not a replacement.",
         "2025-07-24T19:19:49",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/optimize-for-impact-how-to-stay-ahead-of-gen-ai-and-thrive-as-a-data-scientist/",
         "2025-07-26T06:23:31.303423",
         "This article is an excerpt from my upcoming book about how data scientists can not just survive the AI wave, but use it to level up their careers. If you’d like to hear when it’s ready, please join the waitlist here! that junior and even mid-level data scientists take pride in—the stuff that makes them feel smart, technical, and irreplaceable—is now baseline automation. The uncomfortable question isn’t whether AI can do these things as good as a human, it’s whether a human is still adding value by doing them himself. AI is already good enough for most of the routine work that fills a typical data scientist’s day; and in business, good enough at 10% the cost and 1% the time usually wins. Most Data Scientists are Still Optimizing for Accuracy Clinging to your familiar workflows isn’t just inefficient, it’s soon to be a career risk. While you’re perfecting your pandas syntax, your peers are learning to ask better questions, influence real business decisions, and optimize for impact. They’re not trying to outrun the robots; they’re doing the work robots can’t do. Most data scientists are trained for academic rigor. In school or in Kaggle competitions, we got neat and tidy data sets, and set out to build ML models with incrementally better accuracy. We’d been trained to chase clean answers, statistical significance, and low error rates. Once we got our first job, we discovered that clean data rarely exists, and the first 90% of each project would be spent just setting up our data. Gen AI is forcing data scientists into another similar shift of mindset. Much of the work that has been our bread-and-butter can be done by AI now; maybe not as good as we could do it, but certainly good enough, and much faster at that. This isn’t a threat though, it’s an opportunity. What your manager is thinking, or maybe your manager’s manager, is that business impact > technical precision. Delivering a perfect visualization or insight isn’t enough anymore. If you’re not driving decisions, then you are replaceable. The Shift from Outputs to Outcomes To thrive in this new AI era, data scientists must become more strategic. They must start to think like a product manager thinks. This is what I mean by “optimize for impact.” Start with the decision, not the deliverable, and work backward. Focus on actionability, even at the expense of exhaustiveness. Communicate tradeoffs, interpretations, and recommendations with each piece of work. PMs start from the business goal, and then start working towards a decision. As a data scientist, I would often start from the data and ask what questions I could answer with it—this isn’t the way forward anymore. A PM is a ruthless prioritizer: What actually moves the needle? What won’t get done if we spend time on this? A PM thinks in terms of tradeoffs, constraints, and leverage; they care more about impact than elegance. Data is a tool, not the destination. I’ve identified five concrete changes of mindset that every data scientist can learn from PMs. A data scientist who becomes proficient in these skills will become defensible from encroachment by AI. This isn’t necessarily a playbook to a promotion to Staff+ levels (although it can be—there is a lot of overlap), but a framework to capitalize on AI’s weaknesses. Five Tactical Actions to Start Optimizing for Impact 1. Start with the Decision, Not the Data Most data scientists open a new project by pulling a dataset. It’s comforting to poke around the numbers, explore the shape of the data, and see what interesting trends emerge; it gives the satisfying feeling (or more accurately, the illusion) of progress at the start of an ambiguous project. But this is how you end up with dashboards no one looks at and models that never get used. If you want your work to matter, you need to start with three questions: What decision will this inform? What action might it change? What happens if we do nothing? Imagine you’re asked to analyze a user drop-off funnel. A junior data scientist might build a beautiful funnel chart, break it down by platform and region, and maybe even segment it by monthly cohorts. But then what? What decision does that analysis support? What action can the team take? The better question might have been: “What would we do differently if we learned that Android users drop off more?” Maybe the right decision is whether to invest engineering time in fixing the Android onboarding flow. That’s the business context you need before writing a single line of SQL. Before you run your first query, align with your stakeholders on the decision they’re trying to make. If your analysis doesn’t lead to a decision, it’s wasted time. Start at the end and work backward. The key is actionability. Why it differentiates you from AI: LLMs can analyze data, but they can’t understand org dynamics, anticipate political resistance, or choose which battles are worth fighting. That’s judgment—human territory. 2. Prioritize Projects That Move the Roadmap Data scientists often fall into the trap of chasing interesting questions. But interesting is not the same as important. I once spent two weeks writing a 50-page analysis documenting user activity in an emerging line of behaviors; but although everyone in the org read it, no one did anything. I was proud of the result, but it wasn’t actionable. That was a wake-up call. If you want to be indispensable, get close to the roadmap. What are the 2–3 bets the company is making this quarter? What’s the PM losing sleep over? What open question is blocking the next big initiative? Anchor your projects to these. If your work ties directly to a team’s goals, it’s far more likely to drive action—and far more likely to be seen by leadership. A strategic project has five key characteristics: First, it influences a key product or business decision. This isn’t just about providing data to inform a decision, it’s about providing data that actually changes what gets decided. Strategic projects surface insights that make stakeholders think, “We need to reconsider our approach here.” Second, it’s tied to roadmap planning or resourcing. Strategic work feeds into quarterly planning cycles, annual budgeting processes, or major product launches. It’s the analysis that gets referenced in leadership meetings when teams are deciding what to build next. Third, it surfaces tradeoffs or uncertainty in product direction. Strategic projects don’t just confirm what everyone already believes. They reveal hidden assumptions, quantify difficult tradeoffs, or expose blind spots in the team’s thinking. They make the invisible visible. Fourth, it generates reusable artifacts. Strategic projects create metrics, models, frameworks, or insights that get leveraged by other teams or in future decisions. They’re not one-time analyses that disappear into the ether. Fifth, it raises the ceiling of decision-making for others. Strategic work elevates conversations from tactical (“Should we change the button color?”) to strategic (“What does user engagement actually mean for our business?”). Smart data scientists don’t just answer interesting questions. They answer valuable ones. The difference between a junior analyst and a strategic data scientist is their ability to identify work that actually matters; work that influences decisions, changes minds, and moves the business forward. Why it differentiates you from AI: AI can surface insights, but only you can see the product landscape, navigate tradeoffs, and strategically insert yourself where real leverage lives. 3. Define Metrics that Reflect the Business and Incentivize the Right Behaviors Every metric encodes assumptions, priorities, and tradeoffs. The question isn’t “what can we measure?” but “what should we optimize for?” This distinction separates strategic data scientists from tactical ones. Tactical data scientists take metrics as given. “Marketing wants to improve conversion rates? Great, let’s measure conversion rates.” Strategic data scientists ask deeper questions: “What does the business actually care about? What behaviors do we want to encourage? What could backfire if we optimize for this?” Many shady subscription services (in)famously work to drive down cancellations… by making it harder to cancel. That’s not insight, it’s misaligned incentives. It’s your job to define metrics that guide good decisions. That means starting from the business objective and working backward. What does success actually look like? What behavior do we want to encourage? What leading indicator can we use to detect problems early? And what’s the dark side of optimizing for this metric? Sort your metrics into four layers. North Star metrics define long-term success and align the entire company—like YouTube tracking Weekly Active Creators to center their mission around content production. Supporting metrics break down and drive movement in the north star, surfacing where strategic action is most needed—like creator retention or uploads per creator. Guardrail metrics prevent unintended harm while optimizing, ensuring quality and trust stay intact even under aggressive growth. And operational metrics keep the system running day-to-day—essential for execution, but not where strategy lives. Most data scientists will be devising the supporting metrics—these are the ones which provide signal in an experiment. A great supporting metric does three things: reflects reality, influences behavior, and is sensitive to change. Getting this right means working closely with PMs, engineers, and ops to understand the full system. Why it differentiates you from AI: AI can optimize a number, but only you can question whether it’s the right number. Defining success is a political, strategic, and human act influenced by the nuance of your specific business. 4. Match the Analytical Approach to the Decision Risk and Value Before you write a single line of code or draft an experimental design, step back and ask four strategic questions: How fast do we need an answer? How wrong can we afford to be? What constraints do we face? And what decision hangs on this analysis? These questions—timeline, precision, feasibility, and impact—form a mental model for choosing the right analytical approach for the situation at hand. Timeline is often the dominant constraint. If leadership needs a decision by Friday, you’re not running a gold-standard experiment. You’re using historical data, descriptive metrics, or synthetic comparisons to make an informed call fast. Precision is about risk tolerance: bet-the-company decisions require rigorous testing and large samples; a button color change might only need a directional signal. Don’t over-engineer when stakes are low—and don’t under-engineer when stakes are high. Feasibility reminds us that real-world analytics happens under constraints—traffic, tooling, org politics, data access. But those constraints aren’t blockers; they’re design parameters. Your workaround could become your competitive advantage. And finally, Impact is about ruthless prioritization. Your most sophisticated methods should support your most strategic decisions. If an analysis won’t affect what gets built, funded, or killed, you’re either wasting time or avoiding a harder conversation. There is no “best” method in the abstract. The best method is the one that fits your constraints and drives the decision forward. To match method to moment, ask yourself: What’s the cost of a false positive? A false negative? What decision will this analysis inform, and how reversible is that decision? A one-way door needs rigor. A two-way door needs speed. If it’s a million-dollar bet, get tight estimates. If it’s a UX tweak, ship it and monitor over the next week or two. Good analysis isn’t just accurate—it’s appropriately scoped for the decision it supports. Why it differentiates you from AI: AI can calculate statistical significance, but it can’t weigh business risk or adjust for what’s at stake. You’re not just running tests, you’re managing consequences and you need business context from your experience. 5. Turn Insights Into Action, Not Just Understanding The biggest sin in data science isn’t being wrong—it’s being irrelevant. A clever model or rich insight means nothing if it doesn’t change what the business does next. I’ve been guilty of this: presenting a polished analysis, getting polite nods, and walking away thinking I’d done my job. But the real test is whether your work moves someone to act. This means your work needs to come with a point of view. If you’re only showing what happened, then you’re not completing the task. You also need to recommend what to do next. Be clear about tradeoffs, risks, and confidence levels. Show how this insight ties to a decision the team is facing right now. Even better, co-create the action plan with your stakeholder before you ever open a slide deck. One trick: write the recommendation slide before you start the analysis. If you can’t imagine what action would result from your work, don’t do it. Data science is only as valuable as the decisions it enables. Why it differentiates you from AI: AI can find patterns. You connect them to strategy, urgency, and ownership—then get people to actually act. That’s what drives impact. Strategy is Your New Job You have a choice to make. You can continue doing the same type of work you’ve always done, hoping that someone else will recognize your value and give you opportunities for strategic impact. Or you can proactively develop strategic capabilities, position yourself for high-impact work, and help define what the future of data science looks like. The first path is comfortable but risky. The second path is challenging but rewarding. The five mindset shifts we’ve discussed aren’t just survival tactics. They’re career accelerators. Data scientists who master these skills don’t just become AI-proof; they become indispensable strategic partners who drive real business outcomes (and prime promotion candidates!). Start small, but start now. Pick one project this quarter and apply the decision-first framework. Choose one metric you’re currently tracking and ask whether it’s driving the right behaviors. Take one analysis you’ve completed and ask yourself: “What action should we take based on this?” Building strategic capabilities takes time. You won’t become a strategic data scientist overnight, and you shouldn’t expect to. But every month you spend developing business acumen, every quarter you spend building cross-functional relationships, every year you spend taking on more strategic work will compound over and over. The AI revolution is already here. The question isn’t whether your role will change, but whether you’ll lead that change or let it happen to you. Your technical foundation is solid. Now it’s time to build strategic thinking on top of it. The future belongs to data scientists who can do both—and the future starts with your next project. Did this post ignite your curiosity about becoming a more strategic data scientist? Join the waitlist for The Strategic Data Scientist: How to Level Up and Thrive in the Age of AI. Learn the frameworks, mindsets, and tactics Strategic Data Scientists use to drive impact without managing people; and discover how to work with AI as a strategic co-pilot, not a replacement.",
         "en",
         "{'PER': ['Communicate tradeoffs', 'Feasibility reminds', 'If you can’t', 'Kaggle', 'Your workaround could become your competitive', 'and tradeoffs', 'appropriately scoped for the decision it supports', 'ask yourself:', 'get close to the roadmap', 'hoping that someone else will recognize your value and give you opportunities for', 'navigate tradeoffs', 'not', 'please join the waitlist here!', 'then get people to actually act', 'then you are replaceable', 'then you’re not completing the task'], 'MISC': ['Anchor your projects', 'And finally', 'And what decision hangs on this analysis', 'And what’s the dark side of optimizing for this metric?', 'Be clear about tradeoffs', 'Before you run your first query', 'But the real test is whether your work moves someone to act', 'But this is how you end', 'Choose one metric you’re currently tracking and ask whether it’s driving the right behaviors', 'Data is a tool', 'Data scientists who master these skills don’t just become AI-proof', 'Defining success is a political', 'Delivering a perfect visualization or insight isn’t enough anymore', 'Don’t over-engineer when stakes are low—and don’t under-engineer when stakes are high', 'Even better', 'Focus on actionability', 'Fourth', 'Friday', 'Getting this right means working closely with PMs', 'Great', 'Guardrail', 'How fast do we need an answer', 'How wrong can we afford to be?', 'I would often start from the data and ask what questions I could answer with it—this isn’t the way forward anymore', 'If it’', 'If it’s a UX tweak', 'If you want to be indispensable', 'If your analysis doesn’t lead to a decision', 'If you’re only showing what happened', 'Impact is about ruthless prioritization', 'It’', 'It’s the analysis that gets referenced in leadership meetings when teams are deciding what to build next', 'It’s your job to define metrics that guide good decisions', 'I’ve been guilty of this: presenting', 'Join the waitlist for The Strategic Data Scientist: How to Level Up and Thrive in the Age of AI', 'Learn the frameworks', 'Marketing wants to improve conversion rates', 'Match the Analytical Approach to the Decision Risk and Value Before you write', 'Metrics that Reflect the Business and', 'Most Data Scientists are Still Optimizing for Accuracy Clinging to your familiar workflows isn’t just', 'Much of the work that has been our bread-and-butter can be done by AI now;', 'North Star metrics define long', 'Not the Data Most data scientists open', 'Now it’s time to build strategic thinking on top of it', 'Once we got our first job', 'One trick: write the recommendation slide before you start the analysis', 'Pick one project', 'Precision is about risk tolerance', 'Prioritize Projects', 'Should we', 'Show how this insight', 'Smart data scientists don’t just answer interesting questions', 'Sort your metrics into four layers', 'Start at the end and work backward', 'Start small', 'Start with the Decision', 'Start with the decision', 'Strategic projects create metrics', 'Strategic projects surface insights', 'Strategic work elevates conversations from tactical', 'Strategic work feeds into quarterly planning cycles', 'Supporting metrics break down and drive movement in the north star', 'That means starting from the business objective and working backward', 'That was a wake-up call', 'That’', 'That’s not insight', 'That’s the business context you need before writing', 'The', 'The AI revolution is already here', 'The Shift from Outputs', 'The best method is the one that fits your constraints', 'The better question might have been: “What would we do differently if we learned that Android', 'The difference between', 'The first path is comfortable but risky', 'The five mindset shifts we’ve discussed aren’t just survival tactics', 'The key is actionability', 'The second path is challenging but rewarding', 'They make', 'They must start to think like', 'They reveal hidden assumptions', 'They’re career accelerators', 'This means your work needs to come with', 'Timeline is often the', 'To match method to moment', 'Turn Insights Into', 'We need to reconsider our approach here', 'What action can the team take?', 'What action might it', 'What actually moves the needle?', 'What are the 2–3 bets the company is making this quarter?', 'What behavior do we want to encourage', 'What behaviors do we want to encourage', 'What could backfire if we optimize for this?', 'What decision does that analysis', 'What decision will this', 'What decision will this analysis', 'What does', 'What does success actually look like?', 'What does the business actually care about', 'What happens if we do nothing', 'What leading indicator can we use to detect problems early?', 'What open', 'What won’t get done if we', 'What your manager is thinking', 'What’s the PM', 'While you’re perfecting your pandas syntax', 'Why it differentiates you from AI', 'You also need to recommend what to do next', 'You can continue doing the same type of work you’ve always done', 'You won’t become', 'Your most sophisticated methods should support your most strategic decisions', 'Your technical foundation is solid', 'You’re not just running tests', 'You’re using historical data', 'and discover how to work with AI', 'and how reversible is that decision', 'and human act influenced', 'and low error rates', 'and moves the business forward', 'and ops to understand the full system', 'and optimize for impact', 'and recommendations with each piece of work', 'and strategically insert yourself where real leverage lives', 'and the first 90% of each project would be', 'and walking away thinking I’d done my job', 'and work backward', 'behavior, and is sensitive to change', 'bet-the-company', 'break it down by platform and region', 'don’t do it', 'drop-off funnel', 'even at the expense of exhaustiveness', 'every quarter you', 'getting polite nods', 'good enough at 10% the cost and 1% the time usually wins', 'it gives the satisfying feeling', 'it’', 'it’s whether', 'just setting up our data', 'like YouTube tracking Weekly Active Creators to center their mission around content', 'line of SQL', 'manager’', 'mean for our business', 'might only need', 'model for choosing the right analytical approach for the situation at hand', 'not the deliverable', 'org', 'playbook to', 'position yourself for high-impact work', 'rigorous testing and large samples', 'risks, and confidence levels', 'ship it and monitor over the next week or two', 'starts with your next project', 'step back and ask four', 'success and', 'surfacing where strategic action is most needed—like creator retention or', 'technical', 'the illusion', 'the shape of the data', 'think', 'we discovered that clean data', 'what action would result from your work', 'what the business does next', 'with your stakeholders on the decision they’re trying to make', 'working towards', 'you need to start with three questions', 'your peers are learning to ask better questions', 'you’re either wasting time or avoiding', 'you’re managing consequences and you need business', 'you’re not running'], 'ORG': ['Fifth', 'First', 'Gen AI is forcing data scientists into another', 'I’ve', 'PM thinks in terms of tradeoffs', 'Strategic Data Scientists', 'Strategic data scientists ask deeper', 'Strategic projects don’t just', 'Strategy is Your New Job You have', 'Take one analysis you’ve completed and ask yourself: “What action should we take based on this?', 'These', 'You', 'and impact', 'we got neat and tidy'], 'LOC': ['Building', 'I', 'PM', 'and maybe even segment it by monthly cohorts', 'is', 'it’', 'urgency']}",
         "[-0.05581550672650337, -0.035044655203819275, 0.027863390743732452, 0.01399398036301136, 0.02833600714802742, -0.1144222766160965, -0.045364707708358765, 0.02971823699772358, -0.09036552160978317, 0.030690601095557213, -0.057934198528528214, -0.0032456261105835438, -0.03327162563800812, -0.04061843082308769, -0.01347529236227274, 0.0361989326775074, -0.028188254684209824, -0.04340975731611252, -0.06869760900735855, -0.05782788619399071, -0.12490600347518921, 0.04554714635014534, -0.0036020821426063776, -0.04808415472507477, -0.017209183424711227, 0.03754802793264389, 0.00812787190079689, -0.09283948689699173, -0.014383022673428059, 0.034953344613313675, -0.05151788890361786, -0.0035415056627243757, 0.06766330450773239, 0.07109003514051437, -0.004135192837566137, 0.03549421951174736, 0.0008695750730112195, 0.02311823144555092, 0.03638974949717522, 0.013446101918816566, -0.013828864321112633, -0.10970287024974823, -0.05361045151948929, -0.03239014372229576, -0.03722618892788887, 0.040346354246139526, 0.009245701134204865, -0.09054543823003769, 0.052591029554605484, 0.019269932061433792, -0.1484277844429016, 0.008599705994129181, 0.021347185596823692, -0.018001146614551544, -0.024653494358062744, 0.049143608659505844, 0.08994688093662262, 0.025761626660823822, 0.04050116613507271, 0.025737063959240913, -0.027010740712285042, -0.06252852082252502, 0.04608948156237602, -0.05744662135839462, 0.06588096171617508, 0.02804460935294628, -0.07091298699378967, -0.001070905476808548, -0.01951403170824051, 0.07096409797668457, 0.03347720578312874, 0.011336437426507473, -0.03416536748409271, 0.035839639604091644, 0.0562821701169014, -0.03330276533961296, 0.05931711196899414, -0.07314499467611313, 0.12295230478048325, 0.008723470382392406, -0.007835473865270615, -0.08889561891555786, -0.04456447437405586, 0.08934769779443741, -0.056674402207136154, -0.009136279113590717, -0.008109030313789845, -0.007915725000202656, 0.05528668686747551, -0.04521433264017105, 0.05609269067645073, -0.09204037487506866, 0.013927246443927288, 0.016345180571079254, 0.04955996945500374, 0.09376510977745056, 0.007238833233714104, -0.033375367522239685, -0.05319388583302498, -0.023441653698682785, -0.004652332980185747, 0.02015443705022335, -0.005126906558871269, -0.021588169038295746, -0.07485786080360413, -0.06003504991531372, 0.09766022861003876, 0.012298000045120716, 0.018966112285852432, 0.02020827867090702, 0.023029889911413193, 0.02463018335402012, 0.048319000750780106, -0.04301697388291359, -0.002574426122009754, -0.03634629398584366, -0.11620009690523148, 0.02723538503050804, -0.025827018544077873, 0.04088481515645981, 0.011288950219750404, 0.08017009496688843, 0.02186531014740467, 0.021041279658675194, 0.047101669013500214, -0.04755615070462227, -0.005488951690495014, 3.229528200194198e-33, 0.005466823931783438, 0.009265929460525513, 0.03971307352185249, -0.032517969608306885, -0.017539633437991142, -0.08780470490455627, -0.020132699981331825, -0.00010592493345029652, -0.013208071701228619, 0.021197501569986343, -0.08021245151758194, 0.04998371750116348, -0.04844477400183678, 0.03771911934018135, 0.024610407650470734, -0.015933480113744736, 0.03464822098612785, -0.0646258220076561, -0.05945438891649246, 0.04224399849772453, 0.134941965341568, -0.06103547662496567, -0.018132051452994347, -0.010026671923696995, 0.01723727397620678, -0.040732648223638535, -0.02451103925704956, -0.018327970057725906, 0.0682784765958786, 0.02004975453019142, -0.13555964827537537, 0.025838518515229225, -0.05570884048938751, 0.012432018294930458, -0.0048707942478358746, -0.024673981592059135, 0.005617842543870211, -0.007271963637322187, 0.00625999690964818, 0.041452135890722275, -0.05176495015621185, 0.08293695747852325, 0.021988214924931526, 0.009964600205421448, -0.05900628864765167, 0.0009381030104123056, 0.07946664094924927, -0.011626020073890686, -0.034148748964071274, 0.019080866128206253, -0.022281786426901817, 0.016945013776421547, 0.05390699580311775, -0.015572581440210342, 0.03030684031546116, 0.022447148337960243, 0.007578614633530378, -0.09025561809539795, -0.022185979411005974, -5.825929838465527e-05, 0.015165531076490879, -0.017654545605182648, 0.0007014326984062791, 0.0701330229640007, -0.04193398356437683, 0.077950119972229, 0.08635249733924866, 0.09793781489133835, 0.12456878274679184, 0.0020298308227211237, -0.03344012796878815, 0.005133341066539288, -0.040315911173820496, -0.05531282722949982, 0.05632701888680458, 0.03872495889663696, 0.007285415660589933, -0.07417979091405869, 0.05075452849268913, -0.016423530876636505, 0.049734365195035934, -0.01443049032241106, -0.01959482952952385, -0.03569183871150017, 0.06320301443338394, -0.02048834040760994, -0.030708448961377144, 0.025091305375099182, -0.028505293652415276, 0.00985490158200264, -0.0992465689778328, -0.0637025386095047, -0.006524574942886829, 0.0804940015077591, -0.06713948398828506, -4.7474300964156016e-33, -0.034945178776979446, -0.032130371779203415, -0.05756007134914398, 0.039241619408130646, 0.06347138434648514, 0.019138535484671593, 0.05952398478984833, -0.08528607338666916, 0.025106817483901978, 0.015123152174055576, -0.10503093153238297, -0.05463537946343422, 0.028404049575328827, 0.011728830635547638, 0.0227412860840559, -0.04115884751081467, -0.04371609538793564, 0.08781005442142487, -0.058695316314697266, -0.02372657135128975, 0.014963068068027496, 0.08772730827331543, -0.1409868448972702, -0.0007247680332511663, 0.008915995247662067, 0.05105878412723541, -0.09420779347419739, 0.010459750890731812, -0.008098511025309563, 0.007661406882107258, -0.008808922953903675, -0.002814721316099167, 0.006724577397108078, -0.012605530209839344, 0.07336059957742691, 0.03408230096101761, -0.004857722204178572, -0.04413618892431259, -0.07668998092412949, 0.0007571996538899839, 0.07317378371953964, 0.04378670081496239, -0.08152296394109726, -0.0451207309961319, -0.011456725187599659, 0.03330393135547638, -0.00886218249797821, 0.052929967641830444, -0.05861857160925865, -0.0017306628869846463, 0.010861855000257492, 0.05280919373035431, 0.010213746689260006, -0.00649120332673192, -0.013439429923892021, 0.0033068088814616203, 0.06275412440299988, 0.0188875924795866, -0.05853244289755821, 0.1324402093887329, -0.07466722279787064, -0.04283524304628372, 0.10118243843317032, 0.01566295512020588, -0.02573300711810589, -0.013157152570784092, 0.040665965527296066, 0.03216448798775673, -0.009878130629658699, -0.10130633413791656, 0.024714652448892593, -0.023044349625706673, -0.0054896860383450985, 0.004345950670540333, -0.04642927646636963, 0.036735646426677704, -0.043057046830654144, -0.038985393941402435, 0.0042172567918896675, 0.026200052350759506, -0.012533255852758884, -0.04202130064368248, 0.020833417773246765, 0.09104979038238525, -0.03846461698412895, 0.09110700339078903, 0.01374895591288805, -0.05305233225226402, -0.011165664531290531, -0.004845275543630123, -0.05493134632706642, -0.05287035554647446, -0.11313702911138535, 0.04710061848163605, -0.060964763164520264, -6.458088108729498e-08, 0.04072403162717819, 0.05847475305199623, 0.056383196264505386, -0.016958989202976227, 0.02355404943227768, 0.0014225048944354057, -0.050175588577985764, 0.03885272517800331, 0.003995533101260662, 0.043366216123104095, 0.12729211151599884, -0.07277750968933105, 0.004592600744217634, -0.009458465501666069, 0.07154177874326706, 0.03120468743145466, 0.06047917529940605, -0.02060166746377945, -0.02406429871916771, 0.0451338030397892, 0.12083061039447784, -0.027541669085621834, -0.06819964945316315, -0.041956331580877304, -0.021038908511400223, -0.0503833144903183, -0.025651216506958008, 0.021519917994737625, -0.07461447268724442, 0.07288426160812378, -0.05059807375073433, -0.04072844237089157, 0.03714693710207939, 0.04144679009914398, 0.09928306192159653, -0.09242647141218185, 0.0680350661277771, -0.07261315733194351, -0.06528615951538086, 0.02335396036505699, 0.025915788486599922, 0.07865133881568909, -0.03591255843639374, 0.022487927228212357, 0.04813160374760628, -0.010754968971014023, -0.04348359629511833, 0.020187314599752426, 0.06970378011465073, 0.0407794825732708, 0.06522883474826813, -0.04267720505595207, 0.01630309782922268, 0.04807385802268982, 0.12417292594909668, 0.0328511968255043, -0.025619760155677795, -0.0016860829200595617, -0.08778376132249832, 0.08484352380037308, 0.053139470517635345, 0.012001666240394115, -0.011917103081941605, 0.02342105470597744]",
         "0.186"
        ],
        [
         "24",
         "579",
         "Torchvista: Building an Interactive Pytorch Visualization Package for Notebooks",
         "Building a tool to interactively visualize the forward pass of any Pytorch model from within notebooks. The post Torchvista: Building an Interactive Pytorch Visualization Package for Notebooks appeared first on Towards Data Science .",
         "In this post, I talk through the motivation, complexities and implementation details of building torchvista, an open-source package to interactively visualize the forward pass of any Pytorch model from within web-based notebooks.\n\nTo get a sense of the workings of torchvista while reading this post, you can check out:\n\nGithub page if you want to install it via pip and use it from web-based notebooks (Jupyter, Colab, Kaggle, VSCode, etc)\n\nif you want to install it via and use it from web-based notebooks (Jupyter, Colab, Kaggle, VSCode, etc) An interactive demo page with various well-known models visualized\n\nwith various well-known models visualized A Google Colab tutorial\n\ntutorial A video demo:\n\nMotivation\n\nPytorch models can get very large and complex, and making sense of one from the code alone can be a tiresome and even intractable exercise. Having a graph-like visualization of it is just what we need to make this easier.\n\nWhile there exist tools like Netron, pytorchviz, and torchview that make this easier, my motivation for building torchvista was that I found that they were lacking in some or all of these requirements:\n\nInteraction support: The visualized graph should be interactive and not a static image. It should be a structure you can zoom, drag, expand/collapse, etc. Models can get very large, and if all you are see is a gigantic static image of the graph, how can you really explore it?\n\nDrag and zoom to explore a large model\n\nModular exploration: Large Pytorch models are modular in thought and implementation. For example, think of a module which has a Sequential module which contains a few Attention blocks, which in turn each has Fully connected blocks which contain Linear layers with activation functions and so on. The tool should allow you to tap into this modular structure, and not just present a low-level tensor link graph.\n\nExpanding modules in a modular fashion\n\nNotebook support: We tend to prototype and build our models in notebooks. If a tool were provided as a standalone application that required you to build your model and load it to visualize it, it’s just too long a feedback loop. So the tool has to ideally work from within notebooks.\n\nVisualization within a Jupyter notebook\n\nError debugging support: While building models from scratch, we often run into many errors until the model is able to run a full forward pass end-to-end. So the visualization tool should be error tolerant and show you a partial visualization graph even if there are errors, so that you can debug the error.\n\nA sample visualization of when torch.cat failed due to mismatched tensor shapes\n\nForward pass tracing: Pytorch natively exposes a backward pass graph through its autograd system, which the package pytorchviz exposes as a graph, but this is different from the forward pass. When we build, study and imagine models, we think more about the forward pass, and this can be very useful to visualize.\n\nBuilding torchvista\n\nBasic API\n\nThe goal was to have a simple API that works with almost any Pytorch model.\n\nimport torch from transformers import XLNetModel from torchvista import trace_model model = XLNetModel.from_pretrained(\"xlnet-base-cased\") example_input = torch.randint(0, 32000, (1, 10)) # Trace it! trace_model(model, example_input)\n\nWith one line of code calling trace_model(<model_instance>, <input>) it should just produce an interactive visualization of the forward pass.\n\nSteps involved\n\nBehind the scenes, torchvista, when called, works in two phases:\n\nTracing: This is where torchvista extracts a graph data structure from the forward pass of the model. Pytorch does not inherently expose this graph structure (even though it does expose a graph for the backward pass), so torchvista has to build this data structure by itself. Visualization: Once the graph is extracted, torchvista has to produce the actual visualization as an interactive graph. torchvista’s tracer does this by loading a template HTML file (with JS embedded within it), and injecting serialized graph data structure objects as strings into the template to be subsequently loaded by the browser engine.\n\nBehind the scenes of trace_model()\n\nTracing\n\nTracing is essentially done by (temporarily) wrapping all the important and known tensor operations, and standard Pytorch modules. The goal of wrapping is to modify the functions so that when called, they additionally do the bookkeeping necessary for tracing.\n\nStructure of the graph\n\nThe graph we extract from the model is a directed graph where:\n\nThe nodes are the various Tensor operations and the various inbuilt Pytorch modules that get called during the forward pass Additionally, input and output tensors, and constant valued tensors are also nodes in the graph.\n\nAn edge exists from one node to the other for each tensor sent from the former to the latter.\n\nThe edge label is the dimension of the associated tensor.\n\nExample graph with operations and input/output/constant tensors as nodes, and an edge for every tensor that’s sent, with edge label set as the dimensions of the tensor\n\nBut, the structure of our graph can be more complicated because most Pytorch modules call tensor operations and sometimes other modules’ forward method. This means we have to maintain a graph structure that holds information to visually explore it at any level of depth.\n\nAn example of nested modules shown various depths: TransformerEncoder uses TransformerEncoderLayer which calls multi_head_attention_forward, dropout, and other operations.\n\nTherefore, the structure that torchvista extracts includes two main data structures:\n\nAdjacency list of the lowest level operations/modules that get called.\n\ninput_0 -> [ linear ] linear -> [ __add__ ] __getitem__ -> [ __add__ ] __add__ -> [ multi_head_attention_forward ] multi_head_attention_forward -> [ dropout ] dropout -> [ __add__ ]\n\nHierarchy map that maps each node to its parent module container (if present)\n\nlinear -> Linear multi_head_attention_forward -> MultiheadAttention MultiheadAttention -> TransformerEncoderLayer TransformerEncoderLayer -> TransformerEncoder\n\nWith both of these, we are able to construct any desired views of the forward pass in the visualization layer.\n\nWrapping operations and modules\n\nThe whole idea behind wrapping is to do some bookkeeping before and after the actual operation, so that when the operation is called, our wrapped function instead gets called, and the bookkeeping is carried out. The goals of bookkeeping are:\n\nRecord connections between nodes based on tensor references.\n\nRecord tensor dimensions to show as edge labels.\n\nRecord module hierarchy for modules in the case where modules are nested within one another\n\nHere is a simplified code snippet of how wrapping works:\n\noriginal_operations = {} def wrap_operation(module, operation): original_operations[get_hashable_key(module, operation)] = operation def wrapped_operation(*args, **kwargs): # Do the necessary pre-call bookkeeping do_pre_call_bookkeeping() # Call the original operation result = operation(*args, **kwargs) do_post_call_bookkeeping() return result setattr(module, func_name, wrapped_operation) for module, operation in LONG_LIST_OF_PYTORCH_OPS: wrap_operation(module, operation)\n\nAnd when trace_model is about to complete, we must reset everything back to its original state:\n\nfor module, operation in LONG_LIST_OF_PYTORCH_OPS: setattr(module, func_name, original_operations[get_hashable_key(module, operation)])\n\nThis is done in the same way for the forward() methods of inbuilt Pytorch modules like Linear , Conv2d etc.\n\nConnections between nodes\n\nAs stated previously, an edge exists between two nodes if a tensor was sent from one to the other. This forms the basis of creating connections between nodes while building the graph.\n\nHere is a simplified code snippet of how this works:\n\nadj_list = {} def do_post_call_bookkeeping(module, operation, tensor_output): # Set a \"marker\" on the output tensor so that whoever consumes it # knows which operation produced it tensor_output._source_node = get_hashable_key(module, operation) def do_pre_call_bookkeeping(module, operation, tensor_input): source_node = tensor_input._source_node # Add a link from the producer of the tensor to this node (the consumer) adj_list[source_node].append(get_hashable_key(module, operation))\n\nHow graph edges are created\n\nModule hierarchy map\n\nWhen we wrap modules, things have to be done a little differently to build the module hierarchy map. The idea is to maintain a stack of modules currently being called so that the top of the stack always represents in the immediate parent in the hierarchy map.\n\nHere is a simplified code snippet of how this works:\n\nhierarchy_map = {} module_call_stack = [] def do_pre_call_bookkeeping_for_module(package, module, tensor_output): # Add it to the stack module_call_stack.append(get_hashable_key(package, module)) def do_post_call_bookkeeping_for_module(module, operation, tensor_input): module_call_stack.pop() # Top of the stack now is the parent node hierarchy_map[get_hashable_key(package, module)] = module_call_stack[-1]\n\nVisualization\n\nThis part is entirely handled in Javscript because the visualization happens in web-based notebooks. The key libraries that are used here are:\n\ngraphviz: for generating the layout for the graph (viz-js is the JS port)\n\nd3: for drawing the interactive graph on a canvas\n\niPython: to render HTML contents within a notebook\n\nGraph Layout\n\nGetting the layout for the graph right is an extremely complex problem. The main goal is for the graph to have a top-to-bottom “flow” of edges, and most importantly, for there to not be an overlap between the various nodes, edges, and edge labels.\n\nThis is made all the more complex when we are working with a “hierarchical” graph where there are “container” boxes for modules within which the underlying nodes and subcomponents are shown.\n\nA complex layout with a neat top-to-bottom flow and no overlaps\n\nThankfully, graphviz (viz-js) comes to the rescue for us. graphviz uses a language called “DOT language” through which we specify how we require the graph layout to be constructed.\n\nHere is a sample of the DOT syntax for the above graph:\n\n# Edges and nodes \"input_0\" [width=1.2, height=0.5]; \"output_0\" [width=1.2, height=0.5]; \"input_0\" -> \"linear_1\"[label=\"(1, 16)\", fontsize=\"10\", edge_data_id=\"5623840688\" ]; \"linear_1\" -> \"layer_norm_1\"[label=\"(1, 32)\", fontsize=\"10\", edge_data_id=\"5801314448\" ]; \"linear_1\" -> \"layer_norm_2\"[label=\"(1, 32)\", fontsize=\"10\", edge_data_id=\"5801314448\" ]; ... # Module hierarchy specified using clusters subgraph cluster_FeatureEncoder_1 { label=\"FeatureEncoder_1\"; style=rounded; subgraph cluster_MiddleBlock_1 { label=\"MiddleBlock_1\"; style=rounded; subgraph cluster_InnerBlock_1 { label=\"InnerBlock_1\"; style=rounded; subgraph cluster_LayerNorm_1 { label=\"LayerNorm_1\"; style=rounded; \"layer_norm_1\"; } subgraph cluster_TinyBranch_1 { label=\"TinyBranch_1\"; style=rounded; subgraph cluster_MicroBranch_1 { label=\"MicroBranch_1\"; style=rounded; subgraph cluster_Linear_2 { label=\"Linear_2\"; style=rounded; \"linear_2\"; } ...\n\nOnce this DOT representation is generated from our adjacency list and hierarchy map, graphviz produces a layout with positions and sizes of all nodes and paths for edges.\n\nRendering\n\nOnce the layout is generated, d3 is used to render the graph visually. Everything is drawn on a canvas (which is easy to make draggable and zoomable), and we set various event handlers to detect user clicks.\n\nWhen the user makes these two types of expand/collapse clicks on modules (using the ‘+’ ‘-‘ buttons), torchvista records which node the action was performed on, and just re-renders the graph because the layout has to be reconstructed, and then automatically drags and zooms in to an appropriate level based on the recorded pre-click position.\n\nRendering a graph using d3 is a very detailed topic and otherwise not to unique to torchvista, and hence I leave out the details from this post.\n\n[Bonus] Handling errors in Pytorch models\n\nWhen users trace their Pytorch models (especially while developing the models), sometimes the models throw errors. It would have been easy for torchvista to just give up when this happens and let the user fix the error first before they could use torchvista. But torchvista instead lends a hand at debugging these errors by doing best-effort tracing of the model. The idea is simple – just trace the maximum it can until the error happens, and then render the graph with just so much (with visual indicators showing where the error happened), and then just raise the exception so that the user can also see the stacktrace like they normally would.\n\nWhen an error is thrown, the stack trace is also shown below the partially rendered graph\n\nHere is a simplified code snippet of how this works:\n\ndef trace_model(...): exception = None try: # All the tracing code except Exception as e: exception = e finally: # do all the necessary cleanups (unwrapping all the operations and modules) if exception is not None: raise exception\n\nWrapping up\n\nThis post shed some light on the journey of building a Pytorch visualization package. We first talked about the very specific motivation for building such a tool by comparing with other similar tools. Then, we discussed the design and implementation of torchvista in two parts. The first part was about the process of tracing the forward pass of a Pytorch model using (temporary) wrapping of operations and modules to extract detailed information about the model’s forward pass, including not only the connections between various operations, but also the module hierarchy. Then, in the second part, we went over the visualization layer, and the complexities of layout generation, which were solved using the right choice of libraries.\n\ntorchvista is open source, and all contributions, including feedback, issues and pull requests, are welcome. I hope torchvista helps people of all levels of expertise in building and visualizing their models (regardless of model size), showcasing their work, and as a tool for educating others about machine learning models.\n\nFuture directions\n\nPotential future enhancements to torchvista include:\n\nAdding support for “rolling”, where if the same substructure of a model is repeated several times, it is shown just once with a count of how many times it repeats\n\nSystematic exploration of state-of-the-art models to ensure all their tensor operations are adequately covered\n\nSupport for exporting static images of models as png or pdf files\n\nEfficiency and speed improvements\n\nReferences\n\nAll images unless otherwise stated are by the author.",
         "2025-07-23T18:45:51",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/torchvista-building-an-interactive-pytorch-visualization-package-for-notebooks/",
         "2025-07-26T06:23:31.345669",
         "In this post, I talk through the motivation, complexities and implementation details of building torchvista, an open-source package to interactively visualize the forward pass of any Pytorch model from within web-based notebooks. To get a sense of the workings of torchvista while reading this post, you can check out: Github page if you want to install it via pip and use it from web-based notebooks (Jupyter, Colab, Kaggle, VSCode, etc) if you want to install it via and use it from web-based notebooks (Jupyter, Colab, Kaggle, VSCode, etc) An interactive demo page with various well-known models visualized with various well-known models visualized A Google Colab tutorial tutorial A video demo: Motivation Pytorch models can get very large and complex, and making sense of one from the code alone can be a tiresome and even intractable exercise. Having a graph-like visualization of it is just what we need to make this easier. While there exist tools like Netron, pytorchviz, and torchview that make this easier, my motivation for building torchvista was that I found that they were lacking in some or all of these requirements: Interaction support: The visualized graph should be interactive and not a static image. It should be a structure you can zoom, drag, expand/collapse, etc. Models can get very large, and if all you are see is a gigantic static image of the graph, how can you really explore it? Drag and zoom to explore a large model Modular exploration: Large Pytorch models are modular in thought and implementation. For example, think of a module which has a Sequential module which contains a few Attention blocks, which in turn each has Fully connected blocks which contain Linear layers with activation functions and so on. The tool should allow you to tap into this modular structure, and not just present a low-level tensor link graph. Expanding modules in a modular fashion Notebook support: We tend to prototype and build our models in notebooks. If a tool were provided as a standalone application that required you to build your model and load it to visualize it, it’s just too long a feedback loop. So the tool has to ideally work from within notebooks. Visualization within a Jupyter notebook Error debugging support: While building models from scratch, we often run into many errors until the model is able to run a full forward pass end-to-end. So the visualization tool should be error tolerant and show you a partial visualization graph even if there are errors, so that you can debug the error. A sample visualization of when torch.cat failed due to mismatched tensor shapes Forward pass tracing: Pytorch natively exposes a backward pass graph through its autograd system, which the package pytorchviz exposes as a graph, but this is different from the forward pass. When we build, study and imagine models, we think more about the forward pass, and this can be very useful to visualize. Building torchvista Basic API The goal was to have a simple API that works with almost any Pytorch model. import torch from transformers import XLNetModel from torchvista import trace_model model = XLNetModel.from_pretrained(\"xlnet-base-cased\") example_input = torch.randint(0, 32000, (1, 10)) # Trace it! trace_model(model, example_input) With one line of code calling trace_model(<model_instance>, <input>) it should just produce an interactive visualization of the forward pass. Steps involved Behind the scenes, torchvista, when called, works in two phases: Tracing: This is where torchvista extracts a graph data structure from the forward pass of the model. Pytorch does not inherently expose this graph structure (even though it does expose a graph for the backward pass), so torchvista has to build this data structure by itself. Visualization: Once the graph is extracted, torchvista has to produce the actual visualization as an interactive graph. torchvista’s tracer does this by loading a template HTML file (with JS embedded within it), and injecting serialized graph data structure objects as strings into the template to be subsequently loaded by the browser engine. Behind the scenes of trace_model() Tracing Tracing is essentially done by (temporarily) wrapping all the important and known tensor operations, and standard Pytorch modules. The goal of wrapping is to modify the functions so that when called, they additionally do the bookkeeping necessary for tracing. Structure of the graph The graph we extract from the model is a directed graph where: The nodes are the various Tensor operations and the various inbuilt Pytorch modules that get called during the forward pass Additionally, input and output tensors, and constant valued tensors are also nodes in the graph. An edge exists from one node to the other for each tensor sent from the former to the latter. The edge label is the dimension of the associated tensor. Example graph with operations and input/output/constant tensors as nodes, and an edge for every tensor that’s sent, with edge label set as the dimensions of the tensor But, the structure of our graph can be more complicated because most Pytorch modules call tensor operations and sometimes other modules’ forward method. This means we have to maintain a graph structure that holds information to visually explore it at any level of depth. An example of nested modules shown various depths: TransformerEncoder uses TransformerEncoderLayer which calls multi_head_attention_forward, dropout, and other operations. Therefore, the structure that torchvista extracts includes two main data structures: Adjacency list of the lowest level operations/modules that get called. input_0 -> [ linear ] linear -> [ __add__ ] __getitem__ -> [ __add__ ] __add__ -> [ multi_head_attention_forward ] multi_head_attention_forward -> [ dropout ] dropout -> [ __add__ ] Hierarchy map that maps each node to its parent module container (if present) linear -> Linear multi_head_attention_forward -> MultiheadAttention MultiheadAttention -> TransformerEncoderLayer TransformerEncoderLayer -> TransformerEncoder With both of these, we are able to construct any desired views of the forward pass in the visualization layer. Wrapping operations and modules The whole idea behind wrapping is to do some bookkeeping before and after the actual operation, so that when the operation is called, our wrapped function instead gets called, and the bookkeeping is carried out. The goals of bookkeeping are: Record connections between nodes based on tensor references. Record tensor dimensions to show as edge labels. Record module hierarchy for modules in the case where modules are nested within one another Here is a simplified code snippet of how wrapping works: original_operations = {} def wrap_operation(module, operation): original_operations[get_hashable_key(module, operation)] = operation def wrapped_operation(*args, **kwargs): # Do the necessary pre-call bookkeeping do_pre_call_bookkeeping() # Call the original operation result = operation(*args, **kwargs) do_post_call_bookkeeping() return result setattr(module, func_name, wrapped_operation) for module, operation in LONG_LIST_OF_PYTORCH_OPS: wrap_operation(module, operation) And when trace_model is about to complete, we must reset everything back to its original state: for module, operation in LONG_LIST_OF_PYTORCH_OPS: setattr(module, func_name, original_operations[get_hashable_key(module, operation)]) This is done in the same way for the forward() methods of inbuilt Pytorch modules like Linear , Conv2d etc. Connections between nodes As stated previously, an edge exists between two nodes if a tensor was sent from one to the other. This forms the basis of creating connections between nodes while building the graph. Here is a simplified code snippet of how this works: adj_list = {} def do_post_call_bookkeeping(module, operation, tensor_output): # Set a \"marker\" on the output tensor so that whoever consumes it # knows which operation produced it tensor_output._source_node = get_hashable_key(module, operation) def do_pre_call_bookkeeping(module, operation, tensor_input): source_node = tensor_input._source_node # Add a link from the producer of the tensor to this node (the consumer) adj_list[source_node].append(get_hashable_key(module, operation)) How graph edges are created Module hierarchy map When we wrap modules, things have to be done a little differently to build the module hierarchy map. The idea is to maintain a stack of modules currently being called so that the top of the stack always represents in the immediate parent in the hierarchy map. Here is a simplified code snippet of how this works: hierarchy_map = {} module_call_stack = [] def do_pre_call_bookkeeping_for_module(package, module, tensor_output): # Add it to the stack module_call_stack.append(get_hashable_key(package, module)) def do_post_call_bookkeeping_for_module(module, operation, tensor_input): module_call_stack.pop() # Top of the stack now is the parent node hierarchy_map[get_hashable_key(package, module)] = module_call_stack[-1] Visualization This part is entirely handled in Javscript because the visualization happens in web-based notebooks. The key libraries that are used here are: graphviz: for generating the layout for the graph (viz-js is the JS port) d3: for drawing the interactive graph on a canvas iPython: to render HTML contents within a notebook Graph Layout Getting the layout for the graph right is an extremely complex problem. The main goal is for the graph to have a top-to-bottom “flow” of edges, and most importantly, for there to not be an overlap between the various nodes, edges, and edge labels. This is made all the more complex when we are working with a “hierarchical” graph where there are “container” boxes for modules within which the underlying nodes and subcomponents are shown. A complex layout with a neat top-to-bottom flow and no overlaps Thankfully, graphviz (viz-js) comes to the rescue for us. graphviz uses a language called “DOT language” through which we specify how we require the graph layout to be constructed. Here is a sample of the DOT syntax for the above graph: # Edges and nodes \"input_0\" [width=1.2, height=0.5]; \"output_0\" [width=1.2, height=0.5]; \"input_0\" -> \"linear_1\"[label=\"(1, 16)\", fontsize=\"10\", edge_data_id=\"5623840688\" ]; \"linear_1\" -> \"layer_norm_1\"[label=\"(1, 32)\", fontsize=\"10\", edge_data_id=\"5801314448\" ]; \"linear_1\" -> \"layer_norm_2\"[label=\"(1, 32)\", fontsize=\"10\", edge_data_id=\"5801314448\" ]; ... # Module hierarchy specified using clusters subgraph cluster_FeatureEncoder_1 { label=\"FeatureEncoder_1\"; style=rounded; subgraph cluster_MiddleBlock_1 { label=\"MiddleBlock_1\"; style=rounded; subgraph cluster_InnerBlock_1 { label=\"InnerBlock_1\"; style=rounded; subgraph cluster_LayerNorm_1 { label=\"LayerNorm_1\"; style=rounded; \"layer_norm_1\"; } subgraph cluster_TinyBranch_1 { label=\"TinyBranch_1\"; style=rounded; subgraph cluster_MicroBranch_1 { label=\"MicroBranch_1\"; style=rounded; subgraph cluster_Linear_2 { label=\"Linear_2\"; style=rounded; \"linear_2\"; } ... Once this DOT representation is generated from our adjacency list and hierarchy map, graphviz produces a layout with positions and sizes of all nodes and paths for edges. Rendering Once the layout is generated, d3 is used to render the graph visually. Everything is drawn on a canvas (which is easy to make draggable and zoomable), and we set various event handlers to detect user clicks. When the user makes these two types of expand/collapse clicks on modules (using the ‘+’ ‘-‘ buttons), torchvista records which node the action was performed on, and just re-renders the graph because the layout has to be reconstructed, and then automatically drags and zooms in to an appropriate level based on the recorded pre-click position. Rendering a graph using d3 is a very detailed topic and otherwise not to unique to torchvista, and hence I leave out the details from this post. [Bonus] Handling errors in Pytorch models When users trace their Pytorch models (especially while developing the models), sometimes the models throw errors. It would have been easy for torchvista to just give up when this happens and let the user fix the error first before they could use torchvista. But torchvista instead lends a hand at debugging these errors by doing best-effort tracing of the model. The idea is simple – just trace the maximum it can until the error happens, and then render the graph with just so much (with visual indicators showing where the error happened), and then just raise the exception so that the user can also see the stacktrace like they normally would. When an error is thrown, the stack trace is also shown below the partially rendered graph Here is a simplified code snippet of how this works: def trace_model(...): exception = None try: # All the tracing code except Exception as e: exception = e finally: # do all the necessary cleanups (unwrapping all the operations and modules) if exception is not None: raise exception Wrapping up This post shed some light on the journey of building a Pytorch visualization package. We first talked about the very specific motivation for building such a tool by comparing with other similar tools. Then, we discussed the design and implementation of torchvista in two parts. The first part was about the process of tracing the forward pass of a Pytorch model using (temporary) wrapping of operations and modules to extract detailed information about the model’s forward pass, including not only the connections between various operations, but also the module hierarchy. Then, in the second part, we went over the visualization layer, and the complexities of layout generation, which were solved using the right choice of libraries. torchvista is open source, and all contributions, including feedback, issues and pull requests, are welcome. I hope torchvista helps people of all levels of expertise in building and visualizing their models (regardless of model size), showcasing their work, and as a tool for educating others about machine learning models. Future directions Potential future enhancements to torchvista include: Adding support for “rolling”, where if the same substructure of a model is repeated several times, it is shown just once with a count of how many times it repeats Systematic exploration of state-of-the-art models to ensure all their tensor operations are adequately covered Support for exporting static images of models as png or pdf files Efficiency and speed improvements References All images unless otherwise stated are by the author.",
         "en",
         "{'MISC': ['# Add', '# do all the necessary cleanups', 'A Google Colab', 'A video demo:', 'Add it to the stack module_call_stack.append(get_hashable_key(package', 'Adding support for “rolling”', 'Adjacency list of the lowest level', 'An edge', 'An example of nested modules', 'An interactive', 'Building torchvista Basic API', 'Colab', 'Connections between nodes', 'Edges and nodes', 'Efficiency and speed', 'Everything is drawn on a canvas', 'Expanding modules in', 'Forward pass tracing', 'Github', 'HTML', 'Here is', 'Here is a simplified', 'Hierarchy map that maps each node to its parent module container', 'How graph edges are created Module hierarchy map When we wrap modules', 'I talk through the motivation', 'If', 'In this post', 'It should be', 'It would have been easy for torchvista to just give up when this happens and let the user fix the error first before they could', 'Javscript because the visualization happens in web-based notebooks', 'Jupyter', 'Jupyter notebook Error', 'Linear', 'Models can get very large', 'Motivation Pytorch', 'MultiheadAttention MultiheadAttention', 'None try:', 'Notebook', 'Once the graph is extracted', 'Once this DOT representation is generated from our adjacency list and hierarchy map', 'Pytorch does not inherently', 'Record', 'Rendering Once the layout is generated', 'Set', 'So the tool has to ideally work from within notebooks', 'So the visualization', 'Steps involved Behind the scenes', 'Structure of the graph', 'Support for exporting static images of models as png', 'The', 'The first part was about the process of tracing the forward pass of', 'The goal of wrapping is to modify the functions so that when called', 'The goals of bookkeeping are', 'The graph', 'The idea is simple', 'The idea is to maintain', 'The key libraries that are used here are:', 'The nodes are the various Tensor operations and the various inbuilt Pytorch', 'The tool should allow you to tap into this modular structure', 'The visualized graph should be interactive and not a static image', 'The whole idea behind wrapping is to do some bookkeeping before and after the actual operation, so that when the operation is called', 'Then, in the second', 'Then, we discussed the design and implementation of torchvista in two parts', 'This', 'This is made all the more complex when we are working with a “hierarchical', 'This means we have to maintain', 'To get a sense of the workings of torchvista while reading this post', 'Top of the stack now is the parent node', 'Trace it!', 'Tracing: This is where torchvista extracts', 'TransformerEncoder', 'Visualization', 'Visualization within', 'We first talked about the very specific motivation for building such', 'We tend to prototype and build our models in notebooks', 'When', 'When the user makes these two types of expand/collapse clicks on modules', 'When we build', 'While building models from scratch', 'While there', 'With one line of', 'Wrapping', 'Wrapping operations and modules', 'XLNetModel from torchvista', 'XLNetModel.from_pretrained(\"xlnet-base-cased', 'and all contributions', 'and an edge for every tensor that’s', 'and as', 'and hence I leave out the details from this post', 'and injecting serialized graph data structure objects as strings into the template to be subsequently loaded by the browser engine', 'and just re-renders the graph because the layout has to be reconstructed', 'and making sense of one from the code alone can be a tiresome and even intractable', 'and the complexities of layout generation', 'and then', 'and then automatically drags and zooms in to an appropriate level based on the recorded pre-click position', 'between nodes based', 'but also the module hierarchy', 'cluster_FeatureEncoder_1 { label=\"FeatureEncoder_1', 'd3 is used to render the graph visually', 'dropout', 'graph for the backward pass', 'graphviz: for generating the layout for the graph', 'iPython', 'import torch from', 'including not only the connections between various operations', 'it’', 'just trace the maximum it can until the error', 'layout to be constructed', 'layout with', 'layout with positions and sizes of all nodes and paths for edges', 'my motivation for building torchvista was that I found that they were lacking in some or all of these requirements', 'notebook Graph Layout Getting the layout for the graph right is an extremely complex problem', 'operation)', 'pass graph through its autograd system', 'showcasing their work', 'so torchvista has to build this data structure by itself', 'study and imagine', 'the structure of our graph can be more complicated because most Pytorch', 'things have to be done a little differently to build the module hierarchy map', 'think of', 'tools like Netron', 'torchvista', 'torchvista is open', 'torchvista records which node the action was', 'unwrapping all the operations and modules', 'using d3 is a very detailed topic and otherwise not to unique to torchvista', 'we must', 'we often run into many errors until the model is able to run', 'which the package pytorchviz', 'which were solved using the right choice of libraries', 'with edge label set as the dimensions of the tensor But', 'wrapped_operation) for module', 'wrapping all the important and known tensor', 'you can check out'], 'ORG': ['For', 'Handling', 'Potential', 'Pytorch', 'Therefore', 'TransformerEncoderLayer which calls multi_head_attention_forward', 'and most importantly', 'graphviz uses', 'kwargs): # Do the necessary pre-call bookkeeping do_pre_call_bookkeeping', 'layer_norm_1', 'pip and use it from web-based notebooks', 'pytorchviz'], 'LOC': ['Conv2d', 'I', 'Kaggle', 'Linear multi_head_attention_forward', 'Thankfully', 'and torchview that make this easier', 'cluster_TinyBranch_1 { label=\"TinyBranch_1', 'graphviz', 'kwargs', 'layer_norm_2\"[label=\"(1', 'linear_1\"[label=\"(1', 'module_call_stack.pop', 'our wrapped function instead gets called', 'subgraph cluster_LayerNorm_1 { label=\"LayerNorm_1', 'when called'], 'PER': ['Having', 'LONG_LIST_OF_PYTORCH_OPS', 'Large Pytorch', 'Rendering', 'Tracing Tracing is essentially done by', 'VSCode', 'and constant', 'are welcome', 'cluster_Linear_2', 'including feedback', 'rendered', 'tensor link graph', 'tensor was', 'torchvista has to produce the actual visualization as an interactive graph', 'valued tensors are also nodes in the graph']}",
         "[-0.07904370874166489, -0.12127242982387543, -0.07557598501443863, 0.03824347257614136, 0.03866580128669739, -0.034253787249326706, -0.04098985716700554, 0.08871278911828995, -0.014170565642416477, -0.00045742251677438617, -0.02550548128783703, -0.011644775047898293, -0.0606001541018486, 0.06653065979480743, 0.028601542115211487, 0.003916233777999878, 0.028284747153520584, 0.00842759944498539, -0.06694424152374268, -0.10087402164936066, 0.04657020419836044, -0.07999759912490845, 0.04947404935956001, -0.0273213442414999, -0.01309903897345066, 0.05524962395429611, 0.002978344913572073, 0.019851861521601677, 0.06919022649526596, 0.0045010061003267765, 0.008284972049295902, -0.017669379711151123, -0.054440174251794815, 0.07544130086898804, -0.052546028047800064, -0.013805878348648548, 0.00418076803907752, 0.032742079347372055, -0.07325025647878647, -0.005935962777584791, -0.014111356809735298, 0.0056293318048119545, -0.010309305042028427, 0.015231890603899956, 0.039122324436903, -0.04937432333827019, -0.0271011795848608, -0.062376514077186584, -0.03373786434531212, -0.0784049853682518, -0.07763520628213882, -0.07150395214557648, 0.006747719366103411, 0.01508844830095768, 0.0054497625678777695, -0.009420708753168583, 0.025051111355423927, -0.11378295719623566, 0.024982931092381477, -0.06044477969408035, 0.03375113382935524, 0.02676151692867279, -0.01027155201882124, -0.010716846212744713, -0.025479117408394814, 0.026698719710111618, -0.0011630406370386481, 0.024739732965826988, 0.16111144423484802, -0.08863603323698044, -0.03587925806641579, -0.028297891840338707, -0.05119001120328903, 0.04657268151640892, -0.031911030411720276, -0.03166503459215164, 0.08444811403751373, 0.07521319389343262, -0.0364537313580513, -0.09456567466259003, 0.023903660476207733, 0.044306375086307526, 0.04611462354660034, 0.120049849152565, 0.0297083780169487, 0.06041926145553589, 0.005318969488143921, 0.07415705919265747, 0.05712376534938812, -0.03083810769021511, -0.040002718567848206, -0.007282992824912071, -0.06090153753757477, -0.011758350767195225, -0.017054902389645576, 0.0028219486121088266, 0.12378036230802536, -0.07130157202482224, -0.06807983666658401, 0.04573855921626091, 0.04107825085520744, -0.04266466945409775, 0.05593515560030937, -0.008036105893552303, -0.011705606244504452, -0.023768765851855278, 0.03463653475046158, 0.06760060042142868, 0.037521764636039734, -0.015469753183424473, -0.0014924689894542098, 0.045458290725946426, -0.035462722182273865, -0.03017532452940941, 0.038660358637571335, -0.048208028078079224, -0.026845136657357216, 0.03450924530625343, 0.07777971774339676, 0.05882144346833229, -0.002751430030912161, 0.10479667037725449, -0.02223118208348751, 0.04040331020951271, 0.06555778533220291, -0.022590715438127518, -0.09749764204025269, 4.0786362589351074e-33, 0.060637716203927994, 0.04987533763051033, -0.009807574562728405, 0.04019608721137047, 0.08389810472726822, -0.03779835253953934, 0.04799289256334305, -0.058718495070934296, -0.0075691877864301205, 0.045554082840681076, -0.028688395395874977, 0.04374408721923828, -0.009236744605004787, 0.10951487720012665, -0.028017526492476463, -0.04083181172609329, -0.0747278481721878, 0.004621266853064299, -0.014643298462033272, 0.005232079420238733, 0.032905273139476776, -0.008807878941297531, 0.008123944513499737, 0.036504991352558136, -0.005288147833198309, 0.10450848191976547, -0.056261323392391205, 0.06573233008384705, -0.022202642634510994, 0.016203857958316803, 0.007114427629858255, 0.0290682315826416, -0.03104035183787346, -0.05713785067200661, -0.03972693160176277, -0.02891712822020054, -0.02807691879570484, -0.12001924961805344, 0.0914364606142044, -0.0706544816493988, -0.02254117652773857, -0.006836813408881426, -0.029439568519592285, -0.026011204347014427, -0.07159951329231262, 0.030602768063545227, -0.047260913997888565, 0.04160791262984276, -0.0026949485763907433, -0.05599748715758324, -0.05111996829509735, 0.008917608298361301, 0.011408365331590176, 0.039878960698843, -0.034160856157541275, 0.007407193537801504, 0.0445927269756794, -0.024107668548822403, 0.08939800411462784, 0.01791403628885746, 0.05209339037537575, 0.05831446871161461, -0.03801466524600983, 0.04419063776731491, -0.04588999226689339, 0.00994072575122118, -0.11074941605329514, 0.01374062616378069, -0.0018932393286377192, 0.008194741792976856, -0.16628925502300262, 0.0725415050983429, -0.05819765850901604, -0.061766356229782104, 0.043976251035928726, -0.04347582161426544, -0.015242754481732845, -0.02743903174996376, -0.04163789004087448, 0.029453329741954803, -0.08181073516607285, -0.052389077842235565, 0.018832996487617493, -0.03523406758904457, -0.040952231734991074, 0.003884021658450365, 0.03612659499049187, -0.037636350840330124, -0.04616299644112587, -0.06145123392343521, -0.006280138622969389, -0.0454019270837307, 0.037221260368824005, -0.05131950601935387, 0.020795904099941254, -3.596830879233807e-33, -0.017966030165553093, 0.06091032177209854, -0.01350716408342123, 0.08529331535100937, 0.046905819326639175, -0.024192750453948975, -0.03527018055319786, -0.0468832328915596, -0.04251081123948097, -0.026798231527209282, 0.0019712597131729126, -0.0014934102073311806, -0.02417425811290741, 0.0021368898451328278, 0.09161771088838577, 0.019816851243376732, -0.009154120460152626, -0.0557711124420166, 0.02145535871386528, -0.03125765547156334, -0.04383733123540878, 0.09937983006238937, -0.13488809764385223, -0.09269680082798004, -0.06572692841291428, 0.013238752260804176, 0.0010411815019324422, -0.036584481596946716, 0.01335902139544487, 0.0028333610389381647, 0.011675258167088032, -0.0062220776453614235, -0.02448936365544796, -0.04321078583598137, -0.03213174268603325, 0.04942456632852554, 0.054884519428014755, -0.06701768934726715, 0.0476800762116909, 0.027997329831123352, 0.0582568496465683, 0.01198636181652546, -0.06188293918967247, 0.012069967575371265, -0.04722552374005318, 0.07506216317415237, -0.07402156293392181, 0.04118967801332474, -0.04631935805082321, -0.01941887103021145, 0.01875375770032406, 0.009555775672197342, -0.009829988703131676, -0.05782372131943703, -0.009201185777783394, -0.0689995288848877, 0.021331243216991425, 0.02087375707924366, -0.013208625838160515, -0.020687611773610115, -0.11745695024728775, -0.06604890525341034, 0.010394570417702198, -0.008222787640988827, -0.048645325005054474, -0.019784659147262573, -0.017547819763422012, 0.007224971428513527, 0.01327518280595541, 0.007812037132680416, 0.03394676372408867, 0.05790943652391434, 0.0733771026134491, 0.041276976466178894, 0.07531081885099411, 0.00337318517267704, 0.029339807108044624, 0.05717025324702263, -0.012881203554570675, -0.02900274470448494, 0.0413038469851017, -0.011584440246224403, 0.06383946537971497, -0.007953605614602566, 0.06710078567266464, 0.09215977042913437, -0.040548864752054214, 0.09146786481142044, -0.011335011571645737, -0.011803064495325089, -0.009143487550318241, 0.0009829275077208877, 0.010797596536576748, 0.14366449415683746, 0.1202825978398323, -5.220272214501165e-08, -0.07448248565196991, 0.05782429873943329, -0.044580888003110886, 0.025960970669984818, -0.050779812037944794, 0.0145701440051198, 0.10105419903993607, 0.06424672901630402, -0.014168055728077888, 0.03800084814429283, 0.06738649308681488, 0.007933344691991806, 0.015193652361631393, 0.03491484746336937, -0.01793467067182064, 0.1786728948354721, 0.03158048167824745, 0.030057566240429878, 0.02759166806936264, 0.0012289468431845307, 0.019129786640405655, -0.039137810468673706, -0.035507820546627045, 0.04391516372561455, 0.0354384183883667, 0.009717185981571674, -0.06303303688764572, 0.04658392444252968, -0.06229566037654877, -0.038973741233348846, 0.04462439566850662, 0.01095703337341547, 0.0984969437122345, 0.059592388570308685, 0.07071191072463989, 0.02314438857138157, -0.09230626374483109, -0.018896281719207764, -0.017162946984171867, 0.030569463968276978, -0.013230801559984684, 0.030934708192944527, -0.061453089118003845, 0.00692773750051856, 0.0352347195148468, 0.05736052617430687, -0.07949846237897873, -0.09685660153627396, -0.054189831018447876, 0.07400789111852646, -0.017248980700969696, 0.010372147895395756, -0.003328175749629736, 0.05689031258225441, 0.006042911671102047, 0.07913532108068466, -0.05287378653883934, 0.0017135574016720057, -0.013088284991681576, 0.041198380291461945, -0.007528396788984537, 0.06022300571203232, -0.058150701224803925, -0.012667812407016754]",
         "0.164"
        ],
        [
         "25",
         "585",
         "Understanding Matrices | Part 3: Matrix Transpose",
         "Visualizing matrix transposition, to make sense of transpose-related formulas. The post Understanding Matrices | Part 3: Matrix Transpose appeared first on Towards Data Science .",
         "the first 2 stories of this series [1], [2], we:\n\nIntroduced X-way interpretation of matrices\n\nObserved physical meaning and special cases of matrix-vector multiplication\n\nLooked at the physical meaning of matrix-matrix multiplication\n\nObserved its behavior on several special cases of matrices\n\nIn this story, I want to share my thoughts about the transpose of a matrix, denoted as AT, the operation that just flips the content of the square table around its diagonal.\n\nAn example of a 3×4 matrix “A”, and its transpose “AT“.\n\nIn contrast to many other operations on matrices, it is quite easy to transpose a given matrix ‘A‘ on paper. However, the physical meaning of that often stays behind. On the other hand, it is not so clear why the following transpose-related formulas actually work:\n\n(AB) T = B T A T ,\n\n= B A , (y, Ax) = (x, A T y),\n\ny), (ATA)T = ATA.\n\nIn this story, I am going to give my interpretation of the transpose operation, which, among others, will show why the mentioned formulas are actually the way they are. So let’s dive in!\n\nBut first of all, let me remind all the definitions that are used throughout the stories of this series:\n\nMatrices are denoted with uppercase (like ‘A‘, ‘B‘), while vectors and scalars are denoted with lowercase (like ‘x‘, ‘y‘ or ‘m‘, ‘n‘).\n\n|x| – is the length of vector ‘x‘,\n\nrows(A) – number of rows of matrix ‘A‘,\n\ncolumns(A) – number of columns of matrix ‘A‘,\n\nA T – the transpose of matrix ‘A‘,\n\n– the transpose of matrix ‘A‘, a T i ,j – the value on the i-th row and j-th column of the transposed matrix A T ,\n\n– the value on the i-th row and j-th column of the transposed matrix A , (x, y) – dot product of vectors ‘x‘ and ‘y‘ (i.e. “x 1 y 1 + x 2 y 2 + … + x n y n “).\n\nTranspose vs. X-way interpretation\n\nIn part 1 of this series – “matrix-vector multiplication” [1], I introduced the X-way interpretation of matrices. Let’s recall it with an example:\n\nAn example of a matrix and corresponding X-diagram. All arrows in the diagram are directed from right to left. The arrow which starts at item ‘j’ on the right and finishes at item ‘i’ on the left corresponds to cell “a i,j ” of the matrix.\n\nFrom there, we also remember that the left stack of the X-diagram of ‘A‘ can be associated with rows of matrix ‘A‘, while its right stack can be associated with the columns.\n\nIn the X-diagram of matrix ‘A’, the values which go from the 3’rd from the top item of the right stack are the values of 3’rd column of ‘A’ (highlighted in red).\n\nAt the same time, the values which come to the 2’nd from the top item of the left stack are the values of 2’nd row of ‘A’ (highlighted in purple).\n\nNow, if transposing a matrix is actually flipping the table around its main diagonal, it means that all the columns of ‘A‘ become rows in ‘AT‘, and vice versa.\n\nThe original matrix ‘A’ and its transpose ‘AT‘. We see how the 3’rd column of ‘A’ becomes the 3’rd row in ‘AT‘.\n\nAnd if transposing means changing the places of rows and columns, then perhaps we can do the same on the X-diagram? Thus, to swap rows and columns of the X-diagram, we should flip it horizontally:\n\nHorizontal flip of the X-diagram of ‘A’ corresponds to the transpose of ‘A’. We see that the values adjacent to 3’rd from top item of right stack of original X-diagram (3’rd column of ‘A’), which are [9, 7, 14], are the same as values adjacent to 3’rd from top item of left stack of the flipped X-diagram (3’rd row of AT).\n\nWill the horizontally flipped X-diagram of ‘A‘ represent the X-diagram of ‘AT‘? We know that cell “a i ,j ” is present in the X-diagram as the arrow starting from the j‘th item of the left stack, and directed towards the i‘th item of the right stack. After flipping horizontally, that same arrow will start now from the i‘th item of the right stack and will be directed to the j‘th item of the left stack.\n\nThe value “a 1,3 = 9″ equals the value “aT 3,1 = 9″.\n\nWhich means that the definition of transpose “a i ,j = aT j,i ” does hold.\n\nConcluding this chapter, we have seen that transposing matrix ‘A‘ is the same as horizontally flipping its X-diagram.\n\nTransposing a chain of matrices\n\nLet’s see how interpreting AT as a horizontal flip of its X-diagram will help us to uncover the physical meaning of some transpose-related formulas. Let’s start with the following:\n\n\\[\\begin{equation*}\n\n(AB)^T = B^T A^T\n\n\\end{equation*}\\]\n\nwhich says that transposing the multiplication “A*B” is the same as multiplying transpositions AT and BT, but in reverse order. Now, why does the order actually become reversed?\n\nFrom part 2 of this series – “matrix-matrix multiplication” [2], we remember that the matrix multiplication “A*B” can be interpreted as a concatenation of X-diagrams of ‘A‘ and ‘B‘. Thus, having:\n\ny = (AB)x = A*(Bx)\n\nwill force the input vector ‘x‘ to go at first through the transformation of matrix ‘B‘, and then the intermediate result will go through the transformation of matrix ‘A‘, after which the output vector ‘y‘ will be obtained.\n\nMoving input vector ‘x’ from right to left, through X-diagrams of ‘A’ and ‘B’. At first, after moving through the transformation of ‘B’, it becomes an intermediate vector ‘t = Bx’, which, after moving through the transformation of ‘A’, becomes the final vector ‘y = At = A(Bx)’.\n\nAnd now the physical meaning of the formula “(AB)T = BTAT” becomes clear: flipping horizontally the X-diagram of the product “A*B” will obviously flip the separate X-diagrams of ‘A‘ and the one of ‘B‘, but it also will reverse their order:\n\nFlipping horizontally 2 adjacent figures ‘A’ and ‘B’ will result in the horizontal flip of both figures separately (step 1), as well as in swapping their order (step 2).\n\nIn the previous story [2], we have also seen that a cell c i ,j of the product matrix ‘C=A*B‘ describes all the possible ways in which x j of the input vector ‘x‘ can affect y i of the output vector ‘y = (AB)x‘.\n\nConcatenation of X-diagrams of ‘A’ and ‘B’, which corresponds to the product “A*B”. All 4 possible paths by which the input value ‘x 4 ‘ can affect the output value ‘y 2 ‘ are highlighted in red.\n\nNow, when transposing the product “C=A*B“, thus calculating matrix CT, we want to have the mirroring effect – so cT j,i will describe all possible ways by which y j can affect x i . And in order to get that, we should just flip the concatenation diagram:\n\nIf “C = A*B”, then the value of “c 2,4 ” corresponds to the sum of all 4 possible paths from ‘x 4 ‘ to ‘y 2 ‘ (highlighted in red). At the same time, it is equal to “c 2,4 = cT 4,2 “, which corresponds to the sum of the same 4 possible paths from ‘y 2 ‘ to ‘x 4 ‘, in the horizontally flipped concatenation of “A*B”, which is “BTAT“.\n\nOf course, this interpretation can be generalized on transposing the product of several matrices:\n\n\\[\\begin{equation*}\n\n(ABC)^T = C^T B^T A^T\n\n\\end{equation*}\\]\n\nHorizontally flipping 3 adjacent items ‘A’, ‘B’, and ‘C’ (not necessarily matrices), and reversing their order will have the effect of horizontally flipping the sequence “ABC” itself.\n\nWhy ATA is always symmetrical, for any matrix A\n\nA symmetrical matrix ‘S‘ is such an nxn square matrix, where for any indexes i, j ∈ [1..n], we have ‘s i ,j = s j ,i ‘. This means that it is symmetrical upon its diagonal, as well as that transposing it will have no effect.\n\nAn example of a 4×4 symmetrical matrix. All values are symmetrical along the main diagonal. For example, “a 3,1 = a 1,3 = 16″.\n\nWe see that transposing a symmetrical matrix will have no effect. So, a matrix ‘S‘ is symmetrical if and only if:\n\n\\[\\begin{equation*}\n\nS^T = S\n\n\\end{equation*}\\]\n\nSimilarly, the X-diagram of a symmetrical matrix ‘S‘ has the property that it is not changed after a horizontal flip. That is because for any arrow s i ,j we have an equal arrow s j ,i there:\n\nAn example of a 3×3 symmetrical matrix ‘S’ and its X-diagram. We have there ‘s 1,2 = s 2,1 = 4′. Corresponding arrows are highlighted.\n\nIn matrix analysis, we have a formula stating that for any matrix ‘A‘ (not necessarily symmetrical), the product ATA is always a symmetrical matrix. In other words:\n\n\\[\\begin{equation*}\n\n(A^T A)^T = A^T A\n\n\\end{equation*}\\]\n\nIt is not straightforward to feel the correctness of this formula if looking at matrix multiplication in the traditional way. But its correctness becomes obvious if looking at matrix multiplication as the concatenation of their X-diagrams:\n\nConcatenation of ‘AT‘ and ‘A’, which is a concatenation of two mirrored objects, is always a symmetrical object. Flipping such a concatenation horizontally will have no effect.\n\nWhat will happen if an arbitrary matrix ‘A‘ is concatenated with its horizontal flip AT? The result ATA will be symmetrical, as after a horizontal flip, the right factor ‘A‘ comes to the left side and is flipped, becoming AT, while the left factor AT comes to the right side and is also flipped, becoming ‘A‘.\n\nThis is why for any matrix ‘A‘, the product ATA is always symmetrical.\n\nUnderstanding why (y, Ax) = (x, ATy)\n\nThere is another formula in matrix analysis, stating that:\n\n\\[\\begin{equation*}\n\n(y, Ax) = (x, A^T y)\n\n\\end{equation*}\\]\n\nwhere “(u, v)” is the dot product of vectors ‘u‘ and ‘v‘:\n\n\\[\\begin{equation*}\n\n(u,v) = u_1 v_1 + u_2 v_2 + \\dots + u_n v_n\n\n\\end{equation*}\\]\n\nThe dot product can be calculated only for vectors of equal length. Also, the dot product is not a vector but a single number. If trying to illustrate the dot product “(u, v)” in a way similar to X-diagrams, we can draw something like this:\n\nAs the dot product is the accumulation of terms u i *v i , we can present it as the sum of all possible paths from the right endpoint to the left one.\n\nNow, what does the expression (y, Ax) actually mean? It is the dot product of vector ‘y‘ by the vector “Ax” (or by vector ‘x‘, which went through the transformation of “A“). For the expression (y, Ax) to make sense, we should have:\n\n|x| = columns(A), and\n\n|y| = rows(A).\n\nAt first, let’s calculate (y, Ax) formally. Here, every value y i is multiplied by the i-th value of the vector Ax, denoted here as “(Ax) i “:\n\n\\[\\begin{equation*}\n\n(Ax)_i = a_{i,1}x_1 + a_{i,2}x_2 + \\dots + a_{i,m}x_m\n\n\\end{equation*}\\]\n\nAfter one multiplication, we will have:\n\n\\[\\begin{equation*}\n\ny_i(Ax)_i = y_i a_{i,1}x_1 + y_i a_{i,2}x_2 + \\dots + y_i a_{i,m}x_m\n\n\\end{equation*}\\]\n\nAnd after summing all the terms by “i ∈ [1, n]”, we will have:\n\n\\[\\begin{equation*}\n\n\\begin{split}\n\n(y, Ax) = y_1(Ax)_1 + y_2(Ax)_2 + \\dots + y_n(Ax)_n = \\\\\n\n= y_1 a_{1,1}x_1 + y_1 a_{1,2}x_2 + &\\dots + y_1 a_{1,m}x_m + \\\\\n\n+ y_2 a_{2,1}x_1 + y_2 a_{2,2}x_2 + &\\dots + y_2 a_{2,m}x_m + \\\\\n\n&\\vdots \\\\\n\n+ y_n a_{n,1}x_1 + y_n a_{n,2}x_2 + &\\dots + y_n a_{n,m}x_m\n\n\\end{split}\n\n\\end{equation*}\\]\n\nwhich clearly shows that in the product (y, Ax), every cell a i,j of the matrix “A” participates exactly once, together with the factors y i and x j .\n\nNow let’s move to X-diagrams. If we want to draw something like an X-diagram of vector “Ax“, we can do it in the following way:\n\nThe product “Ax” is a vector of length equal to “|Ax| = rows(A)”, while “|x| = columns(A)”. Here, values of vector “x” are attached from the right side, and on the left side, we receive values of the result vector “Ax”.\n\nNext, if we want to draw the dot product (y, Ax), we can do it this way:\n\nValues of vector ‘y’ are attached to the left side of the X-diagram of “A”, while values of vector ‘x’ remain attached to its right side.\n\nOn this diagram, let’s see how many ways there are to reach the left endpoint from the right one. The path from right to left can pass through any arrow of A‘s X-diagram. If passing through a certain arrow a i ,j , it will be the path composed of x j , the arrow a i ,j , and y i .\n\nIf a path from right to left passes through arrow “a 4,2 ” of the X-diagram of “A”, then it also passes through values “y 4 ” and “x 2 “.\n\nAnd this exactly matches the formal behavior of (y, Ax) derived a bit above, where (y, Ax) was the sum of all triples of the form “y i *a i ,j *x j “. And we can conclude here that if looking at (y, Ax) in the X-interpretation, it is equal to the sum of all possible paths from the right endpoint to the left one.\n\nNow, what will happen if we flip this entire diagram horizontally?\n\nHorizontally flipping the X-diagram of “(y, Ax)” results in the X-diagram of “(x, ATy)”.\n\nFrom the algebraic perspective, the sum of all paths from right to left will not change, as all participating terms remain the same. But looking from the geometrical perspective, the vector ‘y‘ goes to the right part, the vector ‘x‘ comes to the left part, and the matrix “A” is being flipped horizontally; in other words, “A” is transposed. So the flipped X-diagram corresponds to the dot product of vectors “x” and “ATy” now, or has the value of (x, ATy). We see that both (y, Ax) and (x, ATy) represent the same sum, which proves that:\n\n\\[\\begin{equation*}\n\n(y, Ax) = (x, A^T y)\n\n\\end{equation*}\\]\n\nConclusion\n\nThat’s all I wanted to present in regard to the matrix transpose operation. I hope that the visual methods illustrated above will help all of us to gain a better grasp of various matrix operations.\n\nIn the next (and probably the last) story of this series, I will address inverting matrices, and how it can be visualized by X-interpretation. We will see why formulas like “(AB)-1 = B-1A-1” are the way they actually are, and we will observe how the inverse works on several special types of matrices.\n\nSo see you in the next story!\n\nMy gratitude to: – Asya Papyan, for the precise design of all the used illustrations (linkedin.com/in/asya-papyan-b0a1b0243/),\n\n– Roza Galstyan, for careful review of the draft (linkedin.com/in/roza-galstyan-a54a8b352/). If you enjoyed reading this story, feel free to follow me on LinkedIn, where, among other things, I will also post updates (linkedin.com/in/tigran-hayrapetyan-cs/). All used images, unless otherwise noted, are designed by request of the author.\n\nReferences\n\n[1] – Understanding matrices | Part 1: matrix-vector multiplication – https://towardsdatascience.com/understanding-matrices-part-1-matrix-vector-multiplication/\n\n[2] – Understanding matrices | Part 2: matrix-matrix multiplication – https://towardsdatascience.com/understanding-matrices-part-2-matrix-matrix-multiplication/",
         "2025-07-22T21:21:19",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/understanding-matrices-part-3-matrix-transpose/",
         "2025-07-26T06:23:31.381002",
         "the first 2 stories of this series [1], [2], we: Introduced X-way interpretation of matrices Observed physical meaning and special cases of matrix-vector multiplication Looked at the physical meaning of matrix-matrix multiplication Observed its behavior on several special cases of matrices In this story, I want to share my thoughts about the transpose of a matrix, denoted as AT, the operation that just flips the content of the square table around its diagonal. An example of a 3×4 matrix “A”, and its transpose “AT“. In contrast to many other operations on matrices, it is quite easy to transpose a given matrix ‘A‘ on paper. However, the physical meaning of that often stays behind. On the other hand, it is not so clear why the following transpose-related formulas actually work: (AB) T = B T A T , = B A , (y, Ax) = (x, A T y), y), (ATA)T = ATA. In this story, I am going to give my interpretation of the transpose operation, which, among others, will show why the mentioned formulas are actually the way they are. So let’s dive in! But first of all, let me remind all the definitions that are used throughout the stories of this series: Matrices are denoted with uppercase (like ‘A‘, ‘B‘), while vectors and scalars are denoted with lowercase (like ‘x‘, ‘y‘ or ‘m‘, ‘n‘). |x| – is the length of vector ‘x‘, rows(A) – number of rows of matrix ‘A‘, columns(A) – number of columns of matrix ‘A‘, A T – the transpose of matrix ‘A‘, – the transpose of matrix ‘A‘, a T i ,j – the value on the i-th row and j-th column of the transposed matrix A T , – the value on the i-th row and j-th column of the transposed matrix A , (x, y) – dot product of vectors ‘x‘ and ‘y‘ (i.e. “x 1 y 1 + x 2 y 2 + … + x n y n “). Transpose vs. X-way interpretation In part 1 of this series – “matrix-vector multiplication” [1], I introduced the X-way interpretation of matrices. Let’s recall it with an example: An example of a matrix and corresponding X-diagram. All arrows in the diagram are directed from right to left. The arrow which starts at item ‘j’ on the right and finishes at item ‘i’ on the left corresponds to cell “a i,j ” of the matrix. From there, we also remember that the left stack of the X-diagram of ‘A‘ can be associated with rows of matrix ‘A‘, while its right stack can be associated with the columns. In the X-diagram of matrix ‘A’, the values which go from the 3’rd from the top item of the right stack are the values of 3’rd column of ‘A’ (highlighted in red). At the same time, the values which come to the 2’nd from the top item of the left stack are the values of 2’nd row of ‘A’ (highlighted in purple). Now, if transposing a matrix is actually flipping the table around its main diagonal, it means that all the columns of ‘A‘ become rows in ‘AT‘, and vice versa. The original matrix ‘A’ and its transpose ‘AT‘. We see how the 3’rd column of ‘A’ becomes the 3’rd row in ‘AT‘. And if transposing means changing the places of rows and columns, then perhaps we can do the same on the X-diagram? Thus, to swap rows and columns of the X-diagram, we should flip it horizontally: Horizontal flip of the X-diagram of ‘A’ corresponds to the transpose of ‘A’. We see that the values adjacent to 3’rd from top item of right stack of original X-diagram (3’rd column of ‘A’), which are [9, 7, 14], are the same as values adjacent to 3’rd from top item of left stack of the flipped X-diagram (3’rd row of AT). Will the horizontally flipped X-diagram of ‘A‘ represent the X-diagram of ‘AT‘? We know that cell “a i ,j ” is present in the X-diagram as the arrow starting from the j‘th item of the left stack, and directed towards the i‘th item of the right stack. After flipping horizontally, that same arrow will start now from the i‘th item of the right stack and will be directed to the j‘th item of the left stack. The value “a 1,3 = 9″ equals the value “aT 3,1 = 9″. Which means that the definition of transpose “a i ,j = aT j,i ” does hold. Concluding this chapter, we have seen that transposing matrix ‘A‘ is the same as horizontally flipping its X-diagram. Transposing a chain of matrices Let’s see how interpreting AT as a horizontal flip of its X-diagram will help us to uncover the physical meaning of some transpose-related formulas. Let’s start with the following: \\[\\begin{equation*} (AB)^T = B^T A^T \\end{equation*}\\] which says that transposing the multiplication “A*B” is the same as multiplying transpositions AT and BT, but in reverse order. Now, why does the order actually become reversed? From part 2 of this series – “matrix-matrix multiplication” [2], we remember that the matrix multiplication “A*B” can be interpreted as a concatenation of X-diagrams of ‘A‘ and ‘B‘. Thus, having: y = (AB)x = A*(Bx) will force the input vector ‘x‘ to go at first through the transformation of matrix ‘B‘, and then the intermediate result will go through the transformation of matrix ‘A‘, after which the output vector ‘y‘ will be obtained. Moving input vector ‘x’ from right to left, through X-diagrams of ‘A’ and ‘B’. At first, after moving through the transformation of ‘B’, it becomes an intermediate vector ‘t = Bx’, which, after moving through the transformation of ‘A’, becomes the final vector ‘y = At = A(Bx)’. And now the physical meaning of the formula “(AB)T = BTAT” becomes clear: flipping horizontally the X-diagram of the product “A*B” will obviously flip the separate X-diagrams of ‘A‘ and the one of ‘B‘, but it also will reverse their order: Flipping horizontally 2 adjacent figures ‘A’ and ‘B’ will result in the horizontal flip of both figures separately (step 1), as well as in swapping their order (step 2). In the previous story [2], we have also seen that a cell c i ,j of the product matrix ‘C=A*B‘ describes all the possible ways in which x j of the input vector ‘x‘ can affect y i of the output vector ‘y = (AB)x‘. Concatenation of X-diagrams of ‘A’ and ‘B’, which corresponds to the product “A*B”. All 4 possible paths by which the input value ‘x 4 ‘ can affect the output value ‘y 2 ‘ are highlighted in red. Now, when transposing the product “C=A*B“, thus calculating matrix CT, we want to have the mirroring effect – so cT j,i will describe all possible ways by which y j can affect x i . And in order to get that, we should just flip the concatenation diagram: If “C = A*B”, then the value of “c 2,4 ” corresponds to the sum of all 4 possible paths from ‘x 4 ‘ to ‘y 2 ‘ (highlighted in red). At the same time, it is equal to “c 2,4 = cT 4,2 “, which corresponds to the sum of the same 4 possible paths from ‘y 2 ‘ to ‘x 4 ‘, in the horizontally flipped concatenation of “A*B”, which is “BTAT“. Of course, this interpretation can be generalized on transposing the product of several matrices: \\[\\begin{equation*} (ABC)^T = C^T B^T A^T \\end{equation*}\\] Horizontally flipping 3 adjacent items ‘A’, ‘B’, and ‘C’ (not necessarily matrices), and reversing their order will have the effect of horizontally flipping the sequence “ABC” itself. Why ATA is always symmetrical, for any matrix A A symmetrical matrix ‘S‘ is such an nxn square matrix, where for any indexes i, j ∈ [1..n], we have ‘s i ,j = s j ,i ‘. This means that it is symmetrical upon its diagonal, as well as that transposing it will have no effect. An example of a 4×4 symmetrical matrix. All values are symmetrical along the main diagonal. For example, “a 3,1 = a 1,3 = 16″. We see that transposing a symmetrical matrix will have no effect. So, a matrix ‘S‘ is symmetrical if and only if: \\[\\begin{equation*} S^T = S \\end{equation*}\\] Similarly, the X-diagram of a symmetrical matrix ‘S‘ has the property that it is not changed after a horizontal flip. That is because for any arrow s i ,j we have an equal arrow s j ,i there: An example of a 3×3 symmetrical matrix ‘S’ and its X-diagram. We have there ‘s 1,2 = s 2,1 = 4′. Corresponding arrows are highlighted. In matrix analysis, we have a formula stating that for any matrix ‘A‘ (not necessarily symmetrical), the product ATA is always a symmetrical matrix. In other words: \\[\\begin{equation*} (A^T A)^T = A^T A \\end{equation*}\\] It is not straightforward to feel the correctness of this formula if looking at matrix multiplication in the traditional way. But its correctness becomes obvious if looking at matrix multiplication as the concatenation of their X-diagrams: Concatenation of ‘AT‘ and ‘A’, which is a concatenation of two mirrored objects, is always a symmetrical object. Flipping such a concatenation horizontally will have no effect. What will happen if an arbitrary matrix ‘A‘ is concatenated with its horizontal flip AT? The result ATA will be symmetrical, as after a horizontal flip, the right factor ‘A‘ comes to the left side and is flipped, becoming AT, while the left factor AT comes to the right side and is also flipped, becoming ‘A‘. This is why for any matrix ‘A‘, the product ATA is always symmetrical. Understanding why (y, Ax) = (x, ATy) There is another formula in matrix analysis, stating that: \\[\\begin{equation*} (y, Ax) = (x, A^T y) \\end{equation*}\\] where “(u, v)” is the dot product of vectors ‘u‘ and ‘v‘: \\[\\begin{equation*} (u,v) = u_1 v_1 + u_2 v_2 + \\dots + u_n v_n \\end{equation*}\\] The dot product can be calculated only for vectors of equal length. Also, the dot product is not a vector but a single number. If trying to illustrate the dot product “(u, v)” in a way similar to X-diagrams, we can draw something like this: As the dot product is the accumulation of terms u i *v i , we can present it as the sum of all possible paths from the right endpoint to the left one. Now, what does the expression (y, Ax) actually mean? It is the dot product of vector ‘y‘ by the vector “Ax” (or by vector ‘x‘, which went through the transformation of “A“). For the expression (y, Ax) to make sense, we should have: |x| = columns(A), and |y| = rows(A). At first, let’s calculate (y, Ax) formally. Here, every value y i is multiplied by the i-th value of the vector Ax, denoted here as “(Ax) i “: \\[\\begin{equation*} (Ax)_i = a_{i,1}x_1 + a_{i,2}x_2 + \\dots + a_{i,m}x_m \\end{equation*}\\] After one multiplication, we will have: \\[\\begin{equation*} y_i(Ax)_i = y_i a_{i,1}x_1 + y_i a_{i,2}x_2 + \\dots + y_i a_{i,m}x_m \\end{equation*}\\] And after summing all the terms by “i ∈ [1, n]”, we will have: \\[\\begin{equation*} \\begin{split} (y, Ax) = y_1(Ax)_1 + y_2(Ax)_2 + \\dots + y_n(Ax)_n = \\\\ = y_1 a_{1,1}x_1 + y_1 a_{1,2}x_2 + &\\dots + y_1 a_{1,m}x_m + \\\\ + y_2 a_{2,1}x_1 + y_2 a_{2,2}x_2 + &\\dots + y_2 a_{2,m}x_m + \\\\ &\\vdots \\\\ + y_n a_{n,1}x_1 + y_n a_{n,2}x_2 + &\\dots + y_n a_{n,m}x_m \\end{split} \\end{equation*}\\] which clearly shows that in the product (y, Ax), every cell a i,j of the matrix “A” participates exactly once, together with the factors y i and x j . Now let’s move to X-diagrams. If we want to draw something like an X-diagram of vector “Ax“, we can do it in the following way: The product “Ax” is a vector of length equal to “|Ax| = rows(A)”, while “|x| = columns(A)”. Here, values of vector “x” are attached from the right side, and on the left side, we receive values of the result vector “Ax”. Next, if we want to draw the dot product (y, Ax), we can do it this way: Values of vector ‘y’ are attached to the left side of the X-diagram of “A”, while values of vector ‘x’ remain attached to its right side. On this diagram, let’s see how many ways there are to reach the left endpoint from the right one. The path from right to left can pass through any arrow of A‘s X-diagram. If passing through a certain arrow a i ,j , it will be the path composed of x j , the arrow a i ,j , and y i . If a path from right to left passes through arrow “a 4,2 ” of the X-diagram of “A”, then it also passes through values “y 4 ” and “x 2 “. And this exactly matches the formal behavior of (y, Ax) derived a bit above, where (y, Ax) was the sum of all triples of the form “y i *a i ,j *x j “. And we can conclude here that if looking at (y, Ax) in the X-interpretation, it is equal to the sum of all possible paths from the right endpoint to the left one. Now, what will happen if we flip this entire diagram horizontally? Horizontally flipping the X-diagram of “(y, Ax)” results in the X-diagram of “(x, ATy)”. From the algebraic perspective, the sum of all paths from right to left will not change, as all participating terms remain the same. But looking from the geometrical perspective, the vector ‘y‘ goes to the right part, the vector ‘x‘ comes to the left part, and the matrix “A” is being flipped horizontally; in other words, “A” is transposed. So the flipped X-diagram corresponds to the dot product of vectors “x” and “ATy” now, or has the value of (x, ATy). We see that both (y, Ax) and (x, ATy) represent the same sum, which proves that: \\[\\begin{equation*} (y, Ax) = (x, A^T y) \\end{equation*}\\] Conclusion That’s all I wanted to present in regard to the matrix transpose operation. I hope that the visual methods illustrated above will help all of us to gain a better grasp of various matrix operations. In the next (and probably the last) story of this series, I will address inverting matrices, and how it can be visualized by X-interpretation. We will see why formulas like “(AB)-1 = B-1A-1” are the way they actually are, and we will observe how the inverse works on several special types of matrices. So see you in the next story! My gratitude to: – Asya Papyan, for the precise design of all the used illustrations (linkedin.com/in/asya-papyan-b0a1b0243/), – Roza Galstyan, for careful review of the draft (linkedin.com/in/roza-galstyan-a54a8b352/). If you enjoyed reading this story, feel free to follow me on LinkedIn, where, among other things, I will also post updates (linkedin.com/in/tigran-hayrapetyan-cs/). All used images, unless otherwise noted, are designed by request of the author. References [1] – Understanding matrices | Part 1: matrix-vector multiplication – https://towardsdatascience.com/understanding-matrices-part-1-matrix-vector-multiplication/ [2] – Understanding matrices | Part 2: matrix-matrix multiplication – https://towardsdatascience.com/understanding-matrices-part-2-matrix-matrix-multiplication/",
         "en",
         "{'LOC': ['A', 'A T', 'A(Bx', 'AB)-1', 'A^T', 'Ax', 'Ax)_i', 'B', 'B A', 'Corresponding', 'Horizontally', 'Introduced X-way interpretation of matrices', 'S', 'among others', 'becoming AT', 'matrix A', 'matrix CT', 'y_i(Ax)_i'], 'ORG': ['AB', 'AB)^T = B^T A^T', 'AT', 'AT and BT', 'AT‘', 'AT“', 'A^T', 'After one', 'At first', 'B-1A-1” are the way they actually are, and we will', 'Bx’', 'For', 'LinkedIn', 'Observed physical meaning and special cases of matrix-vector', 'X-', 'and vice versa', 'j ” of the matrix'], 'MISC': ['A T – the transpose of matrix ‘A‘, – the transpose of matrix ‘A‘', 'ATA', 'ATA)T', 'ATy', 'After flipping horizontally', 'All 4', 'All arrows in the diagram are directed from right to left', 'All used images', 'All values are', 'Also, the', 'An example of', 'And after summing all the terms by “i ∈', 'And if transposing means changing the places of rows and columns', 'And now the physical meaning of the formula “', 'And we can', 'Ax” is', 'A’ and ‘B’ will result in the horizontal flip of both figures separately', 'BTAT', 'But first of all', 'But its correctness becomes obvious if looking at matrix multiplication', 'C', 'C^T B^T A^T', 'Concatenation of X-diagrams of ‘A’ and ‘B', 'Concatenation of ‘AT‘ and ‘A’', 'Concluding this chapter', 'Conclusion That’s all I wanted to present in regard to the matrix', 'Flipping horizontally 2', 'Flipping such', 'For the expression', 'From part 2 of this series – “', 'From the algebraic perspective', 'From there, we also remember that the left stack of the X', 'Horizontal flip of the X-diagram of ‘A’ corresponds to the transpose of ‘A’', 'Horizontally flipping the X', 'However,', 'I am going to give my interpretation of the', 'I hope that the visual methods illustrated above will help all of us to gain', 'I introduced the X-way interpretation of matrices', 'I want to share my thoughts about the transpose of', 'I will', 'I will also post updates', 'If passing through', 'If trying to illustrate the', 'If we want to draw something like an X', 'If “', 'In', 'In matrix analysis', 'In other words', 'In the X', 'In the next', 'In the previous story', 'It is not straightforward to feel the correctness of this formula if looking at matrix multiplication in the traditional way', 'It is the', 'Let’s recall it with an', 'Let’s see how interpreting', 'Let’s start with the following', 'Matrices are denoted with uppercase', 'My gratitude to: –', 'Now', 'Now let’s move to X-diagrams', 'Observed its behavior on several special cases of matrices In this story', 'Of course', 'S', 'Similarly', 'So', 'So let’', 'So see you in the next story!', 'So the flipped X', 'That is because for any arrow', 'The', 'The arrow which starts at item ‘j’ on the right and finishes at', 'The path from right to left can pass through any arrow of A‘s X-diagram', 'This means that it is symmetrical upon its diagonal', 'Thus', 'Understanding matrices', 'Understanding why', 'We have there ‘', 'We know that cell “a i', 'We see how the 3’rd column of ‘A’ becomes the 3’rd row in ‘AT‘', 'We see that both', 'We see that the values', 'We see that transposing', 'We will see why formulas like “', 'What will happen if an arbitrary matrix ‘A‘ is concatenated with its horizontal flip AT?', 'Which means that the definition of', 'a_{1,2}x_2 + &\\\\dots + y_1 a_{1,m}x_m', 'a_{2,2}x_2 + &\\\\dots + y_2', 'after moving through the transformation of ‘A’', 'after moving through the transformation of ‘B', 'all possible ways by which', 'and on the left side', 'and ‘C’', 'are attached to the left side of the X', 'are designed by request of the author', 'as after', 'as all participating terms remain the same', 'as well as in swapping their order', 'as well as that transposing it will have no effect', 'becoming ‘A', 'denoted as AT', 'feel free to follow', 'horizontal flip of its X', 'horizontally flipping its X', 'i and x j', 'i there: An example of a 3×3', 'i will describe', 'i ” does hold', 'j of the', 'j – the value on the i-th row and j-th column of the transposed matrix A T', 'let’s calculate', 'let’s see how many ways there are to reach the left endpoint from the right one', 'matrix', 'matrix analysis', 'matrix and', 'matrix is actually flipping the table around its main diagonal', 'matrix ‘A’ and its', 'matrix “A', 'matrix-matrix', 'number of rows of matrix ‘A‘', 'stating that', 'stating that for any matrix ‘A‘', 'the X', 'the arrow a i', 'the physical meaning of that often stays behind', 'the product', 'the right factor ‘A‘ comes to the left side and is flipped', 'the sum of all paths from right to left will not change', 'the values which come to the 2’nd from the top item of the left stack are the values of 2’nd row of ‘A’', 'the values which go from the 3’rd from the top item of the right stack are the values of 3’rd column of ‘A’', 'then it also passes through values', 'then perhaps we can do the same on the X-diagram', 'through X', 'to its right side', 'to swap rows and columns of the X', 'u_2', 'u‘ and ‘v‘: \\\\[\\\\begin{equation', 'we can draw something like this: As the', 'we have', 'we have ‘s i', 'we receive values of the result vector “', 'we remember that the matrix multiplication', 'we should flip it horizontally', 'we want to have the mirroring', 'we will have', 'what does the expression', 'when transposing the product “C', 'where for any indexes i', 'which clearly shows that in the product', 'which proves that', 'which went through the transformation of “A“', 'while vectors and scalars are denoted with lowercase', 'why does the', 'will have the effect of horizontally flipping the sequence “', 'will help us to uncover the physical meaning of some', 'works on several special types of matrices', 'x‘ and ‘', '– so cT j'], 'PER': ['A*(Bx', 'A*B', 'ATy', 'ATy) There is another', 'Asya Papyan', 'Ax', 'Here', 'Moving', 'Roza Galstyan', 'T i', 'Transpose', 'Transposing', 'Will the horizontally flipped X', 'and reversing their', 'horizontally will have no effect', 'if transposing', 'let', 'symmetrical matrix', 'symmetrical matrix will have no effect', 'thus calculating', 'v i', 'we should just flip the concatenation', 'which corresponds to the product “', 'which corresponds to the sum of the same', 'will show why the']}",
         "[-0.05772121623158455, -0.04444971680641174, -0.052232805639505386, -0.026323195546865463, -0.037468746304512024, -0.06775418668985367, -0.03964753448963165, -0.042094215750694275, 0.08290226757526398, 0.08581146597862244, 0.015677763149142265, 0.09332811087369919, -0.00910862721502781, 0.015824446454644203, -0.047326505184173584, 0.06156926229596138, -0.009401718154549599, 0.07297496497631073, 0.014558127149939537, 0.0016914112493395805, 0.0383596196770668, -0.04679076746106148, -0.054339248687028885, 0.0018073928076773882, 0.006298196967691183, 0.01870284043252468, -0.04281347244977951, -0.040733251720666885, -0.061510778963565826, 0.024873817339539528, -0.09834904968738556, 0.04218839854001999, -0.09831435233354568, -0.009017008356750011, -0.12019135802984238, 0.02026466652750969, 0.0872107595205307, 0.06757491827011108, 0.06328075379133224, 0.003270318964496255, 0.11402732878923416, -0.05529213324189186, 0.025201993063092232, 0.01935121975839138, 0.022156869992613792, 0.003467612899839878, 0.02791980840265751, -0.08371157199144363, -0.05816876143217087, 0.0009123999625444412, -0.08430970460176468, 0.06307000666856766, -0.007326464168727398, -0.003864377038553357, -0.034028444439172745, -0.012792333960533142, 0.0731198862195015, 0.04024584963917732, 0.026101917028427124, 0.012767260894179344, 0.0061970972456038, -0.024096421897411346, -0.014395222999155521, 0.019163422286510468, 0.0584736093878746, -0.04259921982884407, -0.016543513163924217, -0.017657281830906868, -0.009098922833800316, 0.04687243700027466, -0.08983771502971649, 0.014970743097364902, 0.03341333195567131, 0.015561905689537525, -0.05132265016436577, -0.07975076138973236, 0.06413838267326355, 0.03128218278288841, -0.067458376288414, 0.06604035198688507, 0.027540910989046097, 0.054939307272434235, 0.040264956653118134, 0.010794212110340595, -0.01200792659074068, 0.027187669649720192, -0.009375001303851604, -0.008626425638794899, 0.047783464193344116, 0.040640246123075485, 0.013806052505970001, -0.021241724491119385, 0.03288770839571953, -0.043197259306907654, 0.10045639425516129, -0.012079140171408653, 0.035190705209970474, -0.00789137277752161, 0.04834074154496193, -0.05542277544736862, 0.12147417664527893, 0.056833863258361816, -0.017462734133005142, 0.0008502866257913411, 0.01302393339574337, 0.0030209908727556467, -0.03366396203637123, 0.009876085445284843, 0.01702984981238842, -0.07364632934331894, -0.0005393448518589139, 0.027742726728320122, -0.00992636289447546, -0.0032554606441408396, -0.10331642627716064, 0.0335795059800148, -0.06688374280929565, 0.001664416049607098, 0.10458850115537643, -0.031762536615133286, -0.054801054298877716, 0.03407197445631027, 0.05195796862244606, 0.08314204216003418, 0.09867502748966217, 0.02654486522078514, -0.042744144797325134, 5.3669338945626825e-34, -0.07421454042196274, 0.09366405755281448, 0.022645728662610054, 0.05798523873090744, -0.012134978547692299, -0.0814943015575409, -0.014007884077727795, -0.03449222818017006, 0.07848590612411499, 0.08401906490325928, 0.023269150406122208, 0.03821119666099548, 0.006962220650166273, 0.05750039592385292, -0.047292616218328476, 0.01992400363087654, 0.03457967936992645, -0.019618947058916092, -0.009847958572208881, -0.13514311611652374, 0.022283749654889107, 0.05770229175686836, -0.059995606541633606, 0.011361046694219112, -0.14493171870708466, 0.007676445879042149, -0.009498893283307552, -0.03741726651787758, -0.04401673004031181, 0.0012080910382792354, -0.03648972138762474, 0.03397411108016968, -0.04000214487314224, -0.07454370707273483, 0.02214091271162033, -0.059020549058914185, 0.0241509061306715, -0.09788133949041367, 0.06670946627855301, 0.010278911329805851, -0.040257349610328674, 0.0332769900560379, -0.027042778208851814, -0.028557512909173965, -0.010603654198348522, 0.04784388095140457, -0.04863109067082405, 0.030955402180552483, 0.026939967647194862, -0.05682658776640892, -0.013370427303016186, -0.04084453359246254, 0.053747229278087616, 0.024321749806404114, 0.08549270778894424, -0.0018759217346087098, 0.02184142731130123, -0.02102082222700119, 0.014458701945841312, 0.06390060484409332, 0.020633287727832794, -0.03603191673755646, -0.021548431366682053, -0.02595638483762741, -0.14122019708156586, -0.014768457971513271, 0.003920324612408876, -0.03645280748605728, 0.055911481380462646, 0.07787314057350159, 0.0151777109131217, -0.008684142492711544, -0.019207492470741272, 0.016373712569475174, 0.013709870167076588, -0.02719223126769066, 0.009017974138259888, -0.07357457280158997, 0.00975429080426693, -0.06170117110013962, -0.033911701291799545, 0.11699051409959793, -0.0336177721619606, -0.028240984305739403, -0.014509808272123337, 0.0018725349800661206, -0.009056508541107178, -0.12702850997447968, -0.06303437799215317, -0.010299927555024624, -0.002473716624081135, 0.0010479551274329424, -0.047462090849876404, 0.0027562689501792192, -0.018056180328130722, -3.620550151181493e-33, -0.08326852321624756, 0.013598921708762646, -0.07776376605033875, -0.036470506340265274, -0.02687169425189495, -0.17068937420845032, 0.032116759568452835, -0.05794687196612358, 0.07583902776241302, -0.017997605726122856, -0.02158745750784874, -0.030351098626852036, -0.06728750467300415, -0.04932001978158951, 0.03217043727636337, -0.0027991775423288345, 0.038606755435466766, -0.023371510207653046, -0.05089116469025612, -0.11408919841051102, 0.022427095100283623, 0.08445959538221359, 0.050732146948575974, 0.025982366874814034, -0.03265264257788658, 0.028306126594543457, 0.07247215509414673, 0.0532095693051815, 0.019221628084778786, 0.01648237742483616, -0.034365855157375336, -0.051193881779909134, 0.06280311942100525, 0.09864415228366852, -0.031557127833366394, 0.09142302721738815, -0.03449041768908501, 0.009540887549519539, -0.02387850731611252, -0.006888301111757755, 0.002897470723837614, -0.02617008052766323, 0.04965744912624359, -0.025706090033054352, -0.04457204043865204, 0.06995878368616104, -0.060447823256254196, 0.07430396974086761, 0.04465339332818985, -0.06855495274066925, 0.1004585400223732, 0.014176607131958008, 0.09522946178913116, -0.030603105202317238, -0.03225434198975563, 0.0009356047376058996, -0.02218778058886528, -0.023571204394102097, -0.002902491018176079, 0.04786589369177818, 0.004437674302607775, -0.014007234945893288, -0.01737806759774685, -0.018189813941717148, -0.028576785698533058, 0.014544356614351273, 0.03865841403603554, -0.06789404898881912, -0.02352188155055046, 0.01074785552918911, 0.020666511729359627, -0.05200417712330818, -0.09389233589172363, -0.06937435269355774, 0.059637680649757385, -0.03068050555884838, -0.02001202665269375, -0.04072065278887749, -0.11196671426296234, -0.007059164345264435, -0.06397845596075058, 0.012553147971630096, 0.06352223455905914, -0.007580220233649015, -0.045363496989011765, 0.050171129405498505, -0.017427215352654457, -0.01878308318555355, 0.03849298506975174, 0.03776811063289642, 0.06984339654445648, -0.025237800553441048, -0.032450780272483826, 0.023347049951553345, -0.0014962776331230998, -5.2313886556021316e-08, -0.042787980288267136, 0.0171442162245512, 0.07278575003147125, -0.03516016900539398, -0.06016574800014496, -0.008921067230403423, 0.052146296948194504, 0.024959156289696693, -0.05316191911697388, -0.03071550652384758, -0.08507002145051956, -0.0018653759034350514, -0.00590714905411005, 0.013055520132184029, 0.009504218585789204, 0.07369878888130188, -0.06226704642176628, -0.05067315697669983, -0.008004069328308105, -0.03656887263059616, -0.04547124728560448, -0.01171981543302536, -0.0237557552754879, 0.03690372779965401, -0.03771033510565758, 0.06843745708465576, -0.08199577778577805, 0.07973083853721619, 0.11841242015361786, 0.009869048371911049, 0.024822082370519638, -0.015637319535017014, 0.06969202309846878, 0.0682021975517273, 0.0005119642592035234, 0.013714481145143509, 0.021041663363575935, -0.029344454407691956, 0.024899760261178017, 0.01103622280061245, -0.025845836848020554, -0.05588414892554283, 0.045888688415288925, 0.08677221834659576, 0.04375521093606949, 0.06504552066326141, -0.0995400995016098, 0.08499456942081451, -0.06188173592090607, -0.0058763762935996056, 0.06826616078615189, -0.0043519833125174046, -0.07288358360528946, 0.08071889728307724, -0.0016922526992857456, -0.0392647311091423, -0.035417646169662476, -0.02964494191110134, 0.041509173810482025, 0.04443271458148956, 0.10865990072488785, 0.11427083611488342, -0.03876202553510666, 0.007954279892146587]",
         "0.125"
        ],
        [
         "26",
         "387",
         "Planète 9, comètes interstellaires et migration dans le Système solaire : que peut nous apprendre l'Observatoire Vera-Rubin ?",
         "On espère que l'Observatoire Vera-Rubin, dans le cadre du Legacy Survey of Space and Time (LSST), permettra de percer les secrets de l'énergie noire. Mais il pourrait, au passage, dévoiler d'autres mystères du Système solaire en étudiant comme jamais des comètes et des astéroïdes. Futura a...",
         "On se souvient qu'à la fin du mois de juin de cette année 2025, la noosphère astronomique était entrée un peu en ébullition avec la mise en ligne des premières images fournies par l'Observatoire Vera-C.-Rubin (Vera C. Rubin Observatory, en abrégé VRO), anciennement nommé Large Synoptic Survey Telescope (LSST, en français « Grand Télescope d'étude synoptique »), installé à proximité du sommet du Cerro Pachón au Chili (Futura a suivi la construction du LSST depuis des années).\n\nC'était la fin de la première phase d'un projet commencé il y a plus de deux décennies, inspiré par d'autres projets et idées datant du XXe siècle, comme le grand relevé de galaxies et de quasars du Sloan Digital Sky Survey (SDSS), un programme utilisant un télescope de 2,5 mètres de diamètre observant dans le visible et situé à l'observatoire d'ApacheApache Point (Nouveau-Mexique, États-Unis).\n\nLa seconde phase du projet de l'Observatoire Vera-C.-Rubin avec son télescope, le Simonyi Survey Telescope doté d'un champ d'observation très large (3,5 degrés de diamètre, soit 45 fois la surface apparente de la Lune, qui a un diamètre de 0,5 degré) et de la plus grande caméra numériquenumérique au monde, devrait durer 10 ans.\n\n\n\nLe 23 juin 2025, l’observatoire Rubin, situé au Chili, a révélé les images des premières lumières capturées par la caméra LSST. S'ensuivra un grand relevé astronomique du ciel austral pendant 10 ans qui permettra de réaliser un film sur l’évolution fine de notre ciel nocturne et des profondeurs du cosmos à l’échelle d’un hémisphère entier. © CNRS\n\nElle consistera à photographier tous les trois jours la totalité de la voûte céleste de l'hémisphère sudhémisphère sud à la recherche notamment de phénomènes transitoires, comme les explosions de supernovaesupernovae (ou de kilonovae associées aux sursautssursauts gamma courts émetteurs d'ondes gravitationnellesondes gravitationnelles pour faire de l'astronomie multimessager), mais aussi de mouvementsmouvements d'objets sur cette même voûte.\n\nOn attend en particulier du Vera-Rubin qu'il soit complémentaire du satellite EuclidEuclid pour tenter de percer les mystères de l'énergie noireénergie noire et de la matière noirematière noire.\n\nBien qu'initialement cela soit un projet états-unien, de nombreux laboratoires et chercheurs de par le monde ont été ou sont associés à la première et à la seconde phase du projet Vera-Rubin. En France, plusieurs laboratoires du CNRS peuvent ainsi être cités comme le Laboratoire de physiquephysique subatomique et de cosmologiecosmologie à Grenoble, le Laboratoire de Physique des 2 Infinis Irène Joliot-CurieIrène Joliot-Curie (IJCLab) de l'Université Paris-Saclay, le Laboratoire Lagrange de l'Observatoire de la Côte d'Azur ou encore le Laboratoire de Physique de Clermont Auvergne (LPCA).\n\nIl se trouve que le VRO doit aussi nous permettre d'étudier les astéroïdesastéroïdes et les comètescomètes, fussent-ils d'origine interstellaire, dans le Système solaireSystème solaire. Futura a cherché à en savoir plus en compagnie de Benoit Carry, astronomeastronome au Laboratoire Joseph-Louis LagrangeJoseph-Louis Lagrange (CNRS - Observatoire de la côte d'Azur - Université Côte d'Azur) qui est impliqué dans ce programme de recherche avec le VRO et sa caméra LSST. Le chercheur est aussi un des enseignants du DUAO (Diplôme universitaire d'astronomie observationnelle) de l'Observatoire de la Côte d'Azur (OCA).\n\n\n\nLe 23 juin le ‪Rubin Observatory‬ a dévoilé les premières lumières de l'Univers prises par la caméra LSST pendant 10 ans du ciel austral d’une richesse et d’une profondeur totalement inédite, qui révélera jusqu’aux objets les plus ténus et les plus lointains du cosmos. Ce vaste relevé révèlera pour la première fois à grande échelle les moindres changements de l’Univers, qu’il s’agisse de phénomènes célestes proches (astéroïdes, comètes, etc.) comme très lointains (supernovæ, etc.). Il permettra des avancées majeures en cosmologie, dans l’étude de la matière noire et de l’énergie noire, ou encore dans la compréhension de notre Système solaire. Benoit Carry est astronome au Laboratoire Joseph-Louis Lagrange (CNRS - Observatoire de la Côte d’Azur - Université Côte d’Azur ) © CNRS - En direct des labos\n\nFutura : En ce qui concerne les petits corps célestes sillonnant le Système solaire, que peut faire le Vera-Rubin qu’on ne pouvait pas faire ou pour le moins pas aussi bien avant sa mise en service ?\n\nBenoit Carry : Il y a plusieurs réponses à cette question.\n\nPremièrement, avec ses 8,4 mètres, la taille du miroirmiroir du télescope Simonyi [NdR c'est le nom du philanthrope Charles Simonyi, un informaticien hongrois émigré aux États-Unis qui a contribué au VRO] va lui permettre de détecter de nombreux objets du Système solaire qui étaient trop peu lumineux pour être vus jusqu'à présent, soit parce qu'ils sont trop petits, soit parce qu'ils sont trop loin. On s'attend à voir des astéroïdes de la ceinture principale entre Mars et JupiterJupiter et de la ceinture de Kuiperceinture de Kuiper s'étendant au-delà de l'orbiteorbite de NeptuneNeptune - entre 30 et 55 unités astronomiquesunités astronomiques - avec des magnitudesmagnitudes pouvant aller jusqu'à 24/25, soit un progrès de plusieurs magnitudes.\n\nConcrètement, on passera d'environ 1,5 million de petits corps célestes connus dans le Système solaire à 5 ou 6 millions. Parmi eux, il devrait y avoir des millions d'astéroïdes, des milliers de comètes, des dizaines de milliers d'objets de la ceinture de Kuiper (OBK) et des centaines de milliers d'objets de type géocroiseursgéocroiseurs (NEOS).\n\nDeuxièmement, en couvrant toute la voûte céleste de l'hémisphère sud pendant 10 ans, le VRO devrait en moyenne photographier 400 fois le même objet pour suivre son évolution dans le temps. Les campagnes de relevés concernant ces petits corps rendues possibles par les missions GaiaGaia et Euclid sont très loin de pouvoir faire pareil.\n\nFutura : Que va-t-on apprendre du flot de données concernant ces millions de petits corps célestes ?\n\nBenoit Carry : On peut déjà dire que les découvertes de nouveaux objets devraient se faire au cours des deux premières années de campagne de recherche du VRO. On disposera à terme de données précises concernant les orbites d'un grand nombre d'astéroïdes de la ceinture principale à celle de Kuiper. Or, cette population de corps célestes et ses caractéristiques est une sorte de fossilefossile de l'histoire de la formation et de l'évolution du Système solaire depuis ses débuts, de la naissance des planètes dans le disque protoplanétairedisque protoplanétaire primordial avec ses anneaux, aux migrations planétaires que l'on postule pour expliquer la structure actuelle du Système solaire.\n\nFutura : Le VRO ne fournit pas que des données d’astrométrie pour percer les secrets de la cosmogonie du Système solaire...\n\nBenoit Carry : En effet, la caméra LSST et les instruments qui l'équipent permettent de faire des observations dans différentes bandes à l'aide de six filtres qui sont périodiquement changés et qui couvrent une fenêtrefenêtre d'observation allant du proche infrarougeinfrarouge au proche ultravioletultraviolet. On obtient alors une signature spectrale pour les astéroïdes, qui permet de remonter à la composition minéralogique de leur surface. On avait déjà constaté que la ceinture d'astéroïdes principaleceinture d'astéroïdes principale avait une composition différente selon que l'on s'éloignait du SoleilSoleil. On voit, par exemple, une population dite de type S, car avec un spectrespectre ressemblant à celui des météoritesmétéorites silicatés sur Terre, une population dite de type C (dominante dans la partie externe de la ceinture principale d'astéroïdes), car avec un spectre ressemblant à celui des météorites carbonées sur Terre et d'autres types spectraux encore.\n\nOr, il se trouve que si plusieurs scénarios possibles de migrations planétaires conduisent à des familles orbitalesorbitales d'astéroïdes identiques, ils différent en ce qui concerne les prédictions sur la composition de ces familles. Si l'on dispose d'une statistique suffisamment élevée concernant les diverses compositions de familles de ces corps célestes, on devrait pouvoir départager de façon robuste ces différents scénarios. On peut citer à cet égard le scénario de l'Empty primordial asteroid belt et celui du Grand Tack, tous les deux étudiés par Sean Raymond et ses collègues, notamment à l'OCA.\n\n\n\nSean Raymond, astrophysicien au Laboratoire d'astrophysique de Bordeaux, nous parle de la formation du Système solaire selon le scénario standard par accrétion de planétésimaux donnant des embryons planétaires et complété aujourd'hui par les modèles avec migrations planétaires. © Ideas in Science\n\nFutura : On se souvient de l’excitation causée par l’annonce de la détection en octobre 2017 par un observatoire à Hawaï du premier objet interstellaire, baptisé ‘Oumuamua qui signifie en hawaïen « invité », « messager » ou « éclaireur » (sa classification officielle est 1I/2017 U1). On considère qu’il devrait y en avoir beaucoup dans la Voie lactée. Combien le Vera-Rubin pourrait-il en détecter ?\n\nBenoit Carry : Il est encore trop tôt pour le savoir vraiment, même si le chiffre de un par an a été proposé. Depuis 2017, nous avons eu tout de même la comète 2I/Borisov en 2019 et, tout récemment en 2025, la comète 3I/Atlas. Par contre, c'est le Vera-Rubin qui devrait très probablement donner l'alerte pour déterminer la cible de la mission Comet Interceptor que développe l'ESAESA.\n\nIl s'agit d'une sonde lancée à l'avance et qui sera stationnée au point de Lagrange L2point de Lagrange L2 du système Soleil-Terre en attendant l'identification d'une comète interstellaire qu'elle rejoindra pour l'étudier d'une façon similaire à ce que fut la mission RosettaRosetta pour 67P/Tchourioumov-Guérassimenko.\n\nFutura : On sait que depuis plusieurs années, en se basant sur des observations de petits corps célestes transneptuniens, Konstantin Batygin et Michael Brown en ont déduit qu'il existait peut-être une neuvième grande planète restée inaperçue car trop peu lumineuse et se déplaçant trop lentement sur le Ciel en raison de sa grande distance au Soleil. Le VRO la verra-t-il ?\n\nBenoit Carry : Ce n'est pas impossible, mais personne ne peut l'affirmer en l'état. C'est parce qu'il y a de nombreuses orbites possible pour ladite planète 9, et dans certains cas, elle pourrait être suffisamment proche/grosse pour être visible par le LSST, mais dans d'autres cas... non.\n\n\n\nPar contre, la découverte de nouveaux petits corps transneptuniens et la détermination de leurs orbites pourraient rendre cette hypothèse plus crédible... ou moins !\n\nFutura : Quelle est votre implication dans le programme de recherche avec le VRO ?\n\nBenoit Carry : Pour répondre à votre question, il faut déjà savoir que chaque nuit, tout en changeant 5 à 15 fois les six filtres de couleurcouleur qui équipent sa caméra, l'observatoire va constituer 20 téraoctets de données, soit l'équivalent de la capacité de stockage de 40 disques dursdisques durs ou 4 200 DVDsDVDs. Rapidement, en comparant les images prises avec celles enregistrées, on s'attend à ce qu'environ 10 millions d'alertes soient lancées. Alertes pouvant être dues à l'apparition de supernovae, d'activité de dégazagedégazage d'astéroïdes actifs ou en rapport avec des étoiles variablesétoiles variables, par exemple, ou simplement avec des mouvements d'objets sur la voûte céleste.\n\nOn ne peut pas donner ces alertes directement à la communauté scientifique en raison du volumevolume des données. C'est pourquoi sept centres scientifiques ont été constitués que l'on a appelé des brokers [NdR en français on parlerait de courtiers, qui dans son sens initial désigne un intermédiaire entre un vendeur et un acheteur] qui vont faire un premier filtre (une fausse alerte serait par exemple un satellite de StarlinkStarlink) en identifiant des données qui seront ensuite classées grâce à des techniques de pointe issues du traitement de données massivesdonnées massives (big data) et de l'apprentissage automatique (machine learningmachine learning), selon les types de phénomènes possibles qui intéressent les astrophysiciensastrophysiciens et qui leur seront ensuite signalées et mises à disposition pour des études plus approfondies.\n\n\n\nLe système d'alerte Fink et l'observatoire Vera-Rubin avec les explications de Emille Ishida, ingénieure de recherche au CNRS et au Laboratoire de Physique de Clermont-Ferrand. © CNRS\n\nLe broker français, auquel je me suis associé, s'appelle Fink et il est sous la responsabilité d'un trio de chercheurs et ingénieurs (Anais Möller de la Swinburne University of Technology, Emille E. O. Ishida du LPCA et Julien Peloton d'IJCLab).\n\nComme je l'ai expliqué précédemment, la répartition des types d'astéroïdes selon des orbites autour du Soleil n'est pas la même selon les différentes histoires primitives du Système solaire considérées.\n\nPour départager ces théories, il ne faut pas simplement disposer d'un plus grand nombre d'astéroïdes détectés, il faut aussi réduire les incertitudes et les biais sur la détermination du type spectral de chaque corps détecté.\n\nOr, il se trouve que la quantité de lumièrelumière que nous recevons des astéroïdes est un mélange complexe de leurs couleurs propres (liées à leur composition) et de la géométrie sous laquelle nous les observons. En effet, en fonction de leur distance au soleil et à la Terre, leur phase (comme celles de la Lune), et leur forme patatoïdale, la quantité de lumière varie constamment.\n\n\n\nJ'ai construit des outils (des modèles physiquesmodèles physiques) qui décrivent cette évolution, afin de remonter aux couleurs intrinsèques des astéroïdes.",
         "2025-07-24T19:04:44",
         "https://www.futura-sciences.com/rss/actualites.xml",
         "https://www.futura-sciences.com/sciences/actualites/astronomie-planete-9-cometes-interstellaires-migration-systeme-solaire-peut-nous-apprendre-observatoire-vera-rubin-123891/#xtor%3DRSS-8",
         "2025-07-26T05:53:44.778754",
         "On se souvient qu'à la fin du mois de juin de cette année 2025, la noosphère astronomique était entrée un peu en ébullition avec la mise en ligne des premières images fournies par l'Observatoire Vera-C.-Rubin (Vera C. Rubin Observatory, en abrégé VRO), anciennement nommé Large Synoptic Survey Telescope (LSST, en français « Grand Télescope d'étude synoptique »), installé à proximité du sommet du Cerro Pachón au Chili (Futura a suivi la construction du LSST depuis des années). C'était la fin de la première phase d'un projet commencé il y a plus de deux décennies, inspiré par d'autres projets et idées datant du XXe siècle, comme le grand relevé de galaxies et de quasars du Sloan Digital Sky Survey (SDSS), un programme utilisant un télescope de 2,5 mètres de diamètre observant dans le visible et situé à l'observatoire d'ApacheApache Point (Nouveau-Mexique, États-Unis). La seconde phase du projet de l'Observatoire Vera-C.-Rubin avec son télescope, le Simonyi Survey Telescope doté d'un champ d'observation très large (3,5 degrés de diamètre, soit 45 fois la surface apparente de la Lune, qui a un diamètre de 0,5 degré) et de la plus grande caméra numériquenumérique au monde, devrait durer 10 ans. Le 23 juin 2025, l’observatoire Rubin, situé au Chili, a révélé les images des premières lumières capturées par la caméra LSST. S'ensuivra un grand relevé astronomique du ciel austral pendant 10 ans qui permettra de réaliser un film sur l’évolution fine de notre ciel nocturne et des profondeurs du cosmos à l’échelle d’un hémisphère entier. © CNRS Elle consistera à photographier tous les trois jours la totalité de la voûte céleste de l'hémisphère sudhémisphère sud à la recherche notamment de phénomènes transitoires, comme les explosions de supernovaesupernovae (ou de kilonovae associées aux sursautssursauts gamma courts émetteurs d'ondes gravitationnellesondes gravitationnelles pour faire de l'astronomie multimessager), mais aussi de mouvementsmouvements d'objets sur cette même voûte. On attend en particulier du Vera-Rubin qu'il soit complémentaire du satellite EuclidEuclid pour tenter de percer les mystères de l'énergie noireénergie noire et de la matière noirematière noire. Bien qu'initialement cela soit un projet états-unien, de nombreux laboratoires et chercheurs de par le monde ont été ou sont associés à la première et à la seconde phase du projet Vera-Rubin. En France, plusieurs laboratoires du CNRS peuvent ainsi être cités comme le Laboratoire de physiquephysique subatomique et de cosmologiecosmologie à Grenoble, le Laboratoire de Physique des 2 Infinis Irène Joliot-CurieIrène Joliot-Curie (IJCLab) de l'Université Paris-Saclay, le Laboratoire Lagrange de l'Observatoire de la Côte d'Azur ou encore le Laboratoire de Physique de Clermont Auvergne (LPCA). Il se trouve que le VRO doit aussi nous permettre d'étudier les astéroïdesastéroïdes et les comètescomètes, fussent-ils d'origine interstellaire, dans le Système solaireSystème solaire. Futura a cherché à en savoir plus en compagnie de Benoit Carry, astronomeastronome au Laboratoire Joseph-Louis LagrangeJoseph-Louis Lagrange (CNRS - Observatoire de la côte d'Azur - Université Côte d'Azur) qui est impliqué dans ce programme de recherche avec le VRO et sa caméra LSST. Le chercheur est aussi un des enseignants du DUAO (Diplôme universitaire d'astronomie observationnelle) de l'Observatoire de la Côte d'Azur (OCA). Le 23 juin le ‪Rubin Observatory‬ a dévoilé les premières lumières de l'Univers prises par la caméra LSST pendant 10 ans du ciel austral d’une richesse et d’une profondeur totalement inédite, qui révélera jusqu’aux objets les plus ténus et les plus lointains du cosmos. Ce vaste relevé révèlera pour la première fois à grande échelle les moindres changements de l’Univers, qu’il s’agisse de phénomènes célestes proches (astéroïdes, comètes, etc.) comme très lointains (supernovæ, etc.). Il permettra des avancées majeures en cosmologie, dans l’étude de la matière noire et de l’énergie noire, ou encore dans la compréhension de notre Système solaire. Benoit Carry est astronome au Laboratoire Joseph-Louis Lagrange (CNRS - Observatoire de la Côte d’Azur - Université Côte d’Azur ) © CNRS - En direct des labos Futura : En ce qui concerne les petits corps célestes sillonnant le Système solaire, que peut faire le Vera-Rubin qu’on ne pouvait pas faire ou pour le moins pas aussi bien avant sa mise en service ? Benoit Carry : Il y a plusieurs réponses à cette question. Premièrement, avec ses 8,4 mètres, la taille du miroirmiroir du télescope Simonyi [NdR c'est le nom du philanthrope Charles Simonyi, un informaticien hongrois émigré aux États-Unis qui a contribué au VRO] va lui permettre de détecter de nombreux objets du Système solaire qui étaient trop peu lumineux pour être vus jusqu'à présent, soit parce qu'ils sont trop petits, soit parce qu'ils sont trop loin. On s'attend à voir des astéroïdes de la ceinture principale entre Mars et JupiterJupiter et de la ceinture de Kuiperceinture de Kuiper s'étendant au-delà de l'orbiteorbite de NeptuneNeptune - entre 30 et 55 unités astronomiquesunités astronomiques - avec des magnitudesmagnitudes pouvant aller jusqu'à 24/25, soit un progrès de plusieurs magnitudes. Concrètement, on passera d'environ 1,5 million de petits corps célestes connus dans le Système solaire à 5 ou 6 millions. Parmi eux, il devrait y avoir des millions d'astéroïdes, des milliers de comètes, des dizaines de milliers d'objets de la ceinture de Kuiper (OBK) et des centaines de milliers d'objets de type géocroiseursgéocroiseurs (NEOS). Deuxièmement, en couvrant toute la voûte céleste de l'hémisphère sud pendant 10 ans, le VRO devrait en moyenne photographier 400 fois le même objet pour suivre son évolution dans le temps. Les campagnes de relevés concernant ces petits corps rendues possibles par les missions GaiaGaia et Euclid sont très loin de pouvoir faire pareil. Futura : Que va-t-on apprendre du flot de données concernant ces millions de petits corps célestes ? Benoit Carry : On peut déjà dire que les découvertes de nouveaux objets devraient se faire au cours des deux premières années de campagne de recherche du VRO. On disposera à terme de données précises concernant les orbites d'un grand nombre d'astéroïdes de la ceinture principale à celle de Kuiper. Or, cette population de corps célestes et ses caractéristiques est une sorte de fossilefossile de l'histoire de la formation et de l'évolution du Système solaire depuis ses débuts, de la naissance des planètes dans le disque protoplanétairedisque protoplanétaire primordial avec ses anneaux, aux migrations planétaires que l'on postule pour expliquer la structure actuelle du Système solaire. Futura : Le VRO ne fournit pas que des données d’astrométrie pour percer les secrets de la cosmogonie du Système solaire... Benoit Carry : En effet, la caméra LSST et les instruments qui l'équipent permettent de faire des observations dans différentes bandes à l'aide de six filtres qui sont périodiquement changés et qui couvrent une fenêtrefenêtre d'observation allant du proche infrarougeinfrarouge au proche ultravioletultraviolet. On obtient alors une signature spectrale pour les astéroïdes, qui permet de remonter à la composition minéralogique de leur surface. On avait déjà constaté que la ceinture d'astéroïdes principaleceinture d'astéroïdes principale avait une composition différente selon que l'on s'éloignait du SoleilSoleil. On voit, par exemple, une population dite de type S, car avec un spectrespectre ressemblant à celui des météoritesmétéorites silicatés sur Terre, une population dite de type C (dominante dans la partie externe de la ceinture principale d'astéroïdes), car avec un spectre ressemblant à celui des météorites carbonées sur Terre et d'autres types spectraux encore. Or, il se trouve que si plusieurs scénarios possibles de migrations planétaires conduisent à des familles orbitalesorbitales d'astéroïdes identiques, ils différent en ce qui concerne les prédictions sur la composition de ces familles. Si l'on dispose d'une statistique suffisamment élevée concernant les diverses compositions de familles de ces corps célestes, on devrait pouvoir départager de façon robuste ces différents scénarios. On peut citer à cet égard le scénario de l'Empty primordial asteroid belt et celui du Grand Tack, tous les deux étudiés par Sean Raymond et ses collègues, notamment à l'OCA. Sean Raymond, astrophysicien au Laboratoire d'astrophysique de Bordeaux, nous parle de la formation du Système solaire selon le scénario standard par accrétion de planétésimaux donnant des embryons planétaires et complété aujourd'hui par les modèles avec migrations planétaires. © Ideas in Science Futura : On se souvient de l’excitation causée par l’annonce de la détection en octobre 2017 par un observatoire à Hawaï du premier objet interstellaire, baptisé ‘Oumuamua qui signifie en hawaïen « invité », « messager » ou « éclaireur » (sa classification officielle est 1I/2017 U1). On considère qu’il devrait y en avoir beaucoup dans la Voie lactée. Combien le Vera-Rubin pourrait-il en détecter ? Benoit Carry : Il est encore trop tôt pour le savoir vraiment, même si le chiffre de un par an a été proposé. Depuis 2017, nous avons eu tout de même la comète 2I/Borisov en 2019 et, tout récemment en 2025, la comète 3I/Atlas. Par contre, c'est le Vera-Rubin qui devrait très probablement donner l'alerte pour déterminer la cible de la mission Comet Interceptor que développe l'ESAESA. Il s'agit d'une sonde lancée à l'avance et qui sera stationnée au point de Lagrange L2point de Lagrange L2 du système Soleil-Terre en attendant l'identification d'une comète interstellaire qu'elle rejoindra pour l'étudier d'une façon similaire à ce que fut la mission RosettaRosetta pour 67P/Tchourioumov-Guérassimenko. Futura : On sait que depuis plusieurs années, en se basant sur des observations de petits corps célestes transneptuniens, Konstantin Batygin et Michael Brown en ont déduit qu'il existait peut-être une neuvième grande planète restée inaperçue car trop peu lumineuse et se déplaçant trop lentement sur le Ciel en raison de sa grande distance au Soleil. Le VRO la verra-t-il ? Benoit Carry : Ce n'est pas impossible, mais personne ne peut l'affirmer en l'état. C'est parce qu'il y a de nombreuses orbites possible pour ladite planète 9, et dans certains cas, elle pourrait être suffisamment proche/grosse pour être visible par le LSST, mais dans d'autres cas... non. Par contre, la découverte de nouveaux petits corps transneptuniens et la détermination de leurs orbites pourraient rendre cette hypothèse plus crédible... ou moins ! Futura : Quelle est votre implication dans le programme de recherche avec le VRO ? Benoit Carry : Pour répondre à votre question, il faut déjà savoir que chaque nuit, tout en changeant 5 à 15 fois les six filtres de couleurcouleur qui équipent sa caméra, l'observatoire va constituer 20 téraoctets de données, soit l'équivalent de la capacité de stockage de 40 disques dursdisques durs ou 4 200 DVDsDVDs. Rapidement, en comparant les images prises avec celles enregistrées, on s'attend à ce qu'environ 10 millions d'alertes soient lancées. Alertes pouvant être dues à l'apparition de supernovae, d'activité de dégazagedégazage d'astéroïdes actifs ou en rapport avec des étoiles variablesétoiles variables, par exemple, ou simplement avec des mouvements d'objets sur la voûte céleste. On ne peut pas donner ces alertes directement à la communauté scientifique en raison du volumevolume des données. C'est pourquoi sept centres scientifiques ont été constitués que l'on a appelé des brokers [NdR en français on parlerait de courtiers, qui dans son sens initial désigne un intermédiaire entre un vendeur et un acheteur] qui vont faire un premier filtre (une fausse alerte serait par exemple un satellite de StarlinkStarlink) en identifiant des données qui seront ensuite classées grâce à des techniques de pointe issues du traitement de données massivesdonnées massives (big data) et de l'apprentissage automatique (machine learningmachine learning), selon les types de phénomènes possibles qui intéressent les astrophysiciensastrophysiciens et qui leur seront ensuite signalées et mises à disposition pour des études plus approfondies. Le système d'alerte Fink et l'observatoire Vera-Rubin avec les explications de Emille Ishida, ingénieure de recherche au CNRS et au Laboratoire de Physique de Clermont-Ferrand. © CNRS Le broker français, auquel je me suis associé, s'appelle Fink et il est sous la responsabilité d'un trio de chercheurs et ingénieurs (Anais Möller de la Swinburne University of Technology, Emille E. O. Ishida du LPCA et Julien Peloton d'IJCLab). Comme je l'ai expliqué précédemment, la répartition des types d'astéroïdes selon des orbites autour du Soleil n'est pas la même selon les différentes histoires primitives du Système solaire considérées. Pour départager ces théories, il ne faut pas simplement disposer d'un plus grand nombre d'astéroïdes détectés, il faut aussi réduire les incertitudes et les biais sur la détermination du type spectral de chaque corps détecté. Or, il se trouve que la quantité de lumièrelumière que nous recevons des astéroïdes est un mélange complexe de leurs couleurs propres (liées à leur composition) et de la géométrie sous laquelle nous les observons. En effet, en fonction de leur distance au soleil et à la Terre, leur phase (comme celles de la Lune), et leur forme patatoïdale, la quantité de lumière varie constamment. J'ai construit des outils (des modèles physiquesmodèles physiques) qui décrivent cette évolution, afin de remonter aux couleurs intrinsèques des astéroïdes.",
         "fr",
         "{'LOC': ['Cerro Pachón', 'Chili', 'Côte d’Azur', 'France', 'Futura', 'Grenoble', 'Hawaï', 'JupiterJupiter', 'Kuiper', 'Kuiperceinture', 'Laboratoire Joseph-Louis Lagrange', 'Laboratoire Joseph-Louis LagrangeJoseph-Louis Lagrange', 'Laboratoire Lagrange', \"Laboratoire d'astrophysique de Bordeaux\", 'Laboratoire de Physique', 'Laboratoire de Physique de Clermont Auvergne', 'Laboratoire de Physique de Clermont-Ferrand', 'Lune', 'Mars', 'NeptuneNeptune', 'Nouveau-Mexique', 'Observatoire Vera-C.-Rubin', \"Observatoire de la Côte d'Azur\", 'Oumuamua', 'SDSS', 'Sloan Digital Sky Survey', 'Soleil', 'SoleilSoleil', 'Tchourioumov-Guérassimenko', 'Terre', 'U1', 'Vera-Rubin', 'Voie lactée', 'astéroïdesastéroïdes', \"côte d'Azur\", 'la Terre', 'observatoire Rubin', \"observatoire d'ApacheApache Point\", 'soleil', 'supernovaesupernovae', 'États-Unis'], 'PER': ['Anais Möller', 'Benoit Carry', 'Charles Simonyi', 'Ciel', 'Emille E. O. Ishida', 'Emille Ishida', 'Euclid', 'Fink', 'Irène Joliot-CurieIrène Joliot-Curie', 'Julien Peloton', 'Konstantin Batygin', 'Lagrange L2point de Lagrange L2', 'Michael Brown', 'Sean Raymond', 'Simonyi', 'Vera C. Rubin Observatory', 'Vera-Rubin', 'XXe siècle', 'kilonovae', 'lumièrelumière'], 'MISC': ['2I', '3I/Atlas', 'Borisov', 'C', 'Comet Interceptor', 'Empty primordial asteroid belt', 'EuclidEuclid', 'Fink', 'GaiaGaia', 'Grand Tack', 'IJCLab', 'LSST', 'RosettaRosetta', 'S', 'Simonyi Survey Telescope', 'StarlinkStarlink', 'Système solaire', 'Système solaire considérées', 'Système solaire à 5', 'Système solaireSystème solaire', 'Télescope', 'Univers', 'VRO', 'machine learningmachine learning', '© Ideas in', '\\u202aRubin Observatory\\u202c'], 'ORG': ['CNRS', 'CNRS - Observatoire', 'DUAO', \"Diplôme universitaire d'astronomie observationnelle\", 'ESAESA', 'Futura', 'LPCA', 'LSST', 'Laboratoire de physiquephysique subatomique et de cosmologiecosmologie', 'NEOS', 'OBK', 'OCA', 'Swinburne University of Technology', 'Université Paris-Saclay']}",
         "[-0.06897374987602234, -0.03006710112094879, 0.014640400186181068, -0.004894210025668144, 0.019084230065345764, -0.0627501904964447, -0.14758624136447906, 0.057601187378168106, -0.01920505054295063, 0.016523486003279686, -0.027738386765122414, -0.13172096014022827, 0.02745191380381584, -0.12206298857927322, 0.02461729384958744, -0.030623452737927437, -0.01601436361670494, -0.13261055946350098, 0.0662272498011589, -0.015985339879989624, 0.0015698566567152739, -0.007662419695407152, -0.05308860167860985, 0.012644612230360508, -0.009337212890386581, -0.024795638397336006, -0.1168782189488411, -0.04271114245057106, -0.004401471931487322, 0.0016592575702816248, 0.027499191462993622, 0.10351315140724182, -0.06911133974790573, 0.017048392444849014, 0.053590502589941025, 0.006153130438178778, 0.020688794553279877, -0.12082958966493607, -0.006691181566566229, 0.05041089653968811, -0.049350958317518234, -0.02035478875041008, -0.036982376128435135, -0.056826021522283554, -0.02861543744802475, -0.020257072523236275, 0.04815974831581116, 0.04892514646053314, -0.04451796039938927, -0.03611784428358078, -0.008981394581496716, -0.004643319174647331, 0.015130829066038132, -0.0320894718170166, 0.0021114989649504423, 0.027929170057177544, -0.05423484370112419, -0.10688157379627228, 0.06988674402236938, 0.03495067358016968, 0.04873604699969292, -0.005760135129094124, -0.10316801071166992, -0.034112539142370224, -0.004588101990520954, 0.006006376352161169, -0.0718700960278511, -0.10542022436857224, 0.050198622047901154, -0.026961322873830795, -0.009168777614831924, 0.001460456638596952, 0.011582397855818272, -0.0032354523427784443, 0.013175428844988346, 0.1133245900273323, 0.04953709989786148, 0.008856982924044132, 0.01398446224629879, -0.15618650615215302, 0.08354420214891434, 0.03543734923005104, 0.039408572018146515, -0.008362648077309132, -0.06603922694921494, 0.0335262306034565, -0.024532724171876907, 0.07707483321428299, 0.06770742684602737, -0.05747712776064873, 0.03433990478515625, -0.003661907510831952, -0.18107937276363373, 0.009678205475211143, -0.009159602224826813, -0.017411228269338608, 0.03943347930908203, -0.05961287021636963, 0.042077381163835526, 0.04814688861370087, 0.07081323117017746, -0.015378995798528194, -0.043707046657800674, 0.027954736724495888, -0.05227838084101677, 0.025917232036590576, 0.06705863028764725, -0.02304789610207081, -0.03371809422969818, 0.007037544157356024, -0.008588116616010666, 0.01007763296365738, -0.042690202593803406, -0.11928603053092957, -0.010751990601420403, 0.02579834870994091, 0.038679927587509155, 0.009646193124353886, -0.08415745198726654, -0.09316160529851913, 0.0167793408036232, -0.008451544679701328, -0.0037151454016566277, 0.033204201608896255, 0.027531128376722336, 0.005354639142751694, 0.031139187514781952, 1.2466274812839782e-32, 0.042204350233078, 0.040841005742549896, 0.00889001414179802, -0.011284146457910538, 0.049669068306684494, 0.06999575346708298, -0.06805477291345596, 0.05011650547385216, -0.004487225785851479, -0.002293618395924568, -0.06742378324270248, -0.015134619548916817, -0.033979397267103195, -0.027924830093979836, 0.09267444908618927, -0.007610219996422529, 0.09110439568758011, -0.04069242626428604, -0.07327859103679657, -0.03395538404583931, -0.06336000561714172, -0.0038592794444411993, -0.027804415673017502, 0.028314275667071342, 0.06294099241495132, 0.13078069686889648, 0.06601370126008987, -0.09691449254751205, -0.047420527786016464, 0.04602230340242386, -0.010823717340826988, -0.06150961294770241, 0.02480197697877884, 0.05083918571472168, -0.00413473229855299, -0.060622863471508026, -0.06136808544397354, 0.03974175080657005, -0.03865444287657738, 0.021188979968428612, 0.08643902838230133, 0.08880529552698135, -0.010020848363637924, -0.006567034404724836, 0.006793652195483446, 0.030460920184850693, 0.03538794815540314, 0.0025599480140954256, 0.11079516261816025, 0.006893513724207878, 0.06776203960180283, 0.003321831813082099, -0.13722506165504456, -0.06028897687792778, 0.05850544199347496, 0.03204552084207535, -0.008328504860401154, -0.03097616508603096, -0.028936579823493958, 0.004843279719352722, 0.028458133339881897, -0.07529532164335251, -0.02627619542181492, 0.03199557960033417, -0.01757356896996498, 0.06935051083564758, -0.019950302317738533, 0.05052092671394348, 0.04338783398270607, 0.028605232015252113, -0.08980279415845871, -0.019452817738056183, 0.11752623319625854, -0.002139646327123046, 0.0834733173251152, 0.02610643394291401, 0.023648343980312347, 0.031670160591602325, 0.019650742411613464, 0.10968896746635437, -0.08181557059288025, -0.04236076399683952, 0.03739979490637779, -0.05170911177992821, 0.021562352776527405, -0.049997374415397644, 0.02851756289601326, 0.08873985707759857, 0.022616136819124222, -0.05583283305168152, 0.023945575580000877, 0.08149442076683044, 0.035594455897808075, -0.01268783863633871, -0.06950058788061142, -1.4164054528043858e-32, -0.011145752854645252, 0.025018326938152313, -0.016316602006554604, -0.043174467980861664, -0.06447810679674149, 0.02932008169591427, -0.04389702156186104, 0.024695204570889473, -0.07915415614843369, -0.07241467386484146, -0.007731470745056868, -0.016120193526148796, -0.009940735064446926, -0.06052060425281525, -0.008611801080405712, 0.01761498861014843, -0.010144206695258617, -0.05095133185386658, -0.0978119894862175, 0.032847583293914795, 0.05744461342692375, -0.032566510140895844, 0.027473805472254753, -0.06396196782588959, 0.02172817476093769, -0.0025018604937940836, 0.08473582565784454, -0.023460524156689644, -0.020782817155122757, 0.03339836001396179, -0.0838756263256073, 0.018818313255906105, -0.008110346272587776, 0.04074161499738693, 0.07969165593385696, 0.04061039909720421, 0.09723006933927536, 0.0006965535576455295, -0.0893036276102066, 0.008092264644801617, -0.05834005028009415, 0.14785441756248474, 0.003470331896096468, -0.008999637328088284, 0.01319846697151661, -0.01941044069826603, 0.0041818395256996155, 0.014073987491428852, -0.02443285472691059, -0.0018885873723775148, 0.019930405542254448, -0.07102039456367493, -0.04374443367123604, 0.05204442888498306, 0.028361568227410316, -0.0011170814977958798, 0.002360647078603506, 0.03620573505759239, -0.009845351800322533, -0.05956491455435753, 0.011907380074262619, -0.016899673268198967, 0.003339944174513221, -0.0013630621833726764, 0.06539630144834518, -0.06748117506504059, -0.0038608338218182325, 0.07901828736066818, -0.008158246986567974, 0.05378561466932297, 0.06040698289871216, -0.008935675024986267, -0.045071568340063095, 0.0008703648927621543, 0.02399766631424427, 0.07906991243362427, 0.01683485321700573, -0.022711651399731636, -0.009466622024774551, 0.04262496903538704, -0.11483331024646759, 0.04745425656437874, -0.0001853020366979763, -0.0013760720612481236, 0.08363785594701767, 0.05530853196978569, 0.02350252866744995, -0.048162929713726044, 0.04182551056146622, 0.014062768779695034, 0.02384970150887966, 0.036000095307826996, 0.019732987508177757, 0.03301200270652771, 0.04503217339515686, -6.891389148222515e-08, 0.05365937948226929, 0.018447786569595337, -0.10093583166599274, 0.01900324784219265, -0.01920952834188938, -0.099680095911026, -0.06193404644727707, 0.013988330028951168, 0.004123026039451361, 0.029628649353981018, 0.05525965616106987, 0.028028953820466995, -0.04890809580683708, 0.010195127688348293, -0.04555824398994446, -0.017568184062838554, -0.03164214268326759, -0.0393507145345211, -0.039398644119501114, 0.00959787517786026, -0.009820297360420227, -0.003420306369662285, 0.0001243178703589365, -0.09339380264282227, 0.012215908616781235, -0.003955566789954901, -0.016035662963986397, -0.018279680982232094, -0.01105462945997715, -0.06994201242923737, -0.023346995934844017, -0.010926168411970139, -0.0467715747654438, -0.11174466460943222, -0.04407092183828354, -0.009222951717674732, -0.033090706914663315, 0.09450773149728775, 0.010512740351259708, 0.040781158953905106, 0.0782361701130867, 0.011544489301741123, 0.00600458774715662, 0.007429101970046759, 0.010721156373620033, -0.006458195857703686, -0.002668612403795123, -0.03961332514882088, 0.04460008442401886, 0.0622074231505394, -0.057300884276628494, -0.013888068497180939, 0.04085048288106918, -0.0684366300702095, -0.04661853238940239, 0.014097790233790874, -0.008407965302467346, -0.0045853834599256516, -0.03296415135264397, -0.004697707016021013, -0.003946730867028236, 0.017741825431585312, -0.0875941589474678, -0.03174766153097153]",
         "0.186"
        ],
        [
         "27",
         "39",
         "10 Best Chrome Extensions That Are Perfect for Everyone",
         "Are you a great Chrome user? That’s nice to hear. But first, consider whether or not there are any essential Chrome extensions you are currently missing from your browsing life, so here we're going to share with you 10 Best Chrome Extensions That Are Perfect for Everyone. So Let's Start. 1. LastPass When you have too several passwords to remember, LastPass remembers them for you. This chrome extension is an easy way to save you time and increase security. It’s a single password manager that will log you into all of your accounts. you simply ought to bear in mind one word: your LastPass password to log in to all or any your accounts. Features Save usernames and passwords and LastPasswill log you in automatically. Fill the forms quickly to save your addresses, credit card numbers and more. 2. MozBar MozBar is an SEO toolbar extension that makes it easy for you to analyze your web pages' SEO while you surf. You can customize your search so that you see data for a particular region or for all regions. You get data such as website and domain authority and link profile. The status column tells you whether there are any no-followed links to the page.You can also compare link metrics. There is a pro version of MozBar, too. 3. Grammerly Grammarly is a real-time grammar checking and spelling tool for online writing. It checks spelling, grammar, and punctuation as you type, and has a dictionary feature that suggests related words. if you use mobile phones for writing than Grammerly also have a mobile keyboard app. 4. VidlQ VidIQ is a SaaS product and Chrome Extension that makes it easier to manage and optimize your YouTube channels. It keeps you informed about your channel's performance with real-time analytics and powerful insights. Features Learn more about insights and statistics beyond YouTube Analytics Find great videos with the Trending tab. You can check out any video’s YouTube rankings and see how your own video is doing on the charts. Keep track the history of the keyword to determine when a keyword is rising or down in popularity over time. Quickly find out which videos are performing the best on YouTube right now. Let this tool suggest keywords for you to use in your title, description and tags. 5. ColorZilla ColorZilla is a browser extension that allows you to find out the exact color of any object in your web browser. This is especially useful when you want to match elements on your page to the color of an image. Features Advanced Color Picker (similar to Photoshop's) Ultimate CSS Gradient Generator The \"Webpage Color Analyzer\" site helps you determine the palette of colors used in a particular website. Palette Viewer with 7 pre-installed palettes Eyedropper - sample the color of any pixel on the page Color History of recently picked colors Displays some info about the element, including the tag name, class, id and size. Auto copy picked colors to clipboard Get colors of dynamic hover elements Pick colors from Flash objects Pick colors at any zoom level 6. Honey Honey is a chrome extension with which you save each product from the website and notify it when it is available at low price it's one among the highest extensions for Chrome that finds coupon codes whenever you look online. Features Best for finding exclusive prices on Amazon. A free reward program called Honey Gold. Searches and filters the simplest value fitting your demand. Instant notifications. 7. GMass: Powerful Chrome Extension for Gmail Marketers GMass (or Gmail Mass) permits users to compose and send mass emails using Gmail. it is a great tool as a result of you'll use it as a replacement for a third-party email sending platform. you will love GMass to spice up your emailing functionality on the platform. 8. Notion Web Clipper: Chrome Extension for Geeks It's a Chrome extension for geeks that enables you to highlight and save what you see on the web. It's been designed by Notion, that could be a Google space different that helps groups craft higher ideas and collaborate effectively. Features Save anything online with just one click Use it on any device Organize your saved clips quickly Tag, share and comment on the clips If you are someone who works online, you need to surf the internet to get your business done. And often there is no time to read or analyze something. But it's important that you do it. Notion Web Clipper will help you with that. 9. WhatFont: Chrome Extension for identifying Any Site Fonts WhatFont is a Chrome extension that allows web designers to easily identify and compare different fonts on a page. The first time you use it on any page, WhatFont will copy the selected page.It Uses this page to find out what fonts are present and generate an image that shows all those fonts in different sizes. Besides the apparent websites like Google or Amazon, you'll conjointly use it on sites wherever embedded fonts ar used. 10. SimilarWeb: Traffic Rank & Website Analysis Extension Similar Web is an SEO add on for both Chrome and Firefox.It allows you to check web site traffic and key metrics for any web site, as well as engagement rate, traffic ranking, keyword ranking, and traffic source. this is often a good tool if you are looking to seek out new and effective SEO ways similarly as analyze trends across the web. Features Discover keyword trends Know fresh keywords Get benefit from the real traffic insights Analyze engagement metrics Explore unique visitors data Analyze your industry's category Use month to date data How to Install chrome Extension in Android I know everyone knows how to install extension in pc but most of people don't know how to install it in android phone so i will show you how to install it in android 1. Download Kiwi browser from Play Store and then Open it. Advertisement Continue reading below 2. Tap the three dots at the top right corner and select Extension. 3. Click on (+From Store) to access chrome web store or simple search chrome web store and access it. 4. Once you found an extension click on add to chrome a message will pop-up asking if you wish to confirm your choice. Hit OK to install the extension in the Kiwi browser. 5. To manage extensions on the browser, tap the three dots in the upper right corner. Then select Extensions to access a catalog of installed extensions that you can disable, update or remove with just a few clicks. Your Chrome extensions should install on Android, but there’s no guarantee all of them will work. Because Google Chrome Extensions are not optimized for Android devices. Final Saying We hope this list of 10 best chrome extensions that is perfect for everyone will help you in picking the right Chrome Extensions. We have selected the extensions after matching their features to the needs of different categories of people. Also which extension you like the most let me know in the comment section",
         "Are you a great Chrome user? That’s nice to hear. But first, consider whether or not there are any essential Chrome extensions you are currently missing from your browsing life, so here we're going to share with you 10 Best Chrome Extensions That Are Perfect for Everyone. So Let's Start.\n\n1. LastPass\n\nWhen you have too several passwords to remember, LastPass remembers them for you.\n\nThis chrome extension is an easy way to save you time and increase security. It’s a single password manager that will log you into all of your accounts. you simply ought to bear in mind one word: your LastPass password to log in to all or any your accounts.\n\nFeatures\n\nSave usernames and passwords and LastPasswill log you in automatically.\n\nFill the forms quickly to save your addresses, credit card numbers and more.\n\n2. MozBar\n\nMozBar is an SEO toolbar extension that makes it easy for you to analyze your web pages' SEO while you surf. You can customize your search so that you see data for a particular region or for all regions. You get data such as website and domain authority and link profile. The status column tells you whether there are any no-followed links to the page.You can also compare link metrics. There is a pro version of MozBar, too.\n\n\n\n\n\n3. Grammerly\n\nGrammarly is a real-time grammar checking and spelling tool for online writing. It checks spelling, grammar, and punctuation as you type, and has a dictionary feature that suggests related words. if you use mobile phones for writing than Grammerly also have a mobile keyboard app.\n\n4. VidlQ\n\nVidIQ is a SaaS product and Chrome Extension that makes it easier to manage and optimize your YouTube channels. It keeps you informed about your channel's performance with real-time analytics and powerful insights.\n\nFeatures\n\nLearn more about insights and statistics beyond YouTube Analytics\n\nFind great videos with the Trending tab.\n\nYou can check out any video’s YouTube rankings and see how your own video is doing on the charts.\n\nKeep track the history of the keyword to determine when a keyword is rising or down in popularity over time.\n\nQuickly find out which videos are performing the best on YouTube right now.\n\nLet this tool suggest keywords for you to use in your title, description and tags.\n\n5. ColorZilla\n\nColorZilla is a browser extension that allows you to find out the exact color of any object in your web browser. This is especially useful when you want to match elements on your page to the color of an image.\n\nFeatures\n\nAdvanced Color Picker (similar to Photoshop's)\n\nUltimate CSS Gradient Generator\n\nThe \"Webpage Color Analyzer\" site helps you determine the palette of colors used in a particular website.\n\nPalette Viewer with 7 pre-installed palettes\n\nEyedropper - sample the color of any pixel on the page\n\nColor History of recently picked colors\n\nDisplays some info about the element, including the tag name, class, id and size.\n\nAuto copy picked colors to clipboard\n\nGet colors of dynamic hover elements\n\nPick colors from Flash objects\n\nPick colors at any zoom level\n\n\n\n\n\n\n\n6. Honey\n\nHoney is a chrome extension with which you save each product from the website and notify it when it is available at low price it's one among the highest extensions for Chrome that finds coupon codes whenever you look online.\n\nFeatures\n\nBest for finding exclusive prices on Amazon.\n\nA free reward program called Honey Gold.\n\nSearches and filters the simplest value fitting your demand.\n\nInstant notifications.\n\n\n\n\n\n7. GMass: Powerful Chrome Extension for Gmail Marketers\n\nGMass (or Gmail Mass) permits users to compose and send mass emails using Gmail. it is a great tool as a result of you'll use it as a replacement for a third-party email sending platform. you will love GMass to spice up your emailing functionality on the platform.\n\n\n\n\n\n8. Notion Web Clipper: Chrome Extension for Geeks\n\nIt's a Chrome extension for geeks that enables you to highlight and save what you see on the web.\n\nIt's been designed by Notion, that could be a Google space different that helps groups craft higher ideas and collaborate effectively.\n\nFeatures\n\nSave anything online with just one click\n\nUse it on any device\n\nOrganize your saved clips quickly\n\nTag, share and comment on the clips\n\nIf you are someone who works online, you need to surf the internet to get your business done. And often there is no time to read or analyze something. But it's important that you do it. Notion Web Clipper will help you with that.\n\n9. WhatFont: Chrome Extension for identifying Any Site Fonts\n\nWhatFont is a Chrome extension that allows web designers to easily identify and compare different fonts on a page. The first time you use it on any page, WhatFont will copy the selected page.It Uses this page to find out what fonts are present and generate an image that shows all those fonts in different sizes. Besides the apparent websites like Google or Amazon, you'll conjointly use it on sites wherever embedded fonts ar used.\n\n10. SimilarWeb: Traffic Rank & Website Analysis Extension\n\nSimilar Web is an SEO add on for both Chrome and Firefox.It allows you to check web site traffic and key metrics for any web site, as well as engagement rate, traffic ranking, keyword ranking, and traffic source. this is often a good tool if you are looking to seek out new and effective SEO ways similarly as analyze trends across the web.\n\nFeatures\n\nDiscover keyword trends\n\nKnow fresh keywords\n\nGet benefit from the real traffic insights\n\nAnalyze engagement metrics\n\nExplore unique visitors data\n\nAnalyze your industry's category\n\nUse month to date data\n\n\n\n\n\nHow to Install chrome Extension in Android\n\nI know everyone knows how to install extension in pc but most of people don't know how to install it in android phone so i will show you how to install it in android\n\n1. Download Kiwi browser from Play Store and then Open it.\n\n\n\n\n\nAdvertisement\n\nContinue reading below\n\n\n\n\n\n\n\n\n\n\n\n2. Tap the three dots at the top right corner and select Extension.\n\n\n\n\n\n\n\n\n\n3. Click on (+From Store) to access chrome web store or simple search chrome web store and access it.\n\n\n\n\n\n4. Once you found an extension click on add to chrome a message will pop-up asking if you wish to confirm your choice. Hit OK to install the extension in the Kiwi browser.\n\n\n\n\n\n5. To manage extensions on the browser, tap the three dots in the upper right corner. Then select Extensions to access a catalog of installed extensions that you can disable, update or remove with just a few clicks.\n\n\n\n\n\nYour Chrome extensions should install on Android, but there’s no guarantee all of them will work. Because Google Chrome Extensions are not optimized for Android devices.\n\n\n\n\n\nFinal Saying\n\nWe hope this list of 10 best chrome extensions that is perfect for everyone will help you in picking the right Chrome Extensions. We have selected the extensions after matching their features to the needs of different categories of people. Also which extension you like the most let me know in the comment section",
         "2022-01-31T10:56:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/01/10-best-chrome-extensions-that-are.html",
         "2025-07-26T05:41:35.930678",
         "Are you a great Chrome user? That’s nice to hear. But first, consider whether or not there are any essential Chrome extensions you are currently missing from your browsing life, so here we're going to share with you 10 Best Chrome Extensions That Are Perfect for Everyone. So Let's Start. 1. LastPass When you have too several passwords to remember, LastPass remembers them for you. This chrome extension is an easy way to save you time and increase security. It’s a single password manager that will log you into all of your accounts. you simply ought to bear in mind one word: your LastPass password to log in to all or any your accounts. Features Save usernames and passwords and LastPasswill log you in automatically. Fill the forms quickly to save your addresses, credit card numbers and more. 2. MozBar MozBar is an SEO toolbar extension that makes it easy for you to analyze your web pages' SEO while you surf. You can customize your search so that you see data for a particular region or for all regions. You get data such as website and domain authority and link profile. The status column tells you whether there are any no-followed links to the page.You can also compare link metrics. There is a pro version of MozBar, too. 3. Grammerly Grammarly is a real-time grammar checking and spelling tool for online writing. It checks spelling, grammar, and punctuation as you type, and has a dictionary feature that suggests related words. if you use mobile phones for writing than Grammerly also have a mobile keyboard app. 4. VidlQ VidIQ is a SaaS product and Chrome Extension that makes it easier to manage and optimize your YouTube channels. It keeps you informed about your channel's performance with real-time analytics and powerful insights. Features Learn more about insights and statistics beyond YouTube Analytics Find great videos with the Trending tab. You can check out any video’s YouTube rankings and see how your own video is doing on the charts. Keep track the history of the keyword to determine when a keyword is rising or down in popularity over time. Quickly find out which videos are performing the best on YouTube right now. Let this tool suggest keywords for you to use in your title, description and tags. 5. ColorZilla ColorZilla is a browser extension that allows you to find out the exact color of any object in your web browser. This is especially useful when you want to match elements on your page to the color of an image. Features Advanced Color Picker (similar to Photoshop's) Ultimate CSS Gradient Generator The \"Webpage Color Analyzer\" site helps you determine the palette of colors used in a particular website. Palette Viewer with 7 pre-installed palettes Eyedropper - sample the color of any pixel on the page Color History of recently picked colors Displays some info about the element, including the tag name, class, id and size. Auto copy picked colors to clipboard Get colors of dynamic hover elements Pick colors from Flash objects Pick colors at any zoom level 6. Honey Honey is a chrome extension with which you save each product from the website and notify it when it is available at low price it's one among the highest extensions for Chrome that finds coupon codes whenever you look online. Features Best for finding exclusive prices on Amazon. A free reward program called Honey Gold. Searches and filters the simplest value fitting your demand. Instant notifications. 7. GMass: Powerful Chrome Extension for Gmail Marketers GMass (or Gmail Mass) permits users to compose and send mass emails using Gmail. it is a great tool as a result of you'll use it as a replacement for a third-party email sending platform. you will love GMass to spice up your emailing functionality on the platform. 8. Notion Web Clipper: Chrome Extension for Geeks It's a Chrome extension for geeks that enables you to highlight and save what you see on the web. It's been designed by Notion, that could be a Google space different that helps groups craft higher ideas and collaborate effectively. Features Save anything online with just one click Use it on any device Organize your saved clips quickly Tag, share and comment on the clips If you are someone who works online, you need to surf the internet to get your business done. And often there is no time to read or analyze something. But it's important that you do it. Notion Web Clipper will help you with that. 9. WhatFont: Chrome Extension for identifying Any Site Fonts WhatFont is a Chrome extension that allows web designers to easily identify and compare different fonts on a page. The first time you use it on any page, WhatFont will copy the selected page.It Uses this page to find out what fonts are present and generate an image that shows all those fonts in different sizes. Besides the apparent websites like Google or Amazon, you'll conjointly use it on sites wherever embedded fonts ar used. 10. SimilarWeb: Traffic Rank & Website Analysis Extension Similar Web is an SEO add on for both Chrome and Firefox.It allows you to check web site traffic and key metrics for any web site, as well as engagement rate, traffic ranking, keyword ranking, and traffic source. this is often a good tool if you are looking to seek out new and effective SEO ways similarly as analyze trends across the web. Features Discover keyword trends Know fresh keywords Get benefit from the real traffic insights Analyze engagement metrics Explore unique visitors data Analyze your industry's category Use month to date data How to Install chrome Extension in Android I know everyone knows how to install extension in pc but most of people don't know how to install it in android phone so i will show you how to install it in android 1. Download Kiwi browser from Play Store and then Open it. Advertisement Continue reading below 2. Tap the three dots at the top right corner and select Extension. 3. Click on (+From Store) to access chrome web store or simple search chrome web store and access it. 4. Once you found an extension click on add to chrome a message will pop-up asking if you wish to confirm your choice. Hit OK to install the extension in the Kiwi browser. 5. To manage extensions on the browser, tap the three dots in the upper right corner. Then select Extensions to access a catalog of installed extensions that you can disable, update or remove with just a few clicks. Your Chrome extensions should install on Android, but there’s no guarantee all of them will work. Because Google Chrome Extensions are not optimized for Android devices. Final Saying We hope this list of 10 best chrome extensions that is perfect for everyone will help you in picking the right Chrome Extensions. We have selected the extensions after matching their features to the needs of different categories of people. Also which extension you like the most let me know in the comment section",
         "en",
         "{'MISC': ['Advertisement Continue reading below 2', 'Also which extension you like the most let me know in the', 'Analytics Find great videos with the Trending tab', 'And often there is no time to read or analyze something.', 'Android', 'Are you a great', 'Best for finding', 'Chrome', 'Chrome Extension for identifying', 'Chrome extension for geeks that enables you to highlight and save what you see on the web', 'Click', 'Color History of recently picked', 'Displays some', 'Download Kiwi browser from Play Store and then', \"Explore unique visitors data Analyze your industry's category Use month to\", 'Extension in Android I know everyone knows how to', 'Features Save usernames', 'Fill the forms quickly to save your addresses', 'Final Saying We hope this list of 10 best chrome', 'Flash objects', 'From Store', 'GMass', 'Gmail Mass', 'Google Chrome', 'Hit OK to install the extension in the Kiwi browser', 'Honey Honey is', 'How to Install chrome', 'If you are someone who works online', 'It Uses this page to find out what fonts are present and generate an', 'It allows you to check web site', 'It checks spelling', 'It keeps', \"It's been designed by\", 'It’', 'Keep track the history of the keyword to determine when', 'LastPass When you have too several passwords to remember', 'LastPass remembers them for you', 'MozBar', 'MozBar is an SEO toolbar', 'Once you found an', 'Palette Viewer with 7 pre', 'Pick colors from', 'Powerful Chrome Extension for Gmail Marketers GMass', 'Quickly find out which videos are performing the best on', 'SaaS', 'Searches and filters the simplest', 'SimilarWeb', \"So Let's Start\", 'Tap the three dots at the top right corner and select Extension', 'That’s nice to hear', 'The first time you use it on any page', 'Then select', 'There is a pro version of', 'Traffic Rank & Website Analysis', 'Ultimate CSS', 'Use it on any device Organize', 'VidIQ is a', 'We have selected the extensions after matching their features to the needs of different categories of people', 'Web Clipper', 'Web Clipper will help you with that', 'Webpage Color', 'WhatFont', 'WhatFont will copy the selected page', 'You can', 'You can also', 'You get data such as website and domain authority and link', 'YouTube', 'YouTube rankings and see how', 'YouTube right now', 'Your Chrome extensions should install on Android', 'and has', 'and punctuation as you', 'app', 'including the tag name', 'pc', 'replacement for a third-party email sending platform', 'so i will show you how to install it in android 1', 'tap the three dots in the upper right corner', 'that is perfect for everyone will help you in picking the right Chrome', 'this is often a good tool if you are looking to seek out new and effective SEO ways similarly as analyze trends across the web', 'too', 'update or remove with', 'websites like Google', 'whether or not there are any essential', \"with which you save each product from the website and notify it when it is available at low price it's one among the highest extensions for Chrome that finds coupon codes whenever you look online\", 'you need to surf the internet to get your business done', 'you simply ought to bear in mind one word: your LastPass password to log in to all or any your accounts', 'you will love GMass to spice up your emailing functionality on the platform', \"you'll conjointly\"], 'PER': ['VidlQ', 'if you'], 'ORG': ['Amazon', 'ColorZilla', 'Features', 'Google', 'class', 'id and size'], 'LOC': ['Eyedropper']}",
         "[-0.03727607801556587, -0.056857477873563766, -0.030685124918818474, -0.009936247952282429, 0.039580971002578735, 0.060419660061597824, -0.020015651360154152, 0.003024490550160408, -0.06124584749341011, -0.08444919437170029, -0.0308788251131773, 0.013099155388772488, 0.07736386358737946, -0.07474935799837112, -0.010993835516273975, 0.05512600392103195, -0.037683725357055664, 0.017912467941641808, -0.05924256145954132, -0.05712515860795975, -0.02790304832160473, -0.0831710696220398, 0.01835625432431698, 0.0008781789802014828, -0.1051928773522377, 0.06679221242666245, -0.002837446052581072, -0.037994034588336945, -0.0010601207613945007, -0.05817174166440964, 0.04773610085248947, -0.034612808376550674, 0.052228279411792755, 0.009084558114409447, -0.04816716909408569, -0.07556899636983871, -0.04687044769525528, 0.04349275678396225, -0.04692836105823517, -0.006720077712088823, -0.06429196894168854, 0.04426882043480873, -0.07235749810934067, 0.04465664550662041, 0.019349712878465652, -0.010702709667384624, -0.0058724042028188705, -0.009123328141868114, 0.059049446135759354, 0.0061086127534508705, 0.09563334286212921, -0.01921854168176651, -0.02537061646580696, 0.0012940732995048165, -0.09175826609134674, 0.018765268847346306, -0.030049368739128113, -0.08725756406784058, 0.012792094610631466, -0.016551554203033447, -0.016366658732295036, -0.00040239791269414127, 0.012584340758621693, 0.0325312539935112, -0.011457913555204868, 0.03326314687728882, -0.006232252810150385, -0.015322570689022541, 0.02522709220647812, 0.025802602991461754, -0.08745463937520981, 0.020485641434788704, -0.0868135392665863, 0.0538492426276207, -0.003167315386235714, -0.06152842566370964, 0.05109797418117523, -0.045936014503240585, 0.04449861869215965, 0.06764306873083115, -0.04457756131887436, -0.06140553578734398, -0.05584641546010971, 0.03170876204967499, 0.10593792051076889, -0.014738218858838081, -0.05824698880314827, -0.014736468903720379, 0.027584590017795563, -0.024785973131656647, 0.030635183677077293, -0.03216737508773804, 0.005023706238716841, -0.014125976711511612, 0.0171465165913105, 0.028747549280524254, 0.03267081826925278, 0.025894396007061005, -0.03514504060149193, 0.026094146072864532, 0.10274911671876907, -0.012347903102636337, 0.055664654821157455, -0.06997592747211456, 0.09205348789691925, 0.033627141267061234, 0.11524619907140732, 0.09437648206949234, 0.03709154203534126, 0.08701517432928085, 0.002688569249585271, 0.023483894765377045, -0.02115902304649353, 0.007641531992703676, -0.016750575974583626, 0.010718267410993576, -0.035618629306554794, 0.04411125183105469, 0.06568074226379395, 0.10765340924263, -0.019991526380181313, 0.12714014947414398, 0.013423953205347061, -0.04356531798839569, 0.0240258127450943, 0.013458016328513622, -0.04281540960073471, 3.0757777635394658e-33, 0.00407338747754693, 0.004417893011122942, -0.0864025428891182, 0.018653426319360733, -0.057431645691394806, -0.0015616113087162375, 0.015751834958791733, 0.026386912912130356, -0.07440333813428879, 0.0474851094186306, 0.05666740611195564, 0.10009375214576721, -0.04949173703789711, -0.016933228820562363, 0.03967711329460144, 0.004089714959263802, -0.03683222830295563, 0.0030406855512410402, 0.04041759669780731, -0.023285426199436188, 0.0012580212205648422, -0.008896468207240105, 0.04511893168091774, 0.003102685557678342, 0.08751702308654785, -0.03838418424129486, -0.0012941869208589196, 0.040424443781375885, -0.13266324996948242, 0.01649506576359272, -0.06252053380012512, -0.03922920301556587, -0.039237186312675476, 0.010696040466427803, -0.003803319064900279, 0.03493345528841019, -0.012221554294228554, -0.04141959175467491, -0.016541553661227226, -0.09208063781261444, -0.08534877747297287, -0.078252874314785, -0.06297742575407028, -0.053212132304906845, -0.048731837421655655, -0.03665969520807266, 0.03338027000427246, 0.061066143214702606, 0.03725798800587654, 0.0734410509467125, -0.09056735783815384, -0.03297915309667587, -0.12224706262350082, 0.003092782571911812, -0.11955689638853073, 0.0032638302072882652, -0.07637614011764526, -0.012151376344263554, -0.0002812976890709251, -0.09366156160831451, 0.007040935102850199, -0.04609984531998634, -0.056630488485097885, 0.04689602181315422, -0.033325400203466415, -0.08993151783943176, 0.033458806574344635, 0.06705759465694427, 0.018495682626962662, 0.018428189679980278, -0.016489285975694656, -0.05130447819828987, 0.013338582590222359, 0.03779911994934082, -0.03312930837273598, 0.0032913610339164734, 0.029533203691244125, 0.017807263880968094, -0.015895994380116463, 0.096385158598423, 0.11369427293539047, -0.006427546963095665, -0.03472195193171501, 0.06508512049913406, 0.048695024102926254, 0.024482540786266327, 0.13310843706130981, -0.07613588869571686, -0.09644967317581177, 0.010670998133718967, 0.018442688509821892, -0.026658920571208, 0.054314155131578445, -0.0712810754776001, -0.07334386557340622, -4.688800111616432e-33, -0.04693843424320221, -0.030846603214740753, 0.07823669910430908, -0.02129613421857357, 0.0016515221213921905, 0.01191285066306591, -0.0018759742379188538, 0.007680380251258612, -0.06206371635198593, -0.08722150325775146, -0.03151654452085495, 0.009335869923233986, 0.03030364215373993, 0.011828516609966755, -0.028907310217618942, 0.12608171999454498, -0.020742451772093773, -0.027585769072175026, -0.041132353246212006, -0.06965824961662292, -0.06136341020464897, 0.04202433302998543, -0.07367098331451416, -0.0006976363365538418, -0.028290458023548126, 0.030291125178337097, -0.056195035576820374, 0.04669550433754921, 0.003485325491055846, 0.04668223112821579, 0.0027416131924837828, 0.007282276172190905, 0.024805160239338875, 0.029823586344718933, 0.0017979447729885578, -0.017926618456840515, 0.07419025897979736, 0.10750629752874374, 0.013421816751360893, 0.026622958481311798, 0.02003394067287445, 0.027585899457335472, 0.07662146538496017, -0.06721381843090057, -0.012065881863236427, 0.07072802633047104, -0.04271026700735092, 0.011412149295210838, -0.10103095322847366, 0.04628457874059677, -0.00271833804436028, -0.008738047443330288, -0.022821296006441116, -0.02676446922123432, 0.01725628226995468, 0.012688916176557541, -0.023427579551935196, -0.005576749332249165, 0.022816067561507225, -0.05855565890669823, -0.07732106000185013, 0.03914599493145943, 0.00419453252106905, 0.04662305861711502, -0.039045121520757675, -0.012001979164779186, 0.043853774666786194, 0.05084087327122688, -0.08054598420858383, 0.033918607980012894, -0.0905311182141304, 0.03400788828730583, 0.049005646258592606, -0.07091016322374344, 0.008511478081345558, -0.027486171573400497, 0.03797163441777229, -0.023756083101034164, -0.07635703682899475, -0.049419648945331573, 0.046070389449596405, 0.008859645575284958, 0.015080543234944344, -0.04952387884259224, -0.010279392823576927, -0.049196451902389526, -0.02431710809469223, 0.053669944405555725, 0.08509647846221924, 0.02296026423573494, -0.06176619976758957, 0.0703071728348732, -0.15952976047992706, 0.03347349539399147, 0.01504958514124155, -4.7859739282785085e-08, 0.03371576592326164, 0.013297065161168575, -0.03561985865235329, 0.045943208038806915, 0.045492254197597504, 0.04208968207240105, -0.05813039466738701, 0.043833643198013306, -0.04303199425339699, -0.027951566502451897, 0.09828347712755203, 0.0256439708173275, -0.03220106288790703, 0.0006228015408851206, -0.019294271245598793, 0.05085226893424988, 0.01977694220840931, -0.06522916257381439, 0.03927517309784889, -0.05271528288722038, -0.057229869067668915, -0.00477268360555172, 0.03555021807551384, 0.05173969268798828, 0.09495289623737335, 0.08679457008838654, -0.011223696172237396, 0.0656185895204544, 0.03395331650972366, 0.02232229709625244, -0.030930444598197937, 0.048742156475782394, -0.061893563717603683, -0.09264396876096725, -0.04718370735645294, -0.013918220065534115, 0.006963611580431461, -0.1197730228304863, -0.06480906903743744, 0.066018246114254, 0.0700405016541481, 0.06225607916712761, 0.0517447367310524, 0.04482650384306908, -0.07241012901067734, -0.01886850968003273, 0.002818084554746747, 0.001744252280332148, 0.12563319504261017, 0.028384502977132797, -0.026610393077135086, 0.0029390195850282907, 0.08377254009246826, 0.08347686380147934, 0.004805568605661392, 0.024139437824487686, 0.003493431955575943, 0.010077339597046375, 0.040165066719055176, 0.03047053888440132, 0.022166719660162926, 0.05311432108283043, -0.014459764584898949, -0.0059088063426315784]",
         "0.206"
        ],
        [
         "28",
         "38",
         "Most Frequently Asked Questions About NFTs(Non-Fungible Tokens)",
         "Non-fungible tokens (NFTs) are the most popular digital assets today, capturing the attention of cryptocurrency investors, whales and people from around the world. People find it amazing that some users spend thousands or millions of dollars on a single NFT-based image of a monkey or other token, but you can simply take a screenshot for free. So here we share some freuently asked question about NFTs. 1) What is an NFT? NFT stands for non-fungible token, which is a cryptographic token on a blockchain with unique identification codes that distinguish it from other tokens. NFTs are unique and not interchangeable, which means no two NFTs are the same. NFTs can be a unique artwork, GIF, Images, videos, Audio album. in-game items, collectibles etc. 2) What is Blockchain? A blockchain is a distributed digital ledger that allows for the secure storage of data. By recording any kind of information—such as bank account transactions, the ownership of Non-Fungible Tokens (NFTs), or Decentralized Finance (DeFi) smart contracts—in one place, and distributing it to many different computers, blockchains ensure that data can’t be manipulated without everyone in the system being aware. 3) What makes an NFT valuable? The value of an NFT comes from its ability to be traded freely and securely on the blockchain, which is not possible with other current digital ownership solutionsThe NFT points to its location on the blockchain, but doesn’t necessarily contain the digital property. For example, if you replace one bitcoin with another, you will still have the same thing. If you buy a non-fungible item, such as a movie ticket, it is impossible to replace it with any other movie ticket because each ticket is unique to a specific time and place. 4) How do NFTs work? One of the unique characteristics of non-fungible tokens (NFTs) is that they can be tokenised to create a digital certificate of ownership that can be bought, sold and traded on the blockchain. As with crypto-currency, records of who owns what are stored on a ledger that is maintained by thousands of computers around the world. These records can’t be forged because the whole system operates on an open-source network. NFTs also contain smart contracts—small computer programs that run on the blockchain—that give the artist, for example, a cut of any future sale of the token. 5) What’s the connection between NFTs and cryptocurrency? Non-fungible tokens (NFTs) aren't cryptocurrencies, but they do use blockchain technology. Many NFTs are based on Ethereum, where the blockchain serves as a ledger for all the transactions related to said NFT and the properties it represents.5) How to make an NFT? Anyone can create an NFT. All you need is a digital wallet, some ethereum tokens and a connection to an NFT marketplace where you’ll be able to upload and sell your creations 6) How to validate the authencity of an NFT? When you purchase a stock in NFT, that purchase is recorded on the blockchain—the bitcoin ledger of transactions—and that entry acts as your proof of ownership. 7) How is an NFT valued? What are the most expensive NFTs? The value of an NFT varies a lot based on the digital asset up for grabs. People use NFTs to trade and sell digital art, so when creating an NFT, you should consider the popularity of your digital artwork along with historical statistics. In the year 2021, a digital artist called Pak created an artwork called The Merge. It was sold on the Nifty Gateway NFT market for $91.8 million. 8) Can NFTs be used as an investment? Non-fungible tokens can be used in investment opportunities. One can purchase an NFT and resell it at a profit. Certain NFT marketplaces let sellers of NFTs keep a percentage of the profits from sales of the assets they create. 9) Will NFTs be the future of art and collectibles? Many people want to buy NFTs because it lets them support the arts and own something cool from their favorite musicians, brands, and celebrities. NFTs also give artists an opportunity to program in continual royalties if someone buys their work. Galleries see this as a way to reach new buyers interested in art. 10) How do we buy an NFTs? There are many places to buy digital assets, like opensea and their policies vary. On top shot, for instance, you sign up for a waitlist that can be thousands of people long. When a digital asset goes on sale, you are occasionally chosen to purchase it. 11) Can i mint NFT for free? To mint an NFT token, you must pay some amount of gas fee to process the transaction on the Etherum blockchain, but you can mint your NFT on a different blockchain called Polygon to avoid paying gas fees. This option is available on OpenSea and this simply denotes that your NFT will only be able to trade using Polygon's blockchain and not Etherum's blockchain. Mintable allows you to mint NFTs for free without paying any gas fees. 12) Do i own an NFT if i screenshot it? The answer is no. Non-Fungible Tokens are minted on the blockchain using cryptocurrencies such as Etherum, Solana, Polygon, and so on. Once a Non-Fungible Token is minted, the transaction is recorded on the blockchain and the contract or license is awarded to whoever has that Non-Fungible Token in their wallet. 12) Why are people investing so much in NFT? Non-fungible tokens have gained the hearts of people around the world, and they have given digital creators the recognition they deserve. One of the remarkable things about non-fungible tokens is that you can take a screenshot of one, but you don’t own it. This is because when a non-fungible token is created, then the transaction is stored on the blockchain, and the license or contract to hold such a token is awarded to the person owning the token in their digital wallet. You can sell your work and creations by attaching a license to it on the blockchain, where its ownership can be transferred. This lets you get exposure without losing full ownership of your work. Some of the most successful projects include Cryptopunks, Bored Ape Yatch Club NFTs, SandBox, World of Women and so on. These NFT projects have gained popularity globally and are owned by celebrities and other successful entrepreneurs. Owning one of these NFTs gives you an automatic ticket to exclusive business meetings and life-changing connections. Final Saying That’s a wrap. Hope you guys found this article enlightening. I just answer some question with my limited knowledge about NFTs. If you have any questions or suggestions, feel free to drop them in the comment section below. Also I have a question for you, Is bitcoin an NFTs? let me know in The comment section below",
         "Non-fungible tokens (NFTs) are the most popular digital assets today, capturing the attention of cryptocurrency investors, whales and people from around the world. People find it amazing that some users spend thousands or millions of dollars on a single NFT-based image of a monkey or other token, but you can simply take a screenshot for free. So here we share some freuently asked question about NFTs.\n\n1) What is an NFT?\n\nNFT stands for non-fungible token, which is a cryptographic token on a blockchain with unique identification codes that distinguish it from other tokens. NFTs are unique and not interchangeable, which means no two NFTs are the same. NFTs can be a unique artwork, GIF, Images, videos, Audio album. in-game items, collectibles etc.\n\n2) What is Blockchain?\n\nA blockchain is a distributed digital ledger that allows for the secure storage of data. By recording any kind of information—such as bank account transactions, the ownership of Non-Fungible Tokens (NFTs), or Decentralized Finance (DeFi) smart contracts—in one place, and distributing it to many different computers, blockchains ensure that data can’t be manipulated without everyone in the system being aware.\n\n3) What makes an NFT valuable?\n\n\n\n\n\nThe value of an NFT comes from its ability to be traded freely and securely on the blockchain, which is not possible with other current digital ownership solutionsThe NFT points to its location on the blockchain, but doesn’t necessarily contain the digital property. For example, if you replace one bitcoin with another, you will still have the same thing. If you buy a non-fungible item, such as a movie ticket, it is impossible to replace it with any other movie ticket because each ticket is unique to a specific time and place.\n\n4) How do NFTs work?\n\nOne of the unique characteristics of non-fungible tokens (NFTs) is that they can be tokenised to create a digital certificate of ownership that can be bought, sold and traded on the blockchain.\n\nAs with crypto-currency, records of who owns what are stored on a ledger that is maintained by thousands of computers around the world. These records can’t be forged because the whole system operates on an open-source network.\n\nNFTs also contain smart contracts—small computer programs that run on the blockchain—that give the artist, for example, a cut of any future sale of the token.\n\n5) What’s the connection between NFTs and cryptocurrency?\n\nNon-fungible tokens (NFTs) aren't cryptocurrencies, but they do use blockchain technology. Many NFTs are based on Ethereum, where the blockchain serves as a ledger for all the transactions related to said NFT and the properties it represents.5) How to make an NFT?\n\nAnyone can create an NFT. All you need is a digital wallet, some ethereum tokens and a connection to an NFT marketplace where you’ll be able to upload and sell your creations\n\n6) How to validate the authencity of an NFT?\n\nWhen you purchase a stock in NFT, that purchase is recorded on the blockchain—the bitcoin ledger of transactions—and that entry acts as your proof of ownership.\n\n7) How is an NFT valued? What are the most expensive NFTs?\n\nThe value of an NFT varies a lot based on the digital asset up for grabs. People use NFTs to trade and sell digital art, so when creating an NFT, you should consider the popularity of your digital artwork along with historical statistics.\n\nIn the year 2021, a digital artist called Pak created an artwork called The Merge. It was sold on the Nifty Gateway NFT market for $91.8 million.\n\n8) Can NFTs be used as an investment?\n\nNon-fungible tokens can be used in investment opportunities. One can purchase an NFT and resell it at a profit. Certain NFT marketplaces let sellers of NFTs keep a percentage of the profits from sales of the assets they create.\n\n9) Will NFTs be the future of art and collectibles?\n\nMany people want to buy NFTs because it lets them support the arts and own something cool from their favorite musicians, brands, and celebrities. NFTs also give artists an opportunity to program in continual royalties if someone buys their work. Galleries see this as a way to reach new buyers interested in art.\n\n10) How do we buy an NFTs?\n\nThere are many places to buy digital assets, like opensea and their policies vary. On top shot, for instance, you sign up for a waitlist that can be thousands of people long. When a digital asset goes on sale, you are occasionally chosen to purchase it.\n\n11) Can i mint NFT for free?\n\nTo mint an NFT token, you must pay some amount of gas fee to process the transaction on the Etherum blockchain, but you can mint your NFT on a different blockchain called Polygon to avoid paying gas fees. This option is available on OpenSea and this simply denotes that your NFT will only be able to trade using Polygon's blockchain and not Etherum's blockchain. Mintable allows you to mint NFTs for free without paying any gas fees.\n\n12) Do i own an NFT if i screenshot it?\n\nThe answer is no. Non-Fungible Tokens are minted on the blockchain using cryptocurrencies such as Etherum, Solana, Polygon, and so on. Once a Non-Fungible Token is minted, the transaction is recorded on the blockchain and the contract or license is awarded to whoever has that Non-Fungible Token in their wallet.\n\n12) Why are people investing so much in NFT?\n\n\n\nNon-fungible tokens have gained the hearts of people around the world, and they have given digital creators the recognition they deserve. One of the remarkable things about non-fungible tokens is that you can take a screenshot of one, but you don’t own it. This is because when a non-fungible token is created, then the transaction is stored on the blockchain, and the license or contract to hold such a token is awarded to the person owning the token in their digital wallet.\n\n\n\nYou can sell your work and creations by attaching a license to it on the blockchain, where its ownership can be transferred. This lets you get exposure without losing full ownership of your work. Some of the most successful projects include Cryptopunks, Bored Ape Yatch Club NFTs, SandBox, World of Women and so on. These NFT projects have gained popularity globally and are owned by celebrities and other successful entrepreneurs. Owning one of these NFTs gives you an automatic ticket to exclusive business meetings and life-changing connections.\n\nFinal Saying\n\nThat’s a wrap. Hope you guys found this article enlightening. I just answer some question with my limited knowledge about NFTs. If you have any questions or suggestions, feel free to drop them in the comment section below. Also I have a question for you, Is bitcoin an NFTs? let me know in The comment section below",
         "2022-02-06T10:04:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/02/most-frequently-asked-questions-about.html",
         "2025-07-26T05:41:35.919852",
         "Non-fungible tokens (NFTs) are the most popular digital assets today, capturing the attention of cryptocurrency investors, whales and people from around the world. People find it amazing that some users spend thousands or millions of dollars on a single NFT-based image of a monkey or other token, but you can simply take a screenshot for free. So here we share some freuently asked question about NFTs. 1) What is an NFT? NFT stands for non-fungible token, which is a cryptographic token on a blockchain with unique identification codes that distinguish it from other tokens. NFTs are unique and not interchangeable, which means no two NFTs are the same. NFTs can be a unique artwork, GIF, Images, videos, Audio album. in-game items, collectibles etc. 2) What is Blockchain? A blockchain is a distributed digital ledger that allows for the secure storage of data. By recording any kind of information—such as bank account transactions, the ownership of Non-Fungible Tokens (NFTs), or Decentralized Finance (DeFi) smart contracts—in one place, and distributing it to many different computers, blockchains ensure that data can’t be manipulated without everyone in the system being aware. 3) What makes an NFT valuable? The value of an NFT comes from its ability to be traded freely and securely on the blockchain, which is not possible with other current digital ownership solutionsThe NFT points to its location on the blockchain, but doesn’t necessarily contain the digital property. For example, if you replace one bitcoin with another, you will still have the same thing. If you buy a non-fungible item, such as a movie ticket, it is impossible to replace it with any other movie ticket because each ticket is unique to a specific time and place. 4) How do NFTs work? One of the unique characteristics of non-fungible tokens (NFTs) is that they can be tokenised to create a digital certificate of ownership that can be bought, sold and traded on the blockchain. As with crypto-currency, records of who owns what are stored on a ledger that is maintained by thousands of computers around the world. These records can’t be forged because the whole system operates on an open-source network. NFTs also contain smart contracts—small computer programs that run on the blockchain—that give the artist, for example, a cut of any future sale of the token. 5) What’s the connection between NFTs and cryptocurrency? Non-fungible tokens (NFTs) aren't cryptocurrencies, but they do use blockchain technology. Many NFTs are based on Ethereum, where the blockchain serves as a ledger for all the transactions related to said NFT and the properties it represents.5) How to make an NFT? Anyone can create an NFT. All you need is a digital wallet, some ethereum tokens and a connection to an NFT marketplace where you’ll be able to upload and sell your creations 6) How to validate the authencity of an NFT? When you purchase a stock in NFT, that purchase is recorded on the blockchain—the bitcoin ledger of transactions—and that entry acts as your proof of ownership. 7) How is an NFT valued? What are the most expensive NFTs? The value of an NFT varies a lot based on the digital asset up for grabs. People use NFTs to trade and sell digital art, so when creating an NFT, you should consider the popularity of your digital artwork along with historical statistics. In the year 2021, a digital artist called Pak created an artwork called The Merge. It was sold on the Nifty Gateway NFT market for $91.8 million. 8) Can NFTs be used as an investment? Non-fungible tokens can be used in investment opportunities. One can purchase an NFT and resell it at a profit. Certain NFT marketplaces let sellers of NFTs keep a percentage of the profits from sales of the assets they create. 9) Will NFTs be the future of art and collectibles? Many people want to buy NFTs because it lets them support the arts and own something cool from their favorite musicians, brands, and celebrities. NFTs also give artists an opportunity to program in continual royalties if someone buys their work. Galleries see this as a way to reach new buyers interested in art. 10) How do we buy an NFTs? There are many places to buy digital assets, like opensea and their policies vary. On top shot, for instance, you sign up for a waitlist that can be thousands of people long. When a digital asset goes on sale, you are occasionally chosen to purchase it. 11) Can i mint NFT for free? To mint an NFT token, you must pay some amount of gas fee to process the transaction on the Etherum blockchain, but you can mint your NFT on a different blockchain called Polygon to avoid paying gas fees. This option is available on OpenSea and this simply denotes that your NFT will only be able to trade using Polygon's blockchain and not Etherum's blockchain. Mintable allows you to mint NFTs for free without paying any gas fees. 12) Do i own an NFT if i screenshot it? The answer is no. Non-Fungible Tokens are minted on the blockchain using cryptocurrencies such as Etherum, Solana, Polygon, and so on. Once a Non-Fungible Token is minted, the transaction is recorded on the blockchain and the contract or license is awarded to whoever has that Non-Fungible Token in their wallet. 12) Why are people investing so much in NFT? Non-fungible tokens have gained the hearts of people around the world, and they have given digital creators the recognition they deserve. One of the remarkable things about non-fungible tokens is that you can take a screenshot of one, but you don’t own it. This is because when a non-fungible token is created, then the transaction is stored on the blockchain, and the license or contract to hold such a token is awarded to the person owning the token in their digital wallet. You can sell your work and creations by attaching a license to it on the blockchain, where its ownership can be transferred. This lets you get exposure without losing full ownership of your work. Some of the most successful projects include Cryptopunks, Bored Ape Yatch Club NFTs, SandBox, World of Women and so on. These NFT projects have gained popularity globally and are owned by celebrities and other successful entrepreneurs. Owning one of these NFTs gives you an automatic ticket to exclusive business meetings and life-changing connections. Final Saying That’s a wrap. Hope you guys found this article enlightening. I just answer some question with my limited knowledge about NFTs. If you have any questions or suggestions, feel free to drop them in the comment section below. Also I have a question for you, Is bitcoin an NFTs? let me know in The comment section below",
         "en",
         "{'MISC': ['8) Can', 'All you need is', 'Also I', 'Anyone can create an NFT', 'As with crypto-currency', 'Audio album', 'Bored Ape Yatch Club NFTs', 'By recording any kind of information—such as bank account transactions', 'Can i', 'Decentralized Finance', 'Final Saying That’s a wrap', 'GIF', 'Galleries see this as a way to reach new buyers interested in art', 'Hope you guys found this article enlightening', 'How do NFTs work?', 'How do we buy an NFTs?', 'How is an NFT valued', 'How to make an NFT', 'How to validate the authencity of an NFT', 'If you buy', 'If you have any questions or suggestions', 'Images', 'Is bitcoin an NFTs', 'It was sold on the Nifty', 'Many people want to buy NFTs', 'Mintable allows you to mint NFTs', 'NFTs', 'NFTs to trade and sell digital art', 'NFTs)', \"NFTs) aren't cryptocurrencies\", 'NFTs) is that they can be tokenised to create', 'Non-Fungible Token is minted', 'One can purchase an NFT and resell', 'One of the', 'One of the remarkable things about non-fungible tokens is that you can take', 'OpenSea and this', 'Owning one of these NFTs', 'People', 'People find it amazing that some users', 'Polygon to avoid paying gas fees', 'SandBox', 'So here we share some', 'Some of the most successful projects', 'These NFT', 'These records can’t be forged', 'To mint an', 'What are the most', 'What is Blockchain', 'What is an NFT', 'What makes an NFT valuable', 'When you purchase a stock in NFT', 'Why are people investing so much in NFT?', 'World of Women and so', 'You can sell your work and creations by attaching', 'and distributing it to many different computers', 'called Pak created an artwork called The Merge', 'cut of any future sale of the token', 'feel free to drop them in the comment section below', 'ledger for all the transactions related to said NFT and the properties it represents.5', 'let me know in The', 'like opensea and their policies vary', 'lot based on the digital asset', 'meetings and life-changing connections', 'one bitcoin with another', 'screenshot for free', 'screenshot of one', 'small computer programs that run on the blockchain—that give the artist', 'solutionsThe NFT points to its location', 'some ethereum tokens and', 'such as a movie ticket', 'that distinguish it from other tokens', 'that your NFT', 'the arts and own something cool from their favorite musicians', 'the attention of cryptocurrency', 'the ownership of Non-Fungible Tokens', 'the transaction is recorded on the blockchain and the', 'then the transaction is stored on the blockchain', 'whales and people from around the world', 'which means no two NFTs are the same', 'with my'], 'LOC': ['Polygon', 'thousands or'], 'ORG': ['DeFi', 'For', 'NFT', 'NFTs', 'Once', 'for example', 'for instance', 'up for grabs'], 'PER': ['Cryptopunks', 'Etherum', 'I', 'Solana', 'Will NFTs', 'if you', 'you are occasionally chosen to purchase it', 'you must pay some amount of gas fee to process', 'you should consider', 'you sign up for a waitlist that can be thousands of people', 'you will still have the same thing']}",
         "[-0.07593081146478653, -0.042764414101839066, -0.07514282315969467, 0.012796132825314999, 0.038399409502744675, -0.0582113079726696, 0.035245057195425034, 0.027262773364782333, 0.11409275233745575, -0.0525820255279541, -0.026844315230846405, 0.010626687668263912, -0.007294845301657915, 0.052328966557979584, -0.021312814205884933, -0.06956521421670914, 0.0016137411585077643, 0.008926905691623688, -0.04917065054178238, 0.06847517192363739, 0.07237221300601959, 0.0008305590599775314, -0.03971943259239197, 0.05721326917409897, -0.03855928033590317, 0.046381816267967224, -0.01746070571243763, -0.06469616293907166, -0.04465372487902641, -0.047646306455135345, 0.014498965814709663, 0.07473637163639069, -0.022325078025460243, 0.04171415790915489, -0.00798245519399643, 0.01940762996673584, 0.044082172214984894, 0.07767335325479507, 0.03299650549888611, -0.06768133491277695, -0.0487697497010231, -0.05776851251721382, -0.028413886204361916, -0.03488999977707863, 0.002805395284667611, 0.05656857043504715, -0.010089104995131493, -0.01475653238594532, -0.03803665563464165, 0.00846734270453453, -0.011060136370360851, -0.03951685130596161, 0.01538480632007122, 0.06951650977134705, 0.023261580616235733, -0.04871101304888725, -0.023184828460216522, -0.09852699935436249, -0.009391000494360924, -0.05837751924991608, 0.033619463443756104, -0.03203286975622177, 0.12407765537500381, 0.04893655702471733, 0.09369073808193207, 0.02564786560833454, -0.02498277835547924, 0.04560890793800354, -0.004803577437996864, -0.062077365815639496, 0.04580364748835564, -0.03252334147691727, -0.005670993588864803, 0.024059193208813667, -0.004311337601393461, -0.04844784736633301, 0.07525379210710526, 0.06196366995573044, -0.001781955943442881, 0.0073018670082092285, 0.03578255698084831, 0.09526984393596649, 0.06514786928892136, -0.048631634563207626, 0.03379696607589722, -0.033776432275772095, -0.03316706791520119, 0.04592423141002655, -0.050757650285959244, -0.017375927418470383, -0.11970604211091995, 0.04422011226415634, 0.07609806954860687, -0.05618498474359512, 0.05850616842508316, -0.07638206332921982, 0.0008329295669682324, 0.02771943248808384, 0.0518074631690979, -0.001674753613770008, 0.013685557059943676, 0.06763141602277756, 0.009478325955569744, 0.029780173674225807, 0.0030779133085161448, 0.05689156427979469, -0.014476265758275986, -0.018366055563092232, 0.11426005512475967, 0.010892445221543312, -0.06910714507102966, 0.008608710952103138, -0.07647605985403061, 0.029576048254966736, -0.0549151636660099, -0.008540184237062931, -0.1319941133260727, 0.03440229222178459, 0.006787489168345928, 0.0762334018945694, 0.037736792117357254, -0.018475186079740524, -0.04729047790169716, -0.028440041467547417, -0.03974887356162071, 0.053048986941576004, -2.3191028958535753e-05, 2.6020397648336602e-33, -0.06974303722381592, 0.018485672771930695, -0.0023291870020329952, -0.025517018511891365, 0.0726812407374382, 0.0064747631549835205, -0.025726471096277237, -0.008500289171934128, -0.031214958056807518, 0.10862649977207184, 0.031770575791597366, 0.1318909227848053, 0.031657624989748, 0.0868263989686966, 0.010067793540656567, -0.008986132219433784, -0.05102688819169998, -0.049495942890644073, 0.13983877003192902, 0.00041687305201776326, 0.020050136372447014, 0.10806342959403992, -0.0001321388263022527, -0.005151326302438974, 0.0281390231102705, -0.06363857537508011, -0.036904264241456985, -0.03523476421833038, 0.072276771068573, -0.009015778079628944, 0.0004872246063314378, -0.05141022056341171, 0.05648784339427948, -0.04171805828809738, 0.05359717458486557, -0.011648829095065594, 0.03618859499692917, -0.0636562928557396, -0.027197571471333504, -0.10994745790958405, -0.015459912829101086, -0.009229473769664764, -0.09195449948310852, -0.022671211510896683, -0.06709609925746918, 0.060938943177461624, 0.03277977183461189, 0.0015111699467524886, -0.07501841336488724, -0.0014456306817010045, 0.02972249500453472, 0.036540236324071884, -0.06008419021964073, -0.10778096318244934, 0.051044903695583344, -0.1194169744849205, -0.06467580050230026, -0.05202179029583931, -0.0420708991587162, -0.0039005454163998365, -0.012962667271494865, -0.035587623715400696, -0.007437254302203655, -0.0008698443998582661, -0.03256122022867203, 0.03946485370397568, 0.03045566938817501, 0.04682353883981705, 0.06364983320236206, -0.028069911524653435, 0.017683120444417, 0.018612196668982506, 0.03588401898741722, 0.044891875237226486, 0.01976851001381874, -0.030406659469008446, 0.02282768115401268, 0.03089490905404091, -0.06585538387298584, 0.10348010063171387, -0.05204992741346359, 0.006504542659968138, -0.06177361682057381, 0.028766265138983727, -0.08897077292203903, 0.04442407563328743, 0.0016989513533189893, 0.021517323330044746, 0.0006098722806200385, -0.1710911989212036, 0.002490282291546464, -0.007176610641181469, 0.0030357760842889547, 0.018782181665301323, 0.04445137828588486, -5.074254627484645e-33, 0.03401768207550049, -0.02199495956301689, -0.043714940547943115, -0.009615574963390827, -0.0027682650834321976, 0.0005143528105691075, -0.02141397073864937, 0.01913638599216938, -0.009987062774598598, -0.012955221347510815, -0.10409058630466461, -0.03227422386407852, -0.005176447797566652, -0.009050216525793076, -0.04823412746191025, -0.0551905483007431, -0.04459920525550842, -0.005282169673591852, -0.028906503692269325, -0.04332827031612396, 0.009818376041948795, 0.023977309465408325, -0.07978090643882751, 0.027251262217760086, -0.007245458196848631, 0.14322708547115326, -0.12721246480941772, -0.03480490297079086, 0.053166188299655914, 0.038992006331682205, 0.026388725265860558, -0.0116276228800416, 0.025252381339669228, -0.10574375092983246, 0.03862077742815018, -0.04610295593738556, -0.03017917275428772, 0.02436966449022293, -0.03517846018075943, -0.06411374360322952, -0.014940453693270683, 0.08472578972578049, 0.06685798615217209, -0.01401987299323082, -0.06172060966491699, 0.009847176261246204, -0.061581604182720184, 0.038973696529865265, 0.06825435906648636, -0.04455788806080818, 0.015547357499599457, 0.048678189516067505, -0.021978488191962242, -0.05804246664047241, -0.03821510076522827, 0.09248308837413788, -0.03449253365397453, 0.048143766820430756, 0.06515227258205414, 0.029516052454710007, 0.06211721897125244, -0.0004890753771178424, -0.008250419981777668, 0.12853877246379852, -0.04204019904136658, -0.03485419973731041, -0.0726754367351532, -0.00586886890232563, -0.056711867451667786, 0.025893978774547577, -0.014647320844233036, 0.018631016835570335, -0.0032306606881320477, 0.005712028127163649, 0.006166386418044567, 0.003670755308121443, 0.05763811245560646, -0.11758734285831451, -0.005054269917309284, -0.030837953090667725, 0.02961849607527256, -0.0420227088034153, 0.009996198117733002, 0.049529630690813065, 0.03432726487517357, -0.01925716921687126, 0.03858062997460365, -0.03729056566953659, 0.03439749404788017, -0.04603978618979454, 0.06607344001531601, -0.042621761560440063, -0.09282860904932022, 0.09520303457975388, -0.009797932580113411, -5.157141202971616e-08, 0.009604420512914658, -0.05984077602624893, 0.041192058473825455, -0.08966294676065445, -0.050425466150045395, -0.019757503643631935, 0.06559757888317108, -0.01500094123184681, -0.01578022725880146, -0.03479938954114914, 0.0608179084956646, -0.004217698238790035, -0.15677575767040253, -0.07533811032772064, 0.03459923714399338, 0.05947883427143097, 0.013015031814575195, -0.014997858554124832, 0.03627516329288483, 0.04214094206690788, -0.002221630420535803, -0.01917264424264431, -0.029233437031507492, -0.09734845161437988, -0.06661899387836456, -0.021066900342702866, 0.09640606492757797, -0.012680917978286743, 0.015085878781974316, 0.0012174916919320822, -0.03960074111819267, 0.06509482860565186, 0.08893545717000961, -0.01631896384060383, -0.008378571830689907, -0.004045872017741203, -0.002031927462667227, -0.03952234610915184, -0.04845146834850311, -0.037729255855083466, -0.022222420200705528, 0.0611756332218647, 0.0038750809617340565, -0.03636796399950981, -0.03167402744293213, -0.06825922429561615, 0.008093497715890408, 0.017262304201722145, 0.012098561972379684, 0.050781141966581345, -0.05714986100792885, -0.001502349623478949, 0.01955673098564148, 0.08698069304227829, -0.024858424440026283, 0.01663186587393284, -0.01127029862254858, 0.018936261534690857, 0.03321102261543274, 0.030481651425361633, 0.07918742299079895, -0.07970080524682999, 0.0890362486243248, 0.021627329289913177]",
         "0.187"
        ],
        [
         "29",
         "288",
         "Paris 2024 : Adidas Arena, Centre aquatique olympique, marina de Marseille... Un an après les Jeux, la promesse de l'héritage des sites pérennes est-elle tenue ?",
         "Six sites ont été construits ou rénovés à l'occasion des Jeux olympiques et paralympiques de Paris 2024. Après l'accueil des JOP, tous ces sites avaient une mission d'héritage à remplir.",
         "Six sites ont été construits ou rénovés à l'occasion des Jeux olympiques et paralympiques de Paris 2024. Après l'accueil des JOP, tous ces sites avaient une mission d'héritage à remplir.\n\nIl y a un an, Paris et la France accueillaient les Jeux olympiques et paralympiques de 2024. Dans une démarche plus responsable et économique, le Comité d'organisation des Jeux (Cojop) avait choisi d'utiliser des sites déjà existants ou de construire des stades temporaires. En dehors du village olympique, dont les travaux d'aménagement et de transformation en logements et bureaux touchent à leur fin cet été, seuls deux sites sont sortis de terre pour l'occasion, répondant surtout à un besoin local d'infrastructure : le Centre aquatique olympique (CAO) à Saint-Denis (Seine-Saint-Denis) et l'Adidas Arena, porte de la Chapelle.\n\nLes quatre autres ont été réhabilités pour accueillir les épreuves olympiques et paralympiques, avant d'être réaménagés en version héritage et devenir accessibles au grand public. Un an après les Jeux, franceinfo: sport a passé en revue les fonctionnements de chacun de ses sites.\n\nLe Centre aquatique olympique fait déjà le plein\n\nReconnaissable entre mille avec sa toiture en bois incurvée, tout proche du Stade de France, le Centre aquatique olympique (CAO) est l'un des sites emblématiques des Jeux olympiques de Paris 2024. Après avoir notamment accueilli les épreuves olympiques de waterpolo, de plongeon et de natation artistique, le Centre aquatique olympique Métropole du Grand Paris, de son nouveau nom, s'est transformé pour recevoir tous les publics depuis le 2 juin dernier.\n\nPlus de 20 000 personnes ont fréquenté l'installation de Saint-Denis sur le premier mois d’activité. \"Nous constatons par ailleurs que la fréquentation des premiers jours de juillet est en nette hausse, avec une montée en puissance attendue tout au long de l’été\", nous ont répondu les responsables du site. Au 15 juillet, celui-ci avait déjà fait mieux, avec près de 20 000 entrées sur l'ensemble du lieu. \"Si l'on regarde nos prévisions, nous ambitionnons à l'horizon de 2027 ou 2028, d'accueillir environ un million de personnes sur l'année, soit une moyenne de 2 000 à 2 500 personnes par jour\", a précisé auprès de franceinfo: sport Grégorie Lartigot, directeur délégué du CAO, qui se réjouit d'un début \"très prometteur\".\n\nVue générale de l'extérieur du Centre aquatique olympique (CAO), depuis son ouverture au public le 2 juin 2025. (Architecture : VenhoevenCS & Ateliers 2/3/4/ - Photo : Ossip van Duivenbode)\n\nDans la nouvelle configuration, l'infrastructure est composée de quatre bassins - un de natation, un de plongeon, un d'apprentissage et un aqualudique -, de neuf terrains de padel, de plusieurs espaces de fitness avec des cours de yoga et de Pilates, d'une salle d'escalade de 1 000 m2, de points de restauration et d'une recyclerie sportive. \"Autant d’installations qui permettront la création de près de 50 emplois dont le recrutement sera fait en lien avec France Travail, Plaine Commune et la société d’exploitation Récréa\", est-il écrit dans le dossier de presse d'avril 2025 portant sur l'héritage du bâtiment.\n\nVue générale de l'intérieur du CAO, depuis son ouverture au public. Il est notamment composé de plusieurs bassins, mais aussi d'une salle d'escalade et de terrains de padel. (Architecture : VenhoevenCS & Ateliers 2/3/4/ - Photo : Ossip van Duivenbode)\n\nPendant l'été, des stages de natation sont aussi proposés, et les écoles de natation seront ouvertes à la rentrée. Pas moins de 70 créneaux classes sont attendus par semaine dès le 15 septembre dans le cadre du programme \"Savoir nager\", un autre héritage des JO de Paris. Un projet essentiel alors que plus d'un enfant sur deux en Seine-Saint-Denis ne sait pas nager à son entrée en sixième, d'après une étude réalisée par l'académie de Créteil en 2021.\n\nRespectant les normes internationales, le CAO accueillera aussi des grands événements, comme les championnats d'Europe de natation (du 31 juillet au 16 août 2026), avec une capacité maximale de 5 000 places. Enfin, l'équipe de France de plongeon, qui manquait d'infrastructures aux normes internationales pour s'entraîner, y a également posé ses valises depuis son ouverture.\n\nL'Adidas Arena, seule salle construite dans Paris\n\nSeul site construit intra-muros, l'Adidas Arena a été le théâtre des épreuves de badminton, de la gymnastique rythmique, du parabadminton et de la parahaltérophilie lors des Jeux de Paris 2024. Depuis, ce stade blanc immaculé, situé Porte de la Chapelle (Paris 18e) ne cesse de vibrer. L'Adidas Arena est devenu la salle du Paris Basketball, devenu champion de France fin juin pour la première fois. Elle peut accueillir 8 700 spectateurs en simultané, et jusqu'à 9 000 en mode concert. Selon les chiffres transmis par la mairie de Paris, l'Adidas Arena a réalisé, depuis son ouverture le 11 février 2024 (hors JOP et évènements gratuits), 133 séances, soit l'équivalent de 755 000 billets vendus.\n\nL'arrière du Paris Basket Tyson Ward, lors du match du championnat de France, face au JL Bourg Basket, le 4 juin 2025, à l'Adidas Arena, à Paris. (CYRIL LESTAGE / AFP)\n\nCette salle est également composée de deux gymnases mis à disposition des athlètes pour l'échauffement et l'entraînement. Ceux-ci sont aussi utilisés de manière hebdomadaire, depuis le 4 novembre 2024, par des établissements scolaires ainsi que sept associations sportives, pour y pratiquer basket, badminton, volley, handball, gymnastique ou encore futsal. \"Au total, 17 587 personnes ont fréquenté les gymnases pour un total de 4 519 heures de pratique [depuis son ouverture, chiffre arrêté au 10 juillet]\", a précisé la mairie de Paris. Enfin, 2 000 m2 d'espace sont consacrés à des lieux de loisirs, de restauration et d’animations alors qu'une sensory room, pour l’accueil de personnes ayant des troubles du comportement ou autistiques, est également ouverte au public.\n\nLa colline Elancourt, des épreuves olympiques à un lieu entièrement dédié au grand public\n\nSon terrain escarpé et ses pentes ont offert l'une des plus belles émotions des Jeux de Paris avec le titre olympique de la vététiste Pauline Ferrand-Prévot. Depuis, le site, qui n'était qu'une décharge avant le début des travaux, a été réaménagé pour le public. Aujourd'hui, quatre pistes de VTT de différents niveaux, réparties sur 10 km, sont accessibles pour les vététistes amateurs et 12 km de sentiers sont ouverts à la promenade, la marche nordique, au trail ou encore à la course d’orientation.\n\n😎 Cet été, RDV à la Colline d’Élancourt ☀️\n\nEnvie de prendre l’air, de tester une nouvelle activité ou de passer un bon moment dans un cadre naturel exceptionnel ?\n\nDécouvrez la programmation sportive estivale, GRATUITE & ouverte à tous 👉https://t.co/v9VDilv4Za\n\n🩵@VilleElancourt pic.twitter.com/HPvjheNQ5W — Saint-Quentin-en-Yvelines 🚀 (@sqy) June 5, 2025\n\nLa piste de BMX des JO, le Pumptrack, est en accès libre. Des sessions de découverte sont également proposées sur réservation, tout comme les séances de fitness (Pilate, yoga, crossfit, Qi Gong). La colline d'Elancourt est entièrement ouverte au grand public depuis le 17 mai dernier. \"Plus de 4 500 personnes étaient présentes\" lors de la journée d'ouverture, nous a indiqué l'agglomération de Saint-Quentin-en-Yvelines, qui précise aussi que le site étant ouvert à tous et gratuit, la fréquentation est difficilement quantifiable.\n\nL'agglomération de Saint-Quentin-en-Yvelines a par ailleurs signé une convention avec la Fédération française de cyclisme (FFC) pour accueillir des stages de l'équipe de France. Si aucun événement mondial n'est pour l'heure prévu sur la colline d'Elancourt, Saint-Quentin-en-Yvelines a toutefois déposé des dossiers de candidatures pour l'accueil de compétition, comme les championnats d'Europe en 2028 et du monde en 2030.\n\nLe stade nautique olympique de Vaires-sur-Marne,\n\nun bassin unique en Europe\n\nIl a été l'un des premiers sites olympiques à porter les couleurs de Paris 2024. Si la base nautique de Vaires-sur-Marne existe depuis 1991, le stade d'eaux vives a été construit en vue des Jeux olympiques et paralympiques de Paris 2024, afin d'y accueillir les épreuves de canoë-kayak (ligne, slalom et kayak extrême) et d'aviron. Inauguré en juin 2019, ce complexe de 4 400 m2 est unique en Europe et même l'un des seuls au monde à réunir ces disciplines sur un même site. La Fédération française de canoë-kayak et des sports de pagaie y est installée administrativement depuis 2024, alors que le centre national d'entraînement de l'aviron français y a posé ses valises à la fin des Jeux de Paris.\n\nCette photographie aérienne prise le 7 février 2024 montre une vue du site olympique de Paris 2024 à Vaires-sur-Marne, où se dérouleront les épreuves de kayak et d'aviron. (MARTIN BUREAU / AFP)\n\nDans la phase héritage, le stade nautique olympique a commencé sa nouvelle vie, partagé entre le haut niveau et l'accueil du grand public. Il continue d'accueillir des compétitions internationales, comme les championnats d'Europe de canoë-kayak slalom en mai dernier. Et les athlètes des deux fédérations ont à leur disposition ces infrastructures tout au long de l'année.\n\nPlusieurs activités sont accessibles au grand public, au Stade nautique olympique de Vaires-sur-Marne, comme ici le rafting. (IDLVT)\n\nPour le grand public, le site propose de nombreuses activités, pour tous les niveaux entre son lac et le stade d'eaux vives : catamaran, paddle et planche à voile pour le premier et kayak, canoë et rafting pour le second. Les amateurs de ces sports de glisse profitent d'ailleurs du site depuis l'inauguration en 2019, qui n'a pas connu d'aménagements post-JO particuliers, hors démontage des tribunes.\n\nLa marina olympique au service des Marseillais\n\nL'air des Jeux de Paris 2024 s'est exporté jusqu'à Marseille (Bouches-du-Rhône). La marina olympique, renommée stade nautique Florence Arthaud en hommage à la navigatrice française, a servi d'écrin aux épreuves de voile, après la rénovation du bassin et du stade nautique du Roucas-Blanc et le réaménagement de la partie nord du parc balnéaire du Prado. \"Plus de 7 000 m2 de bâtiments ont été construits. 17 000 m2 d'espaces extérieurs et six hectares de bassin ont également été réaménagés\", rappelle le site de la cité phocéenne. Ces espaces sont ouverts au grand public tous les dimanches, depuis le 22 juin.\n\nLa Marina de Marseille, située sur la Promenade Georges Pompidou, dans le 8e arrondissement, accueille des élèves des écoles primaires de la ville afin de leur apprenddre à naviguer et à découvrir la biodoversité marine, comme ici, le 3 mars 2025. (MAXPPP)\n\nDepuis janvier 2025, la Marina propose aux élèves marseillais de s'initier aux disciplines nautiques ainsi que des ateliers de sensibilisation à la protection de la biodiversité marine. Cette année, 4 500 écoliers ont pu s'initier à la voile. La mairie souhaite que le dispositif bénéficie l'an prochain \"à 9 000 enfants, soit l'entièreté des élèves de la ville dans cette tranche d'âge\", a fixé la municipalité.\n\nHors pratique scolaire, des sessions de découverte et de stages (voilier collectif, planche à voile, wing foil, optimist, catamaran, etc.) sont également proposées aux enfants et adolescents âgés entre 4 et 17 ans, aux étudiants ainsi qu'aux séniors sur réservation. Des associations à destination des publics isolés accueillent aussi des groupes sur le site. Enfin, la Fédération française de voile y a installé son pôle d'excellence afin de préparer ses athlètes aux prochains rendez-vous internationaux.\n\nLe stade Yves du Manoir, haut lieu chargé d'histoire\n\nEnfin, le stade Yves du Manoir a accueilli les épreuves de hockey sur gazon lors des Jeux de Paris 2024, cent ans après avoir accueilli les Jeux de 1924. Depuis, l'enceinte, propriété du département des Hauts-de-Seine, est devenue le berceau de la discipline. La Fédération française de hockey sur gazon s’y est d'ailleurs implantée de manière pérenne, comme le centre national d'entraînement de la fédération (utilisé pour la compétition et les entraînements). Des bureaux sont également occupés par la ligue d'Île-de-France, le comité départemental de hockey, et par un club résident, le Racing club de France Hockey 92 Colombes.\n\nLe stade Yves-du-Manoir, qui a servi de cadre principal aux Jeux olympiques de Paris en 1924, a accueilli les épreuves de hockey sur gazon lors des Jeux olympiques de Paris 2024. (MIGUEL MEDINA / AFP)\n\nEn phase héritage, le stade Yves du Manoir se compose de deux terrains synthétiques de hockey avec une tribune de 1 000 places, deux salles de musculation, quatre terrains de foot et trois de rugby, tous en synthétique, et une nouvelle piste d'athlétisme. Les joueurs du Racing club de France Hockey 92 Colombes partagent le site avec des publics scolaires et universitaires, des associations et des clubs sportifs. \"Environ 5 500 usagers utilisent le stade départemental Yves-du-Manoir chaque semaine, auquel il faut ajouter le public [lors des matchs]\", a précisé le département des Hauts-de-Seine.",
         "2025-07-26T04:00:02",
         "https://www.francetvinfo.fr/titres.rss",
         "https://www.franceinfo.fr/les-jeux-olympiques/paris-2024-adidas-arena-centre-aquatique-olympique-marina-de-marseille-un-an-apres-les-jeux-la-promesse-de-l-heritage-des-sites-perennes-est-elle-tenue_7367251.html#xtor=RSS-3-[lestitres]",
         "2025-07-26T05:53:42.863481",
         "Six sites ont été construits ou rénovés à l'occasion des Jeux olympiques et paralympiques de Paris 2024. Après l'accueil des JOP, tous ces sites avaient une mission d'héritage à remplir. Il y a un an, Paris et la France accueillaient les Jeux olympiques et paralympiques de 2024. Dans une démarche plus responsable et économique, le Comité d'organisation des Jeux (Cojop) avait choisi d'utiliser des sites déjà existants ou de construire des stades temporaires. En dehors du village olympique, dont les travaux d'aménagement et de transformation en logements et bureaux touchent à leur fin cet été, seuls deux sites sont sortis de terre pour l'occasion, répondant surtout à un besoin local d'infrastructure : le Centre aquatique olympique (CAO) à Saint-Denis (Seine-Saint-Denis) et l'Adidas Arena, porte de la Chapelle. Les quatre autres ont été réhabilités pour accueillir les épreuves olympiques et paralympiques, avant d'être réaménagés en version héritage et devenir accessibles au grand public. Un an après les Jeux, franceinfo: sport a passé en revue les fonctionnements de chacun de ses sites. Le Centre aquatique olympique fait déjà le plein Reconnaissable entre mille avec sa toiture en bois incurvée, tout proche du Stade de France, le Centre aquatique olympique (CAO) est l'un des sites emblématiques des Jeux olympiques de Paris 2024. Après avoir notamment accueilli les épreuves olympiques de waterpolo, de plongeon et de natation artistique, le Centre aquatique olympique Métropole du Grand Paris, de son nouveau nom, s'est transformé pour recevoir tous les publics depuis le 2 juin dernier. Plus de 20 000 personnes ont fréquenté l'installation de Saint-Denis sur le premier mois d’activité. \"Nous constatons par ailleurs que la fréquentation des premiers jours de juillet est en nette hausse, avec une montée en puissance attendue tout au long de l’été\", nous ont répondu les responsables du site. Au 15 juillet, celui-ci avait déjà fait mieux, avec près de 20 000 entrées sur l'ensemble du lieu. \"Si l'on regarde nos prévisions, nous ambitionnons à l'horizon de 2027 ou 2028, d'accueillir environ un million de personnes sur l'année, soit une moyenne de 2 000 à 2 500 personnes par jour\", a précisé auprès de franceinfo: sport Grégorie Lartigot, directeur délégué du CAO, qui se réjouit d'un début \"très prometteur\". Vue générale de l'extérieur du Centre aquatique olympique (CAO), depuis son ouverture au public le 2 juin 2025. (Architecture : VenhoevenCS & Ateliers 2/3/4/ - Photo : Ossip van Duivenbode) Dans la nouvelle configuration, l'infrastructure est composée de quatre bassins - un de natation, un de plongeon, un d'apprentissage et un aqualudique -, de neuf terrains de padel, de plusieurs espaces de fitness avec des cours de yoga et de Pilates, d'une salle d'escalade de 1 000 m2, de points de restauration et d'une recyclerie sportive. \"Autant d’installations qui permettront la création de près de 50 emplois dont le recrutement sera fait en lien avec France Travail, Plaine Commune et la société d’exploitation Récréa\", est-il écrit dans le dossier de presse d'avril 2025 portant sur l'héritage du bâtiment. Vue générale de l'intérieur du CAO, depuis son ouverture au public. Il est notamment composé de plusieurs bassins, mais aussi d'une salle d'escalade et de terrains de padel. (Architecture : VenhoevenCS & Ateliers 2/3/4/ - Photo : Ossip van Duivenbode) Pendant l'été, des stages de natation sont aussi proposés, et les écoles de natation seront ouvertes à la rentrée. Pas moins de 70 créneaux classes sont attendus par semaine dès le 15 septembre dans le cadre du programme \"Savoir nager\", un autre héritage des JO de Paris. Un projet essentiel alors que plus d'un enfant sur deux en Seine-Saint-Denis ne sait pas nager à son entrée en sixième, d'après une étude réalisée par l'académie de Créteil en 2021. Respectant les normes internationales, le CAO accueillera aussi des grands événements, comme les championnats d'Europe de natation (du 31 juillet au 16 août 2026), avec une capacité maximale de 5 000 places. Enfin, l'équipe de France de plongeon, qui manquait d'infrastructures aux normes internationales pour s'entraîner, y a également posé ses valises depuis son ouverture. L'Adidas Arena, seule salle construite dans Paris Seul site construit intra-muros, l'Adidas Arena a été le théâtre des épreuves de badminton, de la gymnastique rythmique, du parabadminton et de la parahaltérophilie lors des Jeux de Paris 2024. Depuis, ce stade blanc immaculé, situé Porte de la Chapelle (Paris 18e) ne cesse de vibrer. L'Adidas Arena est devenu la salle du Paris Basketball, devenu champion de France fin juin pour la première fois. Elle peut accueillir 8 700 spectateurs en simultané, et jusqu'à 9 000 en mode concert. Selon les chiffres transmis par la mairie de Paris, l'Adidas Arena a réalisé, depuis son ouverture le 11 février 2024 (hors JOP et évènements gratuits), 133 séances, soit l'équivalent de 755 000 billets vendus. L'arrière du Paris Basket Tyson Ward, lors du match du championnat de France, face au JL Bourg Basket, le 4 juin 2025, à l'Adidas Arena, à Paris. (CYRIL LESTAGE / AFP) Cette salle est également composée de deux gymnases mis à disposition des athlètes pour l'échauffement et l'entraînement. Ceux-ci sont aussi utilisés de manière hebdomadaire, depuis le 4 novembre 2024, par des établissements scolaires ainsi que sept associations sportives, pour y pratiquer basket, badminton, volley, handball, gymnastique ou encore futsal. \"Au total, 17 587 personnes ont fréquenté les gymnases pour un total de 4 519 heures de pratique [depuis son ouverture, chiffre arrêté au 10 juillet]\", a précisé la mairie de Paris. Enfin, 2 000 m2 d'espace sont consacrés à des lieux de loisirs, de restauration et d’animations alors qu'une sensory room, pour l’accueil de personnes ayant des troubles du comportement ou autistiques, est également ouverte au public. La colline Elancourt, des épreuves olympiques à un lieu entièrement dédié au grand public Son terrain escarpé et ses pentes ont offert l'une des plus belles émotions des Jeux de Paris avec le titre olympique de la vététiste Pauline Ferrand-Prévot. Depuis, le site, qui n'était qu'une décharge avant le début des travaux, a été réaménagé pour le public. Aujourd'hui, quatre pistes de VTT de différents niveaux, réparties sur 10 km, sont accessibles pour les vététistes amateurs et 12 km de sentiers sont ouverts à la promenade, la marche nordique, au trail ou encore à la course d’orientation. 😎 Cet été, RDV à la Colline d’Élancourt ☀️ Envie de prendre l’air, de tester une nouvelle activité ou de passer un bon moment dans un cadre naturel exceptionnel ? Découvrez la programmation sportive estivale, GRATUITE & ouverte à tous 👉https://t.co/v9VDilv4Za 🩵@VilleElancourt pic.twitter.com/HPvjheNQ5W — Saint-Quentin-en-Yvelines 🚀 (@sqy) June 5, 2025 La piste de BMX des JO, le Pumptrack, est en accès libre. Des sessions de découverte sont également proposées sur réservation, tout comme les séances de fitness (Pilate, yoga, crossfit, Qi Gong). La colline d'Elancourt est entièrement ouverte au grand public depuis le 17 mai dernier. \"Plus de 4 500 personnes étaient présentes\" lors de la journée d'ouverture, nous a indiqué l'agglomération de Saint-Quentin-en-Yvelines, qui précise aussi que le site étant ouvert à tous et gratuit, la fréquentation est difficilement quantifiable. L'agglomération de Saint-Quentin-en-Yvelines a par ailleurs signé une convention avec la Fédération française de cyclisme (FFC) pour accueillir des stages de l'équipe de France. Si aucun événement mondial n'est pour l'heure prévu sur la colline d'Elancourt, Saint-Quentin-en-Yvelines a toutefois déposé des dossiers de candidatures pour l'accueil de compétition, comme les championnats d'Europe en 2028 et du monde en 2030. Le stade nautique olympique de Vaires-sur-Marne, un bassin unique en Europe Il a été l'un des premiers sites olympiques à porter les couleurs de Paris 2024. Si la base nautique de Vaires-sur-Marne existe depuis 1991, le stade d'eaux vives a été construit en vue des Jeux olympiques et paralympiques de Paris 2024, afin d'y accueillir les épreuves de canoë-kayak (ligne, slalom et kayak extrême) et d'aviron. Inauguré en juin 2019, ce complexe de 4 400 m2 est unique en Europe et même l'un des seuls au monde à réunir ces disciplines sur un même site. La Fédération française de canoë-kayak et des sports de pagaie y est installée administrativement depuis 2024, alors que le centre national d'entraînement de l'aviron français y a posé ses valises à la fin des Jeux de Paris. Cette photographie aérienne prise le 7 février 2024 montre une vue du site olympique de Paris 2024 à Vaires-sur-Marne, où se dérouleront les épreuves de kayak et d'aviron. (MARTIN BUREAU / AFP) Dans la phase héritage, le stade nautique olympique a commencé sa nouvelle vie, partagé entre le haut niveau et l'accueil du grand public. Il continue d'accueillir des compétitions internationales, comme les championnats d'Europe de canoë-kayak slalom en mai dernier. Et les athlètes des deux fédérations ont à leur disposition ces infrastructures tout au long de l'année. Plusieurs activités sont accessibles au grand public, au Stade nautique olympique de Vaires-sur-Marne, comme ici le rafting. (IDLVT) Pour le grand public, le site propose de nombreuses activités, pour tous les niveaux entre son lac et le stade d'eaux vives : catamaran, paddle et planche à voile pour le premier et kayak, canoë et rafting pour le second. Les amateurs de ces sports de glisse profitent d'ailleurs du site depuis l'inauguration en 2019, qui n'a pas connu d'aménagements post-JO particuliers, hors démontage des tribunes. La marina olympique au service des Marseillais L'air des Jeux de Paris 2024 s'est exporté jusqu'à Marseille (Bouches-du-Rhône). La marina olympique, renommée stade nautique Florence Arthaud en hommage à la navigatrice française, a servi d'écrin aux épreuves de voile, après la rénovation du bassin et du stade nautique du Roucas-Blanc et le réaménagement de la partie nord du parc balnéaire du Prado. \"Plus de 7 000 m2 de bâtiments ont été construits. 17 000 m2 d'espaces extérieurs et six hectares de bassin ont également été réaménagés\", rappelle le site de la cité phocéenne. Ces espaces sont ouverts au grand public tous les dimanches, depuis le 22 juin. La Marina de Marseille, située sur la Promenade Georges Pompidou, dans le 8e arrondissement, accueille des élèves des écoles primaires de la ville afin de leur apprenddre à naviguer et à découvrir la biodoversité marine, comme ici, le 3 mars 2025. (MAXPPP) Depuis janvier 2025, la Marina propose aux élèves marseillais de s'initier aux disciplines nautiques ainsi que des ateliers de sensibilisation à la protection de la biodiversité marine. Cette année, 4 500 écoliers ont pu s'initier à la voile. La mairie souhaite que le dispositif bénéficie l'an prochain \"à 9 000 enfants, soit l'entièreté des élèves de la ville dans cette tranche d'âge\", a fixé la municipalité. Hors pratique scolaire, des sessions de découverte et de stages (voilier collectif, planche à voile, wing foil, optimist, catamaran, etc.) sont également proposées aux enfants et adolescents âgés entre 4 et 17 ans, aux étudiants ainsi qu'aux séniors sur réservation. Des associations à destination des publics isolés accueillent aussi des groupes sur le site. Enfin, la Fédération française de voile y a installé son pôle d'excellence afin de préparer ses athlètes aux prochains rendez-vous internationaux. Le stade Yves du Manoir, haut lieu chargé d'histoire Enfin, le stade Yves du Manoir a accueilli les épreuves de hockey sur gazon lors des Jeux de Paris 2024, cent ans après avoir accueilli les Jeux de 1924. Depuis, l'enceinte, propriété du département des Hauts-de-Seine, est devenue le berceau de la discipline. La Fédération française de hockey sur gazon s’y est d'ailleurs implantée de manière pérenne, comme le centre national d'entraînement de la fédération (utilisé pour la compétition et les entraînements). Des bureaux sont également occupés par la ligue d'Île-de-France, le comité départemental de hockey, et par un club résident, le Racing club de France Hockey 92 Colombes. Le stade Yves-du-Manoir, qui a servi de cadre principal aux Jeux olympiques de Paris en 1924, a accueilli les épreuves de hockey sur gazon lors des Jeux olympiques de Paris 2024. (MIGUEL MEDINA / AFP) En phase héritage, le stade Yves du Manoir se compose de deux terrains synthétiques de hockey avec une tribune de 1 000 places, deux salles de musculation, quatre terrains de foot et trois de rugby, tous en synthétique, et une nouvelle piste d'athlétisme. Les joueurs du Racing club de France Hockey 92 Colombes partagent le site avec des publics scolaires et universitaires, des associations et des clubs sportifs. \"Environ 5 500 usagers utilisent le stade départemental Yves-du-Manoir chaque semaine, auquel il faut ajouter le public [lors des matchs]\", a précisé le département des Hauts-de-Seine.",
         "fr",
         "{'MISC': ['Architecture', 'GRATUITE & ouverte', 'JO', 'JO de Paris', 'JOP', 'Jeux', 'Jeux de 1924', 'Jeux de Paris', 'Jeux de Paris 2024', 'Jeux olympiques', 'Jeux olympiques de Paris', 'Jeux olympiques de Paris 2024', \"L'air des Jeux de Paris 2024\", 'LESTAGE', 'MARTIN', 'Pilates', 'VenhoevenCS & Ateliers', 'catamaran, paddle', 'championnat de France', \"championnats d'Europe\", \"championnats d'Europe de canoë-kayak slalom\", \"ligue d'Île-de-France\", '👉https://t.co/v9VDilv4Za'], 'LOC': ['@sqy', 'Adidas Arena', 'Bouches-du-Rhône', 'Centre aquatique olympique', 'Centre aquatique olympique Métropole du Grand Paris', 'Chapelle', 'Cojop', 'Elancourt', 'Europe', 'June 5', 'Marina', 'Marina de Marseille', 'Marseillais', 'Marseille', 'Paris', 'Plaine Commune', 'Porte de la Chapelle', 'Prado', 'Promenade Georges Pompidou', 'Pumptrack', 'RDV', 'Roucas-Blanc', 'Saint-Denis', 'Saint-Quentin-en-Yvelines', 'Seine-Saint-Denis', 'Stade de France', 'Stade nautique olympique de Vaires-sur-Marne', 'Vaires-sur-Marne', 'Yves-du-Manoir', 'académie de Créteil', 'de France', 'département des Hauts-de-Seine', 'la Colline', 'la France', 'stade Yves du Manoir', 'stade Yves-du-Manoir', 'Élancourt ☀️ Envie'], 'ORG': ['AFP', 'Centre aquatique olympique', \"Comité d'organisation des\", 'FFC', 'France Travail', 'Fédération française de canoë-kayak', 'Fédération française de cyclisme', 'Fédération française de hockey sur gazon', 'Fédération française de voile', 'IDLVT', 'MAXPPP', 'MIGUEL MEDINA', 'Paris Basket Tyson Ward', 'Paris Basketball', 'Racing club de France', 'Récréa', 'franceinfo', 'franceinfo: sport'], 'PER': ['Florence Arthaud', 'Grégorie Lartigot', 'JL Bourg Basket', 'Ossip van Duivenbode', 'Pauline Ferrand-Prévot', 'Pilate', 'Qi Gong', 'Reconnaissable']}",
         "[0.03809861093759537, 0.0868900865316391, -0.00942271202802658, -0.08185812085866928, 0.03208627179265022, -0.062843918800354, -0.10807681083679199, 0.0013537579216063023, 0.0022247498854994774, 0.022403616458177567, 0.01633341982960701, -0.07459313422441483, 0.011840864084661007, 0.017199283465743065, 0.025580281391739845, -0.08700095862150192, -0.05289071425795555, 0.01638851687312126, 0.06772828847169876, 0.053100135177373886, 0.016000879928469658, -0.0957266092300415, 0.004075303673744202, -0.027507755905389786, -0.04978685453534126, -0.015135453082621098, -0.07180006802082062, 0.06365017592906952, 0.027726199477910995, -0.023573853075504303, -0.0010103273671120405, 0.04732823371887207, -0.06353355944156647, -0.027775699272751808, 0.03217824548482895, 0.0933145061135292, -0.003059048904106021, -0.11280350387096405, -0.041894350200891495, 0.12501105666160583, -0.009575414471328259, 0.03544597327709198, -0.03362736105918884, -0.025964541360735893, 0.0013167827855795622, -0.0019243709975853562, 0.0946122333407402, 0.011082679964601994, -0.09890943020582199, -0.03762960806488991, 0.09993090480566025, -0.0032366900704801083, 0.021190917119383812, -0.029753927141427994, -0.08474250882863998, -0.02972763031721115, -0.02631375379860401, -0.03211633861064911, 0.06976468116044998, 0.008218764327466488, 0.09972414374351501, 0.031767770648002625, -0.022999674081802368, 0.034754958003759384, 0.010204948484897614, -0.02624327689409256, -0.021214764565229416, -0.006813423708081245, 0.0062593431212008, -0.04825574904680252, -0.016366591677069664, -0.06511900573968887, 0.021718749776482582, -0.051000528037548065, 0.07557103782892227, 0.03172403946518898, -0.07536666095256805, 0.060681503266096115, -0.04280200973153114, -0.17374689877033234, 0.07297331839799881, -0.04014546424150467, 0.06901902705430984, 0.016144856810569763, -0.014890898019075394, -0.01121350284665823, -0.002138185780495405, 0.014257070608437061, 0.08317162841558456, -0.021414170041680336, -0.008748816326260567, 0.03417627140879631, -0.07114138454198837, -0.02413620613515377, 0.05340685695409775, -0.02008381299674511, -0.03803616389632225, -0.001185632310807705, 0.06372583657503128, 0.02739524468779564, -0.014995403587818146, 0.015251265838742256, 0.008240927010774612, 0.046536095440387726, -0.026186726987361908, -0.0054490226320922375, 0.016533052548766136, 0.03277486935257912, -0.05418965220451355, 0.04888925328850746, -0.034321513026952744, -0.0022792848758399487, 0.03649713844060898, -0.09936536103487015, 0.004395813215523958, 0.057627126574516296, -0.03834427893161774, -0.09379038959741592, -0.006192079279571772, -0.0741506963968277, 0.07343525439500809, -0.010324306786060333, 0.0542767234146595, -0.021236121654510498, 0.04390349239110947, 0.08728960901498795, 0.08800391107797623, 7.581193593258921e-33, 0.03858933225274086, 0.07775012403726578, -0.05789409205317497, -0.018946055322885513, 0.07297222316265106, 0.016496745869517326, -0.04595278948545456, 0.017361406236886978, 0.03148818388581276, -0.009309003129601479, 0.025817403569817543, 0.06176153942942619, -0.06966345757246017, -0.017407331615686417, 0.15225684642791748, -0.010087058879435062, 0.11322971433401108, -0.037372518330812454, 0.013245034962892532, 0.014419138431549072, -0.02687878906726837, -0.0021759935189038515, -0.0034625947009772062, 0.09095092862844467, 0.03313184902071953, 0.07197307795286179, -0.044810231775045395, 0.04175058379769325, -0.0877569392323494, 0.017057674005627632, 0.05678678676486015, -0.017262399196624756, -0.0064254566095769405, 0.03553161025047302, 0.03877799212932587, -0.008927930146455765, 0.038205280900001526, -0.02663865126669407, 0.0018061691662296653, -0.02105325646698475, -0.004190238192677498, -0.0005101278075017035, 0.012303764931857586, -0.007199941668659449, 0.04189968854188919, 0.021110953763127327, 0.020103560760617256, -0.023416850715875626, 0.12241720408201218, -0.013328012079000473, -0.01032200362533331, 0.026837864890694618, -0.11739043891429901, -0.025260373950004578, 0.025915183126926422, -0.018664086237549782, -0.12352913618087769, -0.06072748452425003, -0.05931824445724487, 0.030087707564234734, 0.01574971340596676, -0.020586766302585602, -0.04745662584900856, 0.021182719618082047, -0.026752380654215813, -0.03887760266661644, 0.0648471862077713, 0.07135412842035294, 0.08736687153577805, -0.054837666451931, -0.0774712786078453, 0.03336015343666077, 0.06216217577457428, 0.019175661727786064, -0.027437962591648102, 0.07714798301458359, -0.008431417867541313, 0.05578368902206421, -0.03598853945732117, 0.04972991719841957, -0.06967932730913162, 0.02701937034726143, -0.060117997229099274, 0.02137969806790352, 0.07272519171237946, -0.07097265869379044, 0.09634047001600266, -0.012093058787286282, -0.022097088396549225, 0.018386531621217728, -0.044045135378837585, 0.011083084158599377, 0.012886636890470982, 0.01594780571758747, -0.0609278567135334, -1.0829309297875496e-32, -0.02128792367875576, -0.008222898468375206, -0.053451936691999435, 0.012113011442124844, -0.06100489944219589, 0.01711416244506836, 0.04153012856841087, -0.0074077933095395565, -0.018090832978487015, -0.05005791783332825, -0.10443691164255142, 0.003544294275343418, 0.03566130995750427, -0.010393021628260612, -0.034061431884765625, 0.03919772803783417, -0.011817244812846184, -0.03277325630187988, -0.08363816887140274, 0.017777040600776672, 0.03583690524101257, 0.004248904064297676, -0.03522568196058273, -0.06295415014028549, 0.020878829061985016, 0.07117540389299393, -0.038396064192056656, -0.11274298280477524, -0.06881998479366302, -0.020619040355086327, -0.04810059443116188, 0.05000666156411171, 0.0027613253332674503, 0.09713219106197357, 0.028006350621581078, 0.08484918624162674, 0.07528896629810333, 0.06188182160258293, -0.08134917169809341, 0.0448337160050869, 0.04829264432191849, 0.010750887915492058, -0.0026173656806349754, -0.02761748805642128, -0.016789773479104042, 0.04742588475346565, -0.09718652814626694, 0.007580088917165995, -0.03601030260324478, -0.027175553143024445, 0.025071673095226288, 0.04686162993311882, -0.03700482100248337, -0.057519786059856415, 0.023132890462875366, 0.027457263320684433, -0.025035623461008072, -0.003485902212560177, -0.08757665753364563, 0.008162269368767738, 0.0988009124994278, 0.05863748863339424, -0.10209333151578903, 0.04551013931632042, 0.01205429621040821, -0.05075659230351448, -0.03030020371079445, 0.024167947471141815, -0.07471069693565369, 0.022184211760759354, 0.005785483866930008, -0.09466538578271866, -0.041715458035469055, -0.03407198563218117, -0.0003098936867900193, -0.02806478552520275, 0.021251169964671135, 0.04868925362825394, -0.03650347888469696, 0.07223718613386154, -0.14479689300060272, 0.05372101441025734, -0.011611130088567734, -0.022367356345057487, 0.010834727436304092, 0.030750920996069908, -0.028325967490673065, -0.009538172744214535, 0.05015821009874344, -0.03126607835292816, 0.01077723503112793, -9.701690578367561e-05, -0.08075957745313644, 0.01546056754887104, 0.05901159346103668, -6.581931444316069e-08, 0.03951496630907059, 0.042937275022268295, -0.03311772271990776, -0.011920114047825336, -0.05273061990737915, -0.1302439272403717, 0.008761747740209103, -0.00507373409345746, -0.01727641187608242, 0.07201091945171356, -0.058372437953948975, 0.07465080171823502, -0.05870088189840317, -0.01650848612189293, -0.07294498383998871, -0.01076591107994318, -0.04440441355109215, -0.04697846248745918, -0.07823792845010757, -0.06880002468824387, -0.046707771718502045, -0.04703081026673317, -0.06160585582256317, -0.04700031876564026, -0.05950917676091194, -0.0696517676115036, -0.07323398441076279, -0.06898634135723114, 0.008134390227496624, 0.020283404737710953, 0.035669755190610886, 0.008244884200394154, -0.011897916905581951, -0.07990840822458267, 0.006179956253618002, -0.0326288640499115, -0.02738894335925579, 0.018981484696269035, 0.027954939752817154, 0.006357084959745407, 0.04808897152543068, -0.07751636952161789, 0.017528153955936432, 0.028587305918335915, 0.10102618485689163, -0.017766814678907394, -0.0132053904235363, 0.042253509163856506, 0.07260602712631226, -0.03427920490503311, -0.1077616959810257, -0.008405410684645176, -0.01839667744934559, 0.05676322802901268, 0.04281003028154373, -0.03235398977994919, -0.026143155992031097, 0.023520134389400482, 0.027879444882273674, -0.008079051040112972, -0.037716228514909744, -0.00028516078600659966, -0.03852232173085213, -0.04420680180191994]",
         "0.182"
        ],
        [
         "30",
         "584",
         "What Optimization Terminologies for Linear Programming Really Mean",
         "Understanding the duality of optimization problem, primal to dual conversion, and the optimality conditions for linear problems. The post What Optimization Terminologies for Linear Programming Really Mean appeared first on Towards Data Science .",
         "with linear optimization problems at work and for some personal projects, I have always been intrigued by seeing the log messages during solver iterations. It’s fascinating how modern solvers can solve optimization problems with decision variables and constraints in the order of thousands and millions within the time frame of only minutes or hours. It could take days or years if a human were solving such processes manually. Nevertheless, I wanted to better understand the terminologies used in linear programming and the ones I see in the solver log messages.\n\nIn my 2021 post, which I published with Towards Data Science (time flies!), I discussed techniques to solve linear problems in Python and Julia, respectively. In another post, I discussed the steps undertaken by solvers for optimizing, solving, and post-processing linear problems which are packaged in the form of a mathematical programming system. This post is going to be a more theoretical one. I am going to break down different optimization terminologies such as primal, dual, dualness, duality gap, basic solution, and put forward the three optimality conditions that need to be satisfied for linear problems. Let’s get started.\n\nDuality of optimization problem\n\nEvery optimization problem could be viewed from two different perspectives. This concept is referred to as dualness of the optimization problem. For example, if our original objective is to maximize the revenue of a company within the given resource constraints, the same problem could also be formulated in a way to minimize the resource constraints while aiming to sell a certain number of products. The original form of the linear optimization problem that is provided is referred to as the primal problem. For every primal problem, there is a corresponding dual problem. If the primal is a maximization problem, then the dual is a minimization problem, and vice versa. As such, the dual of a dual problem is a primal problem itself. This fundamental dualness in the characterization of optimization problems is referred to as duality.\n\nAs stated above, the sense of the objective functions is just opposite in primal and dual problems. Besides, the decision variables used in primal problems are formulated as constraints in dual problems, and the constraints in the primal problem are formulated as decision variables. This duality has a multitude of advantages in solving linear optimization problems. When a solver solves an optimization problem, both the primal and dual feasibility conditions need to be met. If the primal problem has many variables but fewer constraints, in that case, the dual problem might be easier to solve. Furthermore, duality provides deeper insights into the structure of the optimization problem.\n\nLet’s assume we have a primal problem in the following form:\n\nWhere A, b, and c all belong to real numbers. Say we have m number of constraints, and n number of decision variables. A is the constraint coefficient matrix with the order m*n, x is the decision variable vector with n variables, b is the RHS vector with m elements, and c is the cost vector comprising cost coefficients of each decision variable.\n\nThe corresponding dual problem is given in the form:\n\nWe can see that the transpose of b, which is the resource limit defined in the primal problem, comes in the objective function of the dual problem. y is the decision variable in the dual problem and is hence referred to as dual variables. Dual variables show the sensitivity of the primal objective function with respect to every constraint in the optimal point. In economic interpretation, dual values are also referred to as shadow prices or fair prices.\n\nSteps for conversion of primal problem to dual problem\n\nThe steps for converting a primal problem into a dual problem can be summarized below. This is inspired by this video.\n\nFirst, convert the problem to canonical form. If the problem is maximization, the constraints should be in the form of less than or equal to. And if the problem is minimization, then the constraint should be in the form of greater than or equal to Change the sense of the objective function. Maximization problem becomes minimization, and vice versa. The number of variables in the primal problem will be the number of constraints in the dual problem, and vice versa. Cost constraints in the objective function in the primal problem will be RHS constant of the constraints in the dual problem, and vice versa. For formulating the constraints in the dual problem, use the transpose of the constrain matrix in the primal problem.\n\nExample of primal to dual conversion\n\nPrimal problem\n\nAssume we want to maximize the revenue of a furniture company. x and y are the number of sales of chairs and tables at a particular period, and their unit sales price is 90 and 75, respectively.\n\nSay we have resource constraints in terms of energy, number of labor and working hours. Each chair needs 3 units and each table needs 2 units of energy, and overall, they cannot consume more than 66 units of energy. Each chair needs 9 units and each table needs 4 units of manpower and overall, it should be less than or equal to 180 units of manpower. Each chair needs 2 units and each table needs 10 units of working hours and overall it should be less than or equal to 200 units of working hours. This problem is written in canonical form as follows:\n\nmaximize z = 90x + 75y\n\ns.t. 3x+2y ≤ 66 (energy)\n\n9x+4y ≤ 180 (manpower)\n\n2x+10y ≤ 200 (time)\n\nx, y ≥ 0\n\n(chairs, tables)\n\nDual problem\n\nIn the above-mentioned problem, I have two decision variables, and three constraints in the primal problem. Accordingly, the dual problem will have three variables and two constraints. Let w1, w2 and w3 be the three variables in the dual problem based on each constraint in the primal problem. In this case, w1, w2, and w3 can be considered as the shadow prices associated with energy, manpower, and time constraints, respectively. Shadow prices refer to the amount by which the solution to the primal objective function would change at the optimal point, if the primal RHS constraint is changed by one unit.\n\nWe get:\n\nmin⁡ 66w1+180w2+200w3\n\ns.t. 3w1+9w2+2w3 ≥ 90 (chairs)\n\n2w1+4w2+10w3 ≥ 75 (tables)\n\nw1, w2, w3 ≥ 0\n\n(energy, manpower, time)\n\nConverting the problem to standard form\n\nTo convert the primal and dual problem to standard form means to convert the inequality constraints to equations by adding some variables. This is useful for determining the optimality conditions, which is discussed further in the succeeding section.\n\nIn the primal problem, I add slack variables to convert the less than inequality constraint to an equality constraint as shown below. h1, h2, and h3 are slack variables for energy, manpower and time constraints, respectively.\n\nmaximize z = 90x+75y\n\ns.t. 3x+2y+h1 = 66 (energy)\n\n9x+4y+h2 = 180 (manpower)\n\n2x+10y+h3 = 200 (time)\n\nx, y, h1, h2, h3 ≥ 0\n\nIn the dual problem, I use surplus variables to convert greater than inequality constraint into an equality constraints. s1 and s2 are surplus variables.\n\nmin⁡ 66w1+180w2+200w3\n\ns.t. 3w1+9w2+2w3-s1 = 90 (chairs)\n\n2w1+4w2+10w3-s2 = 75 (tables)\n\nw1, w2, w3, s1, s2 ≥ 0\n\nAs we have used equality constraints in the standard form, the constraints are always binding, meaning we are using all the resources that are available without leaving any waste. In this condition, in the primal optimal solution, the values of slack variables become equal to zero. And in the dual optimal solution, the values of surplus variables also become equal to zero. If the constraint is non-binding (e.g., it has less than or equal to constraint), then the value of these variables could be either greater than or equal to zero in the optimal solution.\n\nOptimality conditions for linear problems\n\nFor a linear optimization problem, the solution to primal problem and a solution to dual problem are optimal if and only if the following three conditions are met. (This is inspired by this video lecture by Gurobi Optimization.)\n\nPrimal feasibility\n\nThe solution needs to be primal feasible. This implies that the value of the decision variables in the solution to the primal problem should satisfy all its constraints. In our case, the number of chairs and tables (x and y) should be within the resource constraints for energy, manpower, and time, respectively.\n\n3x+2y ≤ 66 (energy)\n\n9x+4y ≤ 180 (manpower)\n\n2x+10y ≤ 200 (time)\n\nx, y ≥ 0\n\n\n\nb. Dual feasibility\n\nThis implies that the solution to the dual problem should satisfy all of its constraints. In our case, the shadow prices associated with energy, manpower, and time (w1, w2, and w3) should satisfy the price constraints (cost coefficients) for the chairs and the tables, respectively.\n\n3w1+9w2+2w3-s1 = 90 (chairs)\n\n2w1+4w2+10w3-s2 = 75 (tables)\n\nw1, w2, w3, s1, s2 ≥ 0\n\nc. Complementary (or orthogonal conditions)\n\nSay x* refers to the decision variables in the optimal primal solution and h* refers to the slack variables in the same primal problem. Say s refers to the slack variables in the dual problem, and w refers to the associated shadow prices in the dual problem. At optimality, the product of decision variables in the primal problem and the surplus variables associated with dual problem should be zero. This is referred to as being cost efficient because this condition ensures that we are making the most efficient use of our resources.\n\nx*s = 0\n\nIn our problem, x * s1 = 0 and y * s2 = 0 implies:\n\nx*(3w1+9w2+2w3-90) = 0\n\ny*(2w1+4w2+10w3-75) = 0\n\nAlso, at optimality, the product of slack variables in the primal problem and the shadow prices in the dual problem should be equal to zero. This implies that we are being resource efficient and leaving no waste of resources.\n\nh*w = 0\n\nh1*w1 = 0; h2*w2 = 0; h3*w3 = 0;\n\nBasic Solution, Duality gap, Strong duality and weak duality\n\nBasic Solution\n\nAs per this nice definition from HiGHS documentation, if a linear problem is feasible and has bounded feasible region in the direction of optimization, then it has an optimal solution at a vertex. “At this vertex, the decision variables can be partitioned into as many basic variables as there are constraints, and the non-basic variables. In the given solution, basic variables are the ones having non-zero values, and non-basic variables are the ones having zero values. This set of solutions is referred to as basic solution, and the partition is referred to as basis.\n\n(If a linear problem is solved using simplex algorithm, the set of basic and non-basic solutions can change over time. During iterations, some slack variables will become non-basic, and other variables will become basic. The simplex moves from one basis to another improving the objective function, until it reaches the optimal point and cannot improve the objective function further.)\n\nDuality gap\n\nThe difference between the optimal primal value p* and the optimal dual value d* is referred to as the duality gap p*–d*. This value is always greater than or equal to zero.\n\nStrong duality\n\nStrong duality holds if the primal objective value (solution) and the dual objective value is the same, implying that the duality gap is zero. Strong duality implies that the problem is “often” convex and satisfies certain constraint conditions. The dual problem in this case is a tight approximation of the primal problem.\n\nFor example, if the maximum revenue in a furniture factory composed of sales of chairs and tables is equal to the minimum cost of resource use, including energy, labour, and hours, this condition is referred to as strong duality.\n\nWeak duality\n\nIf the duality gap is greater than or equal to zero, then the condition is referred to as weak duality. This implies that the dual solution is less than or equal to the primal solution.\n\nIn case of weak duality, the dual solution rather provides bounds on the primal objective value. If the primal is a minimization problem, then the dual feasible solution gives the lower bound on the primal objective value. And if the primal is a maximization problem, then the dual feasible solution gives the upper bound on the primal objective value.\n\nConclusion\n\nThis is my first article in Towards Data Science where I describe some mathematical optimization concepts without using any code. In this post, I explain with examples the duality concepts in mathematical optimization, including primal to dual form conversion, canonical and standard forms of the problems, the conditions for optimality, basic solution, duality gap, strong and weak duality. When I started to learn about these concepts, they were quite abstract to me. Therefore, I tried to learn about these concepts on my own, as well as package them together since all these concepts are interrelated. I hope you find them useful. You can refer to some notebooks of my previous optimization-related blogs in this GitHub repository. Thank you for reading!",
         "2025-07-22T22:11:51",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/breaking-down-optimization-terminologies-for-linear-programming/",
         "2025-07-26T06:23:31.375542",
         "with linear optimization problems at work and for some personal projects, I have always been intrigued by seeing the log messages during solver iterations. It’s fascinating how modern solvers can solve optimization problems with decision variables and constraints in the order of thousands and millions within the time frame of only minutes or hours. It could take days or years if a human were solving such processes manually. Nevertheless, I wanted to better understand the terminologies used in linear programming and the ones I see in the solver log messages. In my 2021 post, which I published with Towards Data Science (time flies!), I discussed techniques to solve linear problems in Python and Julia, respectively. In another post, I discussed the steps undertaken by solvers for optimizing, solving, and post-processing linear problems which are packaged in the form of a mathematical programming system. This post is going to be a more theoretical one. I am going to break down different optimization terminologies such as primal, dual, dualness, duality gap, basic solution, and put forward the three optimality conditions that need to be satisfied for linear problems. Let’s get started. Duality of optimization problem Every optimization problem could be viewed from two different perspectives. This concept is referred to as dualness of the optimization problem. For example, if our original objective is to maximize the revenue of a company within the given resource constraints, the same problem could also be formulated in a way to minimize the resource constraints while aiming to sell a certain number of products. The original form of the linear optimization problem that is provided is referred to as the primal problem. For every primal problem, there is a corresponding dual problem. If the primal is a maximization problem, then the dual is a minimization problem, and vice versa. As such, the dual of a dual problem is a primal problem itself. This fundamental dualness in the characterization of optimization problems is referred to as duality. As stated above, the sense of the objective functions is just opposite in primal and dual problems. Besides, the decision variables used in primal problems are formulated as constraints in dual problems, and the constraints in the primal problem are formulated as decision variables. This duality has a multitude of advantages in solving linear optimization problems. When a solver solves an optimization problem, both the primal and dual feasibility conditions need to be met. If the primal problem has many variables but fewer constraints, in that case, the dual problem might be easier to solve. Furthermore, duality provides deeper insights into the structure of the optimization problem. Let’s assume we have a primal problem in the following form: Where A, b, and c all belong to real numbers. Say we have m number of constraints, and n number of decision variables. A is the constraint coefficient matrix with the order m*n, x is the decision variable vector with n variables, b is the RHS vector with m elements, and c is the cost vector comprising cost coefficients of each decision variable. The corresponding dual problem is given in the form: We can see that the transpose of b, which is the resource limit defined in the primal problem, comes in the objective function of the dual problem. y is the decision variable in the dual problem and is hence referred to as dual variables. Dual variables show the sensitivity of the primal objective function with respect to every constraint in the optimal point. In economic interpretation, dual values are also referred to as shadow prices or fair prices. Steps for conversion of primal problem to dual problem The steps for converting a primal problem into a dual problem can be summarized below. This is inspired by this video. First, convert the problem to canonical form. If the problem is maximization, the constraints should be in the form of less than or equal to. And if the problem is minimization, then the constraint should be in the form of greater than or equal to Change the sense of the objective function. Maximization problem becomes minimization, and vice versa. The number of variables in the primal problem will be the number of constraints in the dual problem, and vice versa. Cost constraints in the objective function in the primal problem will be RHS constant of the constraints in the dual problem, and vice versa. For formulating the constraints in the dual problem, use the transpose of the constrain matrix in the primal problem. Example of primal to dual conversion Primal problem Assume we want to maximize the revenue of a furniture company. x and y are the number of sales of chairs and tables at a particular period, and their unit sales price is 90 and 75, respectively. Say we have resource constraints in terms of energy, number of labor and working hours. Each chair needs 3 units and each table needs 2 units of energy, and overall, they cannot consume more than 66 units of energy. Each chair needs 9 units and each table needs 4 units of manpower and overall, it should be less than or equal to 180 units of manpower. Each chair needs 2 units and each table needs 10 units of working hours and overall it should be less than or equal to 200 units of working hours. This problem is written in canonical form as follows: maximize z = 90x + 75y s.t. 3x+2y ≤ 66 (energy) 9x+4y ≤ 180 (manpower) 2x+10y ≤ 200 (time) x, y ≥ 0 (chairs, tables) Dual problem In the above-mentioned problem, I have two decision variables, and three constraints in the primal problem. Accordingly, the dual problem will have three variables and two constraints. Let w1, w2 and w3 be the three variables in the dual problem based on each constraint in the primal problem. In this case, w1, w2, and w3 can be considered as the shadow prices associated with energy, manpower, and time constraints, respectively. Shadow prices refer to the amount by which the solution to the primal objective function would change at the optimal point, if the primal RHS constraint is changed by one unit. We get: min⁡ 66w1+180w2+200w3 s.t. 3w1+9w2+2w3 ≥ 90 (chairs) 2w1+4w2+10w3 ≥ 75 (tables) w1, w2, w3 ≥ 0 (energy, manpower, time) Converting the problem to standard form To convert the primal and dual problem to standard form means to convert the inequality constraints to equations by adding some variables. This is useful for determining the optimality conditions, which is discussed further in the succeeding section. In the primal problem, I add slack variables to convert the less than inequality constraint to an equality constraint as shown below. h1, h2, and h3 are slack variables for energy, manpower and time constraints, respectively. maximize z = 90x+75y s.t. 3x+2y+h1 = 66 (energy) 9x+4y+h2 = 180 (manpower) 2x+10y+h3 = 200 (time) x, y, h1, h2, h3 ≥ 0 In the dual problem, I use surplus variables to convert greater than inequality constraint into an equality constraints. s1 and s2 are surplus variables. min⁡ 66w1+180w2+200w3 s.t. 3w1+9w2+2w3-s1 = 90 (chairs) 2w1+4w2+10w3-s2 = 75 (tables) w1, w2, w3, s1, s2 ≥ 0 As we have used equality constraints in the standard form, the constraints are always binding, meaning we are using all the resources that are available without leaving any waste. In this condition, in the primal optimal solution, the values of slack variables become equal to zero. And in the dual optimal solution, the values of surplus variables also become equal to zero. If the constraint is non-binding (e.g., it has less than or equal to constraint), then the value of these variables could be either greater than or equal to zero in the optimal solution. Optimality conditions for linear problems For a linear optimization problem, the solution to primal problem and a solution to dual problem are optimal if and only if the following three conditions are met. (This is inspired by this video lecture by Gurobi Optimization.) Primal feasibility The solution needs to be primal feasible. This implies that the value of the decision variables in the solution to the primal problem should satisfy all its constraints. In our case, the number of chairs and tables (x and y) should be within the resource constraints for energy, manpower, and time, respectively. 3x+2y ≤ 66 (energy) 9x+4y ≤ 180 (manpower) 2x+10y ≤ 200 (time) x, y ≥ 0 b. Dual feasibility This implies that the solution to the dual problem should satisfy all of its constraints. In our case, the shadow prices associated with energy, manpower, and time (w1, w2, and w3) should satisfy the price constraints (cost coefficients) for the chairs and the tables, respectively. 3w1+9w2+2w3-s1 = 90 (chairs) 2w1+4w2+10w3-s2 = 75 (tables) w1, w2, w3, s1, s2 ≥ 0 c. Complementary (or orthogonal conditions) Say x* refers to the decision variables in the optimal primal solution and h* refers to the slack variables in the same primal problem. Say s refers to the slack variables in the dual problem, and w refers to the associated shadow prices in the dual problem. At optimality, the product of decision variables in the primal problem and the surplus variables associated with dual problem should be zero. This is referred to as being cost efficient because this condition ensures that we are making the most efficient use of our resources. x*s = 0 In our problem, x * s1 = 0 and y * s2 = 0 implies: x*(3w1+9w2+2w3-90) = 0 y*(2w1+4w2+10w3-75) = 0 Also, at optimality, the product of slack variables in the primal problem and the shadow prices in the dual problem should be equal to zero. This implies that we are being resource efficient and leaving no waste of resources. h*w = 0 h1*w1 = 0; h2*w2 = 0; h3*w3 = 0; Basic Solution, Duality gap, Strong duality and weak duality Basic Solution As per this nice definition from HiGHS documentation, if a linear problem is feasible and has bounded feasible region in the direction of optimization, then it has an optimal solution at a vertex. “At this vertex, the decision variables can be partitioned into as many basic variables as there are constraints, and the non-basic variables. In the given solution, basic variables are the ones having non-zero values, and non-basic variables are the ones having zero values. This set of solutions is referred to as basic solution, and the partition is referred to as basis. (If a linear problem is solved using simplex algorithm, the set of basic and non-basic solutions can change over time. During iterations, some slack variables will become non-basic, and other variables will become basic. The simplex moves from one basis to another improving the objective function, until it reaches the optimal point and cannot improve the objective function further.) Duality gap The difference between the optimal primal value p* and the optimal dual value d* is referred to as the duality gap p*–d*. This value is always greater than or equal to zero. Strong duality Strong duality holds if the primal objective value (solution) and the dual objective value is the same, implying that the duality gap is zero. Strong duality implies that the problem is “often” convex and satisfies certain constraint conditions. The dual problem in this case is a tight approximation of the primal problem. For example, if the maximum revenue in a furniture factory composed of sales of chairs and tables is equal to the minimum cost of resource use, including energy, labour, and hours, this condition is referred to as strong duality. Weak duality If the duality gap is greater than or equal to zero, then the condition is referred to as weak duality. This implies that the dual solution is less than or equal to the primal solution. In case of weak duality, the dual solution rather provides bounds on the primal objective value. If the primal is a minimization problem, then the dual feasible solution gives the lower bound on the primal objective value. And if the primal is a maximization problem, then the dual feasible solution gives the upper bound on the primal objective value. Conclusion This is my first article in Towards Data Science where I describe some mathematical optimization concepts without using any code. In this post, I explain with examples the duality concepts in mathematical optimization, including primal to dual form conversion, canonical and standard forms of the problems, the conditions for optimality, basic solution, duality gap, strong and weak duality. When I started to learn about these concepts, they were quite abstract to me. Therefore, I tried to learn about these concepts on my own, as well as package them together since all these concepts are interrelated. I hope you find them useful. You can refer to some notebooks of my previous optimization-related blogs in this GitHub repository. Thank you for reading!",
         "en",
         "{'MISC': ['And if the primal is', 'And in the dual', 'As stated above', 'As such', 'As we have used equality', 'At optimality', 'Basic', 'Cost', 'Dual', 'Dual problem In the above-mentioned problem', 'Duality', 'Duality of optimization problem Every', 'For every primal problem', 'For formulating the constraints in the dual problem', 'GitHub', 'HiGHS', 'I', 'I am going to break down', 'I discussed the steps undertaken by solvers for optimizing', 'I have always been intrigued by seeing the log messages during solver iterations', 'I have two decision variables', 'I hope you find them useful', 'I tried to learn about these concepts on my own', 'I wanted to better understand the terminologies used in linear programming and the ones I see in the solver log', 'If', 'If the constraint is non-binding', 'If the primal is', 'If the primal is a minimization problem', 'If the primal problem has many variables but fewer constraints', 'If the problem is maximization', 'In another post', 'In case of weak duality', 'In my 2021 post', 'In our case', 'In our problem', 'In the primal problem', 'In this post', 'It could take days or years if a human were solving such processes manually', 'It’', 'Let w1', 'Let’', 'Let’s get started', 'Maximization problem becomes minimization', 'Optimization', 'Primal feasibility', 'Primal problem Assume we want to maximize the revenue of', 'Say s refers to the slack variables in the dual problem', 'Say we have', 'Say we have m number of constraints', 'Say x* refers to the decision variables in the', 'Solution As per this nice', 'Steps for conversion of primal problem to dual problem The steps for converting', 'Strong duality and weak duality Basic', 'Strong duality implies that the problem is “often” convex and satisfies', 'Thank you for reading!', 'The', 'The dual problem in this case is a tight approximation of the primal problem', 'The number of variables in the primal problem will be the number of constraints in the dual problem', 'This implies that the dual solution is less than or equal to the primal', 'This implies that the solution to the dual problem should satisfy all of its constraints', 'This implies that the value of the decision variables in the solution to the primal problem should satisfy all its constraints', 'This implies that we are being', 'This is my first article in Towards Data Science where I', 'This is referred to as being cost', 'This post is going to be a more theoretical one', 'This problem is written in canonical', 'To convert the primal and dual problem to standard', 'We can see that the transpose of b', 'We get: min\\u2061 66w1+180w2+200w3', 'Weak duality If the duality gap is greater than or equal to zero', 'When I started to learn about these concepts', 'When a solver solves', 'Where A', 'You can', 'and c all belong to real numbers', 'and c is the cost vector comprising cost coefficients of each decision variable', 'and n number of decision variables', 'and put forward the three optimality conditions that need to be satisfied for linear problems', 'and the non-basic variables', 'and the partition is referred to as basis', 'and their unit sales price is 90 and 75', 'and time', 'and w refers to the associated shadow prices in the dual problem', 'b is the RHS vector with m elements', 'basic', 'basic variables are the ones having non-zero values', 'c. Complementary', 'dual problem', 'dual problem is given in the form', 'dual values are also referred to as shadow prices or fair prices', 'dual, dualness', 'gives', 'gives the upper bound on the primal objective value', 'h*w', 'h1*w1', 'h2', 'h3', 'including energy', 'including primal to dual', 'is referred to as the duality', 'it has less than or equal to constraint', 'manpower and time', 'matrix in the primal problem', 'maximize z = 90x + 75y', 'meaning we are using all the resources that are available without leaving any waste', 'number of labor and working hours', 'of sales of chairs and tables is equal to the minimum cost of resource', 'period', 'point and cannot improve the objective function further', 'problem in the following', 'problem into', 'problem is feasible and has bounded', 'problem is solved using simplex algorithm', 'problem that is provided is referred to as the primal problem', 'problems which are packaged in the form of', 's1 and s2', 'solving', 'strong and weak duality', 'the conditions for optimality', 'the constraints are always binding', 'the decision variables can be partitioned into as many basic variables', 'the decision variables used in primal problems are formulated as', 'the dual of a dual problem is', 'the dual problem might be easier to solve', 'the dual problem will have three variables and two', 'the dual solution rather provides bounds on the primal objective value', 'the number of chairs and tables', 'the product of decision variables in the primal problem and the', 'the product of slack variables in the primal problem and the shadow prices in the dual problem should be equal to zero', 'the same problem could also be formulated in a way to minimize the resource', 'the sense of the objective functions is just opposite in primal and dual problems', 'the set of basic and non-basic solutions can change over time', 'the values of slack variables become equal to zero', 'the values of surplus variables also become equal to zero', 'then it has an', 'then the constraint should be in the form of greater than or equal to Change the sense of the objective function', 'then the value of these variables could be either greater than or equal to zero in the', 'they were quite abstract to me', 'time) Converting the problem to standard', 'until it reaches the', 'we have', 'which I published with Towards Data Science', 'with linear optimization problems', 'with respect to every constraint in the', 'x and y are the number of sales of chairs and tables at'], 'PER': ['Furthermore', 'Nevertheless', 'Shadow', 'Strong duality Strong duality holds if the primal objective value', 'Therefore', 'This', 'h1', 'h2*w2', 'manpower', 'the constraints should be in the form of less than or equal to.', 'while aiming to sell'], 'LOC': ['Besides', 'I', 'and vice versa', 'h3*w3', 'm*n', 'maximize', 'some slack variables will become non-basic', 'variables', 'w1', 'w2'], 'ORG': ['Accordingly', 'Also', 'First', 'For', 'and overall', 'and w3', 'w1', 'w2', 'w2 and w3 be the three variables in the dual problem based on each constraint in the primal problem', 'w3']}",
         "[-0.06221393123269081, -0.006149452645331621, -0.037632256746292114, -0.022845527157187462, 0.0008452378679066896, -0.08520433306694031, -0.0040285466238856316, 0.019010158255696297, -0.05361560732126236, 0.05414246395230293, -0.039948489516973495, 0.04393685236573219, 0.04293196275830269, 0.07597532868385315, 0.04409777373075485, 0.024229545146226883, 0.005897615570574999, 0.0009772508637979627, -0.0427156500518322, 0.02034461684525013, 0.02278250828385353, -0.028340797871351242, -0.06997398287057877, 0.05634886398911476, 0.02293877676129341, -0.012613254599273205, -0.010407042689621449, -0.013275315053761005, -0.02117355912923813, 0.06911059468984604, 0.03628135100007057, 0.06020251661539078, 0.05789947509765625, 0.07567231357097626, -0.0052981022745370865, 0.07326998561620712, -0.04940271005034447, -0.04828227311372757, -0.045385558158159256, -0.014743800275027752, -0.0740991085767746, -0.021731412038207054, -0.046354178339242935, -0.04903167858719826, 0.07258451730012894, 0.009087102487683296, -0.011121705174446106, -0.010641800239682198, -0.04017261788249016, -0.06450274586677551, -0.08462319523096085, -0.0077742924913764, 0.024475540965795517, -0.03684789314866066, -0.006503805052489042, -0.06937702745199203, 0.08774231374263763, -0.037383414804935455, 0.009730986319482327, -0.0554799810051918, -0.028158728033304214, -0.04154663160443306, -0.04873194172978401, 0.015325498767197132, -0.008042187429964542, -0.03207879513502121, 0.021916000172495842, -0.006726918276399374, 0.05971366912126541, 0.10224317014217377, -0.12458685040473938, 0.038156043738126755, -0.017354769632220268, -0.06422977894544601, 0.08444148302078247, -0.07017642259597778, 0.1201205849647522, -0.0034490744583308697, -0.017561249434947968, -0.005696584470570087, 0.06754735857248306, 0.07371871173381805, 0.008907987736165524, -0.008631824515759945, 0.03812085837125778, -0.08150575309991837, -0.02290557324886322, 0.05402430519461632, 0.10650356858968735, -0.047185901552438736, -0.01649620570242405, -0.030175983905792236, -0.010851836763322353, 0.08984086662530899, -0.00013111175212543458, -0.020066488534212112, 0.010107681155204773, 0.04770639166235924, 0.07200952619314194, -0.006031068041920662, 0.038375917822122574, -0.02655848301947117, 0.10327915847301483, -0.060472287237644196, 0.02503941021859646, -0.040081705898046494, -0.002737076487392187, 0.008984506130218506, 0.033663857728242874, -0.09655899554491043, 0.05153202265501022, 0.026804428547620773, 0.059838298708200455, 0.04714994132518768, -0.0163401011377573, -0.02087327465415001, 0.05180566757917404, -0.009405981749296188, 0.1303030103445053, 0.04286457970738411, -0.011435676366090775, -0.026039356365799904, 0.06263501197099686, -0.024643559008836746, 0.0940946415066719, 0.019487440586090088, -0.0868462324142456, 2.895176831860045e-33, -0.060218486934900284, 0.03219876065850258, 0.0023883068934082985, -0.027757100760936737, 0.050062395632267, -0.0026465444825589657, 0.037393275648355484, -0.009956475347280502, -0.02276000939309597, 0.029474351555109024, -0.006294367369264364, 0.009339689277112484, 0.0033000572584569454, 0.10941475629806519, 0.09854906052350998, -0.05365965887904167, 0.001037895679473877, 0.00586377689614892, 0.004883632529526949, -0.016553329303860664, -0.005321379750967026, -0.04175792261958122, 0.0060638366267085075, 0.029688214883208275, 0.04035837575793266, -0.06317763775587082, 0.07099907845258713, -0.126225084066391, -0.09240540862083435, -0.0075522311963140965, -0.09359145164489746, 0.03438946604728699, 0.022803951054811478, 0.07671091705560684, 0.07032687962055206, 0.0539691187441349, 0.024606067687273026, -0.05011851340532303, -0.027314789593219757, -0.012776362709701061, -0.07529491186141968, -0.0017275470308959484, 0.05560363084077835, 0.01396586187183857, -0.019417855888605118, 0.016026027500629425, -0.09148339927196503, 0.13798116147518158, 0.009681666269898415, -0.0696956142783165, -0.04087941348552704, 0.003923338372260332, -0.00047205149894580245, -0.05505382642149925, 0.07472904771566391, 0.04704933613538742, -0.054944753646850586, -0.04839565232396126, -0.014239463023841381, 0.03894669562578201, -0.04237684607505798, -0.10033027082681656, 0.06709176301956177, -0.1017163097858429, 0.01670166477560997, -0.002079464728012681, 0.009658119641244411, -0.00472321966663003, 0.058727242052555084, 0.03012206219136715, -0.07903020083904266, 0.011426116339862347, 0.07495003193616867, -0.03682186082005501, 0.11457673460245132, 0.02583352103829384, 0.1232588067650795, -0.020970666781067848, -0.03646814823150635, -0.011482941918075085, -0.0049348510801792145, 0.09347304701805115, -0.03243532404303551, -0.010534621775150299, -0.05980508774518967, -0.06048409268260002, 0.03908897563815117, 0.001956930384039879, -0.07211057096719742, -0.06677108258008957, -0.10413907468318939, 0.02545468509197235, 0.05434012785553932, 0.02736205793917179, 0.02056136168539524, -5.520574036786529e-33, -0.003919724840670824, -0.02031111717224121, -0.03947517275810242, -0.006406223867088556, 0.011049401946365833, -0.08160469681024551, -0.0080594876781106, -0.12851814925670624, -0.018785443156957626, -0.06334983557462692, 0.008196507580578327, -0.05623603239655495, -0.0018149135867133737, 0.07943655550479889, -0.04686318337917328, 0.0019098210614174604, -0.0467512421309948, 0.02526765502989292, -0.008894708007574081, 0.02853688783943653, 0.03520026430487633, 0.12854507565498352, -0.12394486367702484, -0.06049090996384621, 0.018639881163835526, -0.06042330712080002, -0.0015181194758042693, 0.027769943699240685, -0.010597988031804562, 0.03462836891412735, -0.006342529784888029, 0.005257874261587858, -0.05132559314370155, -0.0090858843177557, 0.022491097450256348, 0.06086788699030876, -0.012756695970892906, -0.03866284340620041, 0.0009598209871910512, 0.03403271362185478, 0.011490060947835445, 0.0007503645610995591, -0.007986878044903278, -0.04375601187348366, 0.0008986910688690841, 0.006884964182972908, -0.04188098758459091, -0.07521016895771027, 0.026144953444600105, 0.005161681212484837, 0.033467862755060196, -0.045881107449531555, 0.030899574980139732, 0.04489707574248314, -0.08659553527832031, -0.02245904505252838, -0.01046273298561573, -0.048019394278526306, 0.013555355370044708, -0.03195371851325035, -0.08040890842676163, -0.026557104662060738, 0.061132095754146576, 0.04868368059396744, -0.041156359016895294, -0.07371275126934052, -0.009484583511948586, -0.10927829146385193, 8.875656931195408e-05, -0.030378691852092743, -0.04423173516988754, -0.04535568505525589, -0.0015006032772362232, 0.10145160555839539, 0.021626906469464302, 0.029089031741023064, -0.05354433134198189, -0.05230753496289253, -0.12614089250564575, -0.005922478158026934, 0.03213072940707207, -0.0010895574232563376, 0.028316015377640724, 0.11322887986898422, -0.0886797085404396, -0.014075382612645626, 0.05613488331437111, 0.034544046968221664, 0.011612282134592533, -0.145111545920372, 0.009446271695196629, -0.030559970065951347, 0.025589942932128906, 0.02126992680132389, -0.014931730926036835, -5.731069308012593e-08, -0.07438419759273529, -0.015959329903125763, -0.04023953154683113, -0.0971711277961731, 0.05628652125597, 0.024240564554929733, 0.03847861662507057, 0.029052218422293663, -0.039899345487356186, -0.007716329302638769, 0.05156315118074417, 0.04554753378033638, 0.03369728848338127, -0.05004580691456795, -0.043731529265642166, 0.024311019107699394, -0.0013872012495994568, -0.08058823645114899, -0.001255176728591323, -0.05270617827773094, 0.03867174685001373, 0.044426385313272476, -0.05020377039909363, 0.03221122547984123, -0.026067418977618217, -0.050837814807891846, 0.0923796072602272, 0.10791485011577606, 0.04613582789897919, -0.0364774614572525, -0.010416855104267597, 0.04448710009455681, 0.05181169509887695, 0.02002263441681862, 0.013385322876274586, 0.04285000264644623, 0.033432379364967346, -0.05867863446474075, -0.029036905616521835, -0.01379348710179329, 0.010177930817008018, 0.04458863288164139, -0.03708324953913689, -0.0066157239489257336, 0.07748696953058243, -0.006631556898355484, -0.012879800982773304, 0.009226677007973194, -0.009164896793663502, -0.0020398893393576145, 0.024756405502557755, 0.09094104170799255, -0.015515778213739395, 0.08207065612077713, 0.07936187833547592, -0.01279055792838335, -0.029875190928578377, -0.05019121617078781, 0.06680575758218765, 0.07111202925443649, 0.006840582005679607, 0.024847865104675293, -0.009109959937632084, -0.04835247993469238]",
         "0.121"
        ],
        [
         "31",
         "466",
         "AI Act : un changement de taille attend les géants de l’IA le 2 août prochain : qu’est ce que ça va changer ?",
         "Les entreprises qui développent les outils d'IA générative les plus utilisés comme ChatGPT ou Copilot devront montrer patte blanche en Europe, à compter du 2 aout 2025, nouvelle entrée en application de l'AI Act, le règlement européen sur l'intelligence artificielle. Voici ce qui va changer à partir de début août, malgré les très nombreux appels ou pressions visant à retarder ou suspendre cette échéance.",
         "Les entreprises qui développent les outils d’IA générative les plus utilisés comme ChatGPT ou Copilot devront montrer patte blanche en Europe, à compter du 2 aout 2025, nouvelle entrée en application de l’AI Act, le règlement européen sur l’intelligence artificielle. Voici ce qui va changer à partir de début août, malgré les très nombreux appels ou pressions visant à retarder ou suspendre cette échéance.\n\nChatGPT, Claude et Perplexity n’ont plus que quelques jours pour se conformer à l’AI Act, le règlement européen sur l’intelligence artificielle (IA). Après l’interdiction des systèmes d’IA avec des risques inacceptables (comme les outils de notation sociale) devenue effective en février dernier, c’est au tour des modèles d’IA à portée générale (appelés dans la loi européenne les « GPAI » pour « General-Purpose artificial intelligence ») de montrer patte blanche.\n\nL’AI Act, entré en vigueur le 1er août 2024, s’applique de manière échelonnée jusqu’en 2030. Et à partir du 2 août 2025, c’est au tour des « GPAI », les modèles conçus pour accomplir plusieurs tâches comme la rédaction, la génération d’images, la recherche ou du calcul, de se conformer à la loi européenne. Pour mesurer ce qui devra bientôt s’appliquer à ChatGPT, Le Chat, Gemini, Copilot, Midjourney et Claude, nous nous sommes entretenus avec Arnaud Latil, auteur du Droit du numérique, une approche par les risques, et maître de conférences en droit privé à la Sorbonne Université.\n\nQui est concerné par la nouvelle échéance de l’AI Act ?\n\nÀ compter du 2 août prochain, les fournisseurs de modèles GPAI, mis sur le marché européen, doivent se conformer à l’AI Act. Il s’agit des outils d’IA capables de générer texte, image, code, analyses, retranscription écrite… qui peuvent être aussi intégrés à d’autres outils.\n\nContrairement à la désignation des très grandes plateformes et des contrôleurs d’accès en matière de DSA ou de DMA, la Commission ne va pas publier une liste des modèles concernés. Mais « les entreprises qui font parties de l’AI Pact et qui ont signé le code de bonnes pratiques reconnaissent que leur modèle entre dans la catégorie des modèles GPAI », souligne Arnaud Latil.\n\nPour savoir quels modèles sont concernés, il existe une « présomption liée à la puissance de calcul utilisée, mais il ne s’agit que d’une présomption, et au-delà, la Commission européenne peut les classer en fonction d’une série de critères qui est très longue », précise le docteur en droit. Tout dépendra de la façon dont la Commission interprète cette liste de critères.\n\nLes « lignes directrices », un document publié mi juillet par la Commission européenne, précisent davantage quels modèles sont concernés. Bruxelles a notamment fixé des seuils à partir desquels un modèle d’IA tomberait dans la catégorie des « fournisseurs d’IA » à portée générale : « ses ressources de calcul pour son entrainement (doivent être) supérieures à 1023 (opérations en virgule flottante) FLOP et il (doit pouvoir) générer du langage (que ce soit sous forme de texte ou d’audio), du texte à l’image ou du texte à la vidéo », détaille le texte.\n\nSelon tous ces éléments, les modèles d’IA concernés par l’échéance du 2 août seront donc vraisemblablement tous les modèles d’IA générative utilisés par le grand public à partir de fin 2022, à savoir : ChatGPT (OpenAI), Copilot (Microsoft), Le Chat (Mistral), Claude (Anthropic), Llama (Meta), et leurs concurrents.\n\nÀ quoi seront-ils tenus en pratique ?\n\nÀ partir du 2 août, ces GPAI doivent se conformer à des obligations de transparence. Ils devront notamment préparer toute une documentation technique qui pourra être partagée avec le « Bureau de l’IA », une émanation de la Commission européenne chargée d’appliquer l’AI Act, et les autorités nationales compétentes, sur demande. Les fournisseurs en aval — ceux qui utilisent ces outils pour une application spécifique — pourront aussi y avoir accès.\n\nLes développeurs de GPAI ont aussi l’obligation de respecter le droit d’auteur, et remplir le modèle de résumé des sources utilisées pour entraîner leurs outils d’IA, un modèle publié par Bruxelles jeudi dernier.\n\nEnfin, pour les GPAI qui « présentent un risque systémique », des obligations supplémentaires d’évaluations et d’atténuations des risques devront être respectées. Il s’agit d’outils d’IA qui pourraient avoir un impact significatif sur les droits fondamentaux, la société, ou la santé publique.\n\nPour se conformer à ces nouvelles obligations, les fournisseurs d’IA peuvent s’appuyer sur trois autres textes publiés courant juillet, qui sont venus préciser l’AI Act :\n\nle code de bonnes pratiques, dont la version finale a été publiée jeudi 10 juillet,\n\nles lignes directrices (publiées le vendredi 18 juillet),\n\nle modèle pour les sources d’entraînement protégées par le droit d’auteur, publié jeudi 24 juillet.\n\nCes documents étaient attendus depuis plusieurs mois. Pour certains, la rédaction de ces textes, qui est passée par une étape de concertation avec les géants de l’IA, les ayants droit et la société civile, a pu donner l’impression que la négociation de l’AI Act était toujours en cours. Pourtant, ces actes de précision ou d’exécution n’ont rien de surprenant, rappelle Arnaud Latil.\n\nLa Commission européenne peut « rédiger des actes d’exécution ou des décisions d’exécution, donc préciser des textes de loi. Cela permet de faire évoluer des textes sans rouvrir le cycle de négociation politique et sans forcément réviser les textes dans leur ensemble », détaille le chercheur au Centre d’études et de recherches en droit de l’immatériel (Université Paris-Saclay).\n\nLe code de bonnes pratiques « n’est pas un document obligatoire, mais il permet aux opérateurs de suivre des recommandations pour être conforme » à l’AI Act, souligne le maître de conférences en droit privé. Le modèle qui a trait au droit d’auteur est, quant à lui, bien obligatoire. Les fournisseurs d’IA devront le remplir – et détailler pour la première fois les sources principales utilisées pour entraîner leur modèle, une première – bien que les ayants droit estiment que le degré de précision est loin d’être suffisant.\n\nY aura-t-il un délai de grâce ?\n\nLa rédaction et la publication de ces trois documents ont eu lieu au beau milieu d’appels à décaler voire suspendre l’application de l’AI Act pour les outils d’IA générative, des appels provenant des industries de l’IA, mais aussi de certains pays de l’Union européenne. Business Europe, le Medef européen, a demandé le 17 juillet dernier « une période de grâce pour implémenter le code de bonnes pratiques sur les modèles à usage général », précédant un message similaire provenant cette fois d’une quarantaine d’entreprises et d’organisations européennes. Le tout s’inscrit dans un contexte géopolitique de négociations de droits de douane de l’administration Trump, qui est vent debout contre une telle règlementation.\n\nPour autant, la Commission européenne a rappelé qu’il n’y aurait ni report ni délai de grâce. « Le règlement sur l’IA a été adopté selon une procédure conforme aux principes de l’état de droit. Il paraît impossible de décider de ne pas appliquer ce texte. Le législateur européen a décidé d’appliquer l’AI Act à une date donnée, sachant que la date à elle-même fait l’objet d’une discussion politique, au même titre que les autres dispositions », rappelle Arnaud Latil.\n\nSuivant la même logique, le fait de ne pas signer le code de bonnes pratiques (non obligatoire) – une approche adoptée par Meta, vendredi 18 juillet – ne change rien à l’application de l’AI Act. Il y aura toutefois un avantage à faire partie des signataires, dont feront partie la start-up française Mistral, et OpenAI, l’entreprise américaine à l’origine de ChatGPT, selon leurs déclarations : le signer permettra de bénéficier d’une présomption de conformité.\n\nSelon un journaliste de MLex, la Commission européenne a suggéré qu’un délai de grâce serait accordé aux signataires du code pour la première année. « En particulier, si ces prestataires ne mettent pas en œuvre tous les engagements immédiatement après avoir signé le code, le Bureau de l’IA ne considérera pas qu’ils ont rompu leurs engagements au titre du code et ne leur reprochera pas d’avoir enfreint la loi sur l’AI. Au contraire, dans de tels cas, le Bureau de l’IA considérera qu’ils ont agi de bonne foi et sera prêt à collaborer pour trouver des moyens d’assurer une conformité totale », écrit-il.\n\nEn termes de droit d’auteur, les ayants droit et les auteurs toujours mécontents\n\nPour l’échéance du 2 août, la question du droit d’auteur a été âprement discutée. Comme le rappelle Arnaud Latil, le droit d’auteur est « enjeu extrêmement important, à la fois pour les ayants droits, pour les auteurs et pour les producteurs de ces modèles. D’un côté, les auteurs veulent savoir si leurs œuvres ont été utilisées dans le cadre de l’entraînement d’un modèle d’IA ».\n\nEn cas positif, les auteurs et ayants droit veulent pouvoir soit s’y opposer, en exerçant leur droit de « opt out », un droit prévu par la directive de 2019 qui permet aux titulaires de droit de refuser que leurs oeuvres soient utilisées pour entraîner une IA, soit pouvoir négocier une licence de droit d’auteur. Mais encore faut-il qu’ils aient accès à cette information – ce qui n’était jusqu’à présent pas le cas.\n\n« D’un autre côté, les producteurs de ces modèles d’IA veulent protéger le secret des affaires. Comme souvent, le législateur a cherché un équilibre : seules les œuvres soumises aux droits d’auteur doivent être révélées, pas l’ensemble des données », explique le docteur en droit privé.\n\nEt si l’AI Act impose aux fournisseurs d’IA de respecter la loi sur le droit d’auteur et les droits voisins, les trois documents annexes publiés en juillet par la Commission européenne ont laissé les ayants droit sur leur faim. Le modèle relatif au droit d’auteur impose aux fournisseurs d’IA de révéler tous les « grands » ensembles de données accessibles au public, ainsi que les 10 % des noms de domaines les plus utilisés, mais il ne s’agit pas d’une liste exhaustive.\n\nLe code de bonnes pratiques, qui comporte un volet spécifique au droit d’auteur, rappelle que les fournisseurs d’IA générative sont bien tenus de respecter le droit d’auteur, sans prévoir de mécanisme de licence obligatoire. Les mentions précédentes d’obligation de moyens de respecter le droit d’auteur ont été supprimées. Le tout est insuffisant pour les ayants droit qui espéraient pouvoir se baser sur cette liste pour réclamer le paiement de droit d’auteur ou de dommages et intérêt.\n\nPour Patrick Kuban, co-président de la fédération internationale UVA (United Voice Artists) et animateur du collectif français hashtag#TouchePasMaVF, « le niveau de détail des données collectées est malheureusement très faible (…). Les ayants droit vont continuer d’être spoliés. L’Europe est en train de plier face aux lobbys essentiellement non-européens ». Pour le comédien de voix off, « le niveau de détail requis dans les résumés des Dataset (données d’entraînement des IAG) est très insuffisant. Les promesses de l’IA Act censées protéger les créateurs ne sont pas au rendez-vous ».\n\nCe « résumé » devra être publié par les fournisseurs d’IA à partir du 2 août 2025, et « au plus tard le 2 août 2027 ». Il s’agit d’un délai bien trop long pour les titulaires de droit, dont certains plaident pour lancer une réforme du droit d’auteur décrit comme inadapté face à l’IA générative.\n\nLes sanctions vont-elles tomber dès le 3 août ?\n\nSi les fournisseurs d’IA ne respectent pas leurs obligations, les sanctions sont particulièrement salées, ces dernières pouvant atteindre 3 % du chiffre d’affaires annuel mondial ou 15 millions d’euros. Pour autant, les amendes ne devraient pas tomber dès le 3 août 2025.\n\nPour Arnaud Latil, « les régulateurs ne vont pas contrôler et sanctionner les acteurs, dès le lendemain de la mise en application des textes. Si on prend un parallèle historique avec le RGPD, il est rentré en vigueur en 2018. Dès le lendemain de son application, on n’a pas vu la CNIL taper à toutes les portes pour aller contrôler tous les acteurs. D’un côté, il y a une date d’application des textes, et de l’autre, il y a aussi le temps de l’action de la régulation. Le régulateur poursuit plusieurs missions : information, conseil, contrôle et enfin sanction. La sanction n’intervient pas avant les opérations que je viens de décrire ».\n\nLe contexte géopolitique et la pression de l’administration Trump pourraient-ils changer la donne ? Le spécialiste estime qu’« on peut être un tout petit peu inquiet quand on voit le détricotage de la réglementation environnementale à peine née. Et pour le numérique, il y a un risque équivalent ».",
         "2025-07-26T05:45:40",
         "https://www.01net.com/rss/actualites/",
         "https://www.01net.com/actualites/ai-act-un-changement-de-taille-attend-les-geants-de-lia-le-2-aout-prochain-quest-ce-que-ca-va-changer.html",
         "2025-07-26T05:53:45.874663",
         "Les entreprises qui développent les outils d’IA générative les plus utilisés comme ChatGPT ou Copilot devront montrer patte blanche en Europe, à compter du 2 aout 2025, nouvelle entrée en application de l’AI Act, le règlement européen sur l’intelligence artificielle. Voici ce qui va changer à partir de début août, malgré les très nombreux appels ou pressions visant à retarder ou suspendre cette échéance. ChatGPT, Claude et Perplexity n’ont plus que quelques jours pour se conformer à l’AI Act, le règlement européen sur l’intelligence artificielle (IA). Après l’interdiction des systèmes d’IA avec des risques inacceptables (comme les outils de notation sociale) devenue effective en février dernier, c’est au tour des modèles d’IA à portée générale (appelés dans la loi européenne les « GPAI » pour « General-Purpose artificial intelligence ») de montrer patte blanche. L’AI Act, entré en vigueur le 1er août 2024, s’applique de manière échelonnée jusqu’en 2030. Et à partir du 2 août 2025, c’est au tour des « GPAI », les modèles conçus pour accomplir plusieurs tâches comme la rédaction, la génération d’images, la recherche ou du calcul, de se conformer à la loi européenne. Pour mesurer ce qui devra bientôt s’appliquer à ChatGPT, Le Chat, Gemini, Copilot, Midjourney et Claude, nous nous sommes entretenus avec Arnaud Latil, auteur du Droit du numérique, une approche par les risques, et maître de conférences en droit privé à la Sorbonne Université. Qui est concerné par la nouvelle échéance de l’AI Act ? À compter du 2 août prochain, les fournisseurs de modèles GPAI, mis sur le marché européen, doivent se conformer à l’AI Act. Il s’agit des outils d’IA capables de générer texte, image, code, analyses, retranscription écrite… qui peuvent être aussi intégrés à d’autres outils. Contrairement à la désignation des très grandes plateformes et des contrôleurs d’accès en matière de DSA ou de DMA, la Commission ne va pas publier une liste des modèles concernés. Mais « les entreprises qui font parties de l’AI Pact et qui ont signé le code de bonnes pratiques reconnaissent que leur modèle entre dans la catégorie des modèles GPAI », souligne Arnaud Latil. Pour savoir quels modèles sont concernés, il existe une « présomption liée à la puissance de calcul utilisée, mais il ne s’agit que d’une présomption, et au-delà, la Commission européenne peut les classer en fonction d’une série de critères qui est très longue », précise le docteur en droit. Tout dépendra de la façon dont la Commission interprète cette liste de critères. Les « lignes directrices », un document publié mi juillet par la Commission européenne, précisent davantage quels modèles sont concernés. Bruxelles a notamment fixé des seuils à partir desquels un modèle d’IA tomberait dans la catégorie des « fournisseurs d’IA » à portée générale : « ses ressources de calcul pour son entrainement (doivent être) supérieures à 1023 (opérations en virgule flottante) FLOP et il (doit pouvoir) générer du langage (que ce soit sous forme de texte ou d’audio), du texte à l’image ou du texte à la vidéo », détaille le texte. Selon tous ces éléments, les modèles d’IA concernés par l’échéance du 2 août seront donc vraisemblablement tous les modèles d’IA générative utilisés par le grand public à partir de fin 2022, à savoir : ChatGPT (OpenAI), Copilot (Microsoft), Le Chat (Mistral), Claude (Anthropic), Llama (Meta), et leurs concurrents. À quoi seront-ils tenus en pratique ? À partir du 2 août, ces GPAI doivent se conformer à des obligations de transparence. Ils devront notamment préparer toute une documentation technique qui pourra être partagée avec le « Bureau de l’IA », une émanation de la Commission européenne chargée d’appliquer l’AI Act, et les autorités nationales compétentes, sur demande. Les fournisseurs en aval — ceux qui utilisent ces outils pour une application spécifique — pourront aussi y avoir accès. Les développeurs de GPAI ont aussi l’obligation de respecter le droit d’auteur, et remplir le modèle de résumé des sources utilisées pour entraîner leurs outils d’IA, un modèle publié par Bruxelles jeudi dernier. Enfin, pour les GPAI qui « présentent un risque systémique », des obligations supplémentaires d’évaluations et d’atténuations des risques devront être respectées. Il s’agit d’outils d’IA qui pourraient avoir un impact significatif sur les droits fondamentaux, la société, ou la santé publique. Pour se conformer à ces nouvelles obligations, les fournisseurs d’IA peuvent s’appuyer sur trois autres textes publiés courant juillet, qui sont venus préciser l’AI Act : le code de bonnes pratiques, dont la version finale a été publiée jeudi 10 juillet, les lignes directrices (publiées le vendredi 18 juillet), le modèle pour les sources d’entraînement protégées par le droit d’auteur, publié jeudi 24 juillet. Ces documents étaient attendus depuis plusieurs mois. Pour certains, la rédaction de ces textes, qui est passée par une étape de concertation avec les géants de l’IA, les ayants droit et la société civile, a pu donner l’impression que la négociation de l’AI Act était toujours en cours. Pourtant, ces actes de précision ou d’exécution n’ont rien de surprenant, rappelle Arnaud Latil. La Commission européenne peut « rédiger des actes d’exécution ou des décisions d’exécution, donc préciser des textes de loi. Cela permet de faire évoluer des textes sans rouvrir le cycle de négociation politique et sans forcément réviser les textes dans leur ensemble », détaille le chercheur au Centre d’études et de recherches en droit de l’immatériel (Université Paris-Saclay). Le code de bonnes pratiques « n’est pas un document obligatoire, mais il permet aux opérateurs de suivre des recommandations pour être conforme » à l’AI Act, souligne le maître de conférences en droit privé. Le modèle qui a trait au droit d’auteur est, quant à lui, bien obligatoire. Les fournisseurs d’IA devront le remplir – et détailler pour la première fois les sources principales utilisées pour entraîner leur modèle, une première – bien que les ayants droit estiment que le degré de précision est loin d’être suffisant. Y aura-t-il un délai de grâce ? La rédaction et la publication de ces trois documents ont eu lieu au beau milieu d’appels à décaler voire suspendre l’application de l’AI Act pour les outils d’IA générative, des appels provenant des industries de l’IA, mais aussi de certains pays de l’Union européenne. Business Europe, le Medef européen, a demandé le 17 juillet dernier « une période de grâce pour implémenter le code de bonnes pratiques sur les modèles à usage général », précédant un message similaire provenant cette fois d’une quarantaine d’entreprises et d’organisations européennes. Le tout s’inscrit dans un contexte géopolitique de négociations de droits de douane de l’administration Trump, qui est vent debout contre une telle règlementation. Pour autant, la Commission européenne a rappelé qu’il n’y aurait ni report ni délai de grâce. « Le règlement sur l’IA a été adopté selon une procédure conforme aux principes de l’état de droit. Il paraît impossible de décider de ne pas appliquer ce texte. Le législateur européen a décidé d’appliquer l’AI Act à une date donnée, sachant que la date à elle-même fait l’objet d’une discussion politique, au même titre que les autres dispositions », rappelle Arnaud Latil. Suivant la même logique, le fait de ne pas signer le code de bonnes pratiques (non obligatoire) – une approche adoptée par Meta, vendredi 18 juillet – ne change rien à l’application de l’AI Act. Il y aura toutefois un avantage à faire partie des signataires, dont feront partie la start-up française Mistral, et OpenAI, l’entreprise américaine à l’origine de ChatGPT, selon leurs déclarations : le signer permettra de bénéficier d’une présomption de conformité. Selon un journaliste de MLex, la Commission européenne a suggéré qu’un délai de grâce serait accordé aux signataires du code pour la première année. « En particulier, si ces prestataires ne mettent pas en œuvre tous les engagements immédiatement après avoir signé le code, le Bureau de l’IA ne considérera pas qu’ils ont rompu leurs engagements au titre du code et ne leur reprochera pas d’avoir enfreint la loi sur l’AI. Au contraire, dans de tels cas, le Bureau de l’IA considérera qu’ils ont agi de bonne foi et sera prêt à collaborer pour trouver des moyens d’assurer une conformité totale », écrit-il. En termes de droit d’auteur, les ayants droit et les auteurs toujours mécontents Pour l’échéance du 2 août, la question du droit d’auteur a été âprement discutée. Comme le rappelle Arnaud Latil, le droit d’auteur est « enjeu extrêmement important, à la fois pour les ayants droits, pour les auteurs et pour les producteurs de ces modèles. D’un côté, les auteurs veulent savoir si leurs œuvres ont été utilisées dans le cadre de l’entraînement d’un modèle d’IA ». En cas positif, les auteurs et ayants droit veulent pouvoir soit s’y opposer, en exerçant leur droit de « opt out », un droit prévu par la directive de 2019 qui permet aux titulaires de droit de refuser que leurs oeuvres soient utilisées pour entraîner une IA, soit pouvoir négocier une licence de droit d’auteur. Mais encore faut-il qu’ils aient accès à cette information – ce qui n’était jusqu’à présent pas le cas. « D’un autre côté, les producteurs de ces modèles d’IA veulent protéger le secret des affaires. Comme souvent, le législateur a cherché un équilibre : seules les œuvres soumises aux droits d’auteur doivent être révélées, pas l’ensemble des données », explique le docteur en droit privé. Et si l’AI Act impose aux fournisseurs d’IA de respecter la loi sur le droit d’auteur et les droits voisins, les trois documents annexes publiés en juillet par la Commission européenne ont laissé les ayants droit sur leur faim. Le modèle relatif au droit d’auteur impose aux fournisseurs d’IA de révéler tous les « grands » ensembles de données accessibles au public, ainsi que les 10 % des noms de domaines les plus utilisés, mais il ne s’agit pas d’une liste exhaustive. Le code de bonnes pratiques, qui comporte un volet spécifique au droit d’auteur, rappelle que les fournisseurs d’IA générative sont bien tenus de respecter le droit d’auteur, sans prévoir de mécanisme de licence obligatoire. Les mentions précédentes d’obligation de moyens de respecter le droit d’auteur ont été supprimées. Le tout est insuffisant pour les ayants droit qui espéraient pouvoir se baser sur cette liste pour réclamer le paiement de droit d’auteur ou de dommages et intérêt. Pour Patrick Kuban, co-président de la fédération internationale UVA (United Voice Artists) et animateur du collectif français hashtag#TouchePasMaVF, « le niveau de détail des données collectées est malheureusement très faible (…). Les ayants droit vont continuer d’être spoliés. L’Europe est en train de plier face aux lobbys essentiellement non-européens ». Pour le comédien de voix off, « le niveau de détail requis dans les résumés des Dataset (données d’entraînement des IAG) est très insuffisant. Les promesses de l’IA Act censées protéger les créateurs ne sont pas au rendez-vous ». Ce « résumé » devra être publié par les fournisseurs d’IA à partir du 2 août 2025, et « au plus tard le 2 août 2027 ». Il s’agit d’un délai bien trop long pour les titulaires de droit, dont certains plaident pour lancer une réforme du droit d’auteur décrit comme inadapté face à l’IA générative. Les sanctions vont-elles tomber dès le 3 août ? Si les fournisseurs d’IA ne respectent pas leurs obligations, les sanctions sont particulièrement salées, ces dernières pouvant atteindre 3 % du chiffre d’affaires annuel mondial ou 15 millions d’euros. Pour autant, les amendes ne devraient pas tomber dès le 3 août 2025. Pour Arnaud Latil, « les régulateurs ne vont pas contrôler et sanctionner les acteurs, dès le lendemain de la mise en application des textes. Si on prend un parallèle historique avec le RGPD, il est rentré en vigueur en 2018. Dès le lendemain de son application, on n’a pas vu la CNIL taper à toutes les portes pour aller contrôler tous les acteurs. D’un côté, il y a une date d’application des textes, et de l’autre, il y a aussi le temps de l’action de la régulation. Le régulateur poursuit plusieurs missions : information, conseil, contrôle et enfin sanction. La sanction n’intervient pas avant les opérations que je viens de décrire ». Le contexte géopolitique et la pression de l’administration Trump pourraient-ils changer la donne ? Le spécialiste estime qu’« on peut être un tout petit peu inquiet quand on voit le détricotage de la réglementation environnementale à peine née. Et pour le numérique, il y a un risque équivalent ».",
         "fr",
         "{'MISC': ['AI Act', 'AI Pact', 'ChatGPT', 'Copilot', 'DMA', 'Droit du numérique', 'GPAI', 'General-Purpose', 'IA Act', 'Le Chat', 'Mistral', 'OpenAI', 'Perplexity', 'RGPD'], 'LOC': ['AI', 'Anthropic', 'Bruxelles', 'Copilot', 'Dataset', 'Europe', 'Gemini', 'Llama', 'L’Europe', 'Université Paris-Saclay'], 'PER': ['Arnaud Latil', 'Claude', 'Midjourney', 'Patrick Kuban', 'Trump'], 'ORG': ['Bureau de l’IA', 'CNIL', 'Centre d’études et de recherches en droit de l’immatériel', 'Commission', 'Commission européenne', 'DSA', 'FLOP', 'IAG', 'MLex', 'Medef européen', 'Meta', 'Microsoft', 'Sorbonne Université', 'Union européenne', 'United Voice Artists', 'fédération internationale UVA']}",
         "[-0.06742265075445175, -0.013570837676525116, -0.0013289222260937095, -0.046219464391469955, -0.0415654294192791, 0.02478310652077198, 0.039737433195114136, 0.0823717936873436, -0.003654071595519781, 0.05670521408319473, 0.020342478528618813, -0.020363904535770416, -0.000485534081235528, -0.0027018932159990072, -0.046191468834877014, -0.04946606233716011, -0.02544538676738739, -0.05683014169335365, -0.07639460265636444, 0.01773606427013874, 0.050297416746616364, -0.020164472982287407, -0.001411012141034007, 0.04081887751817703, -0.06837465614080429, -0.017526384443044662, -0.009772231802344322, -0.06695152819156647, 0.016586722806096077, 0.019102511927485466, 0.03973211348056793, 0.06307865679264069, 0.07186368852853775, -0.04415610805153847, -0.012124486267566681, 0.00675892923027277, 0.010140812955796719, -0.04644487053155899, 0.002180007752031088, 0.008173193782567978, -0.031742095947265625, -0.0639759823679924, -0.06694827973842621, -0.023576484993100166, 0.03224152699112892, -0.015020391903817654, -0.018217094242572784, 0.02146857976913452, -0.17157931625843048, 0.020187003538012505, -0.08476598560810089, 0.006942761596292257, 0.03883320093154907, -0.03089621290564537, -0.016410674899816513, -0.0576724074780941, -0.039008982479572296, 0.005504959262907505, 0.035639841109514236, 0.0008051564800553024, 0.020026760175824165, -0.08307729661464691, 0.07402880489826202, -0.0385330393910408, -0.06764660775661469, 0.060313839465379715, -0.013550537638366222, -0.0494845025241375, 0.017616458237171173, -0.018646590411663055, 0.07021667808294296, -0.07185275107622147, -0.11220528185367584, -0.003673736471682787, 0.04554641246795654, 0.035076890140771866, -0.0331336185336113, -0.01898147724568844, -0.0010816005524247885, -0.1647063046693802, 0.06000082939863205, 0.024217115715146065, 0.004419976845383644, -0.007105946075171232, -0.011525681242346764, -0.08072583377361298, 0.021903935819864273, -0.03450499847531319, 0.14552199840545654, -0.010165494866669178, 0.018272031098604202, -0.05958488956093788, -0.02653696946799755, 0.033551327884197235, 0.1289915144443512, -0.04283980280160904, 0.027010595425963402, -0.056248828768730164, -0.005308839026838541, 0.06783226132392883, 0.00782899372279644, -0.0009122826741077006, -0.017156148329377174, 0.027137670665979385, -0.010230107232928276, 0.030697984620928764, 0.025949813425540924, -0.06782118231058121, -0.04784778505563736, -0.014142087660729885, -0.10218680649995804, -0.0641515702009201, 0.06534764915704727, -0.05895410478115082, 0.04588528722524643, -0.030252300202846527, -0.007298293057829142, 0.01963845081627369, 0.05933072417974472, 0.016527997329831123, 0.06561438739299774, -0.048974744975566864, 0.015024013817310333, 0.028926432132720947, 0.06890103965997696, 0.07981836795806885, -0.049884386360645294, 1.0352733031325432e-32, -0.04062812775373459, -0.021635759621858597, -0.03942067548632622, 0.05070718005299568, -0.021139418706297874, -0.03751986473798752, -0.0573483444750309, -0.027532823383808136, 0.04439719766378403, -0.042868565768003464, -0.05536586418747902, 0.027603037655353546, 0.003623238066211343, 0.09847905486822128, 0.09916531294584274, 0.05803951248526573, 0.0845976248383522, 0.02500198222696781, 0.04629988223314285, -0.03633729740977287, 0.03303886577486992, 0.038267944008111954, 0.05006587505340576, -0.007703529205173254, 0.04597090184688568, 0.1038854643702507, -0.012885160744190216, -0.12708784639835358, -0.025881005451083183, 0.02644699439406395, 0.029785024002194405, 0.012375704944133759, -0.044636569917201996, 0.04602290689945221, 0.010871748439967632, -0.032088782638311386, -0.013274959288537502, 0.008753737434744835, 0.008450837805867195, 0.03529379889369011, 0.02761239744722843, 0.004887161776423454, 0.018012119457125664, -0.02045518532395363, 0.08818496763706207, -0.038753826171159744, -0.0003101687761954963, 0.034342214465141296, -0.005476242862641811, -0.020223358646035194, -0.07166768610477448, 0.05587450787425041, -0.011043188162147999, -0.05851293355226517, 0.026280121877789497, -0.0303567536175251, -0.1330566555261612, 0.07514132559299469, -0.01647268608212471, -0.028044600039720535, -0.0074332826770842075, 0.018810423091053963, -0.0034845685586333275, 0.019816672429442406, 0.030467234551906586, 0.0013353381073102355, -0.07029332220554352, 0.04825262725353241, 0.022305648773908615, 0.010565374977886677, 0.010190589353442192, -0.014107836410403252, 0.009423289448022842, 0.02910233847796917, 0.07104199379682541, 0.036896105855703354, 0.036592788994312286, -0.039880815893411636, -0.08555451035499573, -0.03994456306099892, -0.14725133776664734, 0.02039615996181965, -0.07640833407640457, -0.05233738198876381, -0.016475316137075424, -0.05102253705263138, 0.032802384346723557, 0.049069177359342575, 0.07785475254058838, -0.00959001574665308, -0.06906799226999283, -0.014490083791315556, -0.02377716451883316, 0.06609725952148438, -0.05323368310928345, -1.256861335102237e-32, -0.03961922228336334, 0.03362777456641197, -0.10521650314331055, 0.020090913400053978, 0.0037257070653140545, 0.01699710264801979, -0.02896934002637863, -0.007824376225471497, -0.010036266408860683, -0.02376638539135456, -0.023014865815639496, -0.06120944768190384, 0.025201670825481415, -0.006802434101700783, 0.028947342187166214, 0.008375450037419796, -0.02994503267109394, -0.036093708127737045, -0.004374986048787832, 0.033522702753543854, 0.05961942300200462, -0.05423269793391228, -0.053625356405973434, -0.013246570713818073, 0.03248916566371918, 0.0068546077236533165, -0.01878741756081581, 0.03783990070223808, -0.015274401754140854, 0.001448053983040154, -0.013016683980822563, 0.05337466672062874, -0.014277822338044643, 0.09205363690853119, 0.037009671330451965, 0.06944432109594345, 0.08498804271221161, 0.02155059576034546, -0.08411754667758942, 0.05067221447825432, -0.0070392475463449955, 0.020965881645679474, -0.035424672067165375, -0.007745899725705385, 0.06112195551395416, 0.010691862553358078, -0.054692331701517105, -0.06309518963098526, -0.04699503630399704, -0.10199510306119919, 0.08382929116487503, 0.0008752020657993853, 0.022523516789078712, -0.06015528738498688, -0.037977613508701324, -0.0012476969277486205, 0.04246435686945915, -0.02377578243613243, -0.08445265144109726, 0.05510665848851204, 0.028263315558433533, 0.016100216656923294, 0.05661394074559212, -0.0631149485707283, 0.015668582171201706, -0.044089678674936295, -0.06410308927297592, 0.04755648225545883, 0.03136918321251869, -0.050298888236284256, 0.04630548506975174, -0.04826992750167847, -0.03008514642715454, 0.013377061113715172, 0.013793019577860832, 0.015925053507089615, 0.016442231833934784, 0.001165705150924623, -0.009835395961999893, -0.024361861869692802, -0.06591403484344482, -0.05741329863667488, 0.04302757605910301, 0.0031681712716817856, 7.77559180278331e-05, -0.017968812957406044, 0.00010267660400131717, 0.03260759264230728, 0.02452470362186432, -0.009105605073273182, 0.015814265236258507, 0.01563405431807041, -0.03895753249526024, 0.03996145725250244, -0.03178822994232178, -7.239199106834349e-08, 0.02626672573387623, 0.004170678555965424, -0.019556481391191483, 0.07936891168355942, 0.05764864757657051, -0.025900283828377724, -0.1301615983247757, -0.00703462865203619, -0.04315054416656494, 0.03363662213087082, -0.020252913236618042, -0.024764375761151314, -0.009482897818088531, -0.04034339264035225, 0.002363970736041665, 0.02175985462963581, -0.04044823348522186, -0.016705438494682312, -0.030688520520925522, 0.025875922292470932, 0.09020498394966125, -0.028112303465604782, -0.14241062104701996, -0.0985487848520279, -0.06759709119796753, -0.13066473603248596, -0.022576019167900085, -0.1135454848408699, -0.1414201557636261, 0.07064832746982574, -0.0038556959480047226, 0.05336252599954605, 0.045414820313453674, 0.031744785606861115, 0.06187727302312851, -0.0033969120122492313, 0.0017517686355859041, -0.042809247970581055, -0.014624478295445442, 0.02017843723297119, 0.10854199528694153, 0.02953232266008854, -0.03674326092004776, -0.05429605022072792, 0.1302926391363144, -0.09719034284353256, -0.05037063732743263, -0.09628856182098389, 0.027616363018751144, 0.08742507547140121, -0.04938753321766853, 0.07857554405927658, 0.013904369436204433, 0.07746558636426926, 0.10078033059835434, 0.012647110037505627, 0.017395511269569397, -0.04359976947307587, -0.03577866405248642, 0.039129771292209625, 0.05350835248827934, 0.11177822202444077, 0.00699467770755291, -0.09789589792490005]",
         "0.168"
        ],
        [
         "32",
         "340",
         "Un an après l'or : blues, bébé ou rebond pour nos champions ?",
         "L'année qui suit les JO est souvent particulière pour les athlètes. Il faut digérer cet évènement qui a demandé tant de préparation (et engendré tant d'émotions). Certains enchainent vers de nouvelles performances. D'autres connaissent un blues post-olympique. Un an après Paris 2024, France 24 dresse un panorama de l'après jeux des champions olympiques français.",
         "Un an après les JO : blues, maternité, nouveaux succès... Que sont devenus les champions français ?\n\nLe temps passe vite… Il y a déjà un an que les JO 2024 ont fait vibrer Paris lors d'un été suspendu, entre moments féériques au milieu des monuments parisiens et performances remarquables des sportifs et sportives françaises.\n\nAprès cela, il a fallu revenir à la réalité et au quotidien. Une vérité que les athlètes ont aussi due affronter dans une année post-olympique toujours particulière.\n\nÀ lire aussiJO 2024 : qui a apporté à la France ses 16 médailles d'or ?\n\nVoici ce que devient la cuvée 2024 des championnes et des champions olympiques tricolores.\n\nRugby à VII : les Bleus marquent le pas\n\nPour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nAvec le renfort d'Antoine Dupont, l’équipe de France masculine avait été sacrée championne olympique à Paris, décrochant la première des 16 médailles d'or françaises.\n\nCette année, les performances ont marqué le pas. Les tricolores ont atteint cette saison deux finales sur le circuit, perdues au Cap en décembre face à l’Afrique du Sud, puis à Hong Kong contre l’Argentine en mars. Lors de la finale du circuit mondial, ils n'ont pu faire mieux que la cinquième place.\n\nPendant ce temps, Antoine Dupont est revenu à la version à XV du rugby mais s'est blessé en mars lors du Tournoi du Six nations. Il se verrait bien défendre son titre en 2028, a-t-il avoué dans l'Équipe.\n\nLa cycliste Pauline Ferrand-Prévot sur un chemin pavé de succès\n\nPour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nLa légende du cyclisme a été parmi les premières à faire vibrer le public français lors des JO. Sur la colline d'Elancourt, elle est parvenue à conquérir le titre qui lui avait échappé lors des précédentes olympiades.\n\nÀ lire aussiDans la peau des VTTistes olympiques : la colline d’Élancourt rouvre au public\n\nDans la foulée d'un podium émouvant, elle avait annoncé ses prochaines ambitions. Un retour au cyclisme sur route avec l'ambition de remporter le tout nouveau Tour de France Femmes dans les trois années qui arrivaient.\n\nElle lancera sa première tentative samedi 26 juillet. Sa première partie de saison fut convaincante, avec en point d'orgue une victoire historique sur Paris-Roubaix en avril.\n\nNatation : \"qu'est-ce qui anime vraiment Léon cette saison ?\"\n\nPour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nStar annoncée des JO 2024, Léon Marchand n'a pas failli. À lui seul, il a apporté quatre médailles d'or à la France en natation, dont un fantastique doublé dans la même soirée.\n\nComment se remettre de ces émotions et de ce nouveau statut de star ? Cette interrogation semble travailler le nageur toulousain en cette année post-olympique. Épuisé, il avait renoncé aux Championnats du monde en petit bassin en novembre 2024 à Budapest. Pour se ressourcer, il est parti trois mois en Australie pour découvrir de nouvelles choses.\n\nS'il a repris la compétition en Floride, il a fait l'impasse sur les championnats de France, ce qui commence à crisper du côté de la Fédération française de natation : \"Le vrai questionnement est : qu'est-ce qui anime vraiment Léon cette saison ? Je veux savoir s'il veut vraiment faire les Championnats du monde ou pas\", interrogeait début mai dans l'Équipe le directeur technique national par intérim Denis Auguin.\n\nPour les championnats du monde fin juillet, il a allégé son programme pour se concentrer sur le record du monde du 200 m 4 nages.\n\nCanoë kayak : Nicolas Gestin, retour gagnant\n\nPour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nPour ses premiers JO, Nicolas Gestin a su faire de la base nautique de Vaires-sur-Marne sa maison. Il avait décroché l'or avec la manière : un exploit rarissime dans l'histoire du slalom en remportant les quatre manches au programme de la compétition, les deux de qualifications, la demi-finale et la finale, le tout devant Tony Estanguet, légende de la discipline et patron de Paris 2024.\n\nUn an plus tard, Nicolas Gestin n'a pas connu de passage à vide : \"Après les JO, j'ai pris le temps de faire des bilans, d'échanger avec Tony [Estanguet, NDLR], Denis [Gargaud, NDLR] et d'autres kayakistes. J'ai aussi fait un break en allant surfer et en allant faire du ski de fond. Je me suis autorisé des trucs qui m'ont fait du bien et m'ont permis de me ressourcer\", a-t-il expliqué à l'Équipe à l'heure de la reprise. \"Je repars avec de nouvelles ambitions, j'ai de nouvelles victoires à aller chercher : je n'ai jamais été champion d'Europe, ni champion du monde et je n'ai jamais gagné une manche de Coupe du monde mythique comme celle de Prague.\"\n\nSi le titre européen lui a échappé de peu (médaille d'argent), il a bien remporté la Coupe de Prague en juin dernier. Il a désormais les yeux rivés sur les championnats du monde en Australie fin septembre.\n\nL'escrimeuse Manon Apithy-Brunet devient maman\n\nPour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nC'est l'une des images de Paris 2024 : Manon Apithy-Brunet à genoux, le visage caché dans le cou de Boladé Apithy, son mari escrimeur lui aussi. Lui célèbre le titre de sa femme quand celle-ci n'a pas encore totalement réalisé.\n\nUn an après, le couple a profité de l'année post-JO pour accueillir leur premier enfant. Le petit Orisha est né le 28 juin dernier. Un bébé qui va bouleverser le quotidien de la championne olympique qui se projette tout de même vers Los Angeles, avec un retour à l'entraînement en septembre.\n\n\"Il n'y aura peut-être pas moins de pression parce que j'ai envie de gagner. Mais je sais que le côté important de la vie ne sera pas forcément de gagner mais d'être avec lui\", a fait valoir la Française auprès de RMC.\n\nTriathlon : Cassandre Beaugrand domine toujours\n\nPour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nElle en rêvait après le traumatisme de Tokyo et elle l'a fait. Cassandre Beaugrand est devenue la première championne olympique française de triathlon au terme d'un triple effort dans la Seine et dans les rues de Paris. Dans la foulée, elle avait conquis le titre de championne du monde WTCS à Torremolinos, en Espagne, lors de l'ultime épreuve du championnat.\n\nEn 2025, la championne est repartie sur les mêmes bases : victoire sur la Coupe du monde de triathlon en salle de Liévin le 22 puis le Championnat du monde de Supertri E à Londres.\n\nSeule mauvaise surprise, une vilaine chute lors de sa reprise sur le circuit WTCS en mai. Mais depuis, elle a remporté l'étape de Alghero en Italie et a terminé à la deuxième place à Hambourg.\n\nL'équipe de France de volley : Final 8 de Ligue des nations en vue\n\nPour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nLes doubles champions olympiques viennent d'attaquer leur saison internationale. Cette génération espère décrocher sa première médaille mondiale fin juillet au Final 8 de Niangbo (Chine) ou au Championnat du monde (12-28 septembre) à Manille.\n\nUn peu à la peine sur les qualifications de la Ligue des nations, la faute à l'absence de cadres retenus par leurs clubs, les Bleus ont finalement composté leur ticket pour la fin de la compétition.\n\nBMX : Joris Daudet, la chasse aux partenaires\n\nPour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nDouze mois après le triplé historique du BMX français, c'est l'heure de la soupe à la grimace pour Joris Daudet. En mai dernier, il s'est permis un coup de gueule sur France Info.\n\nÀ lire aussiJO 2024 : Joris Daudet, Sylvain André et Romain Mahieu signent un fabuleux triplé en BMX racing\n\n\"Avec le triplé historique, on pensait que ça allait nous aider, on s'attendait à avoir des partenariats\", décrit le champion olympique de 34 ans. \"On a tapé à la porte de pas mal de choses, mais souvent ils nous ont répondu qu'ils ne sont pas intéressés, qu'il n'y a pas d'argent. On n'est pas un pays dit 'sportif'... Quand on est champion olympique, on n'arrive pas à avoir un partenaire…\"\n\nTaekwondo : Althéa Laurin a perdu des sponsors\n\nPour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nMême mésaventure du côté d'Althéa Laurin, la taekwondoïste qui fut de manière anecdotique la dernière médaille d'or française des JO 2024.\n\n\"J’ai perdu environ un tiers de mes sponsors après les Jeux ! J’ai eu la chance que des fidèles me suivent, mais pour d’autres, les JO étaient passés, c’était terminé… C’était une très mauvaise surprise\", a-t-elle regretté dans Ouest-France.\n\nSur le plan sportif en revanche, la reprise s'est bien passée : elle a été sacrée à l'Open de Turquie.\n\nJudo : Teddy Riner ne se presse pas pour reprendre\n\nPour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nAlors qu'il devait initialement prendre sa retraite à l'issue des Jeux de Paris, les deux médailles d'or conquises ont finalement eu un goût de reviens-y pour Teddy Riner, qui vise désormais LA 2028.\n\nS'il a aidé son club, le PSG, à remporter la Ligue des champions en décembre, il a ensuite été opéré du coude droit durant l'hiver pour soigner une vieille blessure. Depuis, il s'entraîne déjà mais préfère patienter pour son retour à la compétition.\n\n\"J’en ai encore sous le pied. Surtout, l'envie de vivre d'autres grands moments de sport est là. Un jour, je serai rassasié et ce sera l'heure de passer à autre chose. D'ici là, je mène de front le judo et la construction de mon après-carrière. Ça fonctionne comme je le désire, donc je ne vois pas pourquoi j'arrêterais\", a-t-il assuré récemment\n\nLe titre mondial échappe toujours à l'équipe de France de judo\n\nPour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nDouble championne olympique en titre, la France était remontée à bloc à l'idée de conquérir le titre mondial dans l'épreuve par équipes mixtes. Mais c'est raté pour 2025. L'équipe de France de judo a été battue par le Brésil en repêchages. Une vraie désillusion pour les Bleus qui n'ont pas été à la hauteur de leur statut.\n\nKauli Vaast veut accéder à l'élite du surf\n\nPour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nSur la vague de Teahupo'o, Kauli Vaast avait rendu fière toute la Polynésie, ravi de voir le local de 22 ans s'imposer à domicile. Après ce titre olympique, c'est sur le circuit mondial que Kauli Vaast veut briller.\n\n\"Mon objectif cette année est de me qualifier pour le Championship Tour. C'est là où je veux être\", a confié Kauli Vaast à propos de sa saison post-olympique.\n\nPour le moment, il évolue en Challenger Series, sorte de deuxième division du surf mondial. Les dix premiers surfeurs des Challengers Series seront automatiquement qualifiés pour le Championship Tour, le gratin du surf.\n\nCyclisme sur piste : Benjamin Thomas ne se fait \"pas encore reconnaitre dans la rue\"\n\nPour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nBenjamin Thomas n'a pas vraiment eu le temps de gamberger après sa médaille d'or acquis en omnium : \"Deux semaines après les Jeux, j'ai recouru avec Cofidis\", a-t-il expliqué au micro de France 24. \"Je n'ai pas eu le temps de vraiment souffler. J'ai repris un rythme normal cet hiver, une préparation normale.\"\n\nIl avoue que sa médaille n'a pas bouleversé sa vie mais qu'il y a quelques côtés positifs : \"Je ne me fais pas encore reconnaître dans la rue. Mais en France, il y a un peu plus de public qui vient sur les courses de vélo pour demander des photos ou me remercier. Ce sont des choses sympas.\"\n\nEn termes de résultats, Benjamin Thomas n'a pas obtenu de victoires. Mais lors du Tour de France 2025 qu'il dispute actuellement, il a porté de manière éphémère le maillot à pois après son échappée sur la première étape.",
         "2025-07-25T14:02:38",
         "https://www.france24.com/fr/rss",
         "https://www.france24.com/fr/sports/20250725-jo-2024-un-an-apres-or-medailles-champions-francais-jeux-olympiques",
         "2025-07-26T05:53:43.957688",
         "Un an après les JO : blues, maternité, nouveaux succès... Que sont devenus les champions français ? Le temps passe vite… Il y a déjà un an que les JO 2024 ont fait vibrer Paris lors d'un été suspendu, entre moments féériques au milieu des monuments parisiens et performances remarquables des sportifs et sportives françaises. Après cela, il a fallu revenir à la réalité et au quotidien. Une vérité que les athlètes ont aussi due affronter dans une année post-olympique toujours particulière. À lire aussiJO 2024 : qui a apporté à la France ses 16 médailles d'or ? Voici ce que devient la cuvée 2024 des championnes et des champions olympiques tricolores. Rugby à VII : les Bleus marquent le pas Pour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix Avec le renfort d'Antoine Dupont, l’équipe de France masculine avait été sacrée championne olympique à Paris, décrochant la première des 16 médailles d'or françaises. Cette année, les performances ont marqué le pas. Les tricolores ont atteint cette saison deux finales sur le circuit, perdues au Cap en décembre face à l’Afrique du Sud, puis à Hong Kong contre l’Argentine en mars. Lors de la finale du circuit mondial, ils n'ont pu faire mieux que la cinquième place. Pendant ce temps, Antoine Dupont est revenu à la version à XV du rugby mais s'est blessé en mars lors du Tournoi du Six nations. Il se verrait bien défendre son titre en 2028, a-t-il avoué dans l'Équipe. La cycliste Pauline Ferrand-Prévot sur un chemin pavé de succès Pour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix La légende du cyclisme a été parmi les premières à faire vibrer le public français lors des JO. Sur la colline d'Elancourt, elle est parvenue à conquérir le titre qui lui avait échappé lors des précédentes olympiades. À lire aussiDans la peau des VTTistes olympiques : la colline d’Élancourt rouvre au public Dans la foulée d'un podium émouvant, elle avait annoncé ses prochaines ambitions. Un retour au cyclisme sur route avec l'ambition de remporter le tout nouveau Tour de France Femmes dans les trois années qui arrivaient. Elle lancera sa première tentative samedi 26 juillet. Sa première partie de saison fut convaincante, avec en point d'orgue une victoire historique sur Paris-Roubaix en avril. Natation : \"qu'est-ce qui anime vraiment Léon cette saison ?\" Pour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix Star annoncée des JO 2024, Léon Marchand n'a pas failli. À lui seul, il a apporté quatre médailles d'or à la France en natation, dont un fantastique doublé dans la même soirée. Comment se remettre de ces émotions et de ce nouveau statut de star ? Cette interrogation semble travailler le nageur toulousain en cette année post-olympique. Épuisé, il avait renoncé aux Championnats du monde en petit bassin en novembre 2024 à Budapest. Pour se ressourcer, il est parti trois mois en Australie pour découvrir de nouvelles choses. S'il a repris la compétition en Floride, il a fait l'impasse sur les championnats de France, ce qui commence à crisper du côté de la Fédération française de natation : \"Le vrai questionnement est : qu'est-ce qui anime vraiment Léon cette saison ? Je veux savoir s'il veut vraiment faire les Championnats du monde ou pas\", interrogeait début mai dans l'Équipe le directeur technique national par intérim Denis Auguin. Pour les championnats du monde fin juillet, il a allégé son programme pour se concentrer sur le record du monde du 200 m 4 nages. Canoë kayak : Nicolas Gestin, retour gagnant Pour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix Pour ses premiers JO, Nicolas Gestin a su faire de la base nautique de Vaires-sur-Marne sa maison. Il avait décroché l'or avec la manière : un exploit rarissime dans l'histoire du slalom en remportant les quatre manches au programme de la compétition, les deux de qualifications, la demi-finale et la finale, le tout devant Tony Estanguet, légende de la discipline et patron de Paris 2024. Un an plus tard, Nicolas Gestin n'a pas connu de passage à vide : \"Après les JO, j'ai pris le temps de faire des bilans, d'échanger avec Tony [Estanguet, NDLR], Denis [Gargaud, NDLR] et d'autres kayakistes. J'ai aussi fait un break en allant surfer et en allant faire du ski de fond. Je me suis autorisé des trucs qui m'ont fait du bien et m'ont permis de me ressourcer\", a-t-il expliqué à l'Équipe à l'heure de la reprise. \"Je repars avec de nouvelles ambitions, j'ai de nouvelles victoires à aller chercher : je n'ai jamais été champion d'Europe, ni champion du monde et je n'ai jamais gagné une manche de Coupe du monde mythique comme celle de Prague.\" Si le titre européen lui a échappé de peu (médaille d'argent), il a bien remporté la Coupe de Prague en juin dernier. Il a désormais les yeux rivés sur les championnats du monde en Australie fin septembre. L'escrimeuse Manon Apithy-Brunet devient maman Pour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix C'est l'une des images de Paris 2024 : Manon Apithy-Brunet à genoux, le visage caché dans le cou de Boladé Apithy, son mari escrimeur lui aussi. Lui célèbre le titre de sa femme quand celle-ci n'a pas encore totalement réalisé. Un an après, le couple a profité de l'année post-JO pour accueillir leur premier enfant. Le petit Orisha est né le 28 juin dernier. Un bébé qui va bouleverser le quotidien de la championne olympique qui se projette tout de même vers Los Angeles, avec un retour à l'entraînement en septembre. \"Il n'y aura peut-être pas moins de pression parce que j'ai envie de gagner. Mais je sais que le côté important de la vie ne sera pas forcément de gagner mais d'être avec lui\", a fait valoir la Française auprès de RMC. Triathlon : Cassandre Beaugrand domine toujours Pour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix Elle en rêvait après le traumatisme de Tokyo et elle l'a fait. Cassandre Beaugrand est devenue la première championne olympique française de triathlon au terme d'un triple effort dans la Seine et dans les rues de Paris. Dans la foulée, elle avait conquis le titre de championne du monde WTCS à Torremolinos, en Espagne, lors de l'ultime épreuve du championnat. En 2025, la championne est repartie sur les mêmes bases : victoire sur la Coupe du monde de triathlon en salle de Liévin le 22 puis le Championnat du monde de Supertri E à Londres. Seule mauvaise surprise, une vilaine chute lors de sa reprise sur le circuit WTCS en mai. Mais depuis, elle a remporté l'étape de Alghero en Italie et a terminé à la deuxième place à Hambourg. L'équipe de France de volley : Final 8 de Ligue des nations en vue Pour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix Les doubles champions olympiques viennent d'attaquer leur saison internationale. Cette génération espère décrocher sa première médaille mondiale fin juillet au Final 8 de Niangbo (Chine) ou au Championnat du monde (12-28 septembre) à Manille. Un peu à la peine sur les qualifications de la Ligue des nations, la faute à l'absence de cadres retenus par leurs clubs, les Bleus ont finalement composté leur ticket pour la fin de la compétition. BMX : Joris Daudet, la chasse aux partenaires Pour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix Douze mois après le triplé historique du BMX français, c'est l'heure de la soupe à la grimace pour Joris Daudet. En mai dernier, il s'est permis un coup de gueule sur France Info. À lire aussiJO 2024 : Joris Daudet, Sylvain André et Romain Mahieu signent un fabuleux triplé en BMX racing \"Avec le triplé historique, on pensait que ça allait nous aider, on s'attendait à avoir des partenariats\", décrit le champion olympique de 34 ans. \"On a tapé à la porte de pas mal de choses, mais souvent ils nous ont répondu qu'ils ne sont pas intéressés, qu'il n'y a pas d'argent. On n'est pas un pays dit 'sportif'... Quand on est champion olympique, on n'arrive pas à avoir un partenaire…\" Taekwondo : Althéa Laurin a perdu des sponsors Pour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix Même mésaventure du côté d'Althéa Laurin, la taekwondoïste qui fut de manière anecdotique la dernière médaille d'or française des JO 2024. \"J’ai perdu environ un tiers de mes sponsors après les Jeux ! J’ai eu la chance que des fidèles me suivent, mais pour d’autres, les JO étaient passés, c’était terminé… C’était une très mauvaise surprise\", a-t-elle regretté dans Ouest-France. Sur le plan sportif en revanche, la reprise s'est bien passée : elle a été sacrée à l'Open de Turquie. Judo : Teddy Riner ne se presse pas pour reprendre Pour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix Alors qu'il devait initialement prendre sa retraite à l'issue des Jeux de Paris, les deux médailles d'or conquises ont finalement eu un goût de reviens-y pour Teddy Riner, qui vise désormais LA 2028. S'il a aidé son club, le PSG, à remporter la Ligue des champions en décembre, il a ensuite été opéré du coude droit durant l'hiver pour soigner une vieille blessure. Depuis, il s'entraîne déjà mais préfère patienter pour son retour à la compétition. \"J’en ai encore sous le pied. Surtout, l'envie de vivre d'autres grands moments de sport est là. Un jour, je serai rassasié et ce sera l'heure de passer à autre chose. D'ici là, je mène de front le judo et la construction de mon après-carrière. Ça fonctionne comme je le désire, donc je ne vois pas pourquoi j'arrêterais\", a-t-il assuré récemment Le titre mondial échappe toujours à l'équipe de France de judo Pour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix Double championne olympique en titre, la France était remontée à bloc à l'idée de conquérir le titre mondial dans l'épreuve par équipes mixtes. Mais c'est raté pour 2025. L'équipe de France de judo a été battue par le Brésil en repêchages. Une vraie désillusion pour les Bleus qui n'ont pas été à la hauteur de leur statut. Kauli Vaast veut accéder à l'élite du surf Pour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix Sur la vague de Teahupo'o, Kauli Vaast avait rendu fière toute la Polynésie, ravi de voir le local de 22 ans s'imposer à domicile. Après ce titre olympique, c'est sur le circuit mondial que Kauli Vaast veut briller. \"Mon objectif cette année est de me qualifier pour le Championship Tour. C'est là où je veux être\", a confié Kauli Vaast à propos de sa saison post-olympique. Pour le moment, il évolue en Challenger Series, sorte de deuxième division du surf mondial. Les dix premiers surfeurs des Challengers Series seront automatiquement qualifiés pour le Championship Tour, le gratin du surf. Cyclisme sur piste : Benjamin Thomas ne se fait \"pas encore reconnaitre dans la rue\" Pour afficher ce contenu Instagram, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix Benjamin Thomas n'a pas vraiment eu le temps de gamberger après sa médaille d'or acquis en omnium : \"Deux semaines après les Jeux, j'ai recouru avec Cofidis\", a-t-il expliqué au micro de France 24. \"Je n'ai pas eu le temps de vraiment souffler. J'ai repris un rythme normal cet hiver, une préparation normale.\" Il avoue que sa médaille n'a pas bouleversé sa vie mais qu'il y a quelques côtés positifs : \"Je ne me fais pas encore reconnaître dans la rue. Mais en France, il y a un peu plus de public qui vient sur les courses de vélo pour demander des photos ou me remercier. Ce sont des choses sympas.\" En termes de résultats, Benjamin Thomas n'a pas obtenu de victoires. Mais lors du Tour de France 2025 qu'il dispute actuellement, il a porté de manière éphémère le maillot à pois après son échappée sur la première étape.",
         "fr",
         "{'MISC': [\"Avec le renfort d'\", \"C'est l'une des images de Paris 2024\", 'Challenger Series', 'Challengers Series', 'Championnat du monde', 'Championnats du monde', 'Championnats du monde en petit bassin', 'Championship Tour', 'Coupe de Prague', 'Coupe du monde de triathlon en salle', 'Coupe du monde mythique', 'Double championne olympique', 'Elle en rêvait après le traumatisme de Tokyo', 'Final 8', 'Final 8 de Ligue des nations', 'JO', 'JO 2024', 'Jeux', 'Jeux !', 'Jeux de Paris', 'Léon', 'Même mésaventure du côté', 'Open de Turquie', 'Orisha', 'Star', \"Sur la vague de Teahupo'o\", 'Tour de France', 'Tour de France Femmes', 'Tournoi du Six nations', 'Triathlon', 'championnats de France', 'Ça'], 'LOC': ['Alghero', 'Argentine', 'Australie', 'Brésil', 'Budapest', 'Cap', 'Chine', 'Douze', 'Elancourt', 'Espagne', 'Europe', 'Floride', 'France', 'Française', 'Hambourg', 'Hong Kong', 'Instagram', 'Italie', 'Kauli Vaast', 'Liévin', 'Londres', 'Los Angeles', 'Manille', 'Niangbo', 'Paris', 'Paris-Roubaix', 'Polynésie', 'Prague', 'Rugby', 'Supertri E', 'Torremolinos', 'Vaires-sur-Marne', 'de France', 'la France', 'la Seine', 'l’Afrique du Sud', 'post-JO', 'Élancourt'], 'ORG': ['Bleus', 'Cofidis', 'France Info', 'Fédération française de natation', 'Ligue des champions', 'Ligue des nations', 'Ouest-France', 'PSG', 'RMC', 'Taekwondo', 'WTCS', \"l'Équipe\"], 'PER': ['Althéa Laurin', 'Antoine Dupont', 'Benjamin Thomas', 'Boladé Apithy', 'Cassandre Beaugrand', 'Denis Auguin', 'Denis [Gargaud', 'Joris Daudet', 'Kauli Vaast', 'Léon Marchand', 'Manon Apithy-Brunet', 'NDLR', 'Nicolas Gestin', 'Pauline Ferrand-Prévot', 'Romain Mahieu', 'Sylvain André', 'Teddy Riner', 'Tony Estanguet', 'Tony [Estanguet', 'gamberger']}",
         "[0.006470303051173687, 0.0776289701461792, -0.005959019996225834, -0.09722238779067993, -0.002925700042396784, 0.0924137532711029, -0.002097079763188958, 0.060348354279994965, 0.019443387165665627, 0.0724223181605339, -0.09088639169931412, -0.09126335382461548, 0.029781412333250046, -0.009076169691979885, -0.017947180196642876, -0.048031534999608994, -0.04342269152402878, -0.009172821417450905, -0.07344556599855423, 0.08342840522527695, 0.057460688054561615, -0.07512784004211426, -0.01461607962846756, 0.07663761079311371, -0.09081611782312393, -0.07401180267333984, -0.03213004395365715, 0.01528120692819357, -0.04307866096496582, 0.026971396058797836, -0.02486550062894821, 0.02047792077064514, 0.00039989143260754645, -0.0368228554725647, -0.002300836844369769, -0.1082802265882492, 0.029254578053951263, -0.05186630040407181, -0.02480333484709263, 0.052623480558395386, -0.012584883719682693, -0.010667533613741398, -0.09890615195035934, 0.029151367023587227, -0.03932306170463562, -0.0012240299256518483, 0.038791052997112274, 0.035819001495838165, -0.09823177009820938, 0.0023701987229287624, 0.004442901350557804, 0.007258872035890818, 0.058974239975214005, -0.03938670828938484, -0.0403103269636631, -0.06188694015145302, -0.09429749101400375, -0.03117508627474308, 0.09944960474967957, 0.033483605831861496, 0.03165270388126373, -0.02980383113026619, -0.016895748674869537, 0.009996380656957626, -0.09244370460510254, -0.0299239382147789, 0.035214170813560486, -0.039350368082523346, -0.049700938165187836, 0.04669353738427162, 0.03901016712188721, -0.020554866641759872, -0.014347270131111145, -0.05610455572605133, 0.06007714942097664, 0.14439746737480164, -0.05665455013513565, 0.006243131589144468, -0.05595232546329498, -0.18200288712978363, 0.09149036556482315, -0.12451894581317902, 0.020454449579119682, 0.019332697615027428, 0.06578080356121063, 0.015358703210949898, 0.061097387224435806, 0.00025401354650966823, 0.039704933762550354, -0.00040731890476308763, -0.052629947662353516, -0.00817094650119543, -0.0425187423825264, 0.030063653364777565, 0.05303367227315903, 0.0034533694852143526, 0.026118220761418343, -0.08197636157274246, 0.07434610277414322, 0.04109528288245201, -0.008922175504267216, 0.019945012405514717, 0.028472453355789185, 0.05473964288830757, 0.005976607091724873, 0.015299239195883274, -0.03420489653944969, -0.009942170232534409, 0.00027251511346548796, 0.003957761917263269, 0.02815876714885235, 0.012024924159049988, 0.0019157472997903824, -0.0037323080468922853, -0.03076564520597458, 0.04713483527302742, -0.04335876181721687, -0.06124398484826088, 0.041944246739149094, -0.06758593022823334, 0.05750643461942673, 0.023323891684412956, -0.0008771217544563115, -0.06657673418521881, 0.06148603558540344, 0.0036258159670978785, 0.009069452993571758, 9.541004223572732e-33, 0.02690029889345169, 0.04184649884700775, -0.012389246374368668, 0.008245854638516903, -0.02214871533215046, -0.002286519855260849, -0.01363422628492117, 0.052748531103134155, -0.0027384040877223015, -0.03158436343073845, -0.04348742589354515, 0.05414273962378502, 0.022673334926366806, 0.04914044216275215, 0.12643767893314362, 0.04391416907310486, 0.1067613810300827, -0.08435369282960892, 0.0320272371172905, 0.01396286953240633, -0.0021524850744754076, 0.054860107600688934, 0.03744889050722122, 0.09792943298816681, -0.008323810063302517, 0.06349500268697739, 0.004867144860327244, -0.04315099120140076, -0.08638104796409607, 0.02651412971317768, 0.018845245242118835, -0.0340270921587944, -0.026683557778596878, -0.01847480982542038, 0.03059535287320614, 0.009244798682630062, -0.004905402660369873, 0.012836005538702011, 0.042946986854076385, 0.023272236809134483, 0.047603119164705276, 0.005449679214507341, -0.03921119496226311, -0.05801935866475105, -0.014169794507324696, 0.020204002037644386, 0.0042795888148248196, -0.03284380957484245, 0.050432998687028885, 0.023947909474372864, -0.02690507471561432, 0.061291471123695374, -0.03999124839901924, -0.06813514232635498, 0.037126023322343826, -0.059980716556310654, -0.03378032147884369, 0.0052299946546554565, -0.08252491801977158, -0.0826423317193985, 0.04037711024284363, -0.018111063167452812, -0.0064341044053435326, 0.029695846140384674, -0.054797716438770294, -0.006909721065312624, 0.0005999065469950438, 0.016197457909584045, -0.04409610480070114, -0.08752412348985672, -0.03356781229376793, -0.018294936046004295, 0.04646259918808937, -0.07574893534183502, 0.057839155197143555, 0.08031223714351654, 0.034455448389053345, 0.01902972161769867, -0.011130034923553467, 0.009648757986724377, -0.022814560681581497, 0.0027891702484339476, -0.04123350605368614, -0.03847446292638779, -0.03620469197630882, -0.06195509061217308, 0.06481289118528366, 0.06902079284191132, 0.007552491035312414, -0.030335145071148872, -0.05494491755962372, -0.08507987856864929, 0.034259628504514694, 0.04478657245635986, -0.0906892940402031, -1.2244606700317438e-32, -0.01465088501572609, 0.052405308932065964, 0.02023952454328537, 0.11665603518486023, 0.040234826505184174, -0.011898715049028397, 0.035447508096694946, 0.05184836685657501, 0.003164545400068164, -0.0814540833234787, 0.03647714853286743, -0.007818375714123249, 0.013520936481654644, 0.021639639511704445, -0.022763768211007118, 0.0414198599755764, -0.04894593358039856, -0.05416681244969368, -0.06394194066524506, -0.018164264038205147, 0.003910142928361893, 0.017620626837015152, 0.05415162444114685, -0.04404433071613312, -0.0069423578679561615, 0.02024153247475624, 0.04170487821102142, -0.016901671886444092, -0.08534050732851028, -0.03870585933327675, 0.011697002686560154, 0.048415083438158035, 0.056961122900247574, 0.029305288568139076, 0.03799643740057945, 0.036088839173316956, 0.10071870684623718, 0.016627760604023933, -0.028544830158352852, 0.12345154583454132, -0.04015073552727699, 0.026355139911174774, 0.005543924402445555, 0.016888948157429695, 0.03400491550564766, -0.03129667788743973, -0.06512293964624405, -0.05949407070875168, 0.01745639368891716, 0.0014500432880595326, 0.04280181601643562, 0.036716148257255554, -0.04649002477526665, -0.021121913567185402, 0.025908850133419037, -0.0034325290471315384, 0.0002043670101556927, -0.010844854637980461, -0.1052207201719284, 0.02124408632516861, 0.01968749426305294, 0.05354422703385353, -0.02067112922668457, -0.016318269073963165, 0.019806403666734695, 0.022083235904574394, -0.10975724458694458, -0.008953966200351715, -0.04648161306977272, -0.015365752391517162, 0.003995178267359734, -0.016845550388097763, -0.05180248245596886, 0.05629733204841614, -0.05071452632546425, -0.025594379752874374, -0.013809215277433395, 0.016309456899762154, 0.005710037890821695, 0.09920411556959152, -0.16532807052135468, 0.0165800079703331, 0.007091301493346691, -0.009734227322041988, -0.028493763878941536, 0.06965099275112152, -0.011472909711301327, -0.022534223273396492, 0.029207568615674973, -0.08427495509386063, 0.11315670609474182, 0.010691761039197445, 0.04232218861579895, -0.03215569630265236, 0.061863820999860764, -6.474596858652149e-08, 0.05273490399122238, -0.010694844648241997, -0.05886860191822052, 0.0264724250882864, -0.05756835639476776, -0.11332634836435318, -0.050181299448013306, -0.05484491214156151, 0.0057198842987418175, 0.04990607872605324, 0.0017344243824481964, 0.011393330059945583, 0.0034907173831015825, -0.006419754587113857, -0.08164244145154953, 0.017134899273514748, -0.06267150491476059, -0.046080347150564194, -0.07760140299797058, 0.019256414845585823, -0.011615287512540817, -0.0259822066873312, -0.02081448957324028, -0.08695389330387115, -0.010582370683550835, -0.0911114364862442, -0.08169285953044891, -0.09806094318628311, -0.04288436844944954, 0.03021961636841297, 0.028501594439148903, 0.011338485404849052, 0.000643092964310199, -0.1489454060792923, -0.021640503779053688, -0.050302501767873764, 0.048944082111120224, 0.010740390047430992, 0.010070448741316795, 0.060502879321575165, 0.09704907238483429, -0.05962821841239929, -0.06349631398916245, 0.01777138002216816, 0.10043177753686905, -0.12561191618442535, -0.03125227615237236, 0.02567935921251774, -0.026688970625400543, 0.0399252213537693, -0.09907985478639603, 0.07200972735881805, -0.012599365785717964, 0.04123009741306305, -0.01832364872097969, -0.0017253233818337321, -0.06714925915002823, 0.055467389523983, -0.0212247297167778, -0.06812430918216705, 0.05760194733738899, -0.03676227852702141, -0.07118892669677734, -0.04491933807730675]",
         "0.171"
        ],
        [
         "33",
         "37",
         "Ginger VS Grammarly: Which Grammar Checker is Better in (2022) ?",
         "Ginger VS Grammarly: When it comes to grammar checkers, Ginger and Grammarly are two of the most popular choices on the market. This article aims to highlight the specifics of each one so that you can make a more informed decision about the one you'll use. What is Grammarly? If you are a writer, you must have heard of Grammarly before. Grammarly has over 10M users across the globe, it's probably the most popular AI writing enhancement tool, without a doubt. That's why there's a high chance that you already know about Grammarly. But today we are going to do a comparison between Ginger and Grammarly, So let's define Grammarly here. Like Ginger, Grammarly is an AI writing assistant that checks for grammatical errors, spellings, and punctuation. The free version covers the basics like identifying grammar and spelling mistakes While the Premium version offers a lot more functionality, it detects plagiarism in your content, suggests word choice, or adds fluency to it. Features of Grammarly Grammarly detects basic to advance grammatical errors and also help you why this is an error and suggest to you how you can improve it Create a personal dictionary Check to spell for American, British, Canadian, and Australian English. Understand inconsistencies. Detect unclear structure. Detect Plagiarism. Explore overuse of words and wordiness. Get to know about the improper tones. Discover the insensitive language aligns with your intent, audience, style, emotion, and more. What is Ginger Ginger is a writing enhancement tool that not only catches typos and grammatical mistakes but also suggests content improvements. As you type, it picks up on errors then shows you what’s wrong, and suggests a fix. It also provides you with synonyms and definitions of words and allows you to translate your text into dozens of languages. Ginger Software: Features & Benefits Ginger's software helps you identify and correct common grammatical mistakes, such as consecutive nouns, or contextual spelling correction. The sentence rephrasing feature can help you convey your meaning perfectly. Ginger acts like a personal coach that helps you practice certain exercises based on your mistakes. The dictionary feature helps users understand the meanings of words. In addition, the program provides a text reader, so you can gauge your writing’s conversational tone. Ginger vs Grammarly Grammarly and Ginger are two popular grammar checker software brands that help you to become a better writer. But if you’re undecided about which software to use, consider these differences: Grammarly only supports the English language while Ginger supports 40+ languages. Grammarly offers a wordiness feature while Ginger lacks a Wordiness feature. Grammarly shows an accuracy score while Ginger lacks an accuracy score feature. Grammarly has a plagiarism checker while ginger doesn't have such a feature. Grammarly can recognize an incorrect use of numbers while Ginger can’t recognize an incorrect use of numbers. Grammarly and Ginger both have mobile apps. Ginger and Grammarly offer monthly, quarterly, and annual plans. Grammarly allows you to check uploaded documents. while Ginger doesn't check uploaded documents. Grammarly Offers a tone suggestion feature while Ginger doesn't offer a tone suggestion feature. Ginger helps to translate documents into 40+ languages while Grammarly doesn't have a translation feature. Ginger Offers text to speech features while Grammarly doesn't have such features. Grammarly Score: 7/10 Ginger:4/10 So Grammarly wins here. Ginger VS Grammarly: Pricing Difference Ginger offers a Premium subscription for 13.99$/month. it comes at $11.19/month for quarterly and $7.49/month for an annual subscription with 40$ off. On the other hand, Grammarly offers a Premium subscription for $30/month for a monthly plan $20/month for quarterly, and $12/month for an annual subscription. For companies with three or more employees, the Business plan costs $12.50/month for each member of your team. Ginger Wins Here Ginger vs Grammarly – Pros and Cons Grammarly Pros Offers free version All-in-one tool (grammar checker + spell checker + punctuation checker) Allows you to edit a document without affecting the formatting. Style checker (paid version) Active and passive voice checker Personal dictionary Plagiarism checker (paid version) Available on all major devices and platforms Free mobile apps User-friendly interface Browser extensions and MS word add-ons Can upload and download documents Grammarly Cons Supports only English Customer support only via email Limits to 150,000 words Subscription plans can be a bit pricey Doesn’t offer a free trial No refund policy Ginger Pros Offers free version All-in-one tool (grammar checker + spell checker + punctuation checker) Affordable Subscription plans (Additionals discounts are available) Active and passive voice changer Translates documents in 40+ languages Personal dictionary Browser extension available Personal trainers help clients develop their knowledge of grammar. Text-to-speech feature reads work out loud Get a full refund within 7 days Ginger Cons Mobile apps aren't free Limited monthly corrections for free users No style checker No plagiarism checker Not as user-friendly as Grammarly You are unable to upload or download documents; however, you may copy and paste files as needed. Doesn't offer a free trial Summarizing the Ginger VS Grammarly: My Recommendation While both writing assistants are fantastic in their ways, you need to choose the one you want. For example, go for Grammarly if you want a plagiarism tool included. Choose Ginger if you want to write in languages other than English. I will to the differences for you in order to make the distinctions clearer. Grammarly offers a plagiarism checking tool Ginger provides text to speech tool Grammarly helps you check uploaded documents Ginger supports over 40 languages Grammarly has a more friendly UI/UX Both Ginger and Grammarly are awesome writing tools, without a doubt. Depending on your needs, you might want to use Ginger over Grammarly. As per my experience, I found Grammarly easier to use than Ginger. Which one you like let me know in the comments section also give your opinions in the comments section below.",
         "Ginger VS Grammarly: Which Grammar Checker is Better in (2022) ?\n\n\n\n\n\nGinger VS Grammarly: When it comes to grammar checkers, Ginger and Grammarly are two of the most popular choices on the market. This article aims to highlight the specifics of each one so that you can make a more informed decision about the one you'll use.\n\nWhat is Grammarly?\n\nIf you are a writer, you must have heard of Grammarly before. Grammarly has over 10M users across the globe, it's probably the most popular AI writing enhancement tool, without a doubt. That's why there's a high chance that you already know about Grammarly.\n\nBut today we are going to do a comparison between Ginger and Grammarly, So let's define Grammarly here. Like Ginger, Grammarly is an AI writing assistant that checks for grammatical errors, spellings, and punctuation. The free version covers the basics like identifying grammar and spelling mistakes\n\nWhile the Premium version offers a lot more functionality, it detects plagiarism in your content, suggests word choice, or adds fluency to it.\n\nFeatures of Grammarly\n\nGrammarly detects basic to advance grammatical errors and also help you why this is an error and suggest to you how you can improve it\n\nCreate a personal dictionary\n\nCheck to spell for American, British, Canadian, and Australian English.\n\nUnderstand inconsistencies.\n\nDetect unclear structure.\n\nDetect Plagiarism.\n\nExplore overuse of words and wordiness.\n\nGet to know about the improper tones.\n\nDiscover the insensitive language aligns with your intent, audience, style, emotion, and more.\n\n\n\n\n\nWhat is Ginger\n\nGinger is a writing enhancement tool that not only catches typos and grammatical mistakes but also suggests content improvements. As you type, it picks up on errors then shows you what’s wrong, and suggests a fix. It also provides you with synonyms and definitions of words and allows you to translate your text into dozens of languages.\n\n\n\n\n\nGinger Software: Features & Benefits\n\nGinger's software helps you identify and correct common grammatical mistakes, such as consecutive nouns, or contextual spelling correction.\n\nThe sentence rephrasing feature can help you convey your meaning perfectly.\n\nGinger acts like a personal coach that helps you practice certain exercises based on your mistakes.\n\nThe dictionary feature helps users understand the meanings of words.\n\nIn addition, the program provides a text reader, so you can gauge your writing’s conversational tone.\n\n\n\n\n\nGinger vs Grammarly\n\nGrammarly and Ginger are two popular grammar checker software brands that help you to become a better writer. But if you’re undecided about which software to use, consider these differences:\n\nGrammarly only supports the English language while Ginger supports 40+ languages.\n\nGrammarly offers a wordiness feature while Ginger lacks a Wordiness feature.\n\nGrammarly shows an accuracy score while Ginger lacks an accuracy score feature.\n\nGrammarly has a plagiarism checker while ginger doesn't have such a feature.\n\nGrammarly can recognize an incorrect use of numbers while Ginger can’t recognize an incorrect use of numbers.\n\nGrammarly and Ginger both have mobile apps.\n\nGinger and Grammarly offer monthly, quarterly, and annual plans.\n\nGrammarly allows you to check uploaded documents. while Ginger doesn't check uploaded documents.\n\nGrammarly Offers a tone suggestion feature while Ginger doesn't offer a tone suggestion feature.\n\nGinger helps to translate documents into 40+ languages while Grammarly doesn't have a translation feature.\n\nGinger Offers text to speech features while Grammarly doesn't have such features.\n\n\n\n\n\nGrammarly Score: 7/10\n\nGinger:4/10\n\nSo Grammarly wins here.\n\nGinger VS Grammarly: Pricing Difference\n\nGinger offers a Premium subscription for 13.99$/month. it comes at $11.19/month for quarterly and $7.49/month for an annual subscription with 40$ off.\n\nOn the other hand, Grammarly offers a Premium subscription for $30/month for a monthly plan $20/month for quarterly, and $12/month for an annual subscription.\n\nFor companies with three or more employees, the Business plan costs $12.50/month for each member of your team.\n\nGinger Wins Here\n\nGinger vs Grammarly – Pros and Cons\n\n\n\n\n\nGrammarly Pros\n\nOffers free version\n\nAll-in-one tool (grammar checker + spell checker + punctuation checker)\n\nAllows you to edit a document without affecting the formatting.\n\nStyle checker (paid version)\n\n\n\nActive and passive voice checker\n\nPersonal dictionary\n\nPlagiarism checker (paid version)\n\nAvailable on all major devices and platforms\n\nFree mobile apps\n\nUser-friendly interface\n\nBrowser extensions and MS word add-ons\n\nCan upload and download documents\n\n\n\n\n\nGrammarly Cons\n\nSupports only English\n\nCustomer support only via email\n\nLimits to 150,000 words\n\nSubscription plans can be a bit pricey\n\nDoesn’t offer a free trial\n\nNo refund policy\n\nGinger Pros\n\nOffers free version\n\nAll-in-one tool (grammar checker + spell checker + punctuation checker)\n\nAffordable Subscription plans (Additionals discounts are available)\n\nActive and passive voice changer\n\nTranslates documents in 40+ languages\n\nPersonal dictionary\n\nBrowser extension available\n\nPersonal trainers help clients develop their knowledge of grammar.\n\nText-to-speech feature reads work out loud\n\nGet a full refund within 7 days\n\n\n\n\n\nGinger Cons\n\nMobile apps aren't free\n\nLimited monthly corrections for free users\n\nNo style checker\n\nNo plagiarism checker\n\nNot as user-friendly as Grammarly\n\nYou are unable to upload or download documents; however, you may copy and paste files as needed.\n\nDoesn't offer a free trial\n\n\n\n\n\nSummarizing the Ginger VS Grammarly: My Recommendation\n\nWhile both writing assistants are fantastic in their ways, you need to choose the one you want.\n\nFor example, go for Grammarly if you want a plagiarism tool included.\n\nChoose Ginger if you want to write in languages other than English. I will to the differences for you in order to make the distinctions clearer.\n\nGrammarly offers a plagiarism checking tool\n\nGinger provides text to speech tool\n\nGrammarly helps you check uploaded documents\n\nGinger supports over 40 languages\n\nGrammarly has a more friendly UI/UX\n\nBoth Ginger and Grammarly are awesome writing tools, without a doubt. Depending on your needs, you might want to use Ginger over Grammarly. As per my experience, I found Grammarly easier to use than Ginger.\n\nWhich one you like let me know in the comments section also give your opinions in the comments section below.",
         "2022-02-10T10:28:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/02/ginger-vs-grammarly-which-grammar.html",
         "2025-07-26T05:41:35.908215",
         "Ginger VS Grammarly: Which Grammar Checker is Better in (2022) ? Ginger VS Grammarly: When it comes to grammar checkers, Ginger and Grammarly are two of the most popular choices on the market. This article aims to highlight the specifics of each one so that you can make a more informed decision about the one you'll use. What is Grammarly? If you are a writer, you must have heard of Grammarly before. Grammarly has over 10M users across the globe, it's probably the most popular AI writing enhancement tool, without a doubt. That's why there's a high chance that you already know about Grammarly. But today we are going to do a comparison between Ginger and Grammarly, So let's define Grammarly here. Like Ginger, Grammarly is an AI writing assistant that checks for grammatical errors, spellings, and punctuation. The free version covers the basics like identifying grammar and spelling mistakes While the Premium version offers a lot more functionality, it detects plagiarism in your content, suggests word choice, or adds fluency to it. Features of Grammarly Grammarly detects basic to advance grammatical errors and also help you why this is an error and suggest to you how you can improve it Create a personal dictionary Check to spell for American, British, Canadian, and Australian English. Understand inconsistencies. Detect unclear structure. Detect Plagiarism. Explore overuse of words and wordiness. Get to know about the improper tones. Discover the insensitive language aligns with your intent, audience, style, emotion, and more. What is Ginger Ginger is a writing enhancement tool that not only catches typos and grammatical mistakes but also suggests content improvements. As you type, it picks up on errors then shows you what’s wrong, and suggests a fix. It also provides you with synonyms and definitions of words and allows you to translate your text into dozens of languages. Ginger Software: Features & Benefits Ginger's software helps you identify and correct common grammatical mistakes, such as consecutive nouns, or contextual spelling correction. The sentence rephrasing feature can help you convey your meaning perfectly. Ginger acts like a personal coach that helps you practice certain exercises based on your mistakes. The dictionary feature helps users understand the meanings of words. In addition, the program provides a text reader, so you can gauge your writing’s conversational tone. Ginger vs Grammarly Grammarly and Ginger are two popular grammar checker software brands that help you to become a better writer. But if you’re undecided about which software to use, consider these differences: Grammarly only supports the English language while Ginger supports 40+ languages. Grammarly offers a wordiness feature while Ginger lacks a Wordiness feature. Grammarly shows an accuracy score while Ginger lacks an accuracy score feature. Grammarly has a plagiarism checker while ginger doesn't have such a feature. Grammarly can recognize an incorrect use of numbers while Ginger can’t recognize an incorrect use of numbers. Grammarly and Ginger both have mobile apps. Ginger and Grammarly offer monthly, quarterly, and annual plans. Grammarly allows you to check uploaded documents. while Ginger doesn't check uploaded documents. Grammarly Offers a tone suggestion feature while Ginger doesn't offer a tone suggestion feature. Ginger helps to translate documents into 40+ languages while Grammarly doesn't have a translation feature. Ginger Offers text to speech features while Grammarly doesn't have such features. Grammarly Score: 7/10 Ginger:4/10 So Grammarly wins here. Ginger VS Grammarly: Pricing Difference Ginger offers a Premium subscription for 13.99$/month. it comes at $11.19/month for quarterly and $7.49/month for an annual subscription with 40$ off. On the other hand, Grammarly offers a Premium subscription for $30/month for a monthly plan $20/month for quarterly, and $12/month for an annual subscription. For companies with three or more employees, the Business plan costs $12.50/month for each member of your team. Ginger Wins Here Ginger vs Grammarly – Pros and Cons Grammarly Pros Offers free version All-in-one tool (grammar checker + spell checker + punctuation checker) Allows you to edit a document without affecting the formatting. Style checker (paid version) Active and passive voice checker Personal dictionary Plagiarism checker (paid version) Available on all major devices and platforms Free mobile apps User-friendly interface Browser extensions and MS word add-ons Can upload and download documents Grammarly Cons Supports only English Customer support only via email Limits to 150,000 words Subscription plans can be a bit pricey Doesn’t offer a free trial No refund policy Ginger Pros Offers free version All-in-one tool (grammar checker + spell checker + punctuation checker) Affordable Subscription plans (Additionals discounts are available) Active and passive voice changer Translates documents in 40+ languages Personal dictionary Browser extension available Personal trainers help clients develop their knowledge of grammar. Text-to-speech feature reads work out loud Get a full refund within 7 days Ginger Cons Mobile apps aren't free Limited monthly corrections for free users No style checker No plagiarism checker Not as user-friendly as Grammarly You are unable to upload or download documents; however, you may copy and paste files as needed. Doesn't offer a free trial Summarizing the Ginger VS Grammarly: My Recommendation While both writing assistants are fantastic in their ways, you need to choose the one you want. For example, go for Grammarly if you want a plagiarism tool included. Choose Ginger if you want to write in languages other than English. I will to the differences for you in order to make the distinctions clearer. Grammarly offers a plagiarism checking tool Ginger provides text to speech tool Grammarly helps you check uploaded documents Ginger supports over 40 languages Grammarly has a more friendly UI/UX Both Ginger and Grammarly are awesome writing tools, without a doubt. Depending on your needs, you might want to use Ginger over Grammarly. As per my experience, I found Grammarly easier to use than Ginger. Which one you like let me know in the comments section also give your opinions in the comments section below.",
         "en",
         "{'MISC': ['Active and passive voice changer', 'Active and passive voice checker', 'Additionals discounts are available', 'Affordable Subscription', 'All-in-one tool', 'Allows you to edit', 'As per my experience', 'Available on all major devices and platforms Free mobile', 'Browser extensions and MS word add', 'Check to spell for American', 'Detect Plagiarism', 'Discover the insensitive', \"Doesn't offer\", 'For companies with three or more employees', 'For example', 'Get to know about the improper tones', 'Ginger Software', 'Ginger VS Grammarly: Which Grammar Checker is Better in', 'Ginger acts like', 'Ginger and', 'Ginger and Grammarly', 'Ginger and Grammarly are two of the most', \"Ginger doesn't check uploaded\", \"Ginger doesn't offer\", 'Ginger helps to translate documents into 40+ languages while', 'Ginger over Grammarly', 'Ginger supports', 'Ginger:4/10', 'Grammarly', 'Grammarly allows you to check uploaded', \"Grammarly doesn't have such features\", 'Grammarly shows an accuracy score while', 'I found', 'I will to the differences for you in order to make the', 'If you are', 'It also provides you with synonyms and definitions of words and allows you to translate your text into dozens of languages', 'My Recommendation', 'Personal dictionary', 'Premium subscription for', 'Premium subscription for 13.99$/month', \"So let's\", 'Style checker', 'Summarizing the Ginger VS Grammarly', \"That's why there's a high chance that you already know about Grammarly\", 'The dictionary', 'The free version covers the basics like identifying grammar', 'The sentence rephrasing feature can help you convey your meaning perfectly', 'Translates', 'Understand', 'What is Ginger Ginger is a writing', 'What is Grammarly', 'Which one you like let me know in the comments section also give your opinions in the comments', 'conversational tone', 'go for Grammarly if you want', 'grammatical mistakes', 'it comes at $11.19/month for quarterly and', 'plagiarism checking tool', 'reader', 'spellings', 'such as consecutive nouns', 'without a doubt', 'without affecting the formatting', 'you may copy and paste files as needed', 'you need to choose the one you want'], 'PER': ['As you', 'Choose Ginger if you want to write in languages other than English', 'Depending on your needs', 'Ginger', 'Ginger VS Grammarly', 'Ginger Wins Here Ginger vs Grammarly – Pros and Cons Grammarly Pros Offers free version All-in-one tool', 'Ginger lacks', 'Ginger vs Grammarly', 'Grammarly', 'Grammarly You are unable to', 'Grammarly and Ginger both have mobile apps', \"Grammarly doesn't have\", 'Grammarly has', 'Grammarly here', 'Like Ginger', 'Wordiness', 'however', 'it detects plagiarism in your content', 'quarterly', 'you might want to', 'you must have heard of Grammarly before'], 'LOC': ['Canadian', 'and punctuation', 'and suggests a fix'], 'ORG': ['Australian English', 'British', 'Features & Benefits', 'Features of', 'the Business']}",
         "[-0.032266706228256226, -0.10054992884397507, -0.010260669514536858, 0.03752469643950462, 0.036201175302267075, 0.01071564294397831, 0.03600681945681572, 0.02819955162703991, -0.03842601180076599, -0.04414750263094902, -0.019390711560845375, 0.07227122038602829, 0.030651811510324478, 0.01014078501611948, -0.031313568353652954, -0.006662506610155106, 0.038006629794836044, -0.012762630358338356, -0.12604007124900818, -0.06816811859607697, -0.04835672676563263, -0.015859277918934822, -0.029433855786919594, -0.009237314574420452, 0.03164130076766014, 0.021155741065740585, -0.05931689217686653, -0.0738169476389885, -0.08349502086639404, -0.03550203889608383, 0.008438155055046082, 0.016129333525896072, 0.08518466353416443, -0.038587164133787155, -0.08906709402799606, 0.008042125962674618, 0.043478675186634064, -0.03290688991546631, 0.0392952635884285, -0.05449184402823448, -0.10676826536655426, -0.047692086547613144, -0.012549321167171001, -0.006476542912423611, 0.11252371966838837, 0.02135797217488289, -0.0031219234224408865, -0.029804185032844543, -0.04141969978809357, 0.025137176737189293, -0.05939805507659912, -0.011737420223653316, 0.0445295087993145, 0.05038003623485565, -0.011426186189055443, 0.06757964193820953, -0.06940095126628876, 0.048273999243974686, -0.021470246836543083, -0.04927773028612137, -0.03249533474445343, -0.02984912134706974, -0.04138415679335594, 0.05481807142496109, -0.00641224067658186, -0.02538343518972397, 0.06093953549861908, -0.032714225351810455, -0.035944219678640366, 0.01194000244140625, -0.11440711468458176, 0.015248458832502365, -0.0029109518509358168, 0.1068209782242775, 0.011062348261475563, 0.08287201076745987, 0.047912802547216415, -0.008734692819416523, 0.06074851378798485, -0.05892256647348404, 0.011876720935106277, 0.01837420091032982, -0.017698654904961586, 0.03444591909646988, 0.000823691429104656, 0.011325031518936157, 0.034800659865140915, 0.011640333570539951, 0.018022162839770317, 0.011837275698781013, 0.04513643682003021, -0.006802762858569622, 0.12375489622354507, -0.053260140120983124, 0.010344509966671467, 0.004478638991713524, -0.06634235382080078, -0.014636917039752007, -0.04261144995689392, 0.0033338109496980906, 0.022646380588412285, 0.008226669393479824, 0.010863211005926132, -0.07670530676841736, -0.023881249129772186, 0.00390714593231678, 0.005900801159441471, -0.00945860892534256, 0.08711607754230499, -0.012927197851240635, 0.0021017214749008417, 0.028495607897639275, -0.0124467508867383, -0.05361875891685486, 0.048930756747722626, 0.02573874033987522, -0.011518485844135284, 0.06157509237527847, 0.0819626897573471, 0.042524486780166626, -0.022905241698026657, -0.008254878222942352, -0.019196903333067894, 0.012663088738918304, 0.1284749060869217, -0.053303275257349014, -0.047611936926841736, 1.752097839787636e-33, 0.02575535885989666, 0.09853532910346985, -0.03304998576641083, 0.012102305889129639, -0.028877589851617813, 0.010398736223578453, -0.053906332701444626, 0.07599353045225143, -0.002312976634129882, -0.021424800157546997, 0.07756756246089935, 0.013046525418758392, -0.06782963871955872, 0.07466932386159897, 0.059915415942668915, 0.10056784749031067, 0.04350464046001434, -0.06533142924308777, -0.0747658982872963, 0.07042307406663895, 0.056835781782865524, -0.0033900709822773933, 0.021093184128403664, -0.04835200682282448, 0.011293767020106316, -0.09039567410945892, 0.08883704245090485, -0.007714380975812674, 0.028916582465171814, -0.0009708227589726448, -0.011180302128195763, -0.13206230103969574, 0.011003242805600166, 0.06148088723421097, -0.04728551208972931, -0.07999890297651291, -0.045431528240442276, -0.05827873945236206, 0.008866431191563606, 0.024144012480974197, -0.040771301835775375, 0.017636524513363838, 0.017798546701669693, 0.06697496771812439, 0.022641869261860847, 0.10566314309835434, -0.041264090687036514, 0.07777653634548187, 0.08405924588441849, 0.001858395873568952, 0.01571914739906788, 0.02336123213171959, -0.0004111487651243806, 0.1077088937163353, 0.002976025687530637, 0.06078389659523964, -0.03899792209267616, 0.029277872294187546, 0.03599431738257408, 0.014735245145857334, 0.0010534747270867229, 0.08833085000514984, 0.03720292076468468, -0.05384023115038872, 0.04360852390527725, 0.05528917536139488, -0.02635921724140644, 0.062035299837589264, 0.02583758533000946, -0.012306352145969868, -0.04429204761981964, -0.08549404889345169, -0.006002221256494522, 0.10221678763628006, 0.00649883272126317, -0.09498566389083862, 0.09102989733219147, -0.0622071698307991, 0.057848259806632996, 0.0026920412201434374, -0.05004803091287613, 0.010999602265655994, -0.008842378854751587, 0.048518747091293335, -0.090455062687397, -0.1011214405298233, -0.0374419279396534, 0.0453062579035759, 0.02334134466946125, 0.00427036639302969, 0.09906397014856339, -0.005653596017509699, -0.022076552733778954, -0.005137802101671696, -0.046175722032785416, -2.791216846157291e-33, 0.022922605276107788, -0.09482795745134354, -0.09620468318462372, 0.13086022436618805, -0.08109467476606369, -0.06687770783901215, -0.018707551062107086, -0.0019939932972192764, 0.07101627439260483, -0.0642927885055542, -0.057763855904340744, 0.005948328413069248, -0.005371582228690386, 0.05901028960943222, 0.03344796597957611, -0.029540786519646645, -0.02364164963364601, 0.021251296624541283, -0.011143225245177746, 0.04583315551280975, 0.021515842527151108, 0.10090132802724838, -0.047625020146369934, 0.022916650399565697, -0.05391210690140724, 0.020398499444127083, -0.10140267759561539, 0.05757101625204086, -0.09032575786113739, 0.020663736388087273, 0.020171696320176125, 0.08716170489788055, -0.05150732025504112, -0.0886441245675087, -0.005858337040990591, 0.02697702683508396, -0.028951449319720268, -0.029950158670544624, -0.04887281358242035, 0.049696218222379684, 0.05582507327198982, 0.025087781250476837, 0.03911663591861725, -0.012028273195028305, 0.05119280889630318, 0.004112223628908396, -0.07163207232952118, 0.024490274488925934, 0.05262133106589317, 0.09701467305421829, -0.005695200525224209, 0.010177573189139366, -0.0581214539706707, 0.04000191390514374, -0.006354686804115772, -0.023658057674765587, 0.04768989980220795, -0.06557026505470276, -0.02577127516269684, 0.059406161308288574, -0.09539277106523514, 0.027419934049248695, 0.040930312126874924, -0.006251097656786442, 0.018792670220136642, -0.07088478654623032, 0.06096433848142624, 0.024065624922513962, 0.061912376433610916, -0.04394020885229111, -0.0028917640447616577, -0.07967187464237213, -0.016374899074435234, 0.04191792011260986, -0.06623170524835587, 0.08124849945306778, 0.04151036590337753, -0.023060016334056854, -0.03970247507095337, -0.024104423820972443, 0.021021457388997078, -0.02358504757285118, 0.004118659999221563, 0.05466451123356819, -0.004046820104122162, 0.053440339863300323, -0.03389611467719078, 0.038008518517017365, 0.03438101336359978, 0.012139781378209591, 0.05626920238137245, 0.013997224159538746, -0.02551671490073204, 0.00918765552341938, -0.08301619440317154, -4.7023196003692647e-08, 0.021790960803627968, -0.0784267708659172, 0.025452211499214172, 0.009615101851522923, 0.026838023215532303, -0.035568807274103165, -0.019992347806692123, 0.02426549233496189, -0.05015893653035164, -0.07407668977975845, 0.011075840331614017, 0.013586914166808128, -0.12537604570388794, -0.11439864337444305, 0.013311893679201603, 0.10727445036172867, -0.02896122820675373, 0.07121716439723969, -0.09451348334550858, 0.08168241381645203, 0.051266446709632874, -0.03933827206492424, -0.12836408615112305, 0.011373930610716343, -0.024061881005764008, -0.0007583559490740299, 0.014712869189679623, 0.05656664818525314, -0.03053988330066204, 0.002310517244040966, 0.07997434586286545, 0.04437960684299469, 0.03652184456586838, -0.029536379501223564, -0.01487009972333908, -0.0045881266705691814, 0.04650447517633438, -0.01682918705046177, -0.009588905610144138, 0.009774433448910713, -0.006018003914505243, -0.026404885575175285, -0.01707330159842968, -0.015592331066727638, 0.02955373004078865, -0.08841858059167862, -0.027595309540629387, -0.13531482219696045, 0.018516475334763527, -0.07159905880689621, -0.013106480240821838, -0.0649285763502121, 0.04533834755420685, 0.011145655065774918, -0.02041321061551571, -0.010303834453225136, -0.03855137899518013, -0.013970553874969482, 0.05981903523206711, 0.033844802528619766, 0.03808705136179924, 0.032647982239723206, 0.03688516840338707, -0.008867592550814152]",
         "0.193"
        ],
        [
         "34",
         "332",
         "Les experts douteux du Global fact-checking network, l’organisation russe de vérification",
         "Lancée en avril 2025, l’organisation russe intitulée Global Fact-checking network (GFCN) soutient vouloir lutter contre la désinformation. Mais parmi la soixantaine d'experts membres du réseau, plusieurs sont des relais réguliers de désinformation en ligne. Décryptage.",
         "Il s’agit d’une plateforme réunissant “des experts qui se consacrent à exposer les informations non vérifiées\", selon les mots du porte-parole du ministère russe des Affaires étrangères, Maria Zakharova. Le 9 avril, elle annonçait lors d'une conférence de presse le lancement du Global Fact-checking Network (GFCN), une plateforme qui doit promouvoir la vérification de l'information, à travers “une approche honnête et ouverte du fact-checking\".\n\nPour Reporters sans frontières cependant, le GFCN est “le dernier outil de propagande du Kremlin\". L'organisation de défense de la liberté de la presse a ainsi déclaré dans un rapport publié le 24 juin que le GFCN s'inscrivait \"dans une stratégie bien établie du Kremlin : imiter les institutions indépendantes pour mieux diffuser sa propagande\".\n\nL'objectif du GFCN n'est pas caché : l'organisation souhaite faire contrepoint aux services de fact-checking occidentaux et à l'International Fact-checking network (IFCN), la structure développée en 2015 qui regroupe plus de 170 organisations de fact-checking [dont la rédaction des Observateurs de France 24] à travers le monde autour d'un code de pratiques sur la vérification de l'information.\n\nThibaut Bruttin, directeur général de RSF, dénonce le GFCN comme un \"nouvel outil de propagande\". Pour afficher ce contenu X (Twitter), il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nEn apparence, les éléments présentés par le GFCN ressemblent à ceux développés par une organisation de vérification des faits comme l'IFCN : la plateforme propose par exemple un code du \"fact-checking responsable\" autour de principes comme l'objectivité, l'impartialité ou la mise en avant de \"données vérifiées\". Depuis début juin, elle met également en accès libre des cours sur les réflexes de base du fact-checking et un \" challenge international\" pour mieux détecter les vidéos générées par IA.\n\nCo-fondée par Tass et une ONG sous sanctions\n\nPour ses critiques cependant, les organisations à l'origine du GFCN interrogent quant à ces objectifs : le GFCN a en effet été cofondé par l'agence de presse étatique russe TASS, la New Media School, un programme fédéral de formation des journalistes russes, et l'ONG Ano Dialog.\n\nPublication de promotion du GFCN par le ministère des Affaires étrangères russe sur X, le 4 juin 2025. © MFA Russia / X\n\nActuellement sous sanctions américaines , cette ONG a été décrite par de nombreux spécialistes et gouvernements occidentaux comme très proche du Kremlin et liée à différentes opérations de désinformation. Son directeur général, Vladimir Tabak, placé sous sanctions de plusieurs pays occidentaux, est désormais également président du GFCN.\n\nPhoto publiée par le GFCN de son président Vladimir Tabak, lors d'une conférence organisée début juin. © Capture d'écran / GFCN\n\nPour Maxime Audinet et Colin Gérard, chercheurs spécialistes de l’influence informationnelle russe, le GFCN est un des acteurs principaux de l'opération de désinformation Doppelgänger , à l'origine de sites-miroir usurpant l'identité de médias occidentaux pour publier de fausses informations. Vladimir Tabak a déclaré que l'objectif du GFCN, qui rassemblait à la mi-juillet 2025, 65 membres de 40 pays, était “de rassembler des experts, des journalistes et des représentants des médias prêts à défendre le droit à une information fiable\".\n\nHuit intox en douze jours\n\nMais plusieurs des experts présentés sur le site du GFCN s'avèrent être des relais réguliers d'informations fausses, qui s'appuient sur des contenus non sourcés et non vérifiés. \"De nombreuses voix dans cette liste sont extrêmement partiales et manquent de légitimité\", estime auprès de la rédaction des Observateurs Darren Linvill, professeur à la Clemson University aux États-Unis et auteur de plusieurs rapports sur les réseaux de désinformation russe en ligne.\n\nEn consultant le compte X du premier nom de la liste, Tim Anderson, on remarque la présence de nombreuses fausses informations sur son fil d'actualité. Cet ancien professeur d'université australien, qui a fondé en 2016 le Centre d'études contre-hégémoniques pour dénoncer la marginalisation des discours anti-impériaux, a relayé huit fausses affirmations lors de la guerre de douze jours entre Israël et l'Iran en juin dernier, selon notre décompte .\n\nParmi ces intox, toujours en ligne : des images de jeu vidéo ou générées par intelligence artificielle pour soutenir que l'Iran avait détruit plusieurs F-35 israéliens, alors qu'aucune preuve sérieuse à ce jour ne vient soutenir cette version, comme notre rédaction l'avait vérifié . Anderson a également diffusé une vidéo annonçant à tort la mort du chef du Mossad David Barnea. Ces erreurs semblent en contradiction avec le code du GFCN, qui stipule le besoin de \"vérifier les sources d'information pour s'assurer qu'elles sont fiables et authentiques\". Nous avons analysé les huit intox relayées par Tim Anderson, la liste est à retrouver ici .\n\nLes experts du GFCN, rassemblés dans une liste visible en Une du site. Les trois premiers noms mis en avant ont tous déjà partagé de fausses informations. © Capture d'écran / GFCN\n\nD'autres experts du GFCN ont aussi partagé de fausses affirmations à partir de contenus non vérifiés. Le journaliste pakistanais Furqan Rao a par exemple relayé à deux reprises des images fausses ou décontextualisées lors du conflit entre l'Inde et le Pakistan en mai dernier. Il avait notamment partagé une vidéo d'un jeu de simulation militaire pour soutenir que le Pakistan avait détruit une base militaire, et également diffusé une vidéo prise à Dubaï en 2021 pour affirmer qu'un dépôt de missiles indien avait été visé. Il n’a pas corrigé ses publications.\n\nDans cette liste d'experts se trouvent également des profils plus éloignés du monde du journalisme, comme Roigar López Rivas. Présenté sur le site du GFCN comme le président de l'Institut national pour le développement des petites et moyennes industries au Venezuela, il faisait partie des experts présents sur scène à un événement du GFCN en juin.\n\nEntre novembre 2023 et juillet 2025, ce fervent partisan du président vénézuélien Nicolas Maduro a reçu 33 notes de la communauté (Community Notes) - des notes ajoutées par des internautes sur la plateforme X pour recontextualiser des publications, comme l'a recensé l'outil Community-Notes-Leaderboard. On compte parmi ces notes un faux montage contre Volodymyr Zelensky , une fausse affiche demandant la capture de l’opposant vénézuélien Juan Guaido par le FBI - vérifiée par le service de vérification partenaire de l'IFCN Cazadores - ou encore une vidéo de frappe présentée comme ayant touché Moscou alors qu’il s’agissait d’une frappe iranienne en Israël.\n\nDes experts proches de l'opération \"Storm-1516\"\n\nLe GFCN affiche aussi plusieurs noms documentés depuis plusieurs années comme des acteurs de réseaux de désinformation pro-russes en ligne. Ainsi de la journaliste indépendante néerlandaise Sonja Van den Ende et de l'analyste brésilien Lucas Leiroz, tous deux décrits par le Clemson Institute ou le service technique et opérationnel français chargé de la protection contre les ingérences numériques étrangères, Viginum , comme des relais importants de l'opération de désinformation russe \"Storm-1516\".\n\nOpération aux schémas de diffusion complexes, Storm-1516 cherche notamment à diffuser de fausses informations, sur la guerre en Ukraine ou les pays occidentaux, à partir de faux sites d'information ou de sites d'information prêts à relayer des intox créées de toutes pièces.\n\nEntre 2023 et 2024, Sonja Van den Ende et Lucas Leiroz ont chacun partagé à huit reprises des narratifs de cette opération, selon le rapport du Clemson Institute. Par exemple, une intox dans un média nigérian prétendant que Volodymyr Zelensky avait acheté une maison en Égypte. Malgré les démentis et articles de vérification , leurs posts sur X diffusant l'intox sont toujours en ligne ( ici et ici ).\n\nLucas Leiroz est également connu pour son activité dans l'Association des journalistes des BRICS (BJA) qui affirme représenter les journalistes hors-Occident. Elle vient d'être placée sous sanctions européennes le 15 juillet pour \"diffusion de récits pro-russes et de désinformation sous couvert de journalisme indépendant\" à la suite de rapports décrivant l'implication de plusieurs membres dans Storm-1516.\n\nLeiroz a ainsi défendu publiquement le journaliste irlandais de RT Chay Bowes, considéré comme un des relais principaux de l’opération Storm-1516, comme notre rédaction l'a documenté à plusieurs reprises.\n\n\"Le principal succès de la Russie est d'avoir réussi à construire une collection de voix qui diffusent des fausses informations et leur donnent une légitimité\", reprend Darren Linvill, qui décrit des organisations comme l'Association des journalistes des BRICS comme “des 'outils de légitimation de la désinformation\", au même titre que le GFCN.\n\n.\n\nPhoto prise du journaliste de RT Chay Bowes, lors d'une table-ronde organisée début juin, et à laquelle participaient le président du GFCN Vladimir Tabak et la porte-parole du ministère des Affaires étrangères russe Maria Zakharova. © Capture d'écran / GFCN\n\nChay Bowes est également soutenu par Timofey V, de son vrai nom Vasiliev. Présenté sur le site du GFCN comme un responsable d'ANO Dialog, cet autre expert est également à l'origine du média War on Fakes, qui diffusait de la propagande russe sous couvert de faire du fact-checking . En février 2025, Timofey V a relayé une fausse vidéo partagée par Bowes au sujet d'une supposée fraude électorale contre le parti d'extrême-droite allemand AfD. Comme l'a expliqué l'AFP Factuel , cette vidéo était une mise en scène.\n\nContacté par la rédaction des Observateurs de France 24, le GFCN répond que “les experts dans les articles publiés sous l'égide du GFCN respectent les normes éthiques et professionnelles énoncées dans le Code de l'association”.\n\n\"Communiquer\" à l'international\n\n\"Le GFCN n'est pas une structure indépendante du reste des opérations d'influence russes\", déclare à notre rédaction Pauline Maufrais, responsable régionale pour l'Ukraine à Reporters sans frontières et autrice du rapport sur le GFCN. \"On retrouve les mêmes figures de la propagande pro-Kremlin, qui vivotent dans ces cercles depuis des années, et qui se recyclent dès qu'il y a de nouveaux projets\".\n\nParmi les participants du GFCN, figure également le média International Reporters, fondé fin 2023. Ce projet est porté notamment par la journaliste française Christelle Néant, qui travaille dans la région du Donbass depuis 2016 et y dénonce ce qu’elle qualifie de \"mensonges\" des Occidentaux sur la Russie.\n\nAux yeux de Darren Linvill, ce choix d'intégrer des profils issus du monde entier fait partie d'une stratégie globale d'influence : \"La Russie est très douée pour donner l'impression d'être inclusive. Cela remplit plusieurs fonctions : non seulement, cela leur donne une bonne image, mais cela leur permet aussi de communiquer efficacement dans ces communautés\".\n\n\"Ce n'est pas anodin que le ministère des Affaires étrangères russe s'investisse autant\", note également Pauline Maufrais. \"L'objectif est d'aller chercher de nouvelles audiences pour aller diffuser son narratif, avec l'ambition d'être visible à l'échelle internationale\". La plateforme est également mise en avant par différentes ambassades russes, au Bangladesh comme en Afrique du Sud .\n\nUne agence de presse sur l’Afrique dans le giron du GFCN\n\nAutre signe de cette collaboration entre les différentes structures d'influence russes, l'African Initiative, agence de presse russe créée en 2023 qui se présente comme un \"pont informationnel\" avec l'Afrique, a rejoint la liste des organisations participantes au GFCN.\n\nDans un rapport publié par Viginum et le Service européen pour l'action extérieure (SEAE) en mai 2025, la structure est décrite comme une agence de promotion de la \"propagande anti-occidentale et pro-Kremlin\" sur le continent africain. Comme le GFCN, elle propose également des formations contre la désinformation pour \"contrer de manière indépendante la propagande imposée par l'Occident\".\n\n\"La plupart de la désinformation et propagande russe visent à délégitimer l'Occident, à la fois sur le plan politique, culturel et institutionnel\", décrit Darren Linvill. \"Une organisation comme le GFCN fait ces trois choses à la fois\".",
         "2025-07-25T16:19:26",
         "https://www.france24.com/fr/rss",
         "https://www.france24.com/fr/europe/20250725-global-fact-checking-network-organisation-russe-fact-checking-experts-douteux",
         "2025-07-26T05:53:43.861709",
         "Il s’agit d’une plateforme réunissant “des experts qui se consacrent à exposer les informations non vérifiées\", selon les mots du porte-parole du ministère russe des Affaires étrangères, Maria Zakharova. Le 9 avril, elle annonçait lors d'une conférence de presse le lancement du Global Fact-checking Network (GFCN), une plateforme qui doit promouvoir la vérification de l'information, à travers “une approche honnête et ouverte du fact-checking\". Pour Reporters sans frontières cependant, le GFCN est “le dernier outil de propagande du Kremlin\". L'organisation de défense de la liberté de la presse a ainsi déclaré dans un rapport publié le 24 juin que le GFCN s'inscrivait \"dans une stratégie bien établie du Kremlin : imiter les institutions indépendantes pour mieux diffuser sa propagande\". L'objectif du GFCN n'est pas caché : l'organisation souhaite faire contrepoint aux services de fact-checking occidentaux et à l'International Fact-checking network (IFCN), la structure développée en 2015 qui regroupe plus de 170 organisations de fact-checking [dont la rédaction des Observateurs de France 24] à travers le monde autour d'un code de pratiques sur la vérification de l'information. Thibaut Bruttin, directeur général de RSF, dénonce le GFCN comme un \"nouvel outil de propagande\". Pour afficher ce contenu X (Twitter), il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix En apparence, les éléments présentés par le GFCN ressemblent à ceux développés par une organisation de vérification des faits comme l'IFCN : la plateforme propose par exemple un code du \"fact-checking responsable\" autour de principes comme l'objectivité, l'impartialité ou la mise en avant de \"données vérifiées\". Depuis début juin, elle met également en accès libre des cours sur les réflexes de base du fact-checking et un \" challenge international\" pour mieux détecter les vidéos générées par IA. Co-fondée par Tass et une ONG sous sanctions Pour ses critiques cependant, les organisations à l'origine du GFCN interrogent quant à ces objectifs : le GFCN a en effet été cofondé par l'agence de presse étatique russe TASS, la New Media School, un programme fédéral de formation des journalistes russes, et l'ONG Ano Dialog. Publication de promotion du GFCN par le ministère des Affaires étrangères russe sur X, le 4 juin 2025. © MFA Russia / X Actuellement sous sanctions américaines , cette ONG a été décrite par de nombreux spécialistes et gouvernements occidentaux comme très proche du Kremlin et liée à différentes opérations de désinformation. Son directeur général, Vladimir Tabak, placé sous sanctions de plusieurs pays occidentaux, est désormais également président du GFCN. Photo publiée par le GFCN de son président Vladimir Tabak, lors d'une conférence organisée début juin. © Capture d'écran / GFCN Pour Maxime Audinet et Colin Gérard, chercheurs spécialistes de l’influence informationnelle russe, le GFCN est un des acteurs principaux de l'opération de désinformation Doppelgänger , à l'origine de sites-miroir usurpant l'identité de médias occidentaux pour publier de fausses informations. Vladimir Tabak a déclaré que l'objectif du GFCN, qui rassemblait à la mi-juillet 2025, 65 membres de 40 pays, était “de rassembler des experts, des journalistes et des représentants des médias prêts à défendre le droit à une information fiable\". Huit intox en douze jours Mais plusieurs des experts présentés sur le site du GFCN s'avèrent être des relais réguliers d'informations fausses, qui s'appuient sur des contenus non sourcés et non vérifiés. \"De nombreuses voix dans cette liste sont extrêmement partiales et manquent de légitimité\", estime auprès de la rédaction des Observateurs Darren Linvill, professeur à la Clemson University aux États-Unis et auteur de plusieurs rapports sur les réseaux de désinformation russe en ligne. En consultant le compte X du premier nom de la liste, Tim Anderson, on remarque la présence de nombreuses fausses informations sur son fil d'actualité. Cet ancien professeur d'université australien, qui a fondé en 2016 le Centre d'études contre-hégémoniques pour dénoncer la marginalisation des discours anti-impériaux, a relayé huit fausses affirmations lors de la guerre de douze jours entre Israël et l'Iran en juin dernier, selon notre décompte . Parmi ces intox, toujours en ligne : des images de jeu vidéo ou générées par intelligence artificielle pour soutenir que l'Iran avait détruit plusieurs F-35 israéliens, alors qu'aucune preuve sérieuse à ce jour ne vient soutenir cette version, comme notre rédaction l'avait vérifié . Anderson a également diffusé une vidéo annonçant à tort la mort du chef du Mossad David Barnea. Ces erreurs semblent en contradiction avec le code du GFCN, qui stipule le besoin de \"vérifier les sources d'information pour s'assurer qu'elles sont fiables et authentiques\". Nous avons analysé les huit intox relayées par Tim Anderson, la liste est à retrouver ici . Les experts du GFCN, rassemblés dans une liste visible en Une du site. Les trois premiers noms mis en avant ont tous déjà partagé de fausses informations. © Capture d'écran / GFCN D'autres experts du GFCN ont aussi partagé de fausses affirmations à partir de contenus non vérifiés. Le journaliste pakistanais Furqan Rao a par exemple relayé à deux reprises des images fausses ou décontextualisées lors du conflit entre l'Inde et le Pakistan en mai dernier. Il avait notamment partagé une vidéo d'un jeu de simulation militaire pour soutenir que le Pakistan avait détruit une base militaire, et également diffusé une vidéo prise à Dubaï en 2021 pour affirmer qu'un dépôt de missiles indien avait été visé. Il n’a pas corrigé ses publications. Dans cette liste d'experts se trouvent également des profils plus éloignés du monde du journalisme, comme Roigar López Rivas. Présenté sur le site du GFCN comme le président de l'Institut national pour le développement des petites et moyennes industries au Venezuela, il faisait partie des experts présents sur scène à un événement du GFCN en juin. Entre novembre 2023 et juillet 2025, ce fervent partisan du président vénézuélien Nicolas Maduro a reçu 33 notes de la communauté (Community Notes) - des notes ajoutées par des internautes sur la plateforme X pour recontextualiser des publications, comme l'a recensé l'outil Community-Notes-Leaderboard. On compte parmi ces notes un faux montage contre Volodymyr Zelensky , une fausse affiche demandant la capture de l’opposant vénézuélien Juan Guaido par le FBI - vérifiée par le service de vérification partenaire de l'IFCN Cazadores - ou encore une vidéo de frappe présentée comme ayant touché Moscou alors qu’il s’agissait d’une frappe iranienne en Israël. Des experts proches de l'opération \"Storm-1516\" Le GFCN affiche aussi plusieurs noms documentés depuis plusieurs années comme des acteurs de réseaux de désinformation pro-russes en ligne. Ainsi de la journaliste indépendante néerlandaise Sonja Van den Ende et de l'analyste brésilien Lucas Leiroz, tous deux décrits par le Clemson Institute ou le service technique et opérationnel français chargé de la protection contre les ingérences numériques étrangères, Viginum , comme des relais importants de l'opération de désinformation russe \"Storm-1516\". Opération aux schémas de diffusion complexes, Storm-1516 cherche notamment à diffuser de fausses informations, sur la guerre en Ukraine ou les pays occidentaux, à partir de faux sites d'information ou de sites d'information prêts à relayer des intox créées de toutes pièces. Entre 2023 et 2024, Sonja Van den Ende et Lucas Leiroz ont chacun partagé à huit reprises des narratifs de cette opération, selon le rapport du Clemson Institute. Par exemple, une intox dans un média nigérian prétendant que Volodymyr Zelensky avait acheté une maison en Égypte. Malgré les démentis et articles de vérification , leurs posts sur X diffusant l'intox sont toujours en ligne ( ici et ici ). Lucas Leiroz est également connu pour son activité dans l'Association des journalistes des BRICS (BJA) qui affirme représenter les journalistes hors-Occident. Elle vient d'être placée sous sanctions européennes le 15 juillet pour \"diffusion de récits pro-russes et de désinformation sous couvert de journalisme indépendant\" à la suite de rapports décrivant l'implication de plusieurs membres dans Storm-1516. Leiroz a ainsi défendu publiquement le journaliste irlandais de RT Chay Bowes, considéré comme un des relais principaux de l’opération Storm-1516, comme notre rédaction l'a documenté à plusieurs reprises. \"Le principal succès de la Russie est d'avoir réussi à construire une collection de voix qui diffusent des fausses informations et leur donnent une légitimité\", reprend Darren Linvill, qui décrit des organisations comme l'Association des journalistes des BRICS comme “des 'outils de légitimation de la désinformation\", au même titre que le GFCN. . Photo prise du journaliste de RT Chay Bowes, lors d'une table-ronde organisée début juin, et à laquelle participaient le président du GFCN Vladimir Tabak et la porte-parole du ministère des Affaires étrangères russe Maria Zakharova. © Capture d'écran / GFCN Chay Bowes est également soutenu par Timofey V, de son vrai nom Vasiliev. Présenté sur le site du GFCN comme un responsable d'ANO Dialog, cet autre expert est également à l'origine du média War on Fakes, qui diffusait de la propagande russe sous couvert de faire du fact-checking . En février 2025, Timofey V a relayé une fausse vidéo partagée par Bowes au sujet d'une supposée fraude électorale contre le parti d'extrême-droite allemand AfD. Comme l'a expliqué l'AFP Factuel , cette vidéo était une mise en scène. Contacté par la rédaction des Observateurs de France 24, le GFCN répond que “les experts dans les articles publiés sous l'égide du GFCN respectent les normes éthiques et professionnelles énoncées dans le Code de l'association”. \"Communiquer\" à l'international \"Le GFCN n'est pas une structure indépendante du reste des opérations d'influence russes\", déclare à notre rédaction Pauline Maufrais, responsable régionale pour l'Ukraine à Reporters sans frontières et autrice du rapport sur le GFCN. \"On retrouve les mêmes figures de la propagande pro-Kremlin, qui vivotent dans ces cercles depuis des années, et qui se recyclent dès qu'il y a de nouveaux projets\". Parmi les participants du GFCN, figure également le média International Reporters, fondé fin 2023. Ce projet est porté notamment par la journaliste française Christelle Néant, qui travaille dans la région du Donbass depuis 2016 et y dénonce ce qu’elle qualifie de \"mensonges\" des Occidentaux sur la Russie. Aux yeux de Darren Linvill, ce choix d'intégrer des profils issus du monde entier fait partie d'une stratégie globale d'influence : \"La Russie est très douée pour donner l'impression d'être inclusive. Cela remplit plusieurs fonctions : non seulement, cela leur donne une bonne image, mais cela leur permet aussi de communiquer efficacement dans ces communautés\". \"Ce n'est pas anodin que le ministère des Affaires étrangères russe s'investisse autant\", note également Pauline Maufrais. \"L'objectif est d'aller chercher de nouvelles audiences pour aller diffuser son narratif, avec l'ambition d'être visible à l'échelle internationale\". La plateforme est également mise en avant par différentes ambassades russes, au Bangladesh comme en Afrique du Sud . Une agence de presse sur l’Afrique dans le giron du GFCN Autre signe de cette collaboration entre les différentes structures d'influence russes, l'African Initiative, agence de presse russe créée en 2023 qui se présente comme un \"pont informationnel\" avec l'Afrique, a rejoint la liste des organisations participantes au GFCN. Dans un rapport publié par Viginum et le Service européen pour l'action extérieure (SEAE) en mai 2025, la structure est décrite comme une agence de promotion de la \"propagande anti-occidentale et pro-Kremlin\" sur le continent africain. Comme le GFCN, elle propose également des formations contre la désinformation pour \"contrer de manière indépendante la propagande imposée par l'Occident\". \"La plupart de la désinformation et propagande russe visent à délégitimer l'Occident, à la fois sur le plan politique, culturel et institutionnel\", décrit Darren Linvill. \"Une organisation comme le GFCN fait ces trois choses à la fois\".",
         "fr",
         "{'ORG': ['AFP Factuel', 'ANO Dialog', 'AfD.', 'African Initiative', 'Ano Dialog', 'Association des journalistes', 'Association des journalistes des', 'BJA', 'BRICS', \"Centre d'études contre-hégémoniques\", 'Clemson Institute', 'Clemson University', 'F-35', 'FBI', 'GFCN', 'IFCN', 'Institut national pour le développement des petites et moyennes industries', 'International Fact-checking network', 'International Reporters', 'Mossad', 'New Media School', 'Observateurs', 'Observateurs de France', 'Observateurs de France 24', 'RSF', 'Reporters sans frontières', 'SEAE', \"Service européen pour l'action extérieure\", 'Tass', 'X', 'ministère des Affaires étrangères russe', 'ministère russe des Affaires étrangères'], 'PER': ['Anderson', 'Bowes', 'Chay Bowes', 'Christelle Néant', 'Colin Gérard', 'Darren Linvill', 'David Barnea', 'Doppelgänger', 'Furqan Rao', 'Juan Guaido', 'Leiroz', 'Lucas Leiroz', 'Maria Zakharova', 'Maxime Audinet', 'Nicolas Maduro', 'Pauline Maufrais', 'RT Chay Bowes', 'Roigar López Rivas', 'Sonja Van den Ende', 'Storm-1516', 'Thibaut Bruttin', 'Tim Anderson', 'Timofey V', 'Viginum', 'Vladimir Tabak', 'Volodymyr Zelensky'], 'MISC': ['Capture', \"Code de l'association”\", 'Community Notes', 'Community-Notes', 'GFCN', 'Global Fact-checking Network', 'Occidentaux', 'Opération aux schémas de diffusion complexes', 'TASS', 'Twitter', 'Une du site', 'Vasiliev', 'War on Fakes', 'X', 'guerre de douze jours', 'opération Storm-1516'], 'LOC': ['Afrique du Sud', 'Bangladesh', 'Donbass', 'Dubaï', 'GFCN', 'Inde', 'Iran', 'Israël', 'Kremlin', 'Moscou', 'Occident', 'Pakistan', 'Russia', 'Russie', 'Ukraine', 'Venezuela', \"l'Afrique\", 'l’Afrique', 'Égypte', 'États-Unis']}",
         "[-0.05396295338869095, 0.008826537057757378, -0.04309342801570892, -0.05709564685821533, 0.0704803541302681, 0.02721085213124752, 0.010112469084560871, 0.006717135198414326, 0.028980648145079613, 0.036253053694963455, 0.01918955333530903, -0.01602688431739807, -0.005213955882936716, 0.0029009762220084667, -0.06052128225564957, -0.13030683994293213, 0.041187770664691925, 0.008128449320793152, -0.05347254127264023, -0.05461042374372482, -0.02408720925450325, -0.06323114037513733, 0.06390129774808884, 0.015642773360013962, -0.019435251131653786, -0.02095697447657585, -0.10838347673416138, -0.039588090032339096, 0.03275227174162865, 0.0038516821805387735, -0.021929915994405746, 0.06446846574544907, -0.007733422331511974, 0.033296164125204086, 0.06831688433885574, 0.008829313330352306, 0.04582074657082558, -0.04475488141179085, 0.00929692480713129, 0.03966953977942467, -0.005004886072129011, -0.10000815242528915, -0.05391555652022362, -0.040133778005838394, 0.026284031569957733, 0.06155191734433174, 0.03384925425052643, 0.10763689130544662, -0.17050281167030334, 0.002299464773386717, 0.029240639880299568, -0.033431392163038254, 0.09158947318792343, -0.024124087765812874, 0.06218406930565834, -0.03464999422430992, -0.07413231581449509, 0.0021713157184422016, 0.022319544106721878, 0.07711593806743622, -0.008069979026913643, 0.0032071215100586414, -0.08829127997159958, -0.005328381899744272, -0.03245975077152252, 0.06722747534513474, 0.04229007288813591, -0.004236235748976469, 0.02364562638103962, 0.021948041394352913, 0.09748518466949463, -0.014143639244139194, -0.050136812031269073, -0.03470095619559288, -0.03185717388987541, -0.0010011715348809958, -0.03807564079761505, 0.053581129759550095, 0.0023830316495150328, -0.18616020679473877, 0.08543561398983002, -0.0014110838528722525, 0.05655082315206528, -0.029827872291207314, -0.025014720857143402, -0.13087183237075806, -0.05117916315793991, 0.0183937456458807, -0.009828736074268818, 0.0016270545311272144, 0.011154302395880222, 0.0033878907561302185, 0.07317259162664413, -0.011323828250169754, 0.10076668113470078, -0.0041704000905156136, 0.001552482834085822, -0.02590218000113964, 0.051891736686229706, 0.039715725928545, 0.012730211950838566, 0.03029310330748558, -0.023979689925909042, 0.011941296048462391, -0.003453226527199149, 0.005385860335081816, -0.029516631737351418, 0.018602043390274048, 0.04519139230251312, 0.03953588381409645, -0.028559846803545952, 0.025763683021068573, -0.01979788765311241, -0.1273813098669052, 0.019212406128644943, -0.10092155635356903, -0.004827804397791624, 0.0059912302531301975, -0.07884451746940613, -0.020767388865351677, 0.02045421116054058, -0.030196918174624443, -0.06010511517524719, -0.05431117117404938, 0.06315677613019943, -0.022710083052515984, 0.006456976290792227, 8.625572569506521e-33, 0.057010866701602936, 0.07797007262706757, -0.015194287523627281, -0.015576621517539024, -0.0244955625385046, 0.07312196493148804, -0.07212565839290619, 0.011085285805165768, 0.04702189937233925, 0.05457186698913574, -0.04696426913142204, 0.11524319648742676, -0.10034685581922531, -0.024299252778291702, 0.04433517903089523, 0.03633030503988266, -0.03342614322900772, 0.029802655801177025, 0.0702647715806961, 0.047878511250019073, 0.05992196127772331, -0.02404053322970867, 0.04489131271839142, -0.002967348089441657, 0.07640396803617477, 0.053186796605587006, -0.044948797672986984, -0.05317956954240799, -0.07343950867652893, 0.027554506435990334, -0.008396162651479244, -0.05763300508260727, 0.019161121919751167, 0.017424754798412323, -0.0015283332904800773, -0.13357695937156677, -0.00673651834949851, -0.06019698828458786, 0.009572923183441162, -0.0187201090157032, 0.017339546233415604, -0.018700746819376945, 0.016246559098362923, -0.05263495817780495, 0.048198167234659195, 0.018922792747616768, -0.008034816011786461, -0.03189088776707649, 0.11101751774549484, -0.020212296396493912, 0.11532969772815704, -0.019669996574521065, -0.07300664484500885, -0.06470636278390884, 0.03371523320674896, 0.030398117378354073, -0.06871415674686432, -0.011001232080161572, 0.021477246657013893, -0.003801535116508603, 0.007884460501372814, 0.026936747133731842, -0.10111876577138901, -0.008692029863595963, -0.00556536391377449, 0.05724310129880905, -0.11231290549039841, 0.004190089181065559, 0.08284591138362885, -0.029088016599416733, -0.046281930059194565, 0.00900714285671711, -0.062409792095422745, 0.042127564549446106, 0.0397210568189621, 0.0031392399687319994, -0.07332189381122589, 0.07054372131824493, -0.07759509980678558, 0.015088931657373905, -0.028607524931430817, 0.0005587504711002111, 0.025054719299077988, -0.014424971304833889, -0.04884961247444153, 0.044744331389665604, 0.040196020156145096, 0.023099403828382492, 0.0231035053730011, 0.01216928381472826, -0.07988892495632172, -0.05985385552048683, 0.06258204579353333, 0.056220538914203644, -0.015434656292200089, -1.2032885474054959e-32, -0.06707093119621277, -0.005719098728150129, -0.08736877143383026, 0.04717071354389191, -0.090043805539608, 0.01529455091804266, -0.017899660393595695, 0.006976167671382427, -0.011673808097839355, -0.023333344608545303, -0.0016293569933623075, -0.08085576444864273, 0.02383601851761341, -0.05023307353258133, -0.07396116852760315, -0.013075253926217556, -0.04979091137647629, -0.04900004714727402, -0.06243711709976196, 0.016278862953186035, 0.07606392353773117, -0.12715409696102142, 0.00016427275841124356, 0.07038924098014832, 0.029524249956011772, 0.006477333139628172, 0.05840367451310158, -0.07732901722192764, -0.00040323921712115407, 0.02005271427333355, -0.017462952062487602, 0.017843106761574745, -0.041946232318878174, 0.01698039099574089, 0.03869498148560524, -0.032302942126989365, 0.1079443022608757, 0.0555250346660614, -0.08757178485393524, 0.03926737979054451, 0.017949070781469345, 0.08770188689231873, -0.061972521245479584, -0.01856984570622444, -0.08777374029159546, 0.003422986250370741, -0.0642554759979248, 0.01383028831332922, -0.005523498170077801, -0.09850603342056274, 0.018243419006466866, 0.011407557874917984, -0.009940029121935368, -0.008306346833705902, -0.042675815522670746, 0.07646258920431137, -0.012023499235510826, 0.03463410213589668, 0.004713536240160465, 0.04135836660861969, 0.022700263187289238, -0.014224868267774582, -0.08004085719585419, 0.0376148447394371, 0.1156582161784172, -0.01294857170432806, 0.008531683124601841, 0.007286242209374905, 0.08387384563684464, 0.012489311397075653, 0.07095992565155029, -0.07915692776441574, -0.01397389080375433, -0.00775351095944643, 0.045366160571575165, 0.0635446310043335, 0.012856421060860157, -0.01452952716499567, -0.07570008933544159, 0.10530754923820496, -0.006846962030977011, -0.038719967007637024, -0.03359983488917351, -0.01784457080066204, 0.07183173298835754, -0.057513754814863205, 0.04798060283064842, -0.03660997375845909, 0.010434983298182487, 0.015310247428715229, 0.0006952259573154151, -0.04709460586309433, -0.015178382396697998, -0.012225624173879623, -0.00890278909355402, -6.645528571880277e-08, -0.008496448397636414, -0.020636864006519318, -0.08289191871881485, -0.033047016710042953, 0.006027392111718655, -0.1108451634645462, -0.019328013062477112, -0.06376314163208008, -0.032630760222673416, -0.020861342549324036, 0.06340721249580383, 0.04327836632728577, -0.140427827835083, -0.08458662033081055, 0.01779017597436905, -0.027230026200413704, -0.06407953053712845, -0.046806272119283676, -0.02014082856476307, -0.009886447340250015, 0.08430245518684387, -0.05198436602950096, -0.06962907314300537, -0.014174232259392738, -0.010431777685880661, -0.035778217017650604, -0.004471427761018276, -0.03147372230887413, 0.030431637540459633, 0.12396767735481262, 0.0034252575132995844, 0.002538478933274746, 0.049274858087301254, -0.0567898266017437, 0.028841955587267876, 0.07406877726316452, 0.07057524472475052, 0.009382140822708607, 0.01618230529129505, -0.021197885274887085, 0.027543671429157257, 0.01473493967205286, -0.04528850317001343, -0.00390847772359848, 0.021863587200641632, -0.08153190463781357, 0.007198704872280359, 0.03781016916036606, 0.03770534321665764, -0.0031008904334157705, -0.0013746951008215547, -0.012760967947542667, -0.04181845113635063, 0.062373727560043335, -0.03997751697897911, -0.04053015634417534, 0.04949812591075897, -0.04148360341787338, 0.0006867994088679552, -0.039630621671676636, 0.048177678138017654, 0.018871095031499863, 0.046846646815538406, -0.008541984483599663]",
         "0.183"
        ],
        [
         "35",
         "567",
         "Declarative and Imperative Prompt Engineering for Generative AI",
         "Conceptual overview and practical considerations The post Declarative and Imperative Prompt Engineering for Generative AI appeared first on Towards Data Science .",
         "refers to the careful design and optimization of inputs (e.g., queries or instructions) for guiding the behavior and responses of generative AI models. Prompts are typically structured using either the declarative or imperative paradigm, or a mixture of both. The choice of paradigm can have a big impact on the accuracy and relevance of the resulting model output. This article provides a conceptual overview of declarative and imperative prompting, discusses advantages and limitations of each paradigm, and considers the practical implications.\n\nThe What and the How\n\nIn simple terms, declarative prompts express what should be done, while imperative prompts specify how something should be done. Suppose you are at a pizzeria with a friend. You tell the waiter that you will have the Neapolitan. Since you only mention the type of pizza you want without specifying exactly how you want it prepared, this is an example of a declarative prompt. Meanwhile, your friend — who has some very particular culinary preferences and is in the mood for a bespoke pizza alle quattro stagioni — proceeds to tell the waiter exactly how she would like it made; this is an example of an imperative prompt.\n\nDeclarative and imperative paradigms of expression have a long history in computing, with some programming languages favoring one paradigm over the other. A language such as C tends to be used for imperative programming, while a language like Prolog is geared towards declarative programming. For example, consider the following problem of identifying the ancestors of a person named Charlie. We happen to know the following facts about Charlie’s relatives: Bob is Charlie’s parent, Alice is Bob’s parent, Susan is Dave’s parent, and John is Alice’s parent. Based on this information, the code below shows how we can identify Charlie’s ancestors using Prolog.\n\nparent(alice, bob). parent(bob, charlie). parent(susan, dave). parent(john, alice). ancestor(X, Y) :- parent(X, Y). ancestor(X, Y) :- parent(X, Z), ancestor(Z, Y). get_ancestors(Person, Ancestors) :- findall(X, ancestor(X, Person), Ancestors). ?- get_ancestors(charlie, Ancestors).\n\nAlthough the Prolog syntax may seem strange at first, it actually expresses the problem we wish to solve in a concise and intuitive way. First, the code lays out the known facts (i.e., who is whose parent). It then recursively defines the predicate ancestor(X, Y) , which evaluates to true if X is an ancestor of Y . Finally, the predicate findall(X, Goal, List) triggers the Prolog interpreter to repeatedly evaluate Goal and store all successful bindings of X in List . In our case, this means identifying all solutions to ancestor(X, Person) and storing them in the variable Ancestors . Notice that we do not specify the implementation details (the “how”) of any of these predicates (the “what”).\n\nIn contrast, the C implementation below identifies Charlie’s ancestors by describing in painstaking detail exactly how this should be done.\n\n#include <stdio.h> #include <string.h> #define MAX_PEOPLE 10 #define MAX_ANCESTORS 10 // Structure to represent parent relationships typedef struct { char parent[20]; char child[20]; } ParentRelation; ParentRelation relations[] = { {\"alice\", \"bob\"}, {\"bob\", \"charlie\"}, {\"susan\", \"dave\"}, {\"john\", \"alice\"} }; int numRelations = 4; // Check if X is a parent of Y int isParent(const char *x, const char *y) { for (int i = 0; i < numRelations; ++i) { if (strcmp(relations[i].parent, x) == 0 && strcmp(relations[i].child, y) == 0) { return 1; } } return 0; } // Recursive function to check if X is an ancestor of Y int isAncestor(const char *x, const char *y) { if (isParent(x, y)) return 1; for (int i = 0; i < numRelations; ++i) { if (strcmp(relations[i].child, y) == 0) { if (isAncestor(x, relations[i].parent)) return 1; } } return 0; } // Get all ancestors of a person void getAncestors(const char *person, char ancestors[][20], int *numAncestors) { *numAncestors = 0; for (int i = 0; i < numRelations; ++i) { if (isAncestor(relations[i].parent, person)) { strcpy(ancestors[*numAncestors], relations[i].parent); (*numAncestors)++; } } } int main() { char person[] = \"charlie\"; char ancestors[MAX_ANCESTORS][20]; int count; getAncestors(person, ancestors, &count); printf(\"Ancestors of %s:\n\n\", person); for (int i = 0; i < count; ++i) { printf(\"%s\n\n\", ancestors[i]); } return 0; }\n\nNowadays, the increasing availability of feature-rich libraries and APIs, and the consolidation of architectural best practices (e.g., programming to interfaces, using configuration over code), allows us to focus on the “what” without having to worry about the “how” in many cases. Indeed, as suggested in the short video below, a lot of code can — and perhaps should — be written in a declarative manner.\n\nFrom Programming to Prompting\n\nIf we think of prompt engineering as the next evolutionary step in programming — tracing the journey from machine-centric languages such as Assembly and C to more human-centric languages like Java and Python — then the relevance of declarative and imperative paradigms to prompt engineering becomes apparent. Although we can now instruct a generative AI model simply using natural language, we still need to decide on the extent to which the instruction should express what is to be achieved versus how it is to be achieved.\n\nConsider the scenario of a developer who would like to use an AI assistant to generate code — specifically, Python code to compute the cosine distance between two vectors. Following are three versions of a prompt that the developer might write to achieve her goal. Version 1 is declarative, Version 2 is imperative, and Version 3 is a hybrid of the two. The code generated by OpenAI’s GPT-4 model in response to each of these prompts is also provided.\n\nPrompt Version 1 (Declarative)\n\nWrite a short and fast function in Python to compute the cosine distance between two input vectors.\n\nResult:\n\nimport numpy as np def cosine_distance(u, v): u = np.array(u) v = np.array(v) return 1 - np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n\nPrompt Version 2 (Imperative)\n\nWrite a Python function cosine_distance(v1, v2) that computes the cosine distance between two vectors. Follow these steps using only built-in functions: 1. Raise a ValueError exception if v1 or v2 are empty, or if v1 and v2 are of different lengths. 2. Compute the dot product of v1 and v2. 3. Compute the magnitude of each vector and raise a ValueError if either magnitude is zero. 4. Divide the dot product by the product of the two magnitudes to get the cosine similarity. 5. Do 1 minus the cosine similarity to obtain cosine distance. 6. Return the resulting distance.\n\nResult:\n\nimport math def cosine_distance(v1, v2): # Step 1: Input validation if not v1 or not v2: raise ValueError(\"Input vectors must not be empty.\") if len(v1) != len(v2): raise ValueError(\"Vectors must be of the same length.\") # Step 2: Compute dot product dot_product = sum(a * b for a, b in zip(v1, v2)) # Step 3: Compute magnitudes mag_v1 = math.sqrt(sum(a ** 2 for a in v1)) mag_v2 = math.sqrt(sum(b ** 2 for b in v2)) if mag_v1 == 0 or mag_v2 == 0: raise ValueError(\"Vectors must not have zero magnitude.\") # Step 4 & 5: Compute cosine similarity and distance cosine_similarity = dot_product / (mag_v1 * mag_v2) cosine_distance = 1 - cosine_similarity # Step 6: Return result return cosine_distance\n\nPrompt Version 3 (Hybrid)\n\nWrite a fast Python function that computes the cosine distance between two vectors v1 and v2 using relevant optimized functions from numpy and scipy. The function should validate the input vectors (non-empty, equal length) and gracefully handle invalid inputs with exceptions.\n\nResult:\n\nimport numpy as np from scipy.spatial.distance import cosine def cosine_distance(v1, v2): # Convert inputs to NumPy arrays v1 = np.asarray(v1, dtype=np.float64) v2 = np.asarray(v2, dtype=np.float64) # Validation checks if v1.size == 0 or v2.size == 0: raise ValueError(\"Input vectors must be non-empty.\") if v1.shape != v2.shape: raise ValueError(\"Vectors must have the same shape.\") if not np.any(v1) or not np.any(v2): raise ValueError(\"Vectors must not be zero vectors.\") # Compute cosine distance using optimized function return cosine(v1, v2)\n\nHorses for Courses\n\nThe three prompts and their respective AI-generated implementations shown above imply different trade-offs and may be suited to different personas and scenarios in practice.\n\nThe declarative prompt (Version 1) is short and simple. It does not specify details of the exact algorithmic approach to be taken, expressing instead the high-level task only. As such, it promotes creativity and flexibility in implementation. The downside of such a prompt, of course, is that the result may not always be reproducible or robust; in the above case, the code generated by the declarative prompt could vary significantly across inference calls, and does not handle edge cases, which could be a problem if the code is intended for use in production. Despite these limitations, typical personas who may favor the declarative paradigm include product managers, UX designers, and business domain experts who lack coding expertise and may not need production-grade AI responses. Software developers and data scientists may also use declarative prompting to quickly generate a first draft, but they would be expected to review and refine the code afterward. Of course, one must keep in mind that the time needed to improve AI-generated code may cancel out the time saved by writing a short declarative prompt in the first place.\n\nBy contrast, the imperative prompt (Version 2) leaves very little to chance — each algorithmic step is specified in detail. Dependencies on non-standard packages are explicitly avoided, which can sidestep certain problems in production (e.g., breaking changes or deprecations in third-party packages, difficulty debugging strange code behavior, exposure to security vulnerabilities, installation overhead). But the greater control and robustness come at the cost of a verbose prompt, which may be almost as effort-intensive as writing the code directly. Typical personas who opt for imperative prompting may include software developers and data scientists. While they are quite capable of writing the actual code from scratch, they may find it more efficient to feed pseudocode to a generative AI model instead. For example, a Python developer might use pseudocode to quickly generate code in a different and less familiar programming language, such as C++ or Java, thereby reducing the likelihood of syntactic errors and the time spent debugging them.\n\nFinally, the hybrid prompt (Version 3) seeks to combine the best of both worlds, using imperative instructions to fix key implementation details (e.g., stipulating the use of NumPy and SciPy), while otherwise employing declarative formulations to keep the overall prompt concise and easy to follow. Hybrid prompts offer freedom within a framework, guiding the implementation without completely locking it in. Typical personas who may lean toward a hybrid of declarative and imperative prompting include senior developers, data scientists, and solution architects. For example, in the case of code generation, a data scientist may wish to optimize an algorithm using advanced libraries that a generative AI model might not select by default. Meanwhile, a solution architect may need to explicitly steer the AI away from certain third-party components to comply with architectural guidelines.\n\nUltimately, the choice between declarative and imperative prompt engineering for generative AI should be a deliberate one, weighing the pros and cons of each paradigm in the given application context.",
         "2025-07-25T20:41:22",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/declarative-and-imperative-prompt-engineering-for-generative-ai/",
         "2025-07-26T06:23:31.272668",
         "refers to the careful design and optimization of inputs (e.g., queries or instructions) for guiding the behavior and responses of generative AI models. Prompts are typically structured using either the declarative or imperative paradigm, or a mixture of both. The choice of paradigm can have a big impact on the accuracy and relevance of the resulting model output. This article provides a conceptual overview of declarative and imperative prompting, discusses advantages and limitations of each paradigm, and considers the practical implications. The What and the How In simple terms, declarative prompts express what should be done, while imperative prompts specify how something should be done. Suppose you are at a pizzeria with a friend. You tell the waiter that you will have the Neapolitan. Since you only mention the type of pizza you want without specifying exactly how you want it prepared, this is an example of a declarative prompt. Meanwhile, your friend — who has some very particular culinary preferences and is in the mood for a bespoke pizza alle quattro stagioni — proceeds to tell the waiter exactly how she would like it made; this is an example of an imperative prompt. Declarative and imperative paradigms of expression have a long history in computing, with some programming languages favoring one paradigm over the other. A language such as C tends to be used for imperative programming, while a language like Prolog is geared towards declarative programming. For example, consider the following problem of identifying the ancestors of a person named Charlie. We happen to know the following facts about Charlie’s relatives: Bob is Charlie’s parent, Alice is Bob’s parent, Susan is Dave’s parent, and John is Alice’s parent. Based on this information, the code below shows how we can identify Charlie’s ancestors using Prolog. parent(alice, bob). parent(bob, charlie). parent(susan, dave). parent(john, alice). ancestor(X, Y) :- parent(X, Y). ancestor(X, Y) :- parent(X, Z), ancestor(Z, Y). get_ancestors(Person, Ancestors) :- findall(X, ancestor(X, Person), Ancestors). ?- get_ancestors(charlie, Ancestors). Although the Prolog syntax may seem strange at first, it actually expresses the problem we wish to solve in a concise and intuitive way. First, the code lays out the known facts (i.e., who is whose parent). It then recursively defines the predicate ancestor(X, Y) , which evaluates to true if X is an ancestor of Y . Finally, the predicate findall(X, Goal, List) triggers the Prolog interpreter to repeatedly evaluate Goal and store all successful bindings of X in List . In our case, this means identifying all solutions to ancestor(X, Person) and storing them in the variable Ancestors . Notice that we do not specify the implementation details (the “how”) of any of these predicates (the “what”). In contrast, the C implementation below identifies Charlie’s ancestors by describing in painstaking detail exactly how this should be done. #include <stdio.h> #include <string.h> #define MAX_PEOPLE 10 #define MAX_ANCESTORS 10 // Structure to represent parent relationships typedef struct { char parent[20]; char child[20]; } ParentRelation; ParentRelation relations[] = { {\"alice\", \"bob\"}, {\"bob\", \"charlie\"}, {\"susan\", \"dave\"}, {\"john\", \"alice\"} }; int numRelations = 4; // Check if X is a parent of Y int isParent(const char *x, const char *y) { for (int i = 0; i < numRelations; ++i) { if (strcmp(relations[i].parent, x) == 0 && strcmp(relations[i].child, y) == 0) { return 1; } } return 0; } // Recursive function to check if X is an ancestor of Y int isAncestor(const char *x, const char *y) { if (isParent(x, y)) return 1; for (int i = 0; i < numRelations; ++i) { if (strcmp(relations[i].child, y) == 0) { if (isAncestor(x, relations[i].parent)) return 1; } } return 0; } // Get all ancestors of a person void getAncestors(const char *person, char ancestors[][20], int *numAncestors) { *numAncestors = 0; for (int i = 0; i < numRelations; ++i) { if (isAncestor(relations[i].parent, person)) { strcpy(ancestors[*numAncestors], relations[i].parent); (*numAncestors)++; } } } int main() { char person[] = \"charlie\"; char ancestors[MAX_ANCESTORS][20]; int count; getAncestors(person, ancestors, &count); printf(\"Ancestors of %s: \", person); for (int i = 0; i < count; ++i) { printf(\"%s \", ancestors[i]); } return 0; } Nowadays, the increasing availability of feature-rich libraries and APIs, and the consolidation of architectural best practices (e.g., programming to interfaces, using configuration over code), allows us to focus on the “what” without having to worry about the “how” in many cases. Indeed, as suggested in the short video below, a lot of code can — and perhaps should — be written in a declarative manner. From Programming to Prompting If we think of prompt engineering as the next evolutionary step in programming — tracing the journey from machine-centric languages such as Assembly and C to more human-centric languages like Java and Python — then the relevance of declarative and imperative paradigms to prompt engineering becomes apparent. Although we can now instruct a generative AI model simply using natural language, we still need to decide on the extent to which the instruction should express what is to be achieved versus how it is to be achieved. Consider the scenario of a developer who would like to use an AI assistant to generate code — specifically, Python code to compute the cosine distance between two vectors. Following are three versions of a prompt that the developer might write to achieve her goal. Version 1 is declarative, Version 2 is imperative, and Version 3 is a hybrid of the two. The code generated by OpenAI’s GPT-4 model in response to each of these prompts is also provided. Prompt Version 1 (Declarative) Write a short and fast function in Python to compute the cosine distance between two input vectors. Result: import numpy as np def cosine_distance(u, v): u = np.array(u) v = np.array(v) return 1 - np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v)) Prompt Version 2 (Imperative) Write a Python function cosine_distance(v1, v2) that computes the cosine distance between two vectors. Follow these steps using only built-in functions: 1. Raise a ValueError exception if v1 or v2 are empty, or if v1 and v2 are of different lengths. 2. Compute the dot product of v1 and v2. 3. Compute the magnitude of each vector and raise a ValueError if either magnitude is zero. 4. Divide the dot product by the product of the two magnitudes to get the cosine similarity. 5. Do 1 minus the cosine similarity to obtain cosine distance. 6. Return the resulting distance. Result: import math def cosine_distance(v1, v2): # Step 1: Input validation if not v1 or not v2: raise ValueError(\"Input vectors must not be empty.\") if len(v1) != len(v2): raise ValueError(\"Vectors must be of the same length.\") # Step 2: Compute dot product dot_product = sum(a * b for a, b in zip(v1, v2)) # Step 3: Compute magnitudes mag_v1 = math.sqrt(sum(a ** 2 for a in v1)) mag_v2 = math.sqrt(sum(b ** 2 for b in v2)) if mag_v1 == 0 or mag_v2 == 0: raise ValueError(\"Vectors must not have zero magnitude.\") # Step 4 & 5: Compute cosine similarity and distance cosine_similarity = dot_product / (mag_v1 * mag_v2) cosine_distance = 1 - cosine_similarity # Step 6: Return result return cosine_distance Prompt Version 3 (Hybrid) Write a fast Python function that computes the cosine distance between two vectors v1 and v2 using relevant optimized functions from numpy and scipy. The function should validate the input vectors (non-empty, equal length) and gracefully handle invalid inputs with exceptions. Result: import numpy as np from scipy.spatial.distance import cosine def cosine_distance(v1, v2): # Convert inputs to NumPy arrays v1 = np.asarray(v1, dtype=np.float64) v2 = np.asarray(v2, dtype=np.float64) # Validation checks if v1.size == 0 or v2.size == 0: raise ValueError(\"Input vectors must be non-empty.\") if v1.shape != v2.shape: raise ValueError(\"Vectors must have the same shape.\") if not np.any(v1) or not np.any(v2): raise ValueError(\"Vectors must not be zero vectors.\") # Compute cosine distance using optimized function return cosine(v1, v2) Horses for Courses The three prompts and their respective AI-generated implementations shown above imply different trade-offs and may be suited to different personas and scenarios in practice. The declarative prompt (Version 1) is short and simple. It does not specify details of the exact algorithmic approach to be taken, expressing instead the high-level task only. As such, it promotes creativity and flexibility in implementation. The downside of such a prompt, of course, is that the result may not always be reproducible or robust; in the above case, the code generated by the declarative prompt could vary significantly across inference calls, and does not handle edge cases, which could be a problem if the code is intended for use in production. Despite these limitations, typical personas who may favor the declarative paradigm include product managers, UX designers, and business domain experts who lack coding expertise and may not need production-grade AI responses. Software developers and data scientists may also use declarative prompting to quickly generate a first draft, but they would be expected to review and refine the code afterward. Of course, one must keep in mind that the time needed to improve AI-generated code may cancel out the time saved by writing a short declarative prompt in the first place. By contrast, the imperative prompt (Version 2) leaves very little to chance — each algorithmic step is specified in detail. Dependencies on non-standard packages are explicitly avoided, which can sidestep certain problems in production (e.g., breaking changes or deprecations in third-party packages, difficulty debugging strange code behavior, exposure to security vulnerabilities, installation overhead). But the greater control and robustness come at the cost of a verbose prompt, which may be almost as effort-intensive as writing the code directly. Typical personas who opt for imperative prompting may include software developers and data scientists. While they are quite capable of writing the actual code from scratch, they may find it more efficient to feed pseudocode to a generative AI model instead. For example, a Python developer might use pseudocode to quickly generate code in a different and less familiar programming language, such as C++ or Java, thereby reducing the likelihood of syntactic errors and the time spent debugging them. Finally, the hybrid prompt (Version 3) seeks to combine the best of both worlds, using imperative instructions to fix key implementation details (e.g., stipulating the use of NumPy and SciPy), while otherwise employing declarative formulations to keep the overall prompt concise and easy to follow. Hybrid prompts offer freedom within a framework, guiding the implementation without completely locking it in. Typical personas who may lean toward a hybrid of declarative and imperative prompting include senior developers, data scientists, and solution architects. For example, in the case of code generation, a data scientist may wish to optimize an algorithm using advanced libraries that a generative AI model might not select by default. Meanwhile, a solution architect may need to explicitly steer the AI away from certain third-party components to comply with architectural guidelines. Ultimately, the choice between declarative and imperative prompt engineering for generative AI should be a deliberate one, weighing the pros and cons of each paradigm in the given application context.",
         "en",
         "{'MISC': ['#', '# Compute cosine distance using optimized', '# Validation checks if', '&count', 'AI model', 'AI model instead', 'AI model might not select by default', 'APIs', 'Alice is Bob’', 'Although the Prolog syntax may seem strange at first', 'Although we can now instruct', 'Ancestors', 'Assembly and C to more human-centric languages like Java and Python — then the relevance of declarative and imperative paradigms', 'Based', 'Bob is Charlie’', 'C++ or', 'Charlie’', 'Check if X is', 'Compute the', 'Compute the magnitude of each vector and raise', 'Divide the', 'Do 1 minus', 'Finally', 'Follow these steps using only built-in functions', 'Following are three versions of', 'From Programming to Prompting If we think of prompt engineering as the next evolutionary step in programming — tracing the journey from machine', 'GPT-4', 'Get all ancestors', 'Goal', 'Goal and store all successful bindings of X in List', 'Horses for Courses The three', 'Imperative', 'Indeed', 'Input validation if not v1 or not v2', 'It does not specify details of the', 'Meanwhile', 'Of course', 'Person', 'Person) and storing them in the variable', 'Prolog', 'Prompt Version 2', 'Python', 'Python to compute', 'Raise', 'Return the resulting distance', 'Step 2: Compute', 'Step 3:', 'Step 4 & 5:', 'Step 6', 'Structure to', 'The What and the How In simple terms', 'The choice of paradigm can', 'The code generated by OpenAI’', 'The downside of such', 'The function should validate the input vectors', 'Typical personas', 'Ultimately', 'ValueError', 'Version 1', 'Version 2', 'Version 2 is', 'Version 3', 'Version 3) seeks to combine the best of both worlds', 'We happen to know the following facts about Charlie’', 'While they are', 'Write', 'You tell the waiter that you will have the Neapolitan', 'allows us to focus on the “what” without having to worry about the “how” in many cases', 'and Version 3 is', 'and considers the practical implications', 'and does not handle edge cases', 'and the consolidation of architectural best practices', 'breaking changes or deprecations in third-party packages', 'charlie', 'engineering for generative AI should be', 'equal length) and gracefully handle invalid inputs with exceptions', 'for guiding the behavior and responses of generative', 'freedom within', 'guiding the implementation without completely locking it in', 'is that the result may not always be reproducible or', 'isAncestor(x', 'numRelations', 'numpy as np', 'of writing the actual code from scratch', 'one must keep in mind that the time needed to improve AI-generated', 'programming to interfaces', 'raise ValueError(\"Vectors must have the same shape', 'specify how something should be done', 'stipulating the use of NumPy and SciPy', 'strcmp(relations[i].child', 'strcmp(relations[i].parent', 'the C implementation below', 'the choice between declarative and imperative', 'the code below shows how we can', 'the code generated by the declarative', 'the following problem of identifying the ancestors of', 'the scenario of', 'thereby reducing the likelihood of syntactic errors and the time', 'they may find it more efficient to feed pseudocode to a generative', 'this means identifying all solutions to ancestor(X', 'v): u', 'v2', 'v2 are empty', 'v2): # Step 1', 'weighing the pros and cons of each paradigm in the given application context', 'which may be almost as effort', 'while', 'with some programming languages favoring one paradigm over the other'], 'PER': ['- get_ancestors(charlie', 'Charlie', 'Despite', 'List', 'Python', 'Recursive', 'Since you only mention the type of pizza you want without specifying', 'Suppose you are', 'Susan is Dave’', 'Write', 'Y', 'ancestors by describing', 'and John is Alice’', 'getAncestors(person', 'int count', 'it promotes creativity and flexibility in implementation', 'parent(bob', 'verbose', 'which can sidestep'], 'ORG': ['First', 'For', 'Hybrid', 'Nowadays', 'ParentRelation', 'Software developers and data scientists may also', 'The declarative', 'b for', 'dave', 'e.g', 'numAncestors', 'software developers and data scientists', 'the increasing availability of feature-rich'], 'LOC': ['AI', 'Declarative', 'Result', 'Typical', 'UX', 'Write', 'Y', 'Z', 'ancestors', 'cosine', 'instead the high-level task only.', 'math.sqrt(sum(a', 'math.sqrt(sum(b', 'np.float64', 'numAncestors)++', 'prompting']}",
         "[-0.015093160793185234, 0.05118678882718086, 0.03702368214726448, -0.01668277382850647, -0.09097631275653839, -0.03296114504337311, -0.0020041274838149548, 0.04649681597948074, 0.0160345621407032, -0.029003730043768883, -0.044418562203645706, -0.08989040553569794, 0.042280469089746475, -0.02528032287955284, 0.07166208326816559, -0.0761040672659874, 0.13622818887233734, -0.04511695355176926, -0.02690192125737667, 0.016811762005090714, 0.11613021790981293, 0.0003327246231492609, -0.026880383491516113, -0.028230460360646248, -0.04646642878651619, 0.04044797271490097, 0.031975943595170975, -0.059014685451984406, 0.04801357164978981, -0.007315949536859989, -0.01962035335600376, 0.06406727433204651, 0.11094186455011368, 0.09063930064439774, -0.06291196495294571, 0.04852132499217987, -0.022836899384856224, -0.017180783674120903, 0.06044973433017731, -0.0072079431265592575, -0.024834228679537773, -0.02512061782181263, -0.0419253446161747, -0.0409855954349041, 0.045416053384542465, -0.04408120736479759, -0.07961900532245636, 0.024273190647363663, -0.033795084804296494, -0.06373704969882965, -0.16964833438396454, -0.041631489992141724, -0.04695736616849899, -0.0034058920573443174, -0.01140138041228056, -0.011937255039811134, 0.059888068586587906, 0.0028378756251186132, -0.035425249487161636, -0.015072559006512165, -0.1259320080280304, -0.06891069561243057, -0.05247759819030762, 0.049022555351257324, 0.07717359811067581, -0.028296396136283875, -0.01309842336922884, -0.03562953695654869, 0.019585223868489265, 0.0465218722820282, 0.016938157379627228, 0.0050120726227760315, -0.017311854287981987, 0.0034735258668661118, -0.011524180881679058, 0.025160737335681915, -0.0066844807006418705, -0.02099999599158764, -0.07458258420228958, -0.05273708701133728, 0.011628239415585995, 0.036193300038576126, -0.011968610808253288, 0.010719822719693184, 0.014053121209144592, -0.027283931151032448, -0.002968971384689212, 0.01652170903980732, 0.10930486023426056, 0.04452070966362953, -0.018703095614910126, -0.061656080186367035, -0.052973587065935135, -0.02299368381500244, 0.08027619868516922, 0.06300561130046844, -0.019772036001086235, -0.1381610631942749, -0.03423135727643967, 0.023188775405287743, 0.026522014290094376, 0.061905767768621445, 0.035258278250694275, -0.1293829381465912, -0.023393981158733368, -0.042037103325128555, 0.026437580585479736, -0.02149835228919983, 0.03370235860347748, -0.03814901411533356, -0.07181277871131897, 0.01577802002429962, 0.0633457601070404, -0.11613423377275467, -0.03781193494796753, 0.0617033876478672, 0.06452549248933792, 0.024786463007330894, 0.04136548563838005, -0.0354599729180336, 0.04341240972280502, -0.018394988030195236, -0.013069182634353638, 0.05992032587528229, 0.03919360786676407, -0.0524202398955822, -0.06369699537754059, 1.6994738964371992e-33, -0.03853679448366165, 0.035128384828567505, 0.022072166204452515, 0.10155174136161804, 0.05339713767170906, 0.08544009178876877, 0.007876862771809101, -0.016622865572571754, 0.033903785049915314, 0.0144071439281106, 0.02943948283791542, -0.02319648303091526, -0.04199311509728432, 0.1224343329668045, 0.03524034470319748, 1.8797447410179302e-05, 0.02256530337035656, 0.08020216971635818, -0.05602936074137688, -0.023525111377239227, 0.048704177141189575, 0.03300967440009117, -0.011597231030464172, 0.04619516804814339, 0.03243134170770645, 0.018483683466911316, 0.028701364994049072, 0.008725181221961975, -0.05425981432199478, 0.0027258736081421375, -0.05898719280958176, -0.06932632625102997, -0.0633617639541626, -0.002321982989087701, 0.044975683093070984, 0.05482277274131775, -0.06544827669858932, -0.048530954867601395, -0.023782916367053986, -0.026955505833029747, -0.042584143579006195, -0.01934361644089222, -0.03312024846673012, 0.08639153838157654, -0.07940717041492462, -0.02573370188474655, -0.02807149477303028, 0.006931697949767113, -0.03544221073389053, 0.0022749255876988173, 0.03261426463723183, 0.06416101008653641, 0.06711243838071823, -0.0561947375535965, 0.037978000938892365, 0.04218222573399544, 0.053446996957063675, -0.0180340763181448, -0.013912014663219452, -0.06631351262331009, 0.032104477286338806, 0.0008624608162790537, -0.01319935917854309, 0.02824198268353939, -0.001263929414562881, 0.04667913168668747, -0.06895039975643158, 0.023430287837982178, 0.1252029836177826, 0.06440666317939758, -0.04847149923443794, -0.0015364906284958124, -0.06340793520212173, 0.026631120592355728, -0.02508898824453354, 0.015567215159535408, -0.008876001462340355, -0.07918264716863632, 0.1089409813284874, -0.04260243475437164, -0.003397496649995446, 0.016462884843349457, -0.043064769357442856, 0.008265518583357334, 0.003933812025934458, 0.04312705621123314, 0.07355072349309921, 0.0241928119212389, 0.04702550172805786, 0.005989658180624247, -0.009391965344548225, -0.004911170806735754, 0.007992601953446865, 0.02866937592625618, 0.013605157844722271, -3.0686296558605124e-33, -0.012013222090899944, -0.00024050427600741386, -0.1310090571641922, 0.021102124825119972, -0.05413475260138512, -0.02103954367339611, -0.05476527661085129, -0.1102793961763382, 0.030356042087078094, -0.08703160285949707, -0.05446653813123703, 0.022654032334685326, 0.06230973079800606, -0.01676361821591854, -0.01737254299223423, 0.09640174359083176, -0.002634988399222493, -0.004906237591058016, 0.02646246924996376, -0.014247077517211437, -0.014174488373100758, 0.06290704011917114, -0.1276332437992096, -0.03732256591320038, -0.06664421409368515, 0.048079345375299454, -0.06353038549423218, 0.10974742472171783, -0.0020110791083425283, -0.012580519542098045, -0.029905173927545547, 0.000832485849969089, -0.05274323374032974, 0.05189264565706253, -0.03249693289399147, 0.10906405001878738, 0.04081182926893234, -0.0003802121209446341, -0.010988899506628513, 0.0657125860452652, -0.0011574849486351013, -0.06721016019582748, 0.04159126058220863, 0.09839524328708649, -0.043465506285429, -0.06991636753082275, 0.02415384165942669, -0.04651108756661415, 0.014061247929930687, 0.004933843854814768, -0.020016470924019814, 0.01526634395122528, -0.0686076283454895, -0.016156142577528954, -0.08534318953752518, -0.032215844839811325, -0.04271320626139641, -0.03930342569947243, 0.033154282718896866, -0.03025757148861885, -0.042164396494627, 0.012108651921153069, 0.014467228204011917, -0.018228689208626747, -0.040398549288511276, -0.01459114532917738, 0.011969232000410557, -0.045609597116708755, 0.04335365816950798, -0.04385694861412048, 0.02201518975198269, 0.02650739811360836, 0.005762285087257624, 0.02215513214468956, 0.010455670766532421, -0.018286945298314095, -0.019248614087700844, -0.021398862823843956, -0.05108862742781639, -0.047380127012729645, 0.04339783266186714, -0.025399193167686462, -0.016142433509230614, 0.0654061809182167, -0.037701088935136795, -0.028550494462251663, 0.01706446148455143, 0.08990206569433212, -0.08024271577596664, 0.08348869532346725, -0.008248464204370975, 0.03633755445480347, 0.04405903071165085, 0.07220780849456787, 0.034930046647787094, -5.9442424316102915e-08, -0.029923751950263977, 0.001019962364807725, 0.009836193174123764, 0.02032901719212532, 0.11568896472454071, -0.06279881298542023, -0.03591079264879227, -0.07386121153831482, -0.03565562516450882, -0.0808519497513771, -0.019719524309039116, 0.0403660349547863, 0.0036883074790239334, 0.044460784643888474, 0.036817412823438644, 0.06018620729446411, 0.0252806656062603, -0.054032113403081894, -0.046865738928318024, 0.02278454601764679, 0.07595236599445343, -0.03330370411276817, -0.07551813125610352, -0.0034923998173326254, 0.06876762211322784, 0.04522436484694481, 0.025629548355937004, 0.08536659181118011, -0.04956208914518356, 0.09105576574802399, 0.016674062237143517, 0.041564200073480606, 0.004109347239136696, 0.02757950872182846, -0.01022501289844513, 0.02229338139295578, 0.02057204395532608, -0.07868865877389908, 0.030929090455174446, -0.06999030709266663, 0.03295338153839111, -0.0004668195906560868, -0.10561761260032654, 0.02806629054248333, -0.05078279972076416, 0.022617032751441002, 0.04361046850681305, -0.07384133338928223, -0.005753660574555397, 0.11596889793872833, -0.046355120837688446, -0.019267834722995758, 0.08038435131311417, 0.06619621813297272, 0.020229768007993698, 0.040453918278217316, 0.014340443536639214, 0.011282230727374554, 0.02886996604502201, 0.08553648740053177, 0.05945834144949913, 0.12784142792224884, 0.03045782260596752, -0.09240499883890152]",
         "0.184"
        ],
        [
         "36",
         "327",
         "En Indonésie, l’appel à l’aide d’un ex-soldat enrôlé dans l’armée russe enflamme le débat",
         "Dans une vidéo TikTok, un ancien membre de la marine indonésienne, qui aurait perdu sa citoyenneté en partant combattre avec l’armée russe en Ukraine, appelle à l’aide Jakarta pour pouvoir retourner dans son pays. Son appel suscite une vive polémique à bien des égards dans son pays.",
         "À gauche, une image publiée sur TikTok le 7 mai montre Satria Arta Kumbara portant l’uniforme indonésien. À droite, une capture d’écran d’une vidéo publiée sur TikTok le 9 juillet, dans laquelle il apparaît avec un uniforme russe.\n\n“En raison de mon ignorance, j'ai signé un contrat avec le ministère russe de la Défense, ce qui a entraîné le retrait de ma citoyenneté. [...] Je vous prie de bien vouloir faire preuve de magnanimité pour m'aider à mettre fin à ce contrat et à me restituer mon droit à la citoyenneté pour que je puisse retourner en Indonésie” : ainsi s’exprime Satria Arta Kumbara, en uniforme militaire, face caméra, dans une vidéo publiée sur TikTok le 20 juillet.\n\nCette séquence, vue plus d'un million de fois, secoue l’opinion publique en Indonésie, où l’homme en question n’est pas un inconnu.\n\nDébut mai 2025, il avait déjà fait les gros titres, après que ce même compte TikTok - nommé @zstorm689 - a publié deux photos de lui avec l’uniforme militaire indonésien puis russe. “Les Marines se battent maintenant avec la Russie en Ukraine”, était-il écrit en légende de la publication.\n\nVidéo publiée par le compte TikTok @zstorm689 le 7 mai. Pour afficher ce contenu TikTok, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nAncien membre de la marine indonésienne\n\nLe chef du service d'information de la marine indonésienne avait alors confirmé que Satria Arta Kumbara avait bien évolué dans ses rangs, au grade de sergent-chef, et que sa désertion était effective depuis le 13 juin 2022.\n\nIl avait également fait savoir qu’une décision de justice d’avril 2023 avait condamné cet homme “à un an de prison et à une peine supplémentaire de licenciement”.\n\nDifficile de savoir exactement depuis quand l’homme se trouve en Ukraine.\n\nSur Linkedin, on peut voir que Satria Arta Kumbara avait manifesté, entre avril et juillet 2024, son intérêt pour divers postes dans différents pays - agent de sécurité au Koweït , spécialiste en sécurité et protection en Irak ou encore responsable d’un département d'ingénierie . “Je suis intéressé, mais je viens d'Indonésie, est-ce possible ? Avec 16 ans d'expérience dans la marine”, écrivait-il par exemple en commentaire d’une offre . Nous n’avons pas été en mesure d’affirmer s’il avait déjà quitté l’Indonésie à ce moment-là.\n\nEn passant par la Malaisie et le Qatar\n\nLes premières publications de son compte TikTok le montrant en Russie remontent à mars 2025.\n\nIl est possible de retracer une partie de son parcours, grâce notamment à des photos publiées sur un autre compte TikTok : satria_piek689. Celui-ci se présente comme un “2ème compte @zstrom689”, et contient de nombreuses vidéos identiques à celles mentionnées précédemment, laissant à penser qu’il est géré par le même homme.\n\nOn le voit ainsi à Kuala Lumpur, en Malaisie, puis à l’aéroport d’Oufa, capitale de la république de Bachkirie, dans le centre de la Russie.\n\n“Je suis passé par la Malaisie avant d'arriver à Moscou... Jakarta-Malaisie-Qatar-Moscou” écrit d’ailleurs Satria Arta Kumbara en réponse à un des commentaires.\n\nÀ gauche, une image montre Satria Arta Kumbara à Kuala Lumpur. À droite, on le voit à l’aéroport d’Oufa, en Russie. Ces images ont été publiées le 27 juin 2025. © TikTok\n\nPlusieurs images le montrent ensuite en vêtements civils à proximité d’une des places principales de la ville d’Ichimbaï, située à environ 150 kilomètres au sud d’Oufa.\n\nLa rédaction des Observateurs a géolocalisé ces images publiées le 24 mars 2025 (gauche) et le 27 juin (centre, droite) autour de la place Lénine à Ichimbaï. © TikTok\n\nArmée régulière russe\n\nÀ partir de mi-avril 2025, des photos et vidéos publiées sur TikTok ou Facebook le montrent en uniforme, accompagné d’autres soldats, sans qu’il soit possible de déterminer le lieu de combat.\n\nVidéo publiée par le compte Facebook de Satria Arta Kumbara le 1er juin. Pour afficher ce contenu Facebook, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nDans une interview accordée au média indonésien Republika le 10 mai, Satria Arta Kumbara a précisé qu’il n’était pas un mercenaire mais bien un membre de l’armée régulière russe. Il disait être en Ukraine, combattant “avec des citoyens chinois, camerounais, ghanéens et colombiens”.\n\nCapture d’écran de l’article publié par Republika le 10 mai. Sur l’image, Satria Arta Kumbara est assis tout à droite. © Republika\n\nLa Russie a progressivement cherché à attirer en dehors de ses frontières pour grossir son armée. En mai 2022, elle abolissait ainsi la limite d’âge pour être recruté et en septembre, elle créait un processus de naturalisation simplifié et accéléré pour les étrangers qui combattent dans ses rangs.\n\nLe ministère britannique de la Défense estimait en avril 2025 que la Russie avait recruté plus de 1 500 ressortissants étrangers entre avril 2023 et mai 2024, essentiellement issus d’Asie du Sud et de l'Est. La BBC et Mediazona révèlaient par ailleurs en juillet que plus de 500 étrangers combattant avec la Russie avaient été tués en Ukraine.\n\nSur internet, des sites font ainsi la promotion de contrats de service. L’un d’eux incite à signer un contrat à Oufa , mettant en valeur un salaire conséquent (4 220 000 roubles annuelles, soit 45 000 euros). Un autre site mentionne la possibilité, y compris pour les étrangers, de s’enrôler à Ichimbaï.\n\nÀ gauche, un site faisant la promotion de contrat militaire à Oufa. À droite, un site publie des informations pour s’engager dans l’armée à Ichimbaï. Les sites ont été traduits automatiquement par Google. © Observateurs\n\n“Gagner sa vie”\n\nMais pourquoi Satria Arta Kumbara aurait-il rejoint la Russie ?\n\n“Je n'ai jamais trahi mon pays. Mon intention en venant ici était seulement de gagner ma vie”, affirme-t-il dans la vidéo publiée récemment.\n\nDébut juin, il avait aussi partagé une vidéo sur Facebook, dans laquelle il défendait cette même version, et pointait du doigt la réaction de ses détracteurs et la corruption des autorités.\n\n“Ceux qui sont occupés à voler l'argent du peuple sont protégés. Ceux qui essaient de gagner de l'argent dehors avec leur passion et leurs propres compétences sont harcelés”, dénonçait-il.\n\nVidéo publiée par le compte Facebook de Serda Satria Arta Kumbara le 1er juin. Pour afficher ce contenu Facebook, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix\n\nQuatre jours après la publication de la vidéo, le commandant du corps des marines a affirmé que Satria Arta Kumbara était parti en Russie parce qu’il était endetté. Il dit soupçonner que l’homme ait emprunté de l’argent pour “financer son style de vie hédoniste”, puis aurait commencé les jeux d’argent pour rembourser ses dettes, sans succès. Nous n’avons pas été en mesure de confirmer ces déclarations.\n\nLes raisons qui ont poussé le militaire à souhaiter rentrer sont par ailleurs floues. “Peut-être qu’il n'a pas reçu assez d'argent. La situation sur le front empire également”, conjecture Radityo Dharmaputra, directeur du Centre d'études européennes et eurasiennes de l'université indonésienne Airlangga.\n\nControverse sur la question de la citoyenneté\n\nDésormais, c’est la question de l’avenir du soldat qui agite la société indonésienne.\n\n“La citoyenneté indonésienne signifie tout pour moi et n'a pas de prix”, affirme Satria Arta Kumbara dans la vidéo devenue virale, demandant l’aide du président de la République indonésien, du vice-président, et du ministre des Affaires étrangères.\n\nDès mai 2025 , le ministre de la Justice avait confirmé que l’enrôlement de Satria Arta Kumbara en Russie était synonyme de perte de sa citoyenneté indonésienne. Le soldat, lui, affirme ne pas avoir été au courant de ce mécanisme.\n\n“Pour certaines personnes, il est parfaitement acceptable d'aller se battre en Russie”\n\nLe débat sur la réponse à apporter est “polarisé” dans le pays, souligne Radityo Dharmaputra.\n\nIl explique que si de nombreux universitaires et acteurs du milieu militaire ont souligné que le soldat avait enfreint la loi, celui-ci a toutefois bénéficié du soutien d’une partie importante du grand public :\n\n“Le problème, c'est qu'en Indonésie, il est très difficile de trouver du travail. La situation n'est plus aussi bonne qu'il y a quelques années. Les salaires dans l’armée sont aussi assez bas, et c’est un problème pour beaucoup d’emplois. Donc je ne suis pas surpris que s'il y a une offre de l'étranger proposant de l'argent pour travailler, il l'accepte. (...) Il y a des Indonésiens qui veulent partir à l'étranger juste pour avoir une vie meilleure, plus d'argent qu'ils peuvent envoyer à leur famille. Il faut comprendre que la façon dont [le soldat] a présenté la situation résonne parfaitement avec la situation indonésienne, notamment sur la question de la corruption. Certains Indonésiens estiment que son discours est acceptable. Ils se disent : ‘Il n'y a pas d'emploi en Indonésie. Il a trouvé un emploi, a été payé, et maintenant il a perdu sa citoyenneté, alors que tous ces fonctionnaires que nous détestons vraiment sont toujours en sécurité.’ Il y a beaucoup de gens qui, s'ils ne le soutiennent pas directement, critiquent le gouvernement ou ceux qui le condamnent.”\n\nDans les commentaires publiés sous ses vidéos TikTok, de nombreux utilisateurs félicitent d’ailleurs le soldat, ou demandent des informations pour suivre sa voie.\n\n“Beaucoup d'Indonésiens ont une tendance à être anti-occidentaux”\n\nCe soutien d’une partie de l’opinion publique s'inscrit aussi dans le cadre d'un appui plus large d'une frange de la population indonésienne envers la Russie dans le conflit ukrainien , explique Radityo Dharmaputra :\n\n“Premièrement, ce soutien s'explique par l'histoire de l'Union soviétique et de l'Indonésie pendant la Guerre froide. Les Indonésiens ont toujours perçu l'Union soviétique, et par extension la Russie, comme des amis ayant aidé leur pays. Ensuite, beaucoup d'Indonésiens ont une tendance à être anti-occidentaux, et comme la Russie se présente comme une grande puissance anti-occidentale, beaucoup d’entre eux lui sont favorables. Poutine est aussi très populaire. L'idée d'un leader fort résonne beaucoup en Indonésie. Et puis les événements du 7 octobre 2023 à Gaza, combinés à la déclaration initiale de Zelensky soutenant Israël, ont détourné beaucoup d’Indonésiens de leur soutien à l'Ukraine.”\n\nLes récentes informations sur le mode de vie de Satria Arta Kumbara pourraient toutefois provoquer un changement de l’opinion publique, estime le chercheur. Les jeux d’argent en ligne sont théoriquement interdits en Indonésie, mais leur popularité a été croissante récemment, résultant en une série d’incidents et poussant le gouvernement à agir .\n\nRéponse en suspens\n\nSuite à la diffusion de la vidéo, plusieurs autorités ont semblé ne pas vouloir prendre part à ce débat.\n\nLa marine indonésienne a déclaré que Satria Arta Kumbara ne faisait plus partie des forces armées du pays, ajoutant qu’elle ne répondrait pas à la demande de Satria et respecterait la décision de 2023.\n\nLe ministère des Affaires étrangères a lui fait savoir qu’il continuait à “surveiller les allées et venues de la personne concernée et de communiquer avec elle\" et que la question relevait de l'autorité du ministère de la Justice. Un ministère qui a affirmé que la seule manière de retrouver la citoyenneté dans ce cas était de “soumettre une demande de citoyenneté au président”.",
         "2025-07-25T17:42:31",
         "https://www.france24.com/fr/rss",
         "https://www.france24.com/fr/asie-pacifique/20250725-indon%C3%A9sie-appel-ex-soldat-enr%C3%B4l%C3%A9-arm%C3%A9e-russe-ukraine",
         "2025-07-26T05:53:43.794642",
         "À gauche, une image publiée sur TikTok le 7 mai montre Satria Arta Kumbara portant l’uniforme indonésien. À droite, une capture d’écran d’une vidéo publiée sur TikTok le 9 juillet, dans laquelle il apparaît avec un uniforme russe. “En raison de mon ignorance, j'ai signé un contrat avec le ministère russe de la Défense, ce qui a entraîné le retrait de ma citoyenneté. [...] Je vous prie de bien vouloir faire preuve de magnanimité pour m'aider à mettre fin à ce contrat et à me restituer mon droit à la citoyenneté pour que je puisse retourner en Indonésie” : ainsi s’exprime Satria Arta Kumbara, en uniforme militaire, face caméra, dans une vidéo publiée sur TikTok le 20 juillet. Cette séquence, vue plus d'un million de fois, secoue l’opinion publique en Indonésie, où l’homme en question n’est pas un inconnu. Début mai 2025, il avait déjà fait les gros titres, après que ce même compte TikTok - nommé @zstorm689 - a publié deux photos de lui avec l’uniforme militaire indonésien puis russe. “Les Marines se battent maintenant avec la Russie en Ukraine”, était-il écrit en légende de la publication. Vidéo publiée par le compte TikTok @zstorm689 le 7 mai. Pour afficher ce contenu TikTok, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix Ancien membre de la marine indonésienne Le chef du service d'information de la marine indonésienne avait alors confirmé que Satria Arta Kumbara avait bien évolué dans ses rangs, au grade de sergent-chef, et que sa désertion était effective depuis le 13 juin 2022. Il avait également fait savoir qu’une décision de justice d’avril 2023 avait condamné cet homme “à un an de prison et à une peine supplémentaire de licenciement”. Difficile de savoir exactement depuis quand l’homme se trouve en Ukraine. Sur Linkedin, on peut voir que Satria Arta Kumbara avait manifesté, entre avril et juillet 2024, son intérêt pour divers postes dans différents pays - agent de sécurité au Koweït , spécialiste en sécurité et protection en Irak ou encore responsable d’un département d'ingénierie . “Je suis intéressé, mais je viens d'Indonésie, est-ce possible ? Avec 16 ans d'expérience dans la marine”, écrivait-il par exemple en commentaire d’une offre . Nous n’avons pas été en mesure d’affirmer s’il avait déjà quitté l’Indonésie à ce moment-là. En passant par la Malaisie et le Qatar Les premières publications de son compte TikTok le montrant en Russie remontent à mars 2025. Il est possible de retracer une partie de son parcours, grâce notamment à des photos publiées sur un autre compte TikTok : satria_piek689. Celui-ci se présente comme un “2ème compte @zstrom689”, et contient de nombreuses vidéos identiques à celles mentionnées précédemment, laissant à penser qu’il est géré par le même homme. On le voit ainsi à Kuala Lumpur, en Malaisie, puis à l’aéroport d’Oufa, capitale de la république de Bachkirie, dans le centre de la Russie. “Je suis passé par la Malaisie avant d'arriver à Moscou... Jakarta-Malaisie-Qatar-Moscou” écrit d’ailleurs Satria Arta Kumbara en réponse à un des commentaires. À gauche, une image montre Satria Arta Kumbara à Kuala Lumpur. À droite, on le voit à l’aéroport d’Oufa, en Russie. Ces images ont été publiées le 27 juin 2025. © TikTok Plusieurs images le montrent ensuite en vêtements civils à proximité d’une des places principales de la ville d’Ichimbaï, située à environ 150 kilomètres au sud d’Oufa. La rédaction des Observateurs a géolocalisé ces images publiées le 24 mars 2025 (gauche) et le 27 juin (centre, droite) autour de la place Lénine à Ichimbaï. © TikTok Armée régulière russe À partir de mi-avril 2025, des photos et vidéos publiées sur TikTok ou Facebook le montrent en uniforme, accompagné d’autres soldats, sans qu’il soit possible de déterminer le lieu de combat. Vidéo publiée par le compte Facebook de Satria Arta Kumbara le 1er juin. Pour afficher ce contenu Facebook, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix Dans une interview accordée au média indonésien Republika le 10 mai, Satria Arta Kumbara a précisé qu’il n’était pas un mercenaire mais bien un membre de l’armée régulière russe. Il disait être en Ukraine, combattant “avec des citoyens chinois, camerounais, ghanéens et colombiens”. Capture d’écran de l’article publié par Republika le 10 mai. Sur l’image, Satria Arta Kumbara est assis tout à droite. © Republika La Russie a progressivement cherché à attirer en dehors de ses frontières pour grossir son armée. En mai 2022, elle abolissait ainsi la limite d’âge pour être recruté et en septembre, elle créait un processus de naturalisation simplifié et accéléré pour les étrangers qui combattent dans ses rangs. Le ministère britannique de la Défense estimait en avril 2025 que la Russie avait recruté plus de 1 500 ressortissants étrangers entre avril 2023 et mai 2024, essentiellement issus d’Asie du Sud et de l'Est. La BBC et Mediazona révèlaient par ailleurs en juillet que plus de 500 étrangers combattant avec la Russie avaient été tués en Ukraine. Sur internet, des sites font ainsi la promotion de contrats de service. L’un d’eux incite à signer un contrat à Oufa , mettant en valeur un salaire conséquent (4 220 000 roubles annuelles, soit 45 000 euros). Un autre site mentionne la possibilité, y compris pour les étrangers, de s’enrôler à Ichimbaï. À gauche, un site faisant la promotion de contrat militaire à Oufa. À droite, un site publie des informations pour s’engager dans l’armée à Ichimbaï. Les sites ont été traduits automatiquement par Google. © Observateurs “Gagner sa vie” Mais pourquoi Satria Arta Kumbara aurait-il rejoint la Russie ? “Je n'ai jamais trahi mon pays. Mon intention en venant ici était seulement de gagner ma vie”, affirme-t-il dans la vidéo publiée récemment. Début juin, il avait aussi partagé une vidéo sur Facebook, dans laquelle il défendait cette même version, et pointait du doigt la réaction de ses détracteurs et la corruption des autorités. “Ceux qui sont occupés à voler l'argent du peuple sont protégés. Ceux qui essaient de gagner de l'argent dehors avec leur passion et leurs propres compétences sont harcelés”, dénonçait-il. Vidéo publiée par le compte Facebook de Serda Satria Arta Kumbara le 1er juin. Pour afficher ce contenu Facebook, il est nécessaire d'autoriser les cookies de mesure d'audience et de publicité. Accepter Gérer mes choix Quatre jours après la publication de la vidéo, le commandant du corps des marines a affirmé que Satria Arta Kumbara était parti en Russie parce qu’il était endetté. Il dit soupçonner que l’homme ait emprunté de l’argent pour “financer son style de vie hédoniste”, puis aurait commencé les jeux d’argent pour rembourser ses dettes, sans succès. Nous n’avons pas été en mesure de confirmer ces déclarations. Les raisons qui ont poussé le militaire à souhaiter rentrer sont par ailleurs floues. “Peut-être qu’il n'a pas reçu assez d'argent. La situation sur le front empire également”, conjecture Radityo Dharmaputra, directeur du Centre d'études européennes et eurasiennes de l'université indonésienne Airlangga. Controverse sur la question de la citoyenneté Désormais, c’est la question de l’avenir du soldat qui agite la société indonésienne. “La citoyenneté indonésienne signifie tout pour moi et n'a pas de prix”, affirme Satria Arta Kumbara dans la vidéo devenue virale, demandant l’aide du président de la République indonésien, du vice-président, et du ministre des Affaires étrangères. Dès mai 2025 , le ministre de la Justice avait confirmé que l’enrôlement de Satria Arta Kumbara en Russie était synonyme de perte de sa citoyenneté indonésienne. Le soldat, lui, affirme ne pas avoir été au courant de ce mécanisme. “Pour certaines personnes, il est parfaitement acceptable d'aller se battre en Russie” Le débat sur la réponse à apporter est “polarisé” dans le pays, souligne Radityo Dharmaputra. Il explique que si de nombreux universitaires et acteurs du milieu militaire ont souligné que le soldat avait enfreint la loi, celui-ci a toutefois bénéficié du soutien d’une partie importante du grand public : “Le problème, c'est qu'en Indonésie, il est très difficile de trouver du travail. La situation n'est plus aussi bonne qu'il y a quelques années. Les salaires dans l’armée sont aussi assez bas, et c’est un problème pour beaucoup d’emplois. Donc je ne suis pas surpris que s'il y a une offre de l'étranger proposant de l'argent pour travailler, il l'accepte. (...) Il y a des Indonésiens qui veulent partir à l'étranger juste pour avoir une vie meilleure, plus d'argent qu'ils peuvent envoyer à leur famille. Il faut comprendre que la façon dont [le soldat] a présenté la situation résonne parfaitement avec la situation indonésienne, notamment sur la question de la corruption. Certains Indonésiens estiment que son discours est acceptable. Ils se disent : ‘Il n'y a pas d'emploi en Indonésie. Il a trouvé un emploi, a été payé, et maintenant il a perdu sa citoyenneté, alors que tous ces fonctionnaires que nous détestons vraiment sont toujours en sécurité.’ Il y a beaucoup de gens qui, s'ils ne le soutiennent pas directement, critiquent le gouvernement ou ceux qui le condamnent.” Dans les commentaires publiés sous ses vidéos TikTok, de nombreux utilisateurs félicitent d’ailleurs le soldat, ou demandent des informations pour suivre sa voie. “Beaucoup d'Indonésiens ont une tendance à être anti-occidentaux” Ce soutien d’une partie de l’opinion publique s'inscrit aussi dans le cadre d'un appui plus large d'une frange de la population indonésienne envers la Russie dans le conflit ukrainien , explique Radityo Dharmaputra : “Premièrement, ce soutien s'explique par l'histoire de l'Union soviétique et de l'Indonésie pendant la Guerre froide. Les Indonésiens ont toujours perçu l'Union soviétique, et par extension la Russie, comme des amis ayant aidé leur pays. Ensuite, beaucoup d'Indonésiens ont une tendance à être anti-occidentaux, et comme la Russie se présente comme une grande puissance anti-occidentale, beaucoup d’entre eux lui sont favorables. Poutine est aussi très populaire. L'idée d'un leader fort résonne beaucoup en Indonésie. Et puis les événements du 7 octobre 2023 à Gaza, combinés à la déclaration initiale de Zelensky soutenant Israël, ont détourné beaucoup d’Indonésiens de leur soutien à l'Ukraine.” Les récentes informations sur le mode de vie de Satria Arta Kumbara pourraient toutefois provoquer un changement de l’opinion publique, estime le chercheur. Les jeux d’argent en ligne sont théoriquement interdits en Indonésie, mais leur popularité a été croissante récemment, résultant en une série d’incidents et poussant le gouvernement à agir . Réponse en suspens Suite à la diffusion de la vidéo, plusieurs autorités ont semblé ne pas vouloir prendre part à ce débat. La marine indonésienne a déclaré que Satria Arta Kumbara ne faisait plus partie des forces armées du pays, ajoutant qu’elle ne répondrait pas à la demande de Satria et respecterait la décision de 2023. Le ministère des Affaires étrangères a lui fait savoir qu’il continuait à “surveiller les allées et venues de la personne concernée et de communiquer avec elle\" et que la question relevait de l'autorité du ministère de la Justice. Un ministère qui a affirmé que la seule manière de retrouver la citoyenneté dans ce cas était de “soumettre une demande de citoyenneté au président”.",
         "fr",
         "{'ORG': ['@zstorm689 -', '@zstrom689', 'Airlangga', 'BBC', \"Centre d'études européennes et eurasiennes de l'université\", 'Google', 'Justice', 'Linkedin', 'Mediazona', 'Observateurs', 'Observateurs “Gagner sa vie', 'Radityo Dharmaputra', 'Republika', 'TikTok', 'Vidéo', \"l'Union soviétique\", 'ministre de la', 'ministre des Affaires étrangères', 'ministère britannique de la Défense', 'ministère des Affaires étrangères'], 'PER': ['Controverse', 'Lénine', 'Poutine', 'Radityo Dharmaputra', 'Radityo Dharmaputra : “Premièrement', 'Satria Arta', 'Satria Arta Kumbara', 'Vidéo', 'Zelensky', 'président de la République indonésien'], 'LOC': ['Asie du Sud', 'Bachkirie', 'Gaza', 'Ichimbaï', 'Indonésie', 'Indonésiens', 'Irak', 'Israël', 'Jakarta', 'Koweït', 'Kuala Lumpur', 'Malaisie', 'Moscou', 'Oufa', 'Qatar', 'Republika La Russie', 'Russie', 'Satria', 'Ukraine', 'aéroport d’Oufa'], 'MISC': ['Ancien', 'Dans une interview accordée', 'Facebook', 'Guerre froide', 'Les Marines', 'Quatre jours', 'Republika']}",
         "[-0.001989591633901, 0.08982668817043304, 0.0017615724354982376, -0.18698011338710785, -0.06050912290811539, 0.07752607762813568, 0.06209629774093628, 0.06617119163274765, 0.010151009075343609, 0.11561912298202515, 0.04217521473765373, -0.05919013172388077, 0.11171781271696091, 0.0032283554319292307, -0.040039729326963425, -0.10928421467542648, -0.009505757130682468, -0.001171912532299757, -0.021978892385959625, 0.03819871321320534, -0.03487731143832207, -0.10480665415525436, 0.05174453556537628, -0.04959416389465332, -0.04780719056725502, 0.012449727393686771, 0.03130209073424339, -0.009415657259523869, -0.019819991663098335, -0.002216935157775879, -0.008939290419220924, -0.025682907551527023, 0.000359580124495551, 0.032891228795051575, 0.02111397311091423, 0.009015570394694805, 0.012920130975544453, -0.06907765567302704, -0.035268571227788925, 0.09194627404212952, -0.02786562591791153, -0.02733161300420761, -0.13538628816604614, -0.015188967809081078, -0.030309876427054405, 0.044586408883333206, 0.01197470910847187, 0.032765086740255356, -0.008263934403657913, -0.06588241457939148, -0.04966548830270767, -0.01898461952805519, 0.018641114234924316, -0.025247177109122276, 0.04894740879535675, -0.16790950298309326, -0.0067750513553619385, -0.0028610783629119396, 0.05639367923140526, 0.028160791844129562, -0.04653357341885567, 0.010872887447476387, -0.012959151528775692, 0.02205701917409897, -0.03935540094971657, -0.019139403477311134, 0.017396871000528336, -0.05288807302713394, -0.026609230786561966, 0.035952284932136536, 0.016499925404787064, -0.010715696029365063, -0.06716633588075638, -0.03398226946592331, -0.11289216578006744, -0.01419387012720108, -0.07316851615905762, 0.015657030045986176, -0.03366784751415253, -0.19771406054496765, 0.09385478496551514, -0.020015809684991837, 0.024127205833792686, 0.04095270112156868, -0.01251273788511753, -0.037660837173461914, 0.012932437472045422, 0.005595056805759668, 0.10321865975856781, 0.0020260626915842295, 0.0173703171312809, 0.08627400547266006, -0.07139817625284195, -0.06490497291088104, 0.09902560710906982, -0.05810660123825073, 0.03946216404438019, -0.03944075107574463, 0.007142240647226572, 0.022584665566682816, 0.11089089512825012, -0.004172807093709707, -0.05731416866183281, 0.02802225947380066, -0.019556934013962746, -0.050023991614580154, -0.04850570857524872, -0.05225208401679993, -0.019216280430555344, 0.003579104086384177, -0.03224960342049599, -0.047086261212825775, -0.02787877805531025, -0.004105466417968273, 0.012551389634609222, -0.011758591048419476, -0.03302064538002014, -0.057601358741521835, -0.04831767827272415, -0.020911332219839096, 0.04518134519457817, 0.012816178612411022, -0.014852853491902351, -0.0031723317224532366, 0.014210962690412998, -0.041976578533649445, 0.031045109033584595, 7.273561578860943e-33, -0.00516083836555481, 0.017491711303591728, 0.03805578127503395, -0.006640215869992971, 0.045168112963438034, 0.018642408773303032, -0.04493961110711098, 0.06183582916855812, 0.02068622224032879, -0.02551734633743763, -0.06010982766747475, -0.014444645494222641, -0.03465544804930687, 0.003746851347386837, 0.08680551499128342, 0.07634653896093369, -0.06848020106554031, -0.026633355766534805, 0.021418971940875053, 0.0004930145223625004, -0.02464328147470951, -0.0064180344343185425, 0.04307349771261215, 0.07188472151756287, -0.062035784125328064, 0.0078081125393509865, 0.01693015545606613, -0.0418737567961216, -0.02122792974114418, 0.019071493297815323, -0.05213803052902222, -0.013531628996133804, 0.04554050788283348, -0.001317619695328176, -0.02553492970764637, -0.10156210511922836, 0.0024742763489484787, -0.039931900799274445, -0.08501347154378891, 0.023487603291869164, 0.007120856549590826, -0.006698010955005884, 0.048757366836071014, 0.00198717531748116, 0.017210714519023895, 0.011268840171396732, 0.004130868706852198, -0.006703571882098913, 0.023535925894975662, -0.0002591532247606665, 0.05117371305823326, 0.0536804161965847, -0.036234188824892044, -0.0721946433186531, -0.06804487854242325, 0.05789840966463089, -0.05704426392912865, 0.05514604598283768, -0.060439907014369965, -0.053548794239759445, 0.05284447222948074, -0.02292162925004959, 0.013272407464683056, 0.10190366208553314, -0.000784326926805079, -0.008743761107325554, -0.07035861164331436, 0.016222728416323662, 0.07982026040554047, 0.040844209492206573, -0.041343215852975845, 0.02681007608771324, 0.04607941582798958, 0.004576703067868948, 0.016643406823277473, 0.09278620034456253, 0.03647620975971222, 0.03268241509795189, -0.09065183997154236, 0.011137171648442745, -0.11704909056425095, 0.038054708391427994, 0.003247204003855586, -0.0543852299451828, 0.050468795001506805, -0.012388345785439014, 0.07596247643232346, -0.004946855362504721, -0.016762830317020416, 0.04980716481804848, 0.02761734090745449, -0.033811137080192566, -0.04168877378106117, 0.006530461832880974, -0.06236039847135544, -9.848420240883746e-33, -0.01187650766223669, 0.10718271881341934, -0.045363035053014755, 0.02875223569571972, 0.0125926174223423, 0.014811587519943714, 0.018634671345353127, 0.05424521118402481, -0.014060606248676777, 0.007060231640934944, 0.019895896315574646, -0.07530951499938965, 0.08285321295261383, 0.041506316512823105, -0.05258109048008919, 0.016520777717232704, -0.0017251439858227968, -0.018051736056804657, -0.09737513214349747, 0.009988878853619099, 0.023857763037085533, -0.02491046115756035, 0.11016874760389328, 0.02681826800107956, -0.012807976454496384, 0.03878774493932724, 0.028962252661585808, 0.0260209608823061, -0.060406751930713654, 0.04689382016658783, 0.11150762438774109, -0.04375554993748665, -0.03225410357117653, 0.06166123226284981, 0.05438939481973648, -0.01688253879547119, 0.1564442664384842, -0.014817326329648495, -0.05395052582025528, 0.11635196954011917, 0.005101243499666452, 0.03748767077922821, 0.0008515717927366495, -0.006612872704863548, -0.0045026675797998905, -0.032862529158592224, -0.03945182263851166, -0.03397376462817192, -0.021353142336010933, -0.08079146593809128, 0.011065064929425716, 0.05628105625510216, -0.027564585208892822, 0.008056536316871643, -0.012490312568843365, -0.015103662386536598, -0.020156564190983772, 0.03445377200841904, 0.02345389872789383, 0.037723053246736526, 0.04091378301382065, 0.03493889048695564, -0.0767073854804039, -0.06402580440044403, 0.011314189992845058, -0.005418960005044937, -0.010588197968900204, 0.10257367789745331, 0.009037005715072155, -0.02200549840927124, 0.03120698779821396, -0.085335373878479, 0.01841956004500389, -0.01230820082128048, -0.009603400714695454, 0.0017332842107862234, 0.06760452687740326, 0.06107307970523834, 0.042127422988414764, 0.053455401211977005, -0.1034986674785614, -0.028998130932450294, -0.06219791993498802, -0.015506166964769363, 0.026583842933177948, 0.04453960061073303, 0.003929399885237217, -0.06019249185919762, 0.04429401457309723, -0.025102024897933006, 0.02143057808279991, 0.015099212527275085, 0.03222038969397545, 0.020247414708137512, 0.07308842241764069, -5.421578563868934e-08, 0.01627161167562008, -0.009088185615837574, -0.03728503733873367, 0.01685095578432083, 0.03789983689785004, -0.1516747623682022, -0.07797294110059738, -0.029286332428455353, -0.042678821831941605, -0.04065895453095436, 0.04753975197672844, -0.07093845307826996, -0.08355861902236938, 0.0028680304531008005, -0.037296075373888016, 0.058267150074243546, 0.004518132656812668, 0.008379108272492886, -0.03648417443037033, -0.037411343306303024, -0.030271058902144432, -0.07871349900960922, -0.006606587674468756, -0.0725046843290329, -0.1285632848739624, 0.017575670033693314, -0.07782958447933197, -0.13743628561496735, -0.027241012081503868, -0.009552360512316227, -0.016559822484850883, 0.050312090665102005, -0.03673725202679634, -0.0840204507112503, -0.027469035238027573, -0.018893413245677948, -0.026539191603660583, 0.02633097767829895, 0.0770685225725174, 0.06263008713722229, 0.07496495544910431, -0.011944315396249294, -0.04110363870859146, -0.0002067882160190493, 0.05510907992720604, 0.036841850727796555, 0.03769500553607941, 0.011127867735922337, -0.004666093271225691, 0.05584026500582695, -0.028092259541153908, 0.0500752218067646, 0.08395931869745255, 0.020040197297930717, -0.013139757327735424, -0.08822977542877197, 0.04927131161093712, -0.0004728168132714927, -0.029365483671426773, 0.056410543620586395, 0.03668035939335823, 0.03583105653524399, -0.008581518195569515, -0.0033138704020529985]",
         "0.187"
        ],
        [
         "37",
         "576",
         "Why BI in the AI Age",
         "An argument for human-led analysis (at least for now) The post Why BI in the AI Age appeared first on Towards Data Science .",
         "AI forces us analysts to stare in the mirror and ask what exactly is the value produced by making and sharing charts by hand.\n\nLLMs can generate queries and code to create compelling charts from natural language prompts in seconds. They know syntax we have forgotten, packages we’ve never heard of, and are all too eager to respond to every executive demand for charts at all hours of the day!\n\nBut what’s in a chart?\n\nFundamentally, a chart compresses a bunch of data into an easy-to-understand insight that people can hopefully take action on. The viewer of the chart needs to trust that the creator of the chart made sure it was correct and appropriate . Otherwise, the viewer would need to go through their own analytics process to get to the insight themselves.\n\nSo let’s explore the parts of the chart-making process where AI still falls short — not just to point out its current limitations, but to highlight where human analysts add the most value. If you’re working in BI, this article will help you better understand how to partner with AI tools, where to stay hands-on, and how to design your workflows and data models so that both humans and machines can generate more reliable insights.\n\nAt DataCamp, we think a lot about what great analytics looks like in the age of AI. As a platform that teaches both the technical and strategic sides of modern BI, we’ve seen firsthand how the best outcomes come from combining AI speed with human judgment. This article shares some of the key patterns we’ve observed and the practical takeaways we believe BI professionals should carry forward.\n\nTo learn the most popular BI tool, Power BI, and create your own charts and visualizations from scratch—check out the two courses below:\n\nhttps://www.datacamp.com/tracks/power-bi-fundamentals to get the basics right\n\nhttps://www.datacamp.com/tracks/data-analyst-in-power-bi to get job-ready as an analyst\n\n4 areas where AI falls short in the chart making process\n\nLack of metadata Lack of extra data Understanding emerges through exploration Compression is lossy and arbitrary\n\nLack of Metadata\n\nConsider this simple sales dataset:\n\ncustomer_id customer_name order_date amount region sales_rep 1001 ACME 2024-01-15 2500.00 NE Johnson 1002 Bill Sanchez 2024-01-16 1200.50 SW Martinez 1003 Skynet 2024-01-17 NULL SE NULL\n\nAn AI prompt like “show me sales by region” would instantly generate a chart:\n\nAnd this chart seems totally reasonable. Why question it?\n\nWell, let’s look at the counterfactual of having a human answer this same question. While they may just immediately produce the same or similar chart, they more likely will find important metadata context during their process of exploring the data en route to creating the chart:\n\ncustomer_id actually represents both individual customers AND corporate accounts (requiring potentially different analysis approaches)\n\nactually represents both individual customers AND corporate accounts (requiring potentially different analysis approaches) amount represents total contract value booked, not cash received or revenue recognized (crucial for financial reporting)\n\nrepresents total contract value booked, not cash received or revenue recognized (crucial for financial reporting) sales_rep NULL values indicate channel partner sales (a completely different business model)\n\nYou asked for ‘sales by region’ and see in the chart that the AI produced that SE is underperforming. The obvious next step would be to focus on improving the SE sales team. But the human analyst’s metadata investigation reveals this would be the wrong move entirely.\n\nDigging deeper, they could discover that SE’s poor performance is actually driven by collections issues on partner sales (those NULL sales_rep values), not direct sales execution. The region isn’t failing—the partner channel is struggling.\n\nSo the analyst version of the chart may look more like this:\n\nThis isn’t exactly what you prompted for, and that’s the point.\n\nWithout this human investigation that went a bit beyond your ask, you’d be hammering the wrong sales team about performance when you should be reaching out to your channel partners. In addition, these findings also have implications for the data model. You found that you need several transformations and metadata embedded in this table so that it can more reliably be used by an LLM or another human to use this data to create a chart.\n\nIt should be mentioned that many BI tools are adopting various techniques for giving LLMs more metadata access to things like schemas, data dictionaries, and dbt, but these all assume the metadata has been written down, which is often not the case.\n\nLack of Extra Data\n\nThere’s data AI knows, data AI doesn’t know, data AI knows it doesn’t know, and data AI doesn’t know it doesn’t know .\n\nThe data an AI needs in order to interpret a chart or metric may be completely unexpected and hard to proactively make available. Let’s take an expanded version of the same dataset and have an AI try to explain a revenue dip in March 2024:\n\nThese suggestions are all worth potentially looking into and the overall recommendation of it being anomalous makes sense. However, an experienced analyst will likely have instincts to the true root cause. For instance, the human analyst may know of some data that exist outside of the database that they feel confident could be the reason:\n\nExternal Market Event : Your main competitor had a major promotion that month\n\n: Your main competitor had a major promotion that month Internal Activity : Your pricing team ran an A/B test that accidentally excluded 30% of prospects\n\n: Your pricing team ran an A/B test that accidentally excluded 30% of prospects Historical Information: A key integration partner changed their API, breaking sign-up flows for two weeks\n\nThese discoveries require data that is spread across an organization and its ecosystem, not just within the database that’s connected to a BI tool.\n\nThis allows us to better understand what’s going on in the data vs a less informed guess. In the future, more streams of information will certainly be factored into LLM context windows and many teams are evaluating how to design their data to be more digestible by AI. However, in the present, to try to determine causal relationships you need the human analyst’s instinct for generating probable hypotheses and confirming theories.\n\nUnderstanding emerges through exploration\n\nReal datasets are messy and oftentimes the cleaning of the data is key to coming to the right answer. Let’s revisit our sales data with a couple more fields related to orders:\n\ncustomer_id customer_name order_date amount region total_orders order_type 1001 ACME 2024-01-15 2500.00 NE 3 new 1001 ACME 2024-03-22 NULL NE 3 renewal 1002 Bill Sanchez 2024-01-16 1200.50 SW 1 new\n\nNow you have to make some cleaning decisions:\n\nDo you count ACME as one $2500 sale or track their purchasing pattern over time?\n\nWhat does that NULL amount in the second ACME record mean — a return, a pending renewal, or data entry error?\n\nWell, you could ask the AI what to do, and we did:\n\nAn analyst is often put in this position to reconcile and then codify how multiple teams want the business logic to be written. After talking with accounting and sales they determine: “ACME has a renewal with no amount recorded — they’re probably negotiating terms or there’s a processing delay.” The analyst can then decide whether to exclude this record, estimate the amount, or create a separate renewal analysis track.\n\nThis could be a one-off decision or something that gets factored into the data model. If we had just asked the AI for a chart on average sale amount we might never have bumped into and cleaned this oddity. Again, a human poking around to get an answer finds opportunities to make the data better for everyone including AI.\n\nCompression is Lossy and Arbitrary\n\nEven when AI returns a completely correct chart it may not be the right chart. The same sales data tells completely different stories depending on presentation. Here’s how our sales performance data could be presented:\n\nJust the Number — “Total Sales: $1.2M” (Sounds good! But compared to what? What was it last month?)\n\nBasic Bar Chart — Sales by region showing SE lagging behind NE and SW (confirms your bias that the SE team needs help)\n\nFully Annotated and Contextualized — The same chart, but with partner sales segmented out, showing SE direct sales are actually strong and the issue is the partner channel payment processing bug that started in Q3. Industry benchmark and growth trend lines show overall performance is excellent.\n\n(Note: all these charts were generated by Claude, an AI assistant created by Anthropic.)\n\nTo be clear, you can use AI to create any of these (like I did!). But when people self-serve with AI, will they get to an appropriate level of depth and understanding or stop at just getting the number? The AI might give users the misleading middle version, but if routed to a human analyst, they would likely know to dig deeper and present the data in a way that leads to the right action.\n\nAs complete as this final chart feels, this is still just one of many ways to understand this data. We could have segmented by customer size, looked at monthly trends, filtered out renewals, etc. We could have also looked at this data by week or day. The focus on regional totals without segmenting partner vs. direct sales is somewhat arbitrary, and the monthly time grain is compressing daily volatility that might reveal when the partner payment issue started.\n\nAn analyst often makes many charts before settling on the one presented and can thus caveat, contextualize, or quickly respond to why this chart was picked and help people follow up with more questions. Presenting one chart that does not show the whole picture is a feature, not a bug, of data visualization. It allows you to present a focused, understandable view into the data.\n\nUltimately, as an analyst you must ask yourself: are you comfortable with this chart representing all the underlying data? Are you ready to present this chart for others to reliably draw conclusions from?\n\nKeep Calm, and Query On\n\nGreat analytics isn’t about generating charts quickly, it’s about building confidence in decisions through rigorous investigation of data. Every discovery, design choice, and contextual annotation represents a human analyst’s business intelligence (is this even a pun? If so: intended).\n\nIn the AI age, the analysts who thrive will be those who embrace AI as a powerful tool to help write code while recognizing that the most valuable analytical work—the thinking, questioning, and contextualizing—remains fundamentally human.\n\nTo learn more about practical way of improving the AI analytics workflow check out:\n\nTo learn the most popular BI tool, Power BI, and create your own charts and visualizations from scratch—check out the two courses below:\n\nhttps://www.datacamp.com/tracks/power-bi-fundamentals to get the basics right\n\nhttps://www.datacamp.com/tracks/data-analyst-in-power-bi to get job ready as an analyst",
         "2025-07-24T13:00:00",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/why-bi-in-the-ai-age/",
         "2025-07-26T06:23:31.327781",
         "AI forces us analysts to stare in the mirror and ask what exactly is the value produced by making and sharing charts by hand. LLMs can generate queries and code to create compelling charts from natural language prompts in seconds. They know syntax we have forgotten, packages we’ve never heard of, and are all too eager to respond to every executive demand for charts at all hours of the day! But what’s in a chart? Fundamentally, a chart compresses a bunch of data into an easy-to-understand insight that people can hopefully take action on. The viewer of the chart needs to trust that the creator of the chart made sure it was correct and appropriate . Otherwise, the viewer would need to go through their own analytics process to get to the insight themselves. So let’s explore the parts of the chart-making process where AI still falls short — not just to point out its current limitations, but to highlight where human analysts add the most value. If you’re working in BI, this article will help you better understand how to partner with AI tools, where to stay hands-on, and how to design your workflows and data models so that both humans and machines can generate more reliable insights. At DataCamp, we think a lot about what great analytics looks like in the age of AI. As a platform that teaches both the technical and strategic sides of modern BI, we’ve seen firsthand how the best outcomes come from combining AI speed with human judgment. This article shares some of the key patterns we’ve observed and the practical takeaways we believe BI professionals should carry forward. To learn the most popular BI tool, Power BI, and create your own charts and visualizations from scratch—check out the two courses below: https://www.datacamp.com/tracks/power-bi-fundamentals to get the basics right https://www.datacamp.com/tracks/data-analyst-in-power-bi to get job-ready as an analyst 4 areas where AI falls short in the chart making process Lack of metadata Lack of extra data Understanding emerges through exploration Compression is lossy and arbitrary Lack of Metadata Consider this simple sales dataset: customer_id customer_name order_date amount region sales_rep 1001 ACME 2024-01-15 2500.00 NE Johnson 1002 Bill Sanchez 2024-01-16 1200.50 SW Martinez 1003 Skynet 2024-01-17 NULL SE NULL An AI prompt like “show me sales by region” would instantly generate a chart: And this chart seems totally reasonable. Why question it? Well, let’s look at the counterfactual of having a human answer this same question. While they may just immediately produce the same or similar chart, they more likely will find important metadata context during their process of exploring the data en route to creating the chart: customer_id actually represents both individual customers AND corporate accounts (requiring potentially different analysis approaches) actually represents both individual customers AND corporate accounts (requiring potentially different analysis approaches) amount represents total contract value booked, not cash received or revenue recognized (crucial for financial reporting) represents total contract value booked, not cash received or revenue recognized (crucial for financial reporting) sales_rep NULL values indicate channel partner sales (a completely different business model) You asked for ‘sales by region’ and see in the chart that the AI produced that SE is underperforming. The obvious next step would be to focus on improving the SE sales team. But the human analyst’s metadata investigation reveals this would be the wrong move entirely. Digging deeper, they could discover that SE’s poor performance is actually driven by collections issues on partner sales (those NULL sales_rep values), not direct sales execution. The region isn’t failing—the partner channel is struggling. So the analyst version of the chart may look more like this: This isn’t exactly what you prompted for, and that’s the point. Without this human investigation that went a bit beyond your ask, you’d be hammering the wrong sales team about performance when you should be reaching out to your channel partners. In addition, these findings also have implications for the data model. You found that you need several transformations and metadata embedded in this table so that it can more reliably be used by an LLM or another human to use this data to create a chart. It should be mentioned that many BI tools are adopting various techniques for giving LLMs more metadata access to things like schemas, data dictionaries, and dbt, but these all assume the metadata has been written down, which is often not the case. Lack of Extra Data There’s data AI knows, data AI doesn’t know, data AI knows it doesn’t know, and data AI doesn’t know it doesn’t know . The data an AI needs in order to interpret a chart or metric may be completely unexpected and hard to proactively make available. Let’s take an expanded version of the same dataset and have an AI try to explain a revenue dip in March 2024: These suggestions are all worth potentially looking into and the overall recommendation of it being anomalous makes sense. However, an experienced analyst will likely have instincts to the true root cause. For instance, the human analyst may know of some data that exist outside of the database that they feel confident could be the reason: External Market Event : Your main competitor had a major promotion that month : Your main competitor had a major promotion that month Internal Activity : Your pricing team ran an A/B test that accidentally excluded 30% of prospects : Your pricing team ran an A/B test that accidentally excluded 30% of prospects Historical Information: A key integration partner changed their API, breaking sign-up flows for two weeks These discoveries require data that is spread across an organization and its ecosystem, not just within the database that’s connected to a BI tool. This allows us to better understand what’s going on in the data vs a less informed guess. In the future, more streams of information will certainly be factored into LLM context windows and many teams are evaluating how to design their data to be more digestible by AI. However, in the present, to try to determine causal relationships you need the human analyst’s instinct for generating probable hypotheses and confirming theories. Understanding emerges through exploration Real datasets are messy and oftentimes the cleaning of the data is key to coming to the right answer. Let’s revisit our sales data with a couple more fields related to orders: customer_id customer_name order_date amount region total_orders order_type 1001 ACME 2024-01-15 2500.00 NE 3 new 1001 ACME 2024-03-22 NULL NE 3 renewal 1002 Bill Sanchez 2024-01-16 1200.50 SW 1 new Now you have to make some cleaning decisions: Do you count ACME as one $2500 sale or track their purchasing pattern over time? What does that NULL amount in the second ACME record mean — a return, a pending renewal, or data entry error? Well, you could ask the AI what to do, and we did: An analyst is often put in this position to reconcile and then codify how multiple teams want the business logic to be written. After talking with accounting and sales they determine: “ACME has a renewal with no amount recorded — they’re probably negotiating terms or there’s a processing delay.” The analyst can then decide whether to exclude this record, estimate the amount, or create a separate renewal analysis track. This could be a one-off decision or something that gets factored into the data model. If we had just asked the AI for a chart on average sale amount we might never have bumped into and cleaned this oddity. Again, a human poking around to get an answer finds opportunities to make the data better for everyone including AI. Compression is Lossy and Arbitrary Even when AI returns a completely correct chart it may not be the right chart. The same sales data tells completely different stories depending on presentation. Here’s how our sales performance data could be presented: Just the Number — “Total Sales: $1.2M” (Sounds good! But compared to what? What was it last month?) Basic Bar Chart — Sales by region showing SE lagging behind NE and SW (confirms your bias that the SE team needs help) Fully Annotated and Contextualized — The same chart, but with partner sales segmented out, showing SE direct sales are actually strong and the issue is the partner channel payment processing bug that started in Q3. Industry benchmark and growth trend lines show overall performance is excellent. (Note: all these charts were generated by Claude, an AI assistant created by Anthropic.) To be clear, you can use AI to create any of these (like I did!). But when people self-serve with AI, will they get to an appropriate level of depth and understanding or stop at just getting the number? The AI might give users the misleading middle version, but if routed to a human analyst, they would likely know to dig deeper and present the data in a way that leads to the right action. As complete as this final chart feels, this is still just one of many ways to understand this data. We could have segmented by customer size, looked at monthly trends, filtered out renewals, etc. We could have also looked at this data by week or day. The focus on regional totals without segmenting partner vs. direct sales is somewhat arbitrary, and the monthly time grain is compressing daily volatility that might reveal when the partner payment issue started. An analyst often makes many charts before settling on the one presented and can thus caveat, contextualize, or quickly respond to why this chart was picked and help people follow up with more questions. Presenting one chart that does not show the whole picture is a feature, not a bug, of data visualization. It allows you to present a focused, understandable view into the data. Ultimately, as an analyst you must ask yourself: are you comfortable with this chart representing all the underlying data? Are you ready to present this chart for others to reliably draw conclusions from? Keep Calm, and Query On Great analytics isn’t about generating charts quickly, it’s about building confidence in decisions through rigorous investigation of data. Every discovery, design choice, and contextual annotation represents a human analyst’s business intelligence (is this even a pun? If so: intended). In the AI age, the analysts who thrive will be those who embrace AI as a powerful tool to help write code while recognizing that the most valuable analytical work—the thinking, questioning, and contextualizing—remains fundamentally human. To learn more about practical way of improving the AI analytics workflow check out: To learn the most popular BI tool, Power BI, and create your own charts and visualizations from scratch—check out the two courses below: https://www.datacamp.com/tracks/power-bi-fundamentals to get the basics right https://www.datacamp.com/tracks/data-analyst-in-power-bi to get job ready as an analyst",
         "en",
         "{'MISC': ['AI doesn’t know', 'AI knows it doesn’t know', 'AI to create any of these', 'After talking with accounting and sales they', 'An analyst is often put in this position to reconcile and then codify how multiple teams want the business logic to be written', 'An analyst often makes many charts before settling on the one presented and can thus caveat', 'And this chart seems totally reasonable', 'As', 'BI tool', 'Basic Bar Chart', 'But the human', 'Digging deeper', 'Do you count ACME as one', 'Every discovery', 'External Market Event : Your main competitor had', 'Fully Annotated and Contextualized —', 'If we had just asked the AI for', 'If you’re working in BI', 'In', 'In the AI age', 'It allows you to present', 'It should be mentioned that many BI tools are adopting various techniques for giving LLMs more metadata access to things like schemas', 'Just the Number — “', 'Keep Calm', 'Lack of Extra Data There’s data AI knows', 'Lack of metadata Lack of extra data Understanding emerges through exploration', 'Let’s take an expanded version of the same dataset and have an', 'NULL', 'Otherwise', 'Power BI', 'So let’', 'So the analyst version of the chart may', 'Sounds good!', 'The AI might give', 'The focus on regional totals without segmenting partner vs', 'The obvious next step would be to focus on improving the SE sales team', 'The same sales data tells', 'The viewer of the chart needs to trust that the creator of the chart made sure it was correct and appropriate', 'These suggestions are all worth', 'They know syntax we have forgotten', 'This allows us to better understand what’s going on in the data vs', 'This could be a one-off decision or something that gets factored into the data model', 'To be clear', 'To learn more about practical way of improving the AI analytics workflow check out: To learn the most popular BI tool', 'To learn the most', 'Ultimately', 'Understanding emerges through exploration Real', 'We could have also looked at this data by week or day', 'We could have segmented by customer size', 'Well', 'What does that NULL amount in the second', 'What was it last month', 'While they may just immediately produce', 'Without this human investigation that went', 'You asked for ‘sales by region’ and see in the chart that the AI', 'You found that you need several transformations and metadata embedded in this table', 'Your main competitor had', 'Your pricing team', 'add the most value', 'and Query On Great analytics isn’t about generating charts quickly', 'and create your own charts and visualizations from scratch—check out the two courses below: https://www.datacamp.com/tracks/power-bi-fundamentals to get the basics right https://www.datacamp.com/tracks/data-analyst-in-power-bi to get job ready as an analyst', 'and create your own charts and visualizations from scratch—check out the two courses below: https://www.datacamp.com/tracks/power-bi-fundamentals to get the basics right https://www.datacamp.com/tracks/data-analyst-in-power-bi to get job-ready as an analyst 4 areas where AI', 'and the monthly time grain is compressing daily volatility', 'informed guess', 'it’', 'let’s look at the counterfactual of having a human answer this same', 'looked at monthly trends', 'looking into and the overall recommendation of it being anomalous makes', 'metadata', 'more fields related to orders', 'more streams of information will certainly be factored into LLM context windows and many teams are evaluating how to design their data to be more digestible by AI', 'negotiating terms or there’s', 'not a bug', 'not direct sales execution', 'our sales data with', 'the parts of the chart-making process where AI still falls short', 'the viewer would need to go through their own analytics process to get to the insight themselves', 'their API', 'these findings also have implications for the data model', 'they would likely know to dig deeper and present the data in a way that leads to the right action', 'this is still just one of many ways to understand this data', 'to creating the chart', 'we’ve never heard of', 'we’ve observed and the practical takeaways we believe BI professionals should carry forward', 'we’ve seen firsthand how the best outcomes come from', 'what you prompted for', 'you can use', 'your bias that the SE team needs help', 'you’d be hammering the wrong sales team'], 'LOC': ['ACME 2024', 'ACME 2024-01-15', 'AI', 'B', 'For', 'Fundamentally', 'M', 'Sales', 'Sales by region showing SE lagging behind NE and', 'and contextualizing', 'customer_name order_date amount region', 'data dictionaries', 'region isn’t failing'], 'ORG': ['ACME', 'BI', 'Industry benchmark and growth', 'Q3', 'These', 'and dbt', 'channel partner sales', 'customers AND', 'questioning', 'we think'], 'PER': ['Bill Sanchez', 'Claude', 'Here’', 'However', 'Let’', 'NE Johnson', 'Presenting', 'and contextual', 'filtered out renewals', 'generate', 'human poking around to get an answer', 'not cash received or', 'not just within the database that’', 'the partner channel is struggling', 'you could ask the AI what to do']}",
         "[0.03207316994667053, -0.0387004092335701, -0.022414090111851692, 0.0045416089706122875, 0.02283420041203499, 0.009890052489936352, -0.03260680288076401, 0.051049891859292984, 0.07897017151117325, 0.01787976361811161, -0.08812633901834488, -0.012212127447128296, 0.045177847146987915, 0.018559010699391365, 0.007965912111103535, 0.06381534039974213, 0.055726058781147, -0.08449282497167587, -0.03927849605679512, -0.07050563395023346, -0.020498748868703842, -0.03585405647754669, -0.031111733987927437, -0.01027180440723896, 0.05947679281234741, 0.03178255259990692, 0.0007216451340354979, -0.04299100860953331, 0.04966123774647713, 0.0028711282648146152, -0.011245260946452618, 0.0022219293750822544, 0.054481811821460724, 0.06149445101618767, -0.12316220998764038, 0.014155494049191475, 0.032318875193595886, 0.05392879620194435, 0.04814859479665756, -0.017511488869786263, -0.018072228878736496, -0.01445953082293272, 0.029132351279258728, -0.01778513565659523, 0.02653920277953148, 0.04676327481865883, -0.06884300708770752, -0.06543056666851044, -0.0433649942278862, 0.12832526862621307, -0.1880926638841629, -0.008197788149118423, 0.009659492410719395, -0.0444604754447937, 0.020323343575000763, 0.05580659583210945, 0.0005154467071406543, -0.021784309297800064, 0.017675856128335, 0.03525498881936073, -0.054486680775880814, -0.05293525010347366, 0.07830145210027695, 0.023411927744746208, 0.12185583263635635, 0.009602230973541737, -0.014593956992030144, 0.1006917655467987, -0.015945935621857643, 0.025868747383356094, 0.03603542223572731, -0.021191518753767014, -0.0280887633562088, 0.01600002869963646, -0.042860519140958786, 0.04023096337914467, 0.011700558476150036, -0.05136464163661003, 0.06272263824939728, -0.11934756487607956, 0.0002736079622991383, 0.04196811467409134, -0.014737904071807861, 0.12307211756706238, -0.030564183369278908, -0.0241512693464756, 0.0024985442869365215, -0.032211367040872574, 0.026964139193296432, 0.0034054326824843884, -0.013697112910449505, -0.036073364317417145, -0.028968026861548424, -0.01224126759916544, 0.15964321792125702, 0.10345302522182465, -0.035260483622550964, -0.03519275039434433, 0.02390262484550476, 0.017111044377088547, 0.05940678343176842, 0.045557841658592224, 0.02174203284084797, -0.0715569257736206, -0.08566945791244507, -0.06729832291603088, 0.04621915891766548, -0.01302904449403286, -0.0351102240383625, 0.020659128203988075, 0.005154221784323454, 0.056651365011930466, 0.016231635585427284, -0.0029956090729683638, 0.046977538615465164, -0.06128093600273132, -0.027218719944357872, -0.03934617340564728, 0.018054034560918808, 0.07316087186336517, -0.0449761264026165, 0.08079299330711365, 0.03012862801551819, 0.07606535404920578, 0.069027841091156, 0.01760687120258808, -0.03885670378804207, 1.5463653899006116e-33, -0.024884574115276337, 0.007503097876906395, 0.02271307446062565, 0.04019126668572426, 0.0075717102736234665, -0.01538230199366808, -0.060913097113370895, 0.020732643082737923, 0.006185437552630901, 0.06078106164932251, -0.004642807878553867, 0.1402275264263153, 0.04035576805472374, 0.08675454556941986, 0.012968968600034714, 0.01914762705564499, 0.08490593731403351, 0.021959586068987846, -0.10710024833679199, -0.06862936168909073, -0.022436130791902542, -0.06854531168937683, 0.052767038345336914, 0.023010650649666786, 0.04443947970867157, 0.04612841084599495, 0.04501431807875633, 0.02266242913901806, 0.04663906246423721, -0.0008628652431070805, -0.07207321375608444, 0.013535596430301666, -0.055963195860385895, -0.04509417340159416, 0.01086372695863247, -0.014963368885219097, -0.08054513484239578, 0.00917764287441969, 0.028720082715153694, 0.08082923293113708, -0.007362882141023874, -0.003253223141655326, -0.02282051555812359, -0.015401099808514118, -0.0779588520526886, 0.03346145898103714, -0.009400365874171257, -0.01935414969921112, -0.046664707362651825, -0.030944114550948143, -0.024411417543888092, 0.016733573749661446, -0.0423012413084507, -0.03202960267663002, 0.007471038028597832, 0.01233521569520235, 0.014288337901234627, -0.08574512600898743, -0.01953813247382641, -0.030451221391558647, -0.012281624600291252, 0.05401968955993652, 0.011322218924760818, 0.035813573747873306, -0.03687753155827522, 0.10337641835212708, -0.06164340302348137, 0.07037968188524246, 0.04317649081349373, -0.0071319094859063625, -0.02726450376212597, 0.00956918764859438, -0.0540207102894783, -0.06623803824186325, 0.014917203225195408, -0.017824791371822357, -0.024950174614787102, -0.032362379133701324, 0.058864522725343704, -0.044995252043008804, -0.009902545250952244, -0.10174933075904846, -0.0010598157532513142, -0.027827253565192223, -0.003966497257351875, -0.1012415885925293, -0.03127102181315422, 0.011643270030617714, -0.027711819857358932, 0.04206172376871109, -0.0589226558804512, -0.04866855964064598, -0.06534040719270706, 0.06217588856816292, -0.017101237550377846, -4.1007083694237037e-33, -0.09607196599245071, 0.05997014045715332, 0.008921796455979347, 0.06209620460867882, 0.015244844369590282, -0.012818661518394947, -0.032225728034973145, -0.012733271345496178, 0.04721805080771446, 0.04203513637185097, -0.06835624575614929, -0.08862090110778809, -0.030302630737423897, -0.018743867054581642, 0.0021414447110146284, -0.0438249334692955, -0.004473002627491951, -0.01921417936682701, -0.003844795050099492, -0.02217809297144413, -0.008898455649614334, 0.07092007249593735, -0.0640704333782196, 0.010298711247742176, 0.025393955409526825, 0.07746975123882294, -0.05159632861614227, -0.09747306257486343, -0.01777636632323265, 0.025421638041734695, -0.0376906655728817, -0.11446597427129745, -0.04570060595870018, -0.059558529406785965, 0.02096131257712841, 0.06139625981450081, 0.08093573898077011, -0.05008815973997116, -0.058451805263757706, 0.028805408626794815, 0.0052762702107429504, -0.041338544338941574, -0.05647369474172592, -0.018239418044686317, -0.023591579869389534, 0.041525017470121384, -0.05707402899861336, 0.02692507766187191, -0.035432759672403336, 0.0075213066302239895, 0.03748948499560356, -0.0026054016780108213, 0.0731469914317131, -0.09197252243757248, -0.07054927945137024, -0.07599484920501709, 0.039420560002326965, 0.016533834859728813, -0.05417557805776596, 0.06440609693527222, -0.06219632178544998, -0.036171361804008484, 0.009038207121193409, -0.06746834516525269, -0.08774764090776443, -0.043657105416059494, 0.034384600818157196, -0.0011346912942826748, -0.025952965021133423, -0.01868584379553795, 0.05179207772016525, -0.046034976840019226, -0.023634975776076317, -0.014288140460848808, 0.026958372443914413, 0.04851481691002846, -0.03999626263976097, -0.05365683138370514, 0.006033691111952066, -0.03236602619290352, 0.04781080409884453, -0.04366224259138107, 0.07081613689661026, 0.06177371367812157, 0.011011641472578049, 0.05387302488088608, -0.016321586444973946, 0.017049109563231468, -0.02420610748231411, 0.046261683106422424, -0.05911945924162865, -0.019806429743766785, -0.1440933346748352, 0.05016612261533737, -0.03710660710930824, -5.6854787544580176e-08, -0.08370393514633179, 0.006268076132982969, 0.059446293860673904, 0.013714699074625969, 0.057574886828660965, -0.03354566544294357, -0.02511933073401451, 0.09474828839302063, 0.01652098447084427, 0.09432573616504669, 0.0967845618724823, -0.05467231944203377, -0.07319463789463043, -0.03406671807169914, 0.040449585765600204, -0.001455090125091374, 0.026536818593740463, -0.021139858290553093, 0.0012851704377681017, -0.02292356640100479, 0.0722430944442749, -0.012374809011816978, -0.019370226189494133, -0.025495775043964386, 0.06281935423612595, -0.10471973568201065, -0.04320253059267998, 0.07782278954982758, -0.0860685333609581, 0.05846511572599411, -0.0067910365760326385, 0.014717009849846363, 0.006468481384217739, 0.08278957009315491, 0.06891118735074997, -0.055254898965358734, 0.010469620116055012, -0.0020178088452667, 0.0383024737238884, 0.01582663506269455, -0.05582985654473305, 0.1269129365682602, -0.04654470831155777, 0.010169443674385548, 0.031488437205553055, 0.030842013657093048, -0.04591817781329155, -0.00778600899502635, -0.012667442671954632, -1.3231247976364102e-05, -0.05419301614165306, -0.12267575412988663, 0.062123168259859085, 0.10034345090389252, 0.06922930479049683, 0.021261155605316162, 0.001597999013029039, -0.007643017917871475, 0.01198162417858839, 0.05591646581888199, 0.034381866455078125, 0.019662130624055862, -0.10000010579824448, -0.05987109616398811]",
         "0.183"
        ],
        [
         "38",
         "41",
         "7 Free Websites Every Content Creator Needs to Know",
         "Do you have the desire to become a content creator, but not have the money to start? Here are 7 free websites every content creator needs to know. 1.Exploding Topics (Trending Topics) (Photo Credit:- Exploding Topics) If you're a content creator, you might be wondering what better way to find new topic ideas than to see what people are searching for? This tool gives you this data without anyone else's explanation. It provides related hashtags and tips on how to use them effectively in your posts. It's a great tool for anyone who wants to keep up to date with what's most relevant in their niche. You can also see the most popular hashtags by country, making it easier to understand cross-border and demographic trends. This site makes your search for content easier than ever! There are countless ways to use explosive topics to your advantage as a content creator. Some examples can be: Use the most popular hashtags and keywords to get inspiration for ideas. Find out what people are talking about in real-time. Find new audiences you may not have known were interested in your topic. There’s no excuse not to try this website — it’s free and easy to use! Visit Exploding Topics From Here 2. Headline Studio (Headline Grader) (Photo Credit:-Headline Studio) Headline Studio allows you to create catchy headlines for your content. After writing a title there is data on how often people view articles with similar titles and why they are involved with them. This is a valuable tool when creating new blog posts because it generates catchy headlines for your blog post to catch a reader’s attention. Visit Headline Studio From Here 3. Answer the public (Photo Credit:- Answer The Public) Answer The public is an excellent tool for content creators. It gives you insight into what people are asking on social media sites and communities and lets you guess about topics that matter to your audience. Answer the public allows you to enter a keyword or topic related to your niche and it will show results with popular questions and keywords related to your topic. It's an amazing way to get insights into what people are searching online and allows you to identify topics driven by new blog posts or social media content on platforms like Facebook, Instagram, Youtube, and Twitter as well as the types of questions they ask and also want answers. Visit Answer The Public From Here 4. Surfer Seo (SEO Ranking) (Photo Credit:-Surfer Seo) With this tool, content creators can quickly and easily check the ranking of their websites and those of other competitors. This tool allows you to see how your website compares to others in different categories, including: Rank Potential Organic Search Ranking Surfer Seo is free and the interface is very friendly. It's a great tool for anyone who wants to do quick competitor research or check their site's rankings at any time. Visit SurferSeo From Here 5. Canva (Templates/Graphics) (Photo Credit:- Canva) Canva is a free graphic design platform that makes it easy to create invitations, business cards, mobile videos, Instagram posts, Instagram stories, flyers, and more with professionally designed templates. You can even upload your photos and drag and drop them into Canva templates. It's like having a basic version of Photoshop. You can also remove background from images with one click. Canva offers thousands of free, professionally designed templates that can be customized with just a few clicks. Simply upload your photos to Canva, drag them into the template of your choice, and save the file to your computer. It is free to use for basic use but if you want access to different fonts or more features, then you need to buy a premium plan. Visit Canva From Here 6. Facebook Audience Insights (Audience Research) (Photo Credit:- Facebook Audience Insights Facebook Audience Insights is a powerful tool for content creators when researching their target market. This can help you understand the demographics, interests, and behaviors of your target audience. This information helps determine the direction of your content so that it resonates with them. The most important tools to consider in Facebook Audience Insights are Demographics and Behavior. These two sections provide you with valuable information about your target market, such as their age and from where they belong, how much time they spend on social media per day, what devices they use to access it, etc. There is another section of Facebook Audits that is very helpful. This will let you know the interests, hobbies, and activities that people in your target market are most interested in. You can use this information to create content for them about things they will be about as opposed to topics they may not be so keen on. Visit Facebook Audience Insights From Here 7. Pexels (Images) (Photo Credit: Pixel Pexels is a warehouse for any content creator with millions of free royalty images who wants to find high-quality images that can be used freely without having to worry about permissions or licensing so you are free to use the photos in your content and also there is no watermark on photos The only cons are that some photos contain people, and Pexels doesn't allow you to remove people from photos. Search your keyword and download as many as you want! Visit Pexel From Here So there you have it. We hope that these specially curated websites will come in handy for content creators and small businesses alike. If you've got a site that should be on this list, let us know! And if you're looking for more content creator resources, then let us know in the comments section below",
         "Do you have the desire to become a content creator, but not have the money to start? Here are 7 free websites every content creator needs to know.\n\n1.Exploding Topics (Trending Topics)\n\n(Photo Credit:- Exploding Topics)\n\n\n\n\n\nIf you're a content creator, you might be wondering what better way to find new topic ideas than to see what people are searching for? This tool gives you this data without anyone else's explanation. It provides related hashtags and tips on how to use them effectively in your posts. It's a great tool for anyone who wants to keep up to date with what's most relevant in their niche. You can also see the most popular hashtags by country, making it easier to understand cross-border and demographic trends. This site makes your search for content easier than ever! There are countless ways to use explosive topics to your advantage as a content creator.\n\nSome examples can be:\n\nUse the most popular hashtags and keywords to get inspiration for ideas.\n\nFind out what people are talking about in real-time.\n\nFind new audiences you may not have known were interested in your topic.\n\nThere’s no excuse not to try this website — it’s free and easy to use!\n\nVisit Exploding Topics From Here\n\n2. Headline Studio (Headline Grader)\n\n\n\n\n\nHeadline Studio allows you to create catchy headlines for your content. After writing a title there is data on how often people view articles with similar titles and why they are involved with them.\n\nThis is a valuable tool when creating new blog posts because it generates catchy headlines for your blog post to catch a reader’s attention.\n\nVisit Headline Studio From Here\n\n3. Answer the public\n\n(Photo Credit:- Answer The Public)\n\n\n\nAnswer The public is an excellent tool for content creators. It gives you insight into what people are asking on social media sites and communities and lets you guess about topics that matter to your audience. Answer the public allows you to enter a keyword or topic related to your niche and it will show results with popular questions and keywords related to your topic. It's an amazing way to get insights into what people are searching online and allows you to identify topics driven by new blog posts or social media content on platforms like Facebook, Instagram, Youtube, and Twitter as well as the types of questions they ask and also want answers.\n\nVisit Answer The Public From Here\n\n\n\n\n\n4. Surfer Seo (SEO Ranking)\n\nWith this tool, content creators can quickly and easily check the ranking of their websites and those of other competitors. This tool allows you to see how your website compares to others in different categories, including:\n\nRank Potential\n\nOrganic Search Ranking\n\nSurfer Seo is free and the interface is very friendly. It's a great tool for anyone who wants to do quick competitor research or check their site's rankings at any time.\n\nVisit SurferSeo From Here\n\n5. Canva (Templates/Graphics)\n\nCanva is a free graphic design platform that makes it easy to create invitations, business cards, mobile videos, Instagram posts, Instagram stories, flyers, and more with professionally designed templates. You can even upload your photos and drag and drop them into Canva templates. It's like having a basic version of Photoshop. You can also remove background from images with one click.\n\nCanva offers thousands of free, professionally designed templates that can be customized with just a few clicks. Simply upload your photos to Canva, drag them into the template of your choice, and save the file to your computer.\n\nIt is free to use for basic use but if you want access to different fonts or more features, then you need to buy a premium plan.\n\nVisit Canva From Here\n\n6. Facebook Audience Insights (Audience Research)\n\n(Photo Credit:- Facebook Audience Insights\n\n\n\nFacebook Audience Insights is a powerful tool for content creators when researching their target market. This can help you understand the demographics, interests, and behaviors of your target audience. This information helps determine the direction of your content so that it resonates with them. The most important tools to consider in Facebook Audience Insights are Demographics and Behavior. These two sections provide you with valuable information about your target market, such as their age and from where they belong, how much time they spend on social media per day, what devices they use to access it, etc.\n\n\n\n\n\nThere is another section of Facebook Audits that is very helpful. This will let you know the interests, hobbies, and activities that people in your target market are most interested in. You can use this information to create content for them about things they will be about as opposed to topics they may not be so keen on.\n\nVisit Facebook Audience Insights From Here\n\n7. Pexels (Images)\n\n(Photo Credit: Pixel\n\n\n\nPexels is a warehouse for any content creator with millions of free royalty images who wants to find high-quality images that can be used freely without having to worry about permissions or licensing so you are free to use the photos in your content and also there is no watermark on photos\n\nThe only cons are that some photos contain people, and Pexels doesn't allow you to remove people from photos. Search your keyword and download as many as you want!\n\nVisit Pexel From Here\n\n\n\n\n\nSo there you have it. We hope that these specially curated websites will come in handy for content creators and small businesses alike. If you've got a site that should be on this list, let us know! And if you're looking for more content creator resources, then let us know in the comments section below",
         "2022-01-27T15:19:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/01/7-free-websites-every-content-creator.html",
         "2025-07-26T05:41:35.953081",
         "Do you have the desire to become a content creator, but not have the money to start? Here are 7 free websites every content creator needs to know. 1.Exploding Topics (Trending Topics) (Photo Credit:- Exploding Topics) If you're a content creator, you might be wondering what better way to find new topic ideas than to see what people are searching for? This tool gives you this data without anyone else's explanation. It provides related hashtags and tips on how to use them effectively in your posts. It's a great tool for anyone who wants to keep up to date with what's most relevant in their niche. You can also see the most popular hashtags by country, making it easier to understand cross-border and demographic trends. This site makes your search for content easier than ever! There are countless ways to use explosive topics to your advantage as a content creator. Some examples can be: Use the most popular hashtags and keywords to get inspiration for ideas. Find out what people are talking about in real-time. Find new audiences you may not have known were interested in your topic. There’s no excuse not to try this website — it’s free and easy to use! Visit Exploding Topics From Here 2. Headline Studio (Headline Grader) Headline Studio allows you to create catchy headlines for your content. After writing a title there is data on how often people view articles with similar titles and why they are involved with them. This is a valuable tool when creating new blog posts because it generates catchy headlines for your blog post to catch a reader’s attention. Visit Headline Studio From Here 3. Answer the public (Photo Credit:- Answer The Public) Answer The public is an excellent tool for content creators. It gives you insight into what people are asking on social media sites and communities and lets you guess about topics that matter to your audience. Answer the public allows you to enter a keyword or topic related to your niche and it will show results with popular questions and keywords related to your topic. It's an amazing way to get insights into what people are searching online and allows you to identify topics driven by new blog posts or social media content on platforms like Facebook, Instagram, Youtube, and Twitter as well as the types of questions they ask and also want answers. Visit Answer The Public From Here 4. Surfer Seo (SEO Ranking) With this tool, content creators can quickly and easily check the ranking of their websites and those of other competitors. This tool allows you to see how your website compares to others in different categories, including: Rank Potential Organic Search Ranking Surfer Seo is free and the interface is very friendly. It's a great tool for anyone who wants to do quick competitor research or check their site's rankings at any time. Visit SurferSeo From Here 5. Canva (Templates/Graphics) Canva is a free graphic design platform that makes it easy to create invitations, business cards, mobile videos, Instagram posts, Instagram stories, flyers, and more with professionally designed templates. You can even upload your photos and drag and drop them into Canva templates. It's like having a basic version of Photoshop. You can also remove background from images with one click. Canva offers thousands of free, professionally designed templates that can be customized with just a few clicks. Simply upload your photos to Canva, drag them into the template of your choice, and save the file to your computer. It is free to use for basic use but if you want access to different fonts or more features, then you need to buy a premium plan. Visit Canva From Here 6. Facebook Audience Insights (Audience Research) (Photo Credit:- Facebook Audience Insights Facebook Audience Insights is a powerful tool for content creators when researching their target market. This can help you understand the demographics, interests, and behaviors of your target audience. This information helps determine the direction of your content so that it resonates with them. The most important tools to consider in Facebook Audience Insights are Demographics and Behavior. These two sections provide you with valuable information about your target market, such as their age and from where they belong, how much time they spend on social media per day, what devices they use to access it, etc. There is another section of Facebook Audits that is very helpful. This will let you know the interests, hobbies, and activities that people in your target market are most interested in. You can use this information to create content for them about things they will be about as opposed to topics they may not be so keen on. Visit Facebook Audience Insights From Here 7. Pexels (Images) (Photo Credit: Pixel Pexels is a warehouse for any content creator with millions of free royalty images who wants to find high-quality images that can be used freely without having to worry about permissions or licensing so you are free to use the photos in your content and also there is no watermark on photos The only cons are that some photos contain people, and Pexels doesn't allow you to remove people from photos. Search your keyword and download as many as you want! Visit Pexel From Here So there you have it. We hope that these specially curated websites will come in handy for content creators and small businesses alike. If you've got a site that should be on this list, let us know! And if you're looking for more content creator resources, then let us know in the comments section below",
         "en",
         "{'MISC': ['After writing', 'Answer the public', 'Answer the public allows you to enter', 'Canva', 'Canva offers thousands of free', 'Do you have the desire to become', 'Facebook', 'Facebook Audience Insights are Demographics and Behavior', 'Find new audiences you may not have known were interested in your topic', 'Find out what people are talking about in real-time', 'Headline Grader', 'Headline Studio', 'Headline Studio allows you to create catchy headlines for your content', 'Here are 7 free websites every content creator needs to know', \"If you're\", \"If you've got\", 'Images', 'Instagram', 'Instagram posts', 'Instagram stories', 'It gives you insight into what people are asking on social media sites and communities and lets you guess about topics that matter to your audience', 'It is free to use for basic', \"It'\", \"It's a great tool for anyone who wants to do quick competitor research or check their site'\", \"It's a great tool for anyone who wants to keep up to date with what's most relevant in their niche\", \"It's like having a basic version of Photoshop\", 'Pexels', 'Pixel Pexels is a warehouse for any', 'SEO Ranking', 'Search your keyword and download as many as you want!', 'Seo is free and the interface is very friendly', 'Simply upload your photos to Canva', 'Some', 'SurferSeo From Here 5', 'Templates', 'The most important tools to consider', 'The only cons are that some photos contain people', 'There is another section of Facebook Audits that is very helpful', 'There’', 'This can help you understand the demographics', 'This tool allows you to see how your website', 'Trending Topics', 'Use the most popular hashtags and keywords to get inspiration for ideas', 'Visit Answer The Public From Here 4', 'Visit Canva From Here 6', 'Visit Exploding Topics From Here 2', 'Visit Facebook', 'Visit Headline Studio From Here 3', 'Visit Pexel From Here So there you have it', 'We hope that these specially curated websites will come in handy for content creators and small businesses alike', 'With this tool', 'You can also remove background from images with one click', 'You can also see the most', 'You can even upload your photos and drag and drop them into Canva templates', 'You can use this information to create content for them about things they will be about as', 'Youtube, and Twitter as well as the types of questions they ask and also want answers', \"and Pexels doesn't allow you to remove people from photos\", 'and behaviors of your target audience', 'and more with professionally designed templates', 'and save the file to your computer', 'let us know!', 'such as their age and from where they belong', 'the direction of your content so that it resonates with them', 'then let us know in the comments', 'then you need to buy', 'what devices they use to access it', 'your search for content easier than ever!'], 'PER': ['Surfer Seo', 'Topics'], 'ORG': ['Audience Research', 'Credit', 'These two sections provide you with valuable information about your target market']}",
         "[0.03406400606036186, -0.11211507022380829, -0.03343622758984566, 0.04705981910228729, 0.11154356598854065, 0.01528255920857191, 0.0235429797321558, 0.055931996554136276, 0.03409243002533913, 0.01731717400252819, -0.024083541706204414, -0.019320206716656685, 0.0870477557182312, 0.02981449104845524, -0.0011190084042027593, 0.017102856189012527, 0.05118442326784134, -0.03253874555230141, -0.05374276265501976, -0.08827878534793854, -0.05159609392285347, 0.013121469877660275, 0.07220613211393356, 0.013463770970702171, 0.0027905793394893408, 0.018033860251307487, 0.01597139984369278, 0.008420420810580254, 0.07801342010498047, 0.00034438370494171977, 0.07801321148872375, 0.015514615923166275, 0.01906156912446022, -0.02159731648862362, -0.044541653245687485, 0.02804512530565262, -0.0005973895313218236, 0.054523713886737823, -0.01049618236720562, 0.01544026006013155, 0.00850656721740961, -0.013268403708934784, -0.04296831041574478, 0.02938961423933506, 0.01950172707438469, 0.017593976110219955, -0.012293868698179722, 0.03567534685134888, 0.020158817991614342, 0.019507454708218575, 0.000696412636898458, -0.017944561317563057, 0.026351504027843475, -0.0420684851706028, -0.017294013872742653, -0.029853735119104385, -0.02049405127763748, -0.03240793198347092, 0.0041984557174146175, -0.07121071964502335, -0.008787187747657299, -0.032546110451221466, 0.031537964940071106, -0.05588403716683388, 0.020363477990031242, -0.0610155314207077, 0.018055608496069908, 0.11946612596511841, 0.017240898683667183, -0.0009704313706606627, 0.012214451096951962, 0.04346425086259842, -0.027337918058037758, 0.10411792248487473, 0.04482624679803848, -0.03077094443142414, -0.015059995464980602, -0.03865475207567215, -0.023400453850626945, 0.0647306963801384, 0.04981375113129616, -0.038635771721601486, -0.02550537884235382, 0.0012111908290535212, -0.07152717560529709, -0.0684494748711586, -0.00013635860523208976, 0.048944294452667236, -0.002237478503957391, 0.001212228205986321, -0.028783446177840233, 0.07961618155241013, 0.08086076378822327, -0.051486268639564514, 0.06978623569011688, 0.0275734830647707, -0.0006625440437346697, -0.07308502495288849, 0.011135880835354328, 0.026765350252389908, -0.03825140744447708, -0.016067443415522575, 0.021183278411626816, -0.0007581491954624653, 0.04877316951751709, 0.052442893385887146, -0.06401152908802032, 0.10968182981014252, 0.00923771783709526, 0.05500904470682144, 0.005744559690356255, 0.06346075981855392, -0.058861780911684036, -0.07210660725831985, 0.10009270906448364, -0.008443908765912056, 0.059540923684835434, -0.029933501034975052, 0.022740434855222702, 0.06123575568199158, -0.0038295695558190346, 0.050868675112724304, -0.06288020312786102, -0.03750750049948692, -0.0318462960422039, 0.014062912203371525, -0.09906882792711258, 3.764677880877798e-33, 0.14151166379451752, 0.08073949068784714, 0.06781365722417831, 0.09743096679449081, -0.0730535164475441, 0.045172080397605896, -0.03122025355696678, 0.008543592877686024, -0.02429930865764618, -0.004393736366182566, 0.044113889336586, 0.07181449234485626, -0.0355442613363266, 0.01619223691523075, 0.07933931797742844, -0.12396861612796783, 9.441263682674617e-05, -0.09287235885858536, 0.0037374061066657305, -0.024825111031532288, -0.010579594410955906, -0.0979146733880043, 0.06308579444885254, 0.03312872722744942, -0.04061216488480568, 0.017280884087085724, -0.037020836025476456, -0.08212928473949432, 0.06978046149015427, -0.024792499840259552, -0.06438031792640686, -0.00808605644851923, -0.02945134788751602, -0.03987409919500351, -0.026081761345267296, -0.05430165305733681, -0.06279154121875763, -0.06453283876180649, 0.06902320683002472, -0.05266610532999039, -0.09477353096008301, -0.015648694708943367, -0.018119383603334427, -0.04837610945105553, -0.020197845995426178, 0.04664995148777962, 0.026798071339726448, -0.0780506581068039, 0.06196277216076851, 0.030155764892697334, 0.05948195233941078, -0.04414800554513931, 0.01203219871968031, 0.02507811039686203, -0.016691777855157852, 0.02320004254579544, -0.04198324680328369, -0.11258996278047562, 0.08302643150091171, -0.04741578921675682, -0.0367816798388958, -0.0139405382797122, 0.02241061069071293, 0.03737514093518257, 0.02674180641770363, 0.019958000630140305, 0.10816708207130432, 0.035820089280605316, 0.011671368964016438, 0.06506989151239395, 0.029877794906497, 0.008617090992629528, -0.038177452981472015, -0.059593942016363144, -0.01563200168311596, 0.07243836671113968, -0.030332962051033974, -0.046333927661180496, -0.03476453945040703, 0.0634240135550499, 0.027814606204628944, -0.035732805728912354, 0.050343919545412064, -0.006808013655245304, 0.043058425188064575, -0.027006160467863083, 0.038645390421152115, -0.06265313178300858, 0.01205497793853283, 0.010526647791266441, 0.04331492632627487, 0.02109893225133419, -0.028574980795383453, 0.002690950408577919, -0.038410015404224396, -2.3198144077897756e-33, -0.05437770113348961, -0.044524870812892914, -0.05251162126660347, -0.004776386544108391, 0.03371207416057587, -0.025493774563074112, -0.08012789487838745, -0.013051668182015419, -0.01124904491007328, -0.025278937071561813, -0.02638138458132744, -0.01854933425784111, -0.04989548772573471, 0.04179730638861656, -0.030442429706454277, -0.03968825936317444, 0.03580852597951889, 0.018027404323220253, -0.059087447822093964, 0.02168424054980278, -0.030295707285404205, -0.01709987409412861, -0.18207506835460663, -0.05675685778260231, 0.055575668811798096, 0.004475020337849855, 0.026674820110201836, 0.05601951479911804, 0.05924013629555702, 0.03140681982040405, -0.06488259881734848, 0.03946390748023987, 0.0594460591673851, -0.09466085582971573, -0.059085290879011154, 0.022387780249118805, -0.0124162333086133, -0.017208250239491463, 0.03192809969186783, -0.004132168833166361, -0.023985503241419792, 0.06646808981895447, 0.0020498905796557665, -0.061454497277736664, -0.15324831008911133, 0.014876830391585827, -0.03894295543432236, 0.052753303200006485, 0.03698725253343582, 0.00345424422994256, 0.043973177671432495, 0.00211632763966918, -0.010628404095768929, -0.08117102831602097, 0.020661169663071632, -0.015308184549212456, -0.03344137594103813, 0.053828462958335876, -0.007650634739547968, -0.00021714839385822415, -0.08560770750045776, 0.07729610800743103, -0.022403793409466743, -0.008235922083258629, -0.009619392454624176, -0.14469556510448456, 0.028826087713241577, 0.03736046701669693, -0.09066886454820633, -0.02932003326714039, 0.03367228806018829, 0.022264858707785606, -0.0403444729745388, -0.08847580850124359, -0.07029843330383301, 0.04728265106678009, 0.04643484205007553, 0.02515251375734806, 0.025051593780517578, -0.03944243863224983, 0.006325635127723217, 0.041613589972257614, -0.0068708062171936035, -0.009321519173681736, 0.07901410013437271, 0.03674948588013649, -0.11413649469614029, 0.02840232476592064, -0.02650052309036255, -0.0037475326098501682, -0.028540287166833878, -0.03679368272423744, -0.08822030574083328, 0.1431196630001068, -0.008962498977780342, -5.671548564123441e-08, -0.039853647351264954, -0.0017561654094606638, -0.06593505293130875, 0.06546126306056976, -0.007900320924818516, 0.09283161163330078, -0.0016395238926634192, 0.01225084438920021, -0.01791958138346672, 0.016869882121682167, -0.012335138395428658, -0.05472307652235031, -0.02575143426656723, 0.07321741431951523, 0.0864156112074852, -0.0005877576768398285, -0.01101412158459425, -0.04119406268000603, 0.02553059533238411, -0.058908913284540176, 0.02935323491692543, 0.043638039380311966, -0.05649420991539955, -0.06179805099964142, 0.05929538235068321, 0.04216177389025688, 0.043481286615133286, -0.015825193375349045, -0.03576655685901642, -0.008145115338265896, 0.004833205137401819, 0.004119614139199257, -0.07433435320854187, -0.028639046475291252, 0.07189220190048218, 0.02326149307191372, -0.040076881647109985, -0.042595114558935165, -0.0659671276807785, -0.0021514934487640858, 0.046966034919023514, 0.16173632442951202, 0.10053956508636475, -0.002339341677725315, -0.07663378864526749, 0.05899985507130623, -0.00629354827105999, 0.012184824794530869, 0.0058859894052147865, 0.02491127699613571, -0.07851672172546387, -0.06334161758422852, 0.1008082777261734, -0.044699233025312424, 0.0791601613163948, 0.05519314855337143, 0.009022041223943233, 0.08143046498298645, 0.09688182175159454, 0.07366354018449783, 0.05278729274868965, -0.009628770872950554, -0.011900843121111393, 0.04003918170928955]",
         "0.186"
        ],
        [
         "39",
         "40",
         "Most Frequently Asked Questions About  Email Marketing",
         "1. Why is email marketing important? Email is the marketing tool that helps you create a seamless, connected, frictionless buyer journey. More importantly, email marketing allows you to build relationships with prospects, customers, and past customers. It's your chance to speak to them right in their inbox, at a time that suits them. Along with the right message, email can become one of your most powerful marketing channels. 2. What is benefits of email marketing? Email marketing is best way for creating long term relationship with your clients, and increasing sales in our company. Benefits of email marketing for bussiness: Better brand recognition Statistics of what works best More sales Targeted audience More traffic to your products/services/newsletter Build credibility Most bussinesses are using email marketing and making tons of money with email marketing. 3. What is the simplest day and time to send my marketing emails? Again, the answer to this question varies from company to company. And again, testing is the way to find out what works best. Typically, weekends and mornings seem to be times when multiple emails are opened, but since your audience may have different habits, it's best to experiment and then use your data to decide. 4. Which metrics should I be looking at? The two most important metrics for email marketing are open rate and click-through rate. If your emails aren't opened, subscribers will never see your full marketing message, and if they open them but don't click through to your site, your emails won't convert. 5. How do I write a decent subject line? The best subject lines are short and to the point, accurately describing the content of the email, but also catchy and intriguing, so the reader wants to know more. Once Again, this is the perfect place for A/B testing, to see what types of subject lines work best with your audience. Your call to action should be clear and simple. It should be somewhere at the top of your email for those who haven't finished reading the entire email, then repeated at the end for those reading all the way through. It should state exactly what you want subscribers to do, for example \"Click here to download the premium theme for free. 6. Is email marketing still effective? Email marketing is one of the most effective ways for a business to reach its customers directly. Think about it. You don't post something on your site hoping people will visit it. You don't even post something on a social media page and hope fans see it. You're sending something straight to each person's inbox, where they'll definitely see it! Even if they don't open it, they'll still see your subject line and business name every time you send an email, so you're still communicating directly with your audience. 7. However do I grow my email subscribers list? Should i buy an email list or build it myself? Buying an email list is waste of time & money. These email accounts are unverified and not interested in your brand. The mailing list is useless if your subscribers do not open your emails. There are different ways to grow your mailing list. Give them a free ebook and host it on a landing page where they have to enter the email to download the file and also create a forum page on your website, asks your visitors what questions they might have about your business, and collects email addresses to follow up with them. 8. How do I prevent audience from unsubscribing? If the subject line of the email is irrelevant to customers, they will ignore it multiple times. But, if it keeps repeating, they are intercepted and unsubscribed from your emails. So, send relevant emails for the benefit of the customer. Don't send emails that often only focus on sales, offers and discounts. Submit information about your business and offers so you can connect with customers. You can also update them on recent trends in your industry. The basic role of an email is first and foremost to connect with customers, get the most out of this tool. 9. What is the difference between a cold email and a spam email? Cold emails are mostly sales emails that are sent with content align to the needs of the recipient. It is usually personalized and includes a business perspective. However, it is still an unsolicited email. And all unsolicited emails are marked as SPAM. Regularly receiving this type of unsolicited email in your users' inboxes, chances are your emails will soon be diverted to spam or junk folders. The most important thing to prevent this from happening is to respect your recipients' choice to opt-out of receiving emails from you. You can add the links to easily unsubscribe. You must be familiar with the CAN-SPAM Act and its regulations. 10. Where can I find email template? Almost all email campaign tools provide you with ready-made templates. Whether you use MailChimp or Pardot, you'll get several email templates ready to use. However, if you want to create a template from scratch, you can do so.Most of email campaign tools have option to paste the HTML code of your own design. 11. What email marketing trend will help marketers succeed in 2022? Is it a trend to listen to and get to know your customers? I think people realize how bad it feels for a brand or a company to obsess over themselves without knowing their customers personal needs. People who listen empathetically and then provide value based on what they learn will win. Final Saying You can approach email marketing in different ways. We have compiled a list of most frequently asked questions to help you understand how to get started, what constraints you need to keep in mind, and what future development you will need, we don’t have 100% answers to every situation and there’s always a chance you will have something new and different to deal with as you market your own business.",
         "1. Why is email marketing important?\n\nEmail is the marketing tool that helps you create a seamless, connected, frictionless buyer journey. More importantly, email marketing allows you to build relationships with prospects, customers, and past customers. It's your chance to speak to them right in their inbox, at a time that suits them. Along with the right message, email can become one of your most powerful marketing channels.\n\n2. What is benefits of email marketing?\n\nEmail marketing is best way for creating long term relationship with your clients, and increasing sales in our company.\n\n\n\n\n\nBenefits of email marketing for bussiness:\n\nBetter brand recognition\n\nStatistics of what works best\n\nMore sales\n\nTargeted audience\n\nMore traffic to your products/services/newsletter\n\nBuild credibility\n\nMost bussinesses are using email marketing and making tons of money with email marketing.\n\n\n\n\n\n3. What is the simplest day and time to send my marketing emails?\n\n\n\n\n\nAgain, the answer to this question varies from company to company. And again, testing is the way to find out what works best. Typically, weekends and mornings seem to be times when multiple emails are opened, but since your audience may have different habits, it's best to experiment and then use your data to decide.\n\n\n\n\n\n4. Which metrics should I be looking at?\n\n\n\n\n\nThe two most important metrics for email marketing are open rate and click-through rate. If your emails aren't opened, subscribers will never see your full marketing message, and if they open them but don't click through to your site, your emails won't convert.\n\n\n\n\n\n5. How do I write a decent subject line?\n\n\n\n\n\nThe best subject lines are short and to the point, accurately describing the content of the email, but also catchy and intriguing, so the reader wants to know more. Once Again, this is the perfect place for A/B testing, to see what types of subject lines work best with your audience. Your call to action should be clear and simple. It should be somewhere at the top of your email for those who haven't finished reading the entire email, then repeated at the end for those reading all the way through. It should state exactly what you want subscribers to do, for example \"Click here to download the premium theme for free.\n\n\n\n\n\n\n\n6. Is email marketing still effective?\n\nEmail marketing is one of the most effective ways for a business to reach its customers directly. Think about it. You don't post something on your site hoping people will visit it. You don't even post something on a social media page and hope fans see it. You're sending something straight to each person's inbox, where they'll definitely see it! Even if they don't open it, they'll still see your subject line and business name every time you send an email, so you're still communicating directly with your audience.\n\n\n\n\n\n\n\n\n\n7. However do I grow my email subscribers list? Should i buy an email list or build it myself?\n\nBuying an email list is waste of time & money. These email accounts are unverified and not interested in your brand. The mailing list is useless if your subscribers do not open your emails. There are different ways to grow your mailing list.\n\n\n\n\n\nGive them a free ebook and host it on a landing page where they have to enter the email to download the file and also create a forum page on your website, asks your visitors what questions they might have about your business, and collects email addresses to follow up with them.\n\n\n\n\n\n\n\n\n\n8. How do I prevent audience from unsubscribing?\n\n\n\n\n\nIf the subject line of the email is irrelevant to customers, they will ignore it multiple times. But, if it keeps repeating, they are intercepted and unsubscribed from your emails. So, send relevant emails for the benefit of the customer. Don't send emails that often only focus on sales, offers and discounts.\n\nSubmit information about your business and offers so you can connect with customers. You can also update them on recent trends in your industry. The basic role of an email is first and foremost to connect with customers, get the most out of this tool.\n\n\n\n\n\n9. What is the difference between a cold email and a spam email?\n\n\n\n\n\nCold emails are mostly sales emails that are sent with content align to the needs of the recipient. It is usually personalized and includes a business perspective. However, it is still an unsolicited email. And all unsolicited emails are marked as SPAM.\n\nRegularly receiving this type of unsolicited email in your users' inboxes, chances are your emails will soon be diverted to spam or junk folders. The most important thing to prevent this from happening is to respect your recipients' choice to opt-out of receiving emails from you. You can add the links to easily unsubscribe. You must be familiar with the CAN-SPAM Act and its regulations.\n\n\n\n\n\n10. Where can I find email template?\n\nAlmost all email campaign tools provide you with ready-made templates. Whether you use MailChimp or Pardot, you'll get several email templates ready to use.\n\nHowever, if you want to create a template from scratch, you can do so.Most of email campaign tools have option to paste the HTML code of your own design.\n\n\n\n11. What email marketing trend will help marketers succeed in 2022?",
         "2022-01-29T12:45:00",
         "https://feeds.feedburner.com/TechCrunch/",
         "https://techncruncher.blogspot.com/2022/01/most-frequently-asked-questions-about.html",
         "2025-07-26T05:41:35.941423",
         "1. Why is email marketing important? Email is the marketing tool that helps you create a seamless, connected, frictionless buyer journey. More importantly, email marketing allows you to build relationships with prospects, customers, and past customers. It's your chance to speak to them right in their inbox, at a time that suits them. Along with the right message, email can become one of your most powerful marketing channels. 2. What is benefits of email marketing? Email marketing is best way for creating long term relationship with your clients, and increasing sales in our company. Benefits of email marketing for bussiness: Better brand recognition Statistics of what works best More sales Targeted audience More traffic to your products/services/newsletter Build credibility Most bussinesses are using email marketing and making tons of money with email marketing. 3. What is the simplest day and time to send my marketing emails? Again, the answer to this question varies from company to company. And again, testing is the way to find out what works best. Typically, weekends and mornings seem to be times when multiple emails are opened, but since your audience may have different habits, it's best to experiment and then use your data to decide. 4. Which metrics should I be looking at? The two most important metrics for email marketing are open rate and click-through rate. If your emails aren't opened, subscribers will never see your full marketing message, and if they open them but don't click through to your site, your emails won't convert. 5. How do I write a decent subject line? The best subject lines are short and to the point, accurately describing the content of the email, but also catchy and intriguing, so the reader wants to know more. Once Again, this is the perfect place for A/B testing, to see what types of subject lines work best with your audience. Your call to action should be clear and simple. It should be somewhere at the top of your email for those who haven't finished reading the entire email, then repeated at the end for those reading all the way through. It should state exactly what you want subscribers to do, for example \"Click here to download the premium theme for free. 6. Is email marketing still effective? Email marketing is one of the most effective ways for a business to reach its customers directly. Think about it. You don't post something on your site hoping people will visit it. You don't even post something on a social media page and hope fans see it. You're sending something straight to each person's inbox, where they'll definitely see it! Even if they don't open it, they'll still see your subject line and business name every time you send an email, so you're still communicating directly with your audience. 7. However do I grow my email subscribers list? Should i buy an email list or build it myself? Buying an email list is waste of time & money. These email accounts are unverified and not interested in your brand. The mailing list is useless if your subscribers do not open your emails. There are different ways to grow your mailing list. Give them a free ebook and host it on a landing page where they have to enter the email to download the file and also create a forum page on your website, asks your visitors what questions they might have about your business, and collects email addresses to follow up with them. 8. How do I prevent audience from unsubscribing? If the subject line of the email is irrelevant to customers, they will ignore it multiple times. But, if it keeps repeating, they are intercepted and unsubscribed from your emails. So, send relevant emails for the benefit of the customer. Don't send emails that often only focus on sales, offers and discounts. Submit information about your business and offers so you can connect with customers. You can also update them on recent trends in your industry. The basic role of an email is first and foremost to connect with customers, get the most out of this tool. 9. What is the difference between a cold email and a spam email? Cold emails are mostly sales emails that are sent with content align to the needs of the recipient. It is usually personalized and includes a business perspective. However, it is still an unsolicited email. And all unsolicited emails are marked as SPAM. Regularly receiving this type of unsolicited email in your users' inboxes, chances are your emails will soon be diverted to spam or junk folders. The most important thing to prevent this from happening is to respect your recipients' choice to opt-out of receiving emails from you. You can add the links to easily unsubscribe. You must be familiar with the CAN-SPAM Act and its regulations. 10. Where can I find email template? Almost all email campaign tools provide you with ready-made templates. Whether you use MailChimp or Pardot, you'll get several email templates ready to use. However, if you want to create a template from scratch, you can do so.Most of email campaign tools have option to paste the HTML code of your own design. 11. What email marketing trend will help marketers succeed in 2022?",
         "en",
         "{'MISC': ['Again, the answer to this', 'Almost all email campaign tools provide you with ready', 'Along with the right', 'And again', 'And all unsolicited', 'Better brand recognition Statistics of what works best More sales Targeted audience More traffic to your products/services/newsletter Build credibility Most', 'Click here to download the premium theme for free', 'Cold emails are mostly', 'Email', 'Email is the marketing tool that helps you create a seamless', 'Email marketing is best way for creating', 'Give them a free ebook and host it on', 'How do I', 'If the subject line of the email is irrelevant to customers', \"If your emails aren't opened\", 'It is usually personalized and', \"It should be somewhere at the top of your email for those who haven't finished reading the entire email\", \"It's your chance to speak to them right in their inbox\", 'MailChimp or', 'Most of email campaign', 'Once Again', 'Pardot', 'Regularly receiving this type of unsolicited', 'SPAM', 'Should i buy an email list or', 'So', 'The basic role of an', 'The best subject', 'The mailing list is useless if your subscribers do not open your emails', 'The most important thing to', 'There are different ways to grow your mailing list', 'What is benefits of email marketing', 'What is the difference between', 'What is the simplest day and time to send my marketing emails', 'Where can', 'Whether you', 'Which metrics should I be looking at?', 'You can add the links to easily unsubscribe', 'You can also update them', \"You don't even post something on a social media page and hope fans see it\", \"You don't post something on your site hoping people will visit it\", 'You must be familiar with the CAN-SPAM Act and its regulations', 'Your call to action should be clear and simple', 'and collects email addresses to follow up with them', 'and increasing sales in our company', 'at a time that suits them', 'but also catchy and intriguing', 'customers, and past customers', 'email can become one of your most powerful marketing', 'emails for the benefit of the customer', 'get the most out of this tool', \"it's best to experiment and then\", 'subscribers will never see your full marketing message', 'the content of', 'then repeated at the end for those reading all the way through', 'they are intercepted and unsubscribed from your emails', \"they'll still see your subject line and business name every time you send an email\", 'tools have option', 'with your audience', 'you can do so'], 'PER': ['However', 'More', 'accurately describing', 'they will', 'trends in your industry', \"where they'll definitely see it!\", \"your emails won't convert\"], 'ORG': ['Benefits of email marketing for bussiness', 'Submit'], 'LOC': ['Typically', 'asks your visitors what questions they might have about your business', 'weekends and mornings seem to be times when multiple emails are']}",
         "[0.016141459345817566, -0.052670784294605255, 0.04577792063355446, -0.016985854133963585, 0.05811899155378342, 0.02308247610926628, 0.06487436592578888, 0.020959729328751564, 0.05372919142246246, -0.08807897567749023, -0.06106404587626457, 0.02700260654091835, 0.006300654262304306, 0.038385577499866486, 0.10283474624156952, -0.04886762797832489, 0.03291824832558632, -0.02960585430264473, -0.050640761852264404, 0.009770236909389496, -0.053413696587085724, -0.06709038466215134, 0.06845759600400925, 0.00891620572656393, -0.08098910748958588, -0.019580133259296417, 0.013902632519602776, -0.023735465481877327, -0.11112324893474579, -0.09349991381168365, 0.03857974335551262, -0.00887143611907959, 0.06359292566776276, -0.014004792086780071, -0.043592363595962524, 0.04485083743929863, 0.014801053330302238, -0.009500255808234215, 0.007935781031847, 0.02242579683661461, -0.06612244993448257, -0.08656694740056992, 0.01542720291763544, -0.0126937385648489, 0.04924860969185829, -0.027947261929512024, 0.07697885483503342, 0.10209955275058746, -0.0597991906106472, 0.044977594166994095, -0.032500412315130234, -0.04101734235882759, -0.012476852163672447, 0.05808340013027191, 0.042485956102609634, 0.03313850983977318, -0.08371997624635696, -0.025542864575982094, 0.013037052936851978, 0.016886157914996147, 0.01650198921561241, -0.0056030056439340115, -0.04461051896214485, -0.037096936255693436, -0.04640519991517067, -0.06757872551679611, -0.023353885859251022, 0.016309110447764397, 0.016641337424516678, 0.006720718927681446, -0.07545365393161774, -0.014193200506269932, -0.06520728766918182, 0.09154538065195084, 0.01832692138850689, 0.014989427290856838, 0.03882751986384392, -0.01220849622040987, 0.008070913143455982, 0.08526143431663513, -0.024227870628237724, 0.07149011641740799, -0.07605849206447601, 0.04711303114891052, 0.023639628663659096, 0.05181422084569931, 0.03960386663675308, 0.03609054535627365, -0.06616830080747604, -0.022448493167757988, 0.10253038257360458, 0.0525335967540741, -0.10375381261110306, 0.03870587423443794, 0.02259944938123226, 0.051812898367643356, -0.09752121567726135, 0.0036156526766717434, -0.00467925239354372, 0.007197414059191942, 0.07956293225288391, 0.012877829372882843, 0.017968550324440002, -0.016991451382637024, -0.04538735747337341, -0.04195208102464676, -0.04085004702210426, -9.407861944055185e-05, -0.04253905639052391, 0.025211865082383156, 0.006399592384696007, -0.00034955047885887325, -0.014134484343230724, 0.002894469304010272, 0.08644869923591614, -0.04439600557088852, -0.09407645463943481, 0.08967326581478119, 0.06318533420562744, 0.1411573588848114, -0.03665244206786156, 0.0280274860560894, 0.09476480633020401, -0.07732732594013214, -0.023352792486548424, 0.027132069692015648, 0.006954836193472147, 5.792666448855333e-33, -0.12287653982639313, 0.03971274197101593, 0.03004143200814724, 0.0660780742764473, -0.018138498067855835, -0.004450678359717131, -0.02522333711385727, 0.06156817823648453, -0.03056621178984642, -0.021370725706219673, -0.04124775528907776, 0.05671616643667221, 0.04581112042069435, 0.04264796897768974, 0.007653804030269384, 0.008319307118654251, 0.022050270810723305, 0.011826453730463982, 0.00762268016114831, -0.057282764464616776, 0.022075532004237175, -0.006745838560163975, -0.0027839462272822857, 0.020410925149917603, 0.029434043914079666, -0.13474522531032562, 0.10044755041599274, 0.04638216644525528, -0.010670565068721771, 0.008704088628292084, 0.0013933801092207432, -0.07187763601541519, 0.01765870675444603, 0.0713319182395935, -0.007251490373164415, 0.027267100289463997, -0.07255403697490692, -0.041082993149757385, 0.004393857438117266, 0.049453478306531906, -0.14488038420677185, 0.051116328686475754, 0.00409568240866065, 0.044554583728313446, -0.0005595823749899864, 0.1034073606133461, -0.004050580319017172, -0.07206989079713821, 0.02547047846019268, -0.043023671954870224, 0.09576035290956497, -0.040128063410520554, 0.06819040328264236, 0.03132757544517517, -0.07343184947967529, 0.06347767263650894, 0.029317907989025116, -0.07415757328271866, -6.056967322365381e-05, 0.04038562625646591, -0.06235681474208832, -0.04682367295026779, 0.09341341257095337, -0.04847430810332298, 0.01701587624847889, -0.004077243153005838, 0.018548808991909027, -0.03214702010154724, -0.015273526310920715, 0.01251000352203846, 0.1142113208770752, -0.07676348835229874, -0.01554895006120205, 0.023723041638731956, 0.010887714102864265, -0.060186002403497696, -0.030506165698170662, 0.003949499689042568, -0.01735479198396206, 0.05816080793738365, 0.02872682549059391, 0.043575745075941086, 0.05223720148205757, 0.012499986216425896, 0.027227872982621193, 0.004291164223104715, 0.07292656600475311, 0.003153271973133087, -0.053388770669698715, 0.09674517065286636, -0.03085407055914402, 0.013623226433992386, -0.024192914366722107, 0.07928963750600815, 0.03259905427694321, -4.7382156900730934e-33, 0.008748452179133892, 0.0045607504434883595, 0.0062668039463460445, 0.06349339336156845, -0.00591551698744297, 0.0451740026473999, 0.012682268396019936, -0.03960366174578667, 0.02521483227610588, 0.006654244381934404, -0.08092954754829407, 0.022094324231147766, -0.040489960461854935, 0.008517497219145298, -0.07273010909557343, -0.02576671540737152, 0.08406498283147812, -0.09217343479394913, 0.0008728901739232242, -0.004818928427994251, -0.0074947974644601345, 0.03422315791249275, -0.06696147471666336, -0.05928948149085045, -0.0306096151471138, 0.010656993836164474, -0.10073819756507874, 0.0537659116089344, 0.011770791374146938, -0.016464266926050186, 0.01595749519765377, 0.021000461652874947, 0.03849651291966438, 0.021398652344942093, -0.02278294414281845, -0.00026743646594695747, 0.029147539287805557, -0.03303741291165352, 0.05893843621015549, 0.06633775681257248, 0.014414338394999504, 0.10439525544643402, 0.05515752360224724, -0.06790667772293091, -0.0011837150668725371, 0.06469441950321198, -0.00021141588513273746, 0.029412658885121346, -0.02198953367769718, 0.023854447528719902, 0.021551573649048805, 0.037310581654310226, -0.016350727528333664, -0.03845032677054405, -0.005458138883113861, 0.008280751295387745, -0.004654449410736561, -0.05165241286158562, -0.01380191184580326, 0.08502770215272903, -0.08739294856786728, 0.03148622810840607, 0.054230544716119766, -0.01461392268538475, -0.01124972477555275, -0.07224583625793457, 0.07009685784578323, -0.023117754608392715, -0.010438935831189156, -0.08304865658283234, -0.034540727734565735, -0.006151390727609396, -0.031259652227163315, -0.05117132142186165, -0.11565541476011276, 0.05632738396525383, -0.04113245755434036, 0.018908673897385597, -0.023089297115802765, 0.004776268266141415, -0.08576492220163345, -0.059129223227500916, -0.09783203899860382, -0.012367479503154755, -0.0929541289806366, 0.01396121084690094, 0.07356125116348267, -0.07487819343805313, 0.09347765892744064, -0.012931118719279766, 0.035046931356191635, -0.018246369436383247, -0.029114093631505966, -0.02809016965329647, -0.0017666068160906434, -5.1198934869489676e-08, -0.008796945214271545, -0.11969750374555588, 0.027350375428795815, 0.025679899379611015, -0.09397592395544052, 0.002875594887882471, 0.052932705730199814, 0.09846196323633194, 0.048648651689291, -0.02324242703616619, 0.0456339493393898, -0.02681563049554825, -0.07856707274913788, 0.12063200026750565, 0.06691581755876541, -0.021355407312512398, 0.02592196688055992, -0.04169706627726555, -0.022629348561167717, 0.029236216098070145, 0.06650155782699585, 0.03372792899608612, 0.008476220071315765, -0.06998731195926666, 0.05640512704849243, 0.012122562155127525, 0.051898032426834106, 0.05414135754108429, -0.055989135056734085, -0.054793693125247955, -0.019148437306284904, -0.11276230216026306, -0.07319960743188858, 0.015895692631602287, -0.08064769953489304, -0.033329159021377563, -0.01824319362640381, -0.07133324444293976, -0.0313127227127552, 0.10373292863368988, 0.023616338148713112, 0.018244007602334023, 0.030103452503681183, -0.030543643981218338, -0.032133594155311584, -0.016392631456255913, -0.04000336676836014, 0.02450411207973957, -0.059325672686100006, 0.07643325626850128, -0.020755227655172348, -0.0035250119399279356, 0.05209594592452049, -0.05052153393626213, -0.029266463592648506, -0.013232183642685413, 0.003089252393692732, -0.0022679415997117758, 0.04706665500998497, 0.058190904557704926, -0.04659130051732063, 0.0623246431350708, -0.10141200572252274, 0.02332843840122223]",
         "0.202"
        ],
        [
         "40",
         "501",
         "Test Asus ProArt P16 : pour la création de contenu sous Windows, il peut remplacer le MacBook Pro",
         "Ce PC portable a des performances solides, mais il brillera surtout entre les mains des utilisateurs les plus créatifs qui peuvent accéder à ses options étendues de personnalisation.",
         "La série ProArt d'Asus se compose d'ordinateurs portables élégants dotés d'un équipement haut de gamme pour les créatifs. Au sommet de la gamme se trouve le nouveau ProArt P16 alimenté par AMD : il s'illustre par la puissance et la performance, dans une esthétique élégante et entièrement noire, avec un trackpad géant muni du DialPad propriétaire d'Asus (sorte de trackpoint) et un écran brillant.\n\nRecevez une sélection des derniers produits logiciels et matériels à destination des professionnels chaque semaine dans votre boîte mail avec notre newsletter Guides d'achat. En savoir plus sur l’utilisation des données personnelles\n\nJ'ai eu l'occasion de prendre en mains le ProArt P16 il y a quelques mois et j'ai trouvé qu'il s'agissait d'une machine très performante avec beaucoup de puissance brute. Cependant, il nécessite également une certaine personnalisation et optimisation pour en tirer le meilleur parti. Avant d'aborder ce sujet, jetons un coup d'œil au matériel.\n\nLes points essentiels à retenir de l'ordinateur portable Asus ProArt P16\n\nL'Asus ProArt P16 est disponible à partir de 2500 €.\n\nIl associe un équipement puissant à une série d'options personnalisables conçues pour les créatifs.\n\nLa personnalisation poussée nécessite l'engagement de l'utilisateur, l'énorme trackpad ne plaira pas à tout le monde et l'écran ultra brillant a tendance à éblouir.\n\nProcesseurs et autres équipements haut de gamme\n\nLe ProArt P16 dispose de 32 Go de mémoire, d'un processeur AMD Ryzen AI 9 HX 370 et d'une puce à 12 cœurs et 24 threads avec un NPU 50 TOP. Ce cœur puissant soutient les tâches créatives de l'appareil, qu'il s'agisse d'édition vidéo, d'utilisation de programmes d'animation ou de conception graphique avancés, ou simplement de multitâche avec une poignée de programmes différents et des dizaines d'onglets de navigateur ouverts.\n\nL'un des meilleurs atouts de cet ordinateur portable est toutefois son écran. Il est de type tactile AMOLED, d'une résolution de 3840 x 2400 et d'une luminosité de 500 nits : l'image apparaît claire et lumineuse à travers un revêtement brillant de qualité supérieure. Alimenté par le GPU Nvidia GeForce RTX 4060, il est doté de la technologie DLSS 3 (Deep Learning Super Sampling) et prend en charge le ray tracing.\n\nBien qu'il puisse soutenir une bonne expérience de jeu, le système graphique est un peu freiné par le taux de rafraîchissement de 60 Hz. La décision d'Asus de limiter la fréquence de rafraîchissement est décevante, mais elle permet de maintenir le prix à un certain niveau bas tout en consolidant par ailleurs le caractère \"créatif\" de cette machine.\n\nStylet et écran ferme\n\nDans cette optique, l'ordinateur est livré avec un stylet précis et réactif, en particulier sur l'écran lisse et brillant, qui ressemble à une toile vierge vous invitant à faire des croquis. Le stylet de cet ordinateur portable est suffisamment bon pour que les artistes et les concepteurs l'utilisent sérieusement, car trop souvent, ils sont soit trop lents, soit trop dépouillés de qualités tangibles pour justifier leur utilisation. Ici, cependant, il est vif et réactif et est doté de diverses fonctionnalités qui vont bien en tandem avec le DialPad pour effectuer des actions personnalisées d'un seul clic.\n\nJ'apprécie également que cet ordinateur portable ne soit pas un 2-en-1. Les ordinateurs portables convertibles sont souvent obligés de passer en mode tablette si l'on veut les utiliser avec un stylet, car le fait d'appuyer sur l'écran en mode portable le pousse vers le bas, à moins de le soutenir avec la main.\n\nLe ProArt P16 a été conçu dans cette optique, puisque l'écran se verrouille à son angle le plus éloigné. Au lieu de se replier sous la pression du stylo, il reste droit avec un degré de courbure généreux. Gardez à l'esprit qu'en poussant trop fort vers l'arrière, l'avant de l'appareil se soulèvera du bureau.\n\nLe DialPad d'Asus est une autre caractéristique unique dont les créatifs aimeront profiter. Si vous ne l'avez pas encore vue, il s'agit d'une petite roue surélevée sur le pavé tactile qui peut être personnalisée pour activer différents paramètres, comme la modification de la taille des pinceaux dans Photoshop ou la coupure, la pause ou le rembobinage dans CapCut ou Premiere. La petite taille physique du DialPad permet d'activer et de faire défiler la \"roue\" rapidement et facilement, en particulier pour les fonctions courantes.\n\nKyle Kucharski/ZDNET\n\nMon seul reproche à propos du DialPad est qu'il a fallu une minute pour l'installer. Il était désactivé sur l'ordinateur portable dès sa sortie de l'emballage, ce qui m'obligeait à l'activer par un geste spécifique sur le pavé tactile qui n'est pas évident à moins de le chercher. Pour y parvenir, vous devez appuyer sur l'icône dans le coin supérieur droit du pavé tactile, puis glisser rapidement en diagonale vers le milieu du pavé tactile. Comme il s'agit d'une des fonctions principales de cet ordinateur portable, ne serait-il pas logique qu'elle fonctionne dès la sortie de la boîte et/ou qu'elle soit accompagnée d'un tutoriel d'installation facile ?\n\nUne fois ce DialPad activé, cependant, j'en suis rapidement devenu un fan. J'aime la granularité des personnalisations possibles et l'utilité de l'outil va bien au-delà des cas d'utilisation créatifs. En fait, j'ai trouvé que certains des cas les plus pratiques étaient dans les programmes de productivité et dans l'utilisation du navigateur, permettant des fonctions rapides pendant la journée de travail pour des actions fréquentes.\n\nAsus/ZDNET\n\nLes autres programmes Asus fournis avec l'ordinateur portable sont plus ou moins utiles, sans compter qu'ils sont plutôt lents à démarrer. Le programme \"Muse Tree\" d'Asus, par exemple, a mis un temps fou à s'installer et à démarrer. J'ai eu l'occasion de tester ce programme précédemment, et bien qu'il s'agisse d'une idée très intéressante, je ne suis toujours pas convaincu de son utilité...\n\nDes options d'optimisation à régler\n\nLe clavier haut de gamme et satisfaisant est absolument silencieux. De même, le trackpad est massif, s'étendant du clavier jusqu'au bord de l'appareil, et possède une texture mate et veloutée. L'inconvénient est que j'ai eu du mal à le faire fonctionner à pleine capacité dans un bureau particulièrement froid. Si vous avez les mains froides, les réponses risquent d'être lentes.\n\nCe problème peut être résolu par l'optimisation, qui est l'autre point important que j'aimerais mentionner à propos de cet ordinateur portable. D'après mon expérience, les ordinateurs portables Asus réagissent particulièrement bien aux paramètres d'optimisation. Le ProArt P16 en est un parfait exemple : différents profils ou paramètres de réglages peuvent affecter de manière drastique les performances, allant de l'autonomie de la batterie à la vitesse et à la réactivité.\n\nCela s'applique également aux mises à jour de Windows, en particulier pour les charges de travail exigeantes. Lorsque j'ai démarré cet ordinateur portable pour la première fois, par exemple, ses performances étaient nettement moins bonnes jusqu'à ce que je passe en revue la série de mises à jour de Windows pour le système d'exploitation, que je mette à jour les pilotes et que je suive la liste des mises à jour dans le programme MyAsus.\n\nLes performances du ProArt P16 se sont améliorées après la mise à jour, et elles ont été optimisées une fois que je me suis habitué au DialPad et que j'ai configuré le trackpad et les profils d'alimentation.\n\nKerry Wan/ZDNET\n\nTout cela pour dire que le ProArt P16, pour moi, n'était pas un ordinateur portable prêt à l'emploi, mais qu'il nécessitait plutôt une certaine personnalisation et de l'attention pour en tirer le meilleur parti. Cela s'applique à son riche ensemble de fonctionnalités, mais il faut un certain temps pour l'incorporer dans les flux de travail créatifs. En fin de compte, c'est une bonne chose, car cela encourage le changement de la part de l'utilisateur pour sortir des interfaces utilisateur clonées et des flux de travail qui se ressemblent tous.\n\nEn ce qui concerne ses performances, le ProArt P16 s'est placé dans nos tests de benchmarking entre le MacBook Pro M3 et le M4, bien qu'il soit plus proche du M3 que du dernier produit d'Apple, le M4.\n\nBenchmark de l'ordinateur portable Asus ProArt P16 et d'autres ordinateurs portables concurrents\n\nCinebench 24 MC // Geekbench 6.2.2 SC //Geekbench 6.2.2 MC\n\nApple MacBook Pro avec M4 1 000 // 3 823 // 14 849.\n\nApple MacBook Pro avec M3 906 // 3 072 // 11 623.\n\nAsus ProArt P16 1 096 // 2 904 // 12 787.\n\nApple MacBook Pro avec M1 Pro // 828 // 2,211 // 12,482.\n\nEnfin, parlons brièvement de l'autonomie. Il s'agit d'un ordinateur portable avec un équipement puissant et un écran AMOLED de 16 pouces, donc je ne m'attendais pas à grand-chose lors de mes tests. Cependant, j'ai été agréablement surpris par son autonomie, surtout si l'on fait attention aux paramètres d'économie d'énergie.\n\nJ'ai facilement obtenu plus de 10 heures d'autonomie avec une utilisation normale et des tâches intermittentes à forte demande. En revanche, pour les tâches créatives intensives et le multitâche intensif, vous pouvez compter sur une autonomie d'environ sept heures avant de brancher l'appareil sur une prise de courant.\n\nLes conseils d'achat pour l'ordinateur portable Asus ProArt P16\n\nSi vous recherchez un ordinateur portable puissant, bien équipé et pourvu d'un ensemble de fonctionnalités riches et dynamiques, je recommande l'Asus ProArt P16 comme un choix solide pour les créateurs avancés qui veulent défier le statu quo et qui aiment bricoler avec les paramètres de personnalisation afin de maximiser le rendement.\n\nToutefois, si vous recherchez une machine créative prête à l'emploi, je vous recommande plutôt le MacBook Pro M3 ou M4 d'Apple. Il dispose de tout un équipement puissant aussi et nécessaire pour s'attaquer aux tâches créatives et ne pourrait pas être plus facile à configurer. Mais si vous aimez le ProArt P16 mais que vous voulez quelque chose de plus accessible, le ProArt PZ13 d'Asus est beaucoup moins cher.\n\nSource : \"ZDNet.com\"",
         "2025-07-25T02:07:45",
         "https://www.zdnet.fr/feeds/rss/actualites/https://towardsdatascience.com/feed",
         "https://www.zdnet.fr/guide-achat/test-asus-proart-p16-pour-la-creation-de-contenu-sous-windows-il-peut-remplacer-le-macbook-pro-479324.htm#xtor=RSS-1",
         "2025-07-26T05:53:46.271302",
         "La série ProArt d'Asus se compose d'ordinateurs portables élégants dotés d'un équipement haut de gamme pour les créatifs. Au sommet de la gamme se trouve le nouveau ProArt P16 alimenté par AMD : il s'illustre par la puissance et la performance, dans une esthétique élégante et entièrement noire, avec un trackpad géant muni du DialPad propriétaire d'Asus (sorte de trackpoint) et un écran brillant. Recevez une sélection des derniers produits logiciels et matériels à destination des professionnels chaque semaine dans votre boîte mail avec notre newsletter Guides d'achat. En savoir plus sur l’utilisation des données personnelles J'ai eu l'occasion de prendre en mains le ProArt P16 il y a quelques mois et j'ai trouvé qu'il s'agissait d'une machine très performante avec beaucoup de puissance brute. Cependant, il nécessite également une certaine personnalisation et optimisation pour en tirer le meilleur parti. Avant d'aborder ce sujet, jetons un coup d'œil au matériel. Les points essentiels à retenir de l'ordinateur portable Asus ProArt P16 L'Asus ProArt P16 est disponible à partir de 2500 €. Il associe un équipement puissant à une série d'options personnalisables conçues pour les créatifs. La personnalisation poussée nécessite l'engagement de l'utilisateur, l'énorme trackpad ne plaira pas à tout le monde et l'écran ultra brillant a tendance à éblouir. Processeurs et autres équipements haut de gamme Le ProArt P16 dispose de 32 Go de mémoire, d'un processeur AMD Ryzen AI 9 HX 370 et d'une puce à 12 cœurs et 24 threads avec un NPU 50 TOP. Ce cœur puissant soutient les tâches créatives de l'appareil, qu'il s'agisse d'édition vidéo, d'utilisation de programmes d'animation ou de conception graphique avancés, ou simplement de multitâche avec une poignée de programmes différents et des dizaines d'onglets de navigateur ouverts. L'un des meilleurs atouts de cet ordinateur portable est toutefois son écran. Il est de type tactile AMOLED, d'une résolution de 3840 x 2400 et d'une luminosité de 500 nits : l'image apparaît claire et lumineuse à travers un revêtement brillant de qualité supérieure. Alimenté par le GPU Nvidia GeForce RTX 4060, il est doté de la technologie DLSS 3 (Deep Learning Super Sampling) et prend en charge le ray tracing. Bien qu'il puisse soutenir une bonne expérience de jeu, le système graphique est un peu freiné par le taux de rafraîchissement de 60 Hz. La décision d'Asus de limiter la fréquence de rafraîchissement est décevante, mais elle permet de maintenir le prix à un certain niveau bas tout en consolidant par ailleurs le caractère \"créatif\" de cette machine. Stylet et écran ferme Dans cette optique, l'ordinateur est livré avec un stylet précis et réactif, en particulier sur l'écran lisse et brillant, qui ressemble à une toile vierge vous invitant à faire des croquis. Le stylet de cet ordinateur portable est suffisamment bon pour que les artistes et les concepteurs l'utilisent sérieusement, car trop souvent, ils sont soit trop lents, soit trop dépouillés de qualités tangibles pour justifier leur utilisation. Ici, cependant, il est vif et réactif et est doté de diverses fonctionnalités qui vont bien en tandem avec le DialPad pour effectuer des actions personnalisées d'un seul clic. J'apprécie également que cet ordinateur portable ne soit pas un 2-en-1. Les ordinateurs portables convertibles sont souvent obligés de passer en mode tablette si l'on veut les utiliser avec un stylet, car le fait d'appuyer sur l'écran en mode portable le pousse vers le bas, à moins de le soutenir avec la main. Le ProArt P16 a été conçu dans cette optique, puisque l'écran se verrouille à son angle le plus éloigné. Au lieu de se replier sous la pression du stylo, il reste droit avec un degré de courbure généreux. Gardez à l'esprit qu'en poussant trop fort vers l'arrière, l'avant de l'appareil se soulèvera du bureau. Le DialPad d'Asus est une autre caractéristique unique dont les créatifs aimeront profiter. Si vous ne l'avez pas encore vue, il s'agit d'une petite roue surélevée sur le pavé tactile qui peut être personnalisée pour activer différents paramètres, comme la modification de la taille des pinceaux dans Photoshop ou la coupure, la pause ou le rembobinage dans CapCut ou Premiere. La petite taille physique du DialPad permet d'activer et de faire défiler la \"roue\" rapidement et facilement, en particulier pour les fonctions courantes. Kyle Kucharski/ZDNET Mon seul reproche à propos du DialPad est qu'il a fallu une minute pour l'installer. Il était désactivé sur l'ordinateur portable dès sa sortie de l'emballage, ce qui m'obligeait à l'activer par un geste spécifique sur le pavé tactile qui n'est pas évident à moins de le chercher. Pour y parvenir, vous devez appuyer sur l'icône dans le coin supérieur droit du pavé tactile, puis glisser rapidement en diagonale vers le milieu du pavé tactile. Comme il s'agit d'une des fonctions principales de cet ordinateur portable, ne serait-il pas logique qu'elle fonctionne dès la sortie de la boîte et/ou qu'elle soit accompagnée d'un tutoriel d'installation facile ? Une fois ce DialPad activé, cependant, j'en suis rapidement devenu un fan. J'aime la granularité des personnalisations possibles et l'utilité de l'outil va bien au-delà des cas d'utilisation créatifs. En fait, j'ai trouvé que certains des cas les plus pratiques étaient dans les programmes de productivité et dans l'utilisation du navigateur, permettant des fonctions rapides pendant la journée de travail pour des actions fréquentes. Asus/ZDNET Les autres programmes Asus fournis avec l'ordinateur portable sont plus ou moins utiles, sans compter qu'ils sont plutôt lents à démarrer. Le programme \"Muse Tree\" d'Asus, par exemple, a mis un temps fou à s'installer et à démarrer. J'ai eu l'occasion de tester ce programme précédemment, et bien qu'il s'agisse d'une idée très intéressante, je ne suis toujours pas convaincu de son utilité... Des options d'optimisation à régler Le clavier haut de gamme et satisfaisant est absolument silencieux. De même, le trackpad est massif, s'étendant du clavier jusqu'au bord de l'appareil, et possède une texture mate et veloutée. L'inconvénient est que j'ai eu du mal à le faire fonctionner à pleine capacité dans un bureau particulièrement froid. Si vous avez les mains froides, les réponses risquent d'être lentes. Ce problème peut être résolu par l'optimisation, qui est l'autre point important que j'aimerais mentionner à propos de cet ordinateur portable. D'après mon expérience, les ordinateurs portables Asus réagissent particulièrement bien aux paramètres d'optimisation. Le ProArt P16 en est un parfait exemple : différents profils ou paramètres de réglages peuvent affecter de manière drastique les performances, allant de l'autonomie de la batterie à la vitesse et à la réactivité. Cela s'applique également aux mises à jour de Windows, en particulier pour les charges de travail exigeantes. Lorsque j'ai démarré cet ordinateur portable pour la première fois, par exemple, ses performances étaient nettement moins bonnes jusqu'à ce que je passe en revue la série de mises à jour de Windows pour le système d'exploitation, que je mette à jour les pilotes et que je suive la liste des mises à jour dans le programme MyAsus. Les performances du ProArt P16 se sont améliorées après la mise à jour, et elles ont été optimisées une fois que je me suis habitué au DialPad et que j'ai configuré le trackpad et les profils d'alimentation. Kerry Wan/ZDNET Tout cela pour dire que le ProArt P16, pour moi, n'était pas un ordinateur portable prêt à l'emploi, mais qu'il nécessitait plutôt une certaine personnalisation et de l'attention pour en tirer le meilleur parti. Cela s'applique à son riche ensemble de fonctionnalités, mais il faut un certain temps pour l'incorporer dans les flux de travail créatifs. En fin de compte, c'est une bonne chose, car cela encourage le changement de la part de l'utilisateur pour sortir des interfaces utilisateur clonées et des flux de travail qui se ressemblent tous. En ce qui concerne ses performances, le ProArt P16 s'est placé dans nos tests de benchmarking entre le MacBook Pro M3 et le M4, bien qu'il soit plus proche du M3 que du dernier produit d'Apple, le M4. Benchmark de l'ordinateur portable Asus ProArt P16 et d'autres ordinateurs portables concurrents Cinebench 24 MC // Geekbench 6.2.2 SC //Geekbench 6.2.2 MC Apple MacBook Pro avec M4 1 000 // 3 823 // 14 849. Apple MacBook Pro avec M3 906 // 3 072 // 11 623. Asus ProArt P16 1 096 // 2 904 // 12 787. Apple MacBook Pro avec M1 Pro // 828 // 2,211 // 12,482. Enfin, parlons brièvement de l'autonomie. Il s'agit d'un ordinateur portable avec un équipement puissant et un écran AMOLED de 16 pouces, donc je ne m'attendais pas à grand-chose lors de mes tests. Cependant, j'ai été agréablement surpris par son autonomie, surtout si l'on fait attention aux paramètres d'économie d'énergie. J'ai facilement obtenu plus de 10 heures d'autonomie avec une utilisation normale et des tâches intermittentes à forte demande. En revanche, pour les tâches créatives intensives et le multitâche intensif, vous pouvez compter sur une autonomie d'environ sept heures avant de brancher l'appareil sur une prise de courant. Les conseils d'achat pour l'ordinateur portable Asus ProArt P16 Si vous recherchez un ordinateur portable puissant, bien équipé et pourvu d'un ensemble de fonctionnalités riches et dynamiques, je recommande l'Asus ProArt P16 comme un choix solide pour les créateurs avancés qui veulent défier le statu quo et qui aiment bricoler avec les paramètres de personnalisation afin de maximiser le rendement. Toutefois, si vous recherchez une machine créative prête à l'emploi, je vous recommande plutôt le MacBook Pro M3 ou M4 d'Apple. Il dispose de tout un équipement puissant aussi et nécessaire pour s'attaquer aux tâches créatives et ne pourrait pas être plus facile à configurer. Mais si vous aimez le ProArt P16 mais que vous voulez quelque chose de plus accessible, le ProArt PZ13 d'Asus est beaucoup moins cher. Source : \"ZDNet.com\"",
         "fr",
         "{'MISC': ['Apple MacBook Pro', 'Asus', 'Asus ProArt P16', 'Asus ProArt P16 1', 'Benchmark', 'CapCut', 'Cinebench', 'DLSS', 'Deep Learning Super Sampling', 'DialPad', 'Geekbench 6.2.2', 'Go', \"Guides d'achat\", \"J'ai eu l'occasion de prendre en mains\", 'M1', 'M4', 'MacBook Pro M3', 'MyAsus', 'NPU', 'Nvidia GeForce RTX', 'Photoshop', 'ProArt', 'ProArt P16', \"ProArt PZ13 d'Asus\", 'Processeurs', 'Stylet', 'TOP', 'Windows', 'ZDNET', 'ray tracing'], 'ORG': ['AMD', 'Apple', 'Asus', 'M3', 'Muse Tree'], 'PER': ['Kerry', 'Kyle Kucharski', 'Premiere', 'Recevez'], 'LOC': ['ZDNET', 'ZDNet.com']}",
         "[-0.09386730194091797, -0.015307617373764515, -0.09121006727218628, -0.08879723399877548, -0.057853199541568756, 0.011295788921415806, 0.02730487287044525, 0.09476502239704132, -0.006602650508284569, -0.023708846420049667, 0.036065686494112015, 0.07367623597383499, 0.004499724134802818, -0.04500051587820053, -0.0308745838701725, -0.03708592802286148, 0.05456903204321861, -0.04281770810484886, 0.036843687295913696, 0.00062594871269539, 0.010310675017535686, -0.07963830977678299, 0.017989015206694603, 0.06434384733438492, -0.03882318362593651, -0.03851086273789406, -0.041612256318330765, -0.014501954428851604, 0.014368472620844841, -0.07719865441322327, 0.019564269110560417, 0.02710755355656147, 0.10025907307863235, -0.015049964189529419, 0.0507984459400177, 0.026022428646683693, 0.02058432251214981, -0.035545799881219864, 0.0177688580006361, 0.06508733332157135, -0.039499182254076004, -0.008726809173822403, -0.1073078140616417, -0.041050203144550323, 0.023406947031617165, -0.07033529877662659, 0.008673758246004581, 0.033555712550878525, -0.07399537414312363, -0.0019030768889933825, -0.04103013500571251, 0.03955958038568497, 0.04841737076640129, -0.04269171506166458, -0.08781684935092926, -0.007291906978935003, -0.0350123755633831, -0.05433941259980202, 0.026580877602100372, -0.010776021517813206, -0.04878254979848862, -0.04719679057598114, -0.07076875865459442, 0.005104015581309795, -0.058335091918706894, -5.7597513659857213e-05, 0.010737942531704903, 0.012723071500658989, -0.00846911408007145, 0.036125119775533676, -0.002945684129372239, -0.02516573667526245, -0.051912467926740646, 0.0973251461982727, 0.0021786633878946304, 0.05463284254074097, -0.031713008880615234, -0.07906291633844376, -0.03644575923681259, -0.10247734189033508, 0.012712274678051472, -0.04776972904801369, 0.009026112034916878, 0.03159390389919281, 0.04653962701559067, -0.007216247264295816, 0.0059373765252530575, 0.031487252563238144, 0.03866572678089142, -0.007020036224275827, 0.03959599509835243, -0.01910891942679882, -0.07122586667537689, -0.018711593002080917, 0.059219371527433395, 0.007833459414541721, 0.03555311635136604, -0.12636110186576843, 0.023783518001437187, 0.04248841851949692, 0.01837124489247799, 0.05015961453318596, 0.05286405235528946, -0.039998456835746765, -0.010073570534586906, -0.013163675554096699, -0.03570832684636116, -0.02304243855178356, 0.026901571080088615, 0.03039518930017948, -0.01493238378316164, -0.06565234810113907, -0.04811188578605652, -0.09004491567611694, 0.027404585853219032, -0.042179908603429794, -0.0733543187379837, -0.008156773634254932, 0.0641975849866867, -0.002616097219288349, 0.02485012263059616, -0.032359443604946136, -0.07466790080070496, -0.002846748800948262, 0.03853569179773331, 0.030947552993893623, 0.02599967271089554, 1.0346353035736344e-32, -0.014427648857235909, 0.10058155655860901, 0.0007760872831568122, -0.04136929661035538, 0.046027012169361115, -0.03454786539077759, -0.05601739138364792, 0.02166186086833477, 0.03543545678257942, -0.024458402767777443, -0.08340290188789368, 0.027715349569916725, -0.04566754400730133, 0.02377522550523281, 0.10071246325969696, -0.09219147264957428, 0.08781246840953827, 0.054653532803058624, 0.021609531715512276, -0.02597188390791416, -0.049924999475479126, 0.003346723271533847, 0.051326509565114975, 0.039718106389045715, 0.10586981475353241, 0.052196431905031204, 0.04174340143799782, 0.006148787681013346, -0.07019219547510147, 0.04264429584145546, 0.027612941339612007, -0.037227291613817215, -0.08397334814071655, 0.06717714667320251, -0.05487418547272682, -0.0676533654332161, -0.10042250156402588, -0.0897338017821312, 0.054839324206113815, 0.01136693637818098, -0.06249641999602318, 0.02518368326127529, 0.026665031909942627, -0.04150005429983139, -0.020663104951381683, 0.008937755599617958, -0.01491446141153574, 0.10941328853368759, 0.15489770472049713, -0.05847325921058655, -0.041426386684179306, 0.06347891688346863, 0.0025012418627738953, -0.043973762542009354, 0.05284219607710838, -0.048989515751600266, -0.0533575713634491, 0.04198344424366951, 0.06100240722298622, 0.0238180011510849, 0.024844877421855927, 0.020455272868275642, -0.0066970763728022575, -0.01291752327233553, -0.03339793160557747, -0.01380061823874712, -0.06283644586801529, 0.02240036427974701, 0.09313952177762985, -0.001253116992302239, -0.11285749077796936, 0.004900663159787655, 0.02130797691643238, -0.002354780677706003, 0.05240553244948387, 0.06969277560710907, -0.0007015127339400351, -0.027243969962000847, -0.02192806266248226, -0.03217161446809769, -0.10740040987730026, 0.05213617905974388, -0.04222743958234787, -0.004734431393444538, 0.03900119662284851, -0.03044516034424305, 0.028064286336302757, 0.03459486365318298, -0.017519794404506683, 0.02386079914867878, 0.0069593810476362705, -0.02847459353506565, -0.055300407111644745, 0.06326283514499664, -0.04427541792392731, -1.3382264092038664e-32, -0.03699824586510658, -0.007673528045415878, -0.00859651155769825, 0.09047002345323563, -0.015887662768363953, 0.06382039189338684, 0.010683062486350536, 0.001978429965674877, -0.009039288386702538, -0.03310617059469223, -0.07436266541481018, 0.04164258763194084, 0.026802780106663704, -0.049532003700733185, 0.0011131061473861337, 0.07644877582788467, -0.08007688075304031, -0.014789784327149391, -0.011425419710576534, -0.0790378749370575, 0.07875645905733109, 0.04547819867730141, 0.036252763122320175, -0.028303202241659164, -0.021752556785941124, -0.0598488450050354, -0.009377116337418556, -0.042337071150541306, -0.059893567115068436, -0.008175128139555454, 0.013792877085506916, 0.0005524587468244135, 0.01171647384762764, 0.06583206355571747, -0.039970964193344116, -0.0017023860709741712, 0.09479843080043793, 0.09627734869718552, 0.014975661411881447, 0.09153036028146744, 0.0951349064707756, 0.05353022739291191, 0.07198622822761536, -0.014251277782022953, 0.039579473435878754, -0.0865292176604271, -0.1312372237443924, -0.055230531841516495, 0.007140712346881628, -0.05751039460301399, -0.00461479602381587, 0.020029380917549133, 0.0018396350787952542, -0.012809669598937035, -0.03146161884069443, 0.001410200959071517, -0.05104239284992218, -0.08634021133184433, -0.08948709070682526, 0.020733525976538658, -0.04186077415943146, 0.009996458888053894, 0.025832634419202805, -2.802570270432625e-05, 0.057044047862291336, -0.07675537467002869, -0.06188788264989853, -0.06069188192486763, -0.0499991849064827, 0.0064130206592381, 0.03189670667052269, -0.018777741119265556, -0.02188054472208023, -0.013724112883210182, -0.03522327542304993, 0.0143441678956151, 0.04492480680346489, 0.06421760469675064, -0.03812771663069725, 0.06219525635242462, -0.11007939279079437, 0.006744171492755413, -0.020895395427942276, -0.018542513251304626, -0.0911826640367508, 0.06854386627674103, 0.02541199140250683, -0.010014938190579414, 0.0019618384540081024, 0.06148911640048027, 0.05570310726761818, 0.06953009217977524, 0.09612061828374863, 0.05526503548026085, 0.020159823819994926, -6.89251464791596e-08, -0.01754424162209034, 0.005659866612404585, 0.044748786836862564, 0.011855097487568855, 0.08304685354232788, -0.06891405582427979, -0.03803730383515358, -0.041335996240377426, -0.019511712715029716, -0.041826825588941574, 0.043363042175769806, -0.06873346865177155, -0.057601939886808395, -0.052064746618270874, 0.009365368634462357, 0.02991882525384426, 0.0028783497400581837, 0.06927303224802017, -0.07678084075450897, -0.061775531619787216, 0.12580756843090057, -0.01365730632096529, -0.045468010008335114, -0.007514332886785269, -0.0655277669429779, -0.021142354235053062, -0.1020250916481018, -0.07561063021421432, -0.038674697279930115, 0.042520299553871155, -0.01888125389814377, 0.03877875581383705, 0.04893946647644043, -0.08600359410047531, -0.010835100896656513, -0.030411001294851303, -0.01020092237740755, 0.0089175496250391, -0.035704415291547775, 0.08041543513536453, 0.10826575756072998, -0.11025258898735046, -0.05640929937362671, -0.0200139619410038, 0.10048624873161316, 0.004679952282458544, -0.02500208467245102, -0.06117099151015282, -0.0647808387875557, 0.11129990965127945, -0.04532906785607338, 0.0014264483470469713, 0.05504032224416733, 0.0264983382076025, 0.009917743504047394, 0.04270842298865318, -0.02924884669482708, -0.08578937500715256, -0.0305483341217041, 0.003597970586270094, 0.01745409145951271, 0.04631901532411575, 0.023301050066947937, -0.006079487968236208]",
         "0.195"
        ],
        [
         "41",
         "317",
         "Famine à Gaza: Israël annonce autoriser le largage de l’aide par parachutage",
         "Israël va autoriser à partir de ce vendredi 25 juillet les pays étrangers à larguer de l'aidehumanitaire dans la bande de Gaza, rapporte la radio de l'armée israélienne en citant un responsable militaire. « Une mascarade », voilà ce que dénonce l’ONG Première Urgence Internationale, dont les équipes déployées à Gaza n’ont pas été prévenues par les autorités israéliennes de la reprise des parachutages. Le chef de l'ONU fustige le manque d'« humanité » et de « compassion » pour les Palestiniens de Gaza.",
         "Israël va autoriser à partir de ce vendredi 25 juillet les pays étrangers à larguer de l'aidehumanitaire dans la bande de Gaza, rapporte la radio de l'armée israélienne en citant un responsable militaire. « Une mascarade », voilà ce que dénonce l’ONG Première Urgence Internationale, dont les équipes déployées à Gaza n’ont pas été prévenues par les autorités israéliennes de la reprise des parachutages. Le chef de l'ONU fustige le manque d'« humanité » et de « compassion » pour les Palestiniens de Gaza.\n\nLes Palestiniens attendent de recevoir de la nourriture près de bâtiments résidentiels détruits lors de l'offensive israélienne, dans la ville de Gaza, le 7 juillet 2025.\n\nPublicité Lire la suite\n\nLa famine progresse à Gaza. En cause : l’aide humanitaire qui n’entre pas en quantité suffisante par la route. Israël assure que ce sont les agences de l’ONU qui ne parviennent pas à assurer la distribution. C’est dans ce contexte qu’Israël s'apprêterait à autoriser à nouveau un moyen de distribution controversé, le largage de l’aide par parachutage. La Jordanie et les Émirats arabes unis pourraient reprendre les distributions par les airs.\n\nL’an dernier, les armées américaine, jordanienne, égyptienne et française, notamment, avaient délivré des dizaines de milliers de vivres par ce moyen : des palettes surmontées d’un parachute larguées par avion, explique notre envoyée spéciale à Jérusalem, Aabla Jounaïdi.\n\nIl s'agit d'une méthode très controversée, puisque selon les humanitaires, l’aide pourrait parfaitement être acheminée par la route si l’armée israélienne le permettait. C’est aussi une solution onéreuse qui ne répond que très partiellement aux besoins des Gazaouis. Et ses distributions d'aide avaient fait beaucoup de bruit l’an dernier également, puisque cinq Palestiniens avaient été tués lors d’une de ces opérations.\n\nDes premiers largages dans les prochains jours\n\nDébut mars, Israël a imposé sur la bande de Gaza un blocus total, très partiellement assoupli fin mai, entraînant de graves pénuries de nourriture, de médicaments et de carburant, et suscitant des critiques croissantes sur l'aggravation de la faim auprès de la communauté internationale.\n\nÀ lire aussiPlus de 100 organisations humanitaires alertent sur la «famine de masse» à Gaza\n\nSelon des responsables israéliens, la Jordanie devrait effectuer le premier largage, peut-être dès ce vendredi. Les Émirats arabes unis, ainsi que d'autres États, pourront prendre le relai dans les prochains jours. Ces distributions d'aide se feront en coordination avec l’armée israélienne, qui a confirmé la reprise de ces parachutages à l’Agence France presse, mais sans la participation de l’ONU ni des organisations humanitaires traditionnelles, tenues à l’écart de la distribution d’aide depuis deux mois.\n\n« Une mascarade de plus »\n\nUne mascarade, voilà ce que dénonce l’ONG Première Urgence Internationale. Ses équipes déployées à Gaza n’ont pas été prévenues par les autorités israéliennes de la reprise des parachutages. « Un largage aérien. Ce n'est pas un avion qui va se poser sur un aéroport dans lequel on va pouvoir aller ensuite récupérer la cargaison. Ce sont vraiment des avions qui vont lâcher un peu n'importe où des colis et qui vont les colis vont arriver écrasés par terre s'ils ne s'écrasent pas sur des gens », explique Elsa Softic, adjonte au directeur des opérations de Première Urgence Internationale.\n\nIl y a des milliers de camions qui sont au point d'entrée de Gaza et qui peuvent rentrer dans Gaza par les voies normales. On ne comprend pas, en fait, cette mascarade de plus, et on la dénonce évidemment. 01:18 Elsa Softic, ajointe au directeur des opérations de l'ONG première Urgence Internationale dénonce des largages dangereux et inefficaces Jeanne Bartoli\n\n« La crise alimentaire à Gaza a atteint des niveaux de désespoir sans précédent »\n\nLe Programme alimentaire mondial (PAM), l'agence de l'ONU s'occupant de l'aide alimentaire, a alerté vendredi sur le fait qu'environ un tiers des habitants de la bande de Gaza ne mangent pas pendant des jours et que la malnutrition est en forte augmentation. « La crise alimentaire à Gaza a atteint des niveaux de désespoir sans précédent. Près d'une personne sur trois ne mange pas depuis plusieurs jours. La malnutrition est en forte augmentation, avec 90 000 femmes et enfants ayant besoin d'un traitement urgent », a indiqué le PAM dans un communiqué à l'AFP. Selon l'organisme, 470 000 personnes devraient être confrontées à « une famine catastrophique » entre mai et septembre dans le territoire palestinien assiégé par Israël.\n\nLe chef de l'ONU fustige le manque d'«humanité» et de «compassion» pour les Palestiniens de Gaza\n\nLe secrétaire général de l'ONU Antonio Guterres a fustigé vendredi le manque d'« humanité » et de « compassion » pour les Palestiniens de la bande de Gaza, qui traverse non seulement une crise humanitaire, mais aussi « une crise morale qui défie la conscience mondiale ».\n\nDepuis le début, j'ai condamné de façon répétée les horribles attaques du Hamas du 7-Octobre. Mais rien ne peut justifier l'explosion de morts et de destruction que nous avons vue depuis. L'ampleur et la portée sont au-delà de tout ce que nous avons vu dans l'Histoire récente. 00:29 Antonio Guterres, secrétaire général de l'ONU\n\n« Je ne peux pas expliquer le niveau d'indifférence et d'inaction que nous constatons chez trop de personnes dans la communauté internationale. Le manque de compassion. Le manque de vérité. Le manque d'humanité », a déclaré Antonio Guterres lors d'une intervention par vidéo lors de l'assemblée d'Amnesty International.\n\n« Les enfants disent vouloir aller au paradis, parce qu'au moins, disent-ils, il y a à manger là-bas », a ajouté le secrétaire général. « Ce n'est pas seulement une crise humanitaire. C'est une crise morale qui défie la conscience mondiale. Nous continuerons à nous exprimer à chaque occasion. Mais les mots ne nourrissent pas les enfants qui ont faim. »\n\n« Nos employés héroïques continuent de faire leur travail dans des conditions inimaginables. Beaucoup d'entre eux sont tellement anesthésiés et épuisés qu'ils disent qu'ils ne se sentent ni morts ni vivants », a-t-il également décrit. « Nous avons des appels vidéo avec nos propres humanitaires qui meurent de faim sous nos yeux ». Il a également dénoncé la mort de « plus de 1 000 Palestiniens tués en tentant de chercher à manger » depuis le 27 mai, lorsque la Fondation humanitaire de Gaza (GHF), avec laquelle l'ONU refuse de travailler, a commencé à fonctionner.\n\nL'ONU avait accusé mardi dernier l’armée israélienne d’avoir tué plus de 1 000 personnes tentant d’obtenir de l’aide humanitaire à Gaza. Depuis plusieurs mois, c'est la Fondation Humanitaire de Gaza (GHF), une organisation dont le financement reste opaque, soutenue par Israël et les États-Unis, qui s'occupe de la distribution de l'aide dans l'enclave. Une organisation qui a été vivement critiquée par les organisations internationales comme l’ONU et accusée de « militariser l’aide humanitaire au profit d’Israël ». Des 400 anciens points de distribution, il n'en reste que 4... Et, alors que les Gazaouis souffrent de malnutrition, leurs tentatives de se procurer de la nourriture finissent souvent en bain de sang... Jack Latour est directrice des activités des infirmières canadiennes de Médecins sans frontières et se trouve dans la bande de Gaza depuis maintenant six semaines. Elle témoigne au micro de RFI.\n\n[Les distributions de la GHF] sont incroyablement dangereuses. Ça ne respecte aucunement les principes de distribution d'aide alimentaire. 00:59 Jack Latour, directrice des activités des infirmières canadiennes de Médecins sans frontières RFI\n\nÀ lire aussiGaza: «71 000 enfants risquent de mourir de malnutrition aiguë», alerte l’Unicef\n\nL'USAID n'a trouvé aucune preuve du vol d'aide humanitaire à Gaza par le Hamas C’est une accusation qu’Israël adresse depuis des années, et encore plus depuis le début de la dernière guerre à Gaza. C'est ainsi que le pays justifie le fait que la distribution d'aide doit être gérée par une entité soutenue par Israël et les États-Unis, à savoir la Gaza Humanitarian Foundation (GHF). Mais un rapport venu de l’USAID, l'Agence des États-Unis pour le développement international, vient de remettre en question pour la première fois cette version, rapporte notre envoyée spéciale à Jérusalem, Aabla Jounaïdi. Sur 156 incidents au cours desquels des fournitures humanitaires financées par Washington ont été déclarées volées ou perdues, au moins 44 sont attribuables « directement ou indirectement » aux actions militaires israéliennes. Des groupes armés sont bien impliqués, au moins dans 35 des cas. Le reste des incidents sont attribuables à des sous-traitants de l’armée israélienne corrompus ou des personnes non identifiées. Selon l’agence publique, aucun incident n’est lié directement à une organisation désignée terroriste par les États-Unis. C’est pourtant sous couvert de priver le Hamas de revenus qu’Israël et les États-Unis ont instauré la GHF, dont l’activité a déjà été émaillée de plus de 1 000 morts, selon l’ONU. L'absence de signalement de détournements massifs par le Hamas « ne signifie pas qu'il n'y a pas eu de détournement » pour autant, indique une source à Reuters, mais l'agence ne dispose pas pour le moment de preuves pouvant l'affirmer. Un porte-parole du Département d'État qui abrite désormais l’USAID, a contesté ces conclusions et a accusé les organisations humanitaires traditionnelles de dissimuler la « corruption de l'aide ».\n\nNewsletterRecevez toute l'actualité internationale directement dans votre boite mail Je m'abonne",
         "2025-07-25T18:48:52",
         "https://www.rfi.fr/fr/rss",
         "https://www.rfi.fr/fr/moyen-orient/20250725-famine-%C3%A0-gaza-isra%C3%ABl-annonce-autoriser-le-largage-de-l-aide-par-parachutage",
         "2025-07-26T05:53:43.660823",
         "Israël va autoriser à partir de ce vendredi 25 juillet les pays étrangers à larguer de l'aidehumanitaire dans la bande de Gaza, rapporte la radio de l'armée israélienne en citant un responsable militaire. « Une mascarade », voilà ce que dénonce l’ONG Première Urgence Internationale, dont les équipes déployées à Gaza n’ont pas été prévenues par les autorités israéliennes de la reprise des parachutages. Le chef de l'ONU fustige le manque d'« humanité » et de « compassion » pour les Palestiniens de Gaza. Les Palestiniens attendent de recevoir de la nourriture près de bâtiments résidentiels détruits lors de l'offensive israélienne, dans la ville de Gaza, le 7 juillet 2025. Publicité Lire la suite La famine progresse à Gaza. En cause : l’aide humanitaire qui n’entre pas en quantité suffisante par la route. Israël assure que ce sont les agences de l’ONU qui ne parviennent pas à assurer la distribution. C’est dans ce contexte qu’Israël s'apprêterait à autoriser à nouveau un moyen de distribution controversé, le largage de l’aide par parachutage. La Jordanie et les Émirats arabes unis pourraient reprendre les distributions par les airs. L’an dernier, les armées américaine, jordanienne, égyptienne et française, notamment, avaient délivré des dizaines de milliers de vivres par ce moyen : des palettes surmontées d’un parachute larguées par avion, explique notre envoyée spéciale à Jérusalem, Aabla Jounaïdi. Il s'agit d'une méthode très controversée, puisque selon les humanitaires, l’aide pourrait parfaitement être acheminée par la route si l’armée israélienne le permettait. C’est aussi une solution onéreuse qui ne répond que très partiellement aux besoins des Gazaouis. Et ses distributions d'aide avaient fait beaucoup de bruit l’an dernier également, puisque cinq Palestiniens avaient été tués lors d’une de ces opérations. Des premiers largages dans les prochains jours Début mars, Israël a imposé sur la bande de Gaza un blocus total, très partiellement assoupli fin mai, entraînant de graves pénuries de nourriture, de médicaments et de carburant, et suscitant des critiques croissantes sur l'aggravation de la faim auprès de la communauté internationale. À lire aussiPlus de 100 organisations humanitaires alertent sur la «famine de masse» à Gaza Selon des responsables israéliens, la Jordanie devrait effectuer le premier largage, peut-être dès ce vendredi. Les Émirats arabes unis, ainsi que d'autres États, pourront prendre le relai dans les prochains jours. Ces distributions d'aide se feront en coordination avec l’armée israélienne, qui a confirmé la reprise de ces parachutages à l’Agence France presse, mais sans la participation de l’ONU ni des organisations humanitaires traditionnelles, tenues à l’écart de la distribution d’aide depuis deux mois. « Une mascarade de plus » Une mascarade, voilà ce que dénonce l’ONG Première Urgence Internationale. Ses équipes déployées à Gaza n’ont pas été prévenues par les autorités israéliennes de la reprise des parachutages. « Un largage aérien. Ce n'est pas un avion qui va se poser sur un aéroport dans lequel on va pouvoir aller ensuite récupérer la cargaison. Ce sont vraiment des avions qui vont lâcher un peu n'importe où des colis et qui vont les colis vont arriver écrasés par terre s'ils ne s'écrasent pas sur des gens », explique Elsa Softic, adjonte au directeur des opérations de Première Urgence Internationale. Il y a des milliers de camions qui sont au point d'entrée de Gaza et qui peuvent rentrer dans Gaza par les voies normales. On ne comprend pas, en fait, cette mascarade de plus, et on la dénonce évidemment. 01:18 Elsa Softic, ajointe au directeur des opérations de l'ONG première Urgence Internationale dénonce des largages dangereux et inefficaces Jeanne Bartoli « La crise alimentaire à Gaza a atteint des niveaux de désespoir sans précédent » Le Programme alimentaire mondial (PAM), l'agence de l'ONU s'occupant de l'aide alimentaire, a alerté vendredi sur le fait qu'environ un tiers des habitants de la bande de Gaza ne mangent pas pendant des jours et que la malnutrition est en forte augmentation. « La crise alimentaire à Gaza a atteint des niveaux de désespoir sans précédent. Près d'une personne sur trois ne mange pas depuis plusieurs jours. La malnutrition est en forte augmentation, avec 90 000 femmes et enfants ayant besoin d'un traitement urgent », a indiqué le PAM dans un communiqué à l'AFP. Selon l'organisme, 470 000 personnes devraient être confrontées à « une famine catastrophique » entre mai et septembre dans le territoire palestinien assiégé par Israël. Le chef de l'ONU fustige le manque d'«humanité» et de «compassion» pour les Palestiniens de Gaza Le secrétaire général de l'ONU Antonio Guterres a fustigé vendredi le manque d'« humanité » et de « compassion » pour les Palestiniens de la bande de Gaza, qui traverse non seulement une crise humanitaire, mais aussi « une crise morale qui défie la conscience mondiale ». Depuis le début, j'ai condamné de façon répétée les horribles attaques du Hamas du 7-Octobre. Mais rien ne peut justifier l'explosion de morts et de destruction que nous avons vue depuis. L'ampleur et la portée sont au-delà de tout ce que nous avons vu dans l'Histoire récente. 00:29 Antonio Guterres, secrétaire général de l'ONU « Je ne peux pas expliquer le niveau d'indifférence et d'inaction que nous constatons chez trop de personnes dans la communauté internationale. Le manque de compassion. Le manque de vérité. Le manque d'humanité », a déclaré Antonio Guterres lors d'une intervention par vidéo lors de l'assemblée d'Amnesty International. « Les enfants disent vouloir aller au paradis, parce qu'au moins, disent-ils, il y a à manger là-bas », a ajouté le secrétaire général. « Ce n'est pas seulement une crise humanitaire. C'est une crise morale qui défie la conscience mondiale. Nous continuerons à nous exprimer à chaque occasion. Mais les mots ne nourrissent pas les enfants qui ont faim. » « Nos employés héroïques continuent de faire leur travail dans des conditions inimaginables. Beaucoup d'entre eux sont tellement anesthésiés et épuisés qu'ils disent qu'ils ne se sentent ni morts ni vivants », a-t-il également décrit. « Nous avons des appels vidéo avec nos propres humanitaires qui meurent de faim sous nos yeux ». Il a également dénoncé la mort de « plus de 1 000 Palestiniens tués en tentant de chercher à manger » depuis le 27 mai, lorsque la Fondation humanitaire de Gaza (GHF), avec laquelle l'ONU refuse de travailler, a commencé à fonctionner. L'ONU avait accusé mardi dernier l’armée israélienne d’avoir tué plus de 1 000 personnes tentant d’obtenir de l’aide humanitaire à Gaza. Depuis plusieurs mois, c'est la Fondation Humanitaire de Gaza (GHF), une organisation dont le financement reste opaque, soutenue par Israël et les États-Unis, qui s'occupe de la distribution de l'aide dans l'enclave. Une organisation qui a été vivement critiquée par les organisations internationales comme l’ONU et accusée de « militariser l’aide humanitaire au profit d’Israël ». Des 400 anciens points de distribution, il n'en reste que 4... Et, alors que les Gazaouis souffrent de malnutrition, leurs tentatives de se procurer de la nourriture finissent souvent en bain de sang... Jack Latour est directrice des activités des infirmières canadiennes de Médecins sans frontières et se trouve dans la bande de Gaza depuis maintenant six semaines. Elle témoigne au micro de RFI. [Les distributions de la GHF] sont incroyablement dangereuses. Ça ne respecte aucunement les principes de distribution d'aide alimentaire. 00:59 Jack Latour, directrice des activités des infirmières canadiennes de Médecins sans frontières RFI À lire aussiGaza: «71 000 enfants risquent de mourir de malnutrition aiguë», alerte l’Unicef L'USAID n'a trouvé aucune preuve du vol d'aide humanitaire à Gaza par le Hamas C’est une accusation qu’Israël adresse depuis des années, et encore plus depuis le début de la dernière guerre à Gaza. C'est ainsi que le pays justifie le fait que la distribution d'aide doit être gérée par une entité soutenue par Israël et les États-Unis, à savoir la Gaza Humanitarian Foundation (GHF). Mais un rapport venu de l’USAID, l'Agence des États-Unis pour le développement international, vient de remettre en question pour la première fois cette version, rapporte notre envoyée spéciale à Jérusalem, Aabla Jounaïdi. Sur 156 incidents au cours desquels des fournitures humanitaires financées par Washington ont été déclarées volées ou perdues, au moins 44 sont attribuables « directement ou indirectement » aux actions militaires israéliennes. Des groupes armés sont bien impliqués, au moins dans 35 des cas. Le reste des incidents sont attribuables à des sous-traitants de l’armée israélienne corrompus ou des personnes non identifiées. Selon l’agence publique, aucun incident n’est lié directement à une organisation désignée terroriste par les États-Unis. C’est pourtant sous couvert de priver le Hamas de revenus qu’Israël et les États-Unis ont instauré la GHF, dont l’activité a déjà été émaillée de plus de 1 000 morts, selon l’ONU. L'absence de signalement de détournements massifs par le Hamas « ne signifie pas qu'il n'y a pas eu de détournement » pour autant, indique une source à Reuters, mais l'agence ne dispose pas pour le moment de preuves pouvant l'affirmer. Un porte-parole du Département d'État qui abrite désormais l’USAID, a contesté ces conclusions et a accusé les organisations humanitaires traditionnelles de dissimuler la « corruption de l'aide ». NewsletterRecevez toute l'actualité internationale directement dans votre boite mail Je m'abonne",
         "fr",
         "{'LOC': ['Aabla Jounaïdi', 'GHF', 'Gaza', 'Gazaouis', 'Israël', 'Jordanie', 'Jérusalem', 'Reuters', 'Émirats arabes unis', 'États', 'États-Unis'], 'ORG': ['AFP', 'Agence France', 'Agence des États-Unis', 'Amnesty International', \"Département d'État\", 'Fondation Humanitaire de Gaza', 'Fondation humanitaire de Gaza', 'GHF', 'Gaza Humanitarian', 'Hamas', \"L'ONU\", 'Médecins sans frontières', 'ONU', 'PAM', 'Première Urgence Internationale', 'Programme alimentaire mondial', 'RFI', 'USAID', \"Unicef L'USAID\", 'Urgence Internationale', \"l'ONU\", 'l’ONU'], 'MISC': ['Histoire', \"Je m'abonne\", 'NewsletterRecevez', 'Palestiniens', 'Ça'], 'PER': ['Antonio Guterres', 'Elsa Softic', 'Jack Latour', 'Jeanne Bartoli', 'Washington']}",
         "[-0.027907758951187134, 0.14811906218528748, -0.010130738839507103, -0.029907425865530968, -0.05419756472110748, 0.020396623760461807, 0.09737224876880646, -0.023231586441397667, -0.03186582773923874, 0.11384812742471695, 0.02868686057627201, -0.08154026418924332, -0.008997970260679722, 0.015469908714294434, -0.01705619879066944, -0.08711492270231247, -0.11585848033428192, -0.0793573185801506, -0.07101134210824966, 0.030793322250247, 0.048517338931560516, -0.020103944465517998, 0.015807071700692177, 0.052946798503398895, -0.04069630801677704, 0.006397049408406019, -0.02765648625791073, 0.001967419870197773, 0.020894601941108704, 0.009859313257038593, 0.01362970843911171, 0.013504637405276299, 0.0013322816230356693, -0.05083652213215828, 0.05375326797366142, 0.03299050033092499, 0.01353730633854866, -0.028916649520397186, -0.05594894289970398, -0.011890214867889881, 0.04149707779288292, 0.015477469190955162, -0.1135043352842331, -0.08198624104261398, -0.062157683074474335, 0.002000924665480852, 0.04992736503481865, -0.015602084808051586, -0.08893553912639618, -0.04440935328602791, -0.035371989011764526, -0.06617891043424606, 0.11682529747486115, -0.07202860713005066, -0.049612510949373245, -0.13899296522140503, -0.010033312253654003, -0.05275215953588486, 0.019284486770629883, -0.05764143168926239, -0.02928553707897663, -0.004924018867313862, -0.006888523697853088, -0.03575744107365608, -0.007859046570956707, -0.0672684982419014, 0.09478718042373657, -0.02993009053170681, -0.041994187980890274, -0.01576448790729046, 0.055655788630247116, -0.01978088729083538, -0.03149091452360153, -0.03400410711765289, -0.004327927250415087, -0.045000653713941574, 0.019035514444112778, -0.04520876333117485, -0.03824756667017937, -0.11606258153915405, 0.13545650243759155, -0.061661943793296814, 0.0749504342675209, 0.04108442738652229, 0.0188928060233593, -0.008236297406256199, -0.04021163284778595, 0.00649360753595829, 0.1390215903520584, -0.019335664808750153, 0.002136466559022665, 0.021394969895482063, 0.015166482888162136, -0.030518097802996635, 0.042747899889945984, -0.0052144951187074184, 0.01935640722513199, -0.02237941324710846, 0.03713694587349892, 0.07561030238866806, 0.011908942833542824, -0.059521693736314774, -0.08416679501533508, 0.09536027163267136, 0.050052303820848465, -0.03206020966172218, -0.03481888771057129, -0.0037790893111377954, -0.03940090164542198, 0.028812022879719734, -0.09558120369911194, 0.028979076072573662, -0.011227003298699856, -0.002205411670729518, -0.018449438735842705, -0.027743268758058548, 0.03257467597723007, -0.08058495819568634, 0.03838058188557625, -0.06481897830963135, 0.04682549461722374, -0.03950090706348419, 0.014940868131816387, 0.0015812956262379885, 0.08848952502012253, 0.006299688946455717, -0.03538501262664795, 8.03823240901435e-33, 0.03966008499264717, 0.010896199382841587, 0.026928041130304337, -0.027156192809343338, 0.007116803899407387, -0.032925888895988464, -0.04733554273843765, 0.01449540350586176, 0.03096686117351055, -0.06562315672636032, -0.051166657358407974, -0.09659301489591599, 0.019286222755908966, 0.08446905761957169, -0.01188898365944624, 0.007974609732627869, 0.020373789593577385, -0.043966181576251984, 0.03405744209885597, -0.014404085464775562, -0.030044233426451683, -0.043307531625032425, 0.03237103298306465, 0.10443577915430069, 0.08412571251392365, 0.008910170756280422, 0.035164669156074524, 0.037277281284332275, -0.07479686290025711, -0.0035914811305701733, 0.05896385759115219, 0.0408727303147316, 0.042106837034225464, 0.012186604551970959, 0.031204454600811005, -0.006584998220205307, -0.053526513278484344, 0.09840739518404007, -0.0849444642663002, 0.02406596951186657, 0.09732765704393387, 0.0271561611443758, 0.054416920989751816, -0.021808050572872162, 0.059674736112356186, 0.02508070133626461, 0.006755114533007145, 0.00897158868610859, 0.028189312666654587, 0.02753373794257641, 0.0214071124792099, 0.12733712792396545, -0.05708220228552818, -0.0658704861998558, 0.033938754349946976, 0.00738740898668766, -0.011771372519433498, 0.04192361608147621, -0.09211590141057968, -0.05053597688674927, 0.037902992218732834, -0.028742313385009766, -0.003911541774868965, 0.05534587800502777, 0.07295829802751541, 0.005246036686003208, 0.0445098951458931, 0.04502327740192413, 0.04726574197411537, 0.024127185344696045, -0.05671003460884094, -0.022121118381619453, 0.08688005059957504, 0.014115415513515472, 0.01579536870121956, 0.07165788114070892, -0.040589191019535065, -0.05092838034033775, -0.007427532691508532, -0.009927118197083473, 0.02173033356666565, -0.1044226586818695, 0.00423709861934185, -0.01890144683420658, -0.040338773280382156, -0.058610618114471436, 0.06718465685844421, -0.04650343582034111, 0.019629623740911484, -0.06645002961158752, 0.03598693758249283, 0.02486998774111271, 0.017289573326706886, -0.020936844870448112, -0.07923005521297455, -1.1559469083256698e-32, -0.009319967590272427, 0.08180786669254303, -0.04418179765343666, 0.012911615893244743, -0.019403114914894104, 0.012325067073106766, 0.040696244686841965, -0.002579642925411463, 0.0252054613083601, 0.020232265815138817, -0.060984138399362564, -0.027507413178682327, 0.06564713269472122, 0.008722905069589615, -0.02838539332151413, 0.09633206576108932, 0.0004931647563353181, -0.029514336958527565, 0.012390270829200745, -0.04820951446890831, -0.0727977380156517, 0.011639050208032131, 0.04207034781575203, -0.05037513002753258, 0.002226196462288499, -0.007961305789649487, 0.07676414400339127, 0.07149903476238251, -0.042552776634693146, -0.08595000207424164, -0.012528524734079838, -0.015955602750182152, 0.026570968329906464, -0.0166078582406044, 1.446084843337303e-05, 0.029622824862599373, 0.0022917347960174084, 0.0237016212195158, -0.0307356845587492, 0.01090923696756363, -0.014223232865333557, 0.03187692165374756, -0.00469917943701148, 0.021258683875203133, -0.02192789688706398, -0.017803383991122246, -0.0483374297618866, -0.08286638557910919, -0.06595388799905777, -0.11059702932834625, 0.04458290711045265, 0.01631343364715576, 0.025212252512574196, -0.014191951602697372, 0.048291344195604324, -0.031392037868499756, -0.028430208563804626, 0.020258525386452675, -0.04221531003713608, -0.011625450104475021, 0.03712920844554901, 0.030381154268980026, -0.017964323982596397, 0.0626566931605339, 0.029834970831871033, -0.13166630268096924, -0.009274440817534924, -0.08045227080583572, 0.029309645295143127, 0.10029692947864532, 0.032628338783979416, 0.014123260974884033, 0.004531452432274818, -0.024990113452076912, -0.03368698060512543, 0.006937006488442421, -0.03212255239486694, 0.029589101672172546, 0.008480049669742584, 0.006577145308256149, -0.06646499037742615, -0.041868194937705994, -0.0382416732609272, -0.004465784411877394, -0.018045756965875626, 0.03324133902788162, 0.0392489992082119, 0.07402539253234863, -0.029445316642522812, 0.009313764050602913, -0.01596921868622303, -0.0603405125439167, 0.015089835971593857, 0.006409176159650087, 0.052499931305646896, -7.035532689769752e-08, 0.09860911220312119, -0.047130484133958817, -0.14608854055404663, 0.00662561459466815, 0.0641748458147049, -0.06823360174894333, -0.04424088075757027, -0.01629515178501606, -0.011340483091771603, 0.09650599956512451, -0.03721725195646286, 0.08098835498094559, -0.0020106974989175797, 0.07035470008850098, -0.06859010457992554, -0.02850296162068844, -0.004478792194277048, -0.047424472868442535, -0.10134121030569077, -0.08071634918451309, 0.0017060672398656607, 0.008252914063632488, -0.15499716997146606, -0.08374285697937012, 0.008303862996399403, -0.06593122333288193, -0.050164323300123215, -0.022558651864528656, -0.02862253226339817, -0.008485651575028896, -0.07490606606006622, 0.007728846278041601, -0.008449682965874672, -0.12145858258008957, -0.01617884449660778, 0.029615985229611397, 0.009383372962474823, -0.0597628615796566, -0.009038716554641724, 0.022997243329882622, 0.1189514547586441, 0.031952112913131714, -0.010900700464844704, -0.01276503223925829, 0.03849818557500839, -0.10498153418302536, -0.05440640076994896, 0.0034642633982002735, -0.01050746813416481, 0.017256462946534157, 0.03246457874774933, 0.03222133591771126, -0.0298830084502697, 0.03428482264280319, 0.044347330927848816, -0.05008171498775482, -0.03488980233669281, 0.023487986996769905, 0.028025012463331223, 0.07695649564266205, 0.09611890465021133, -0.015107479877769947, -0.04347415268421173, -0.0629281997680664]",
         "0.192"
        ],
        [
         "42",
         "581",
         "Things I Wish I Had Known Before Starting ML",
         "Part 1: Data, Sales Pitches, Bugs, and Breakthroughs The post Things I Wish I Had Known Before Starting ML appeared first on Towards Data Science .",
         "Ahh, the sea.\n\nvacation on the Mediterranean Sea, I found myself lying on the beach, staring into the waves. Lady Luck was having a good day: the sun glared down from a blue and cloudless sky, heating the sand and salty sea around me. For the first time in a while, I had downtime. There was nothing related to ML in the remote region where I was, where the rough roads would have scared away anybody who is used to the even pavements of western countries.\n\nThen, away from work and, partially, civilization, somewhere between zoning out and full-on daydreaming, my thoughts began to drift. In our day-to-day business, we are too, well, busy to spend time doing nothing. But nothing is strong word here: as my thoughts drifted, I first recalled recent events, then pondered about work, and then, eventually, arrived at machine learning.\n\nMaybe traces of my previous article—where I reflected on 6.5 years of “doing” ML—were still lingering in the back of my mind. Or maybe it was simply the complete absence of anything technical around me, where the sea was my only companion. Whatever the reason was, I mentally started rehearsing the years behind me. What had gone well? What had gone sideways? And—most importantly—what do I wish someone had told me at the beginning?\n\nThis post is a collection of those things. It’s not meant to be a list of dumb mistakes that I urge others to avoid at all costs. Instead, it’s my attempt to write down the things that would have made my journey a bit smoother (but only a bit, uncertainty is necessary to make the future just that: the future). Parts of my list overlap with my previous post, and for good reason: some lessons are worth repeating, and reading again.\n\nHere’s Part 1 of that list. Part 2 is currently buried in my sandy, sea-water stained notebook. My plan is to follow up with it in the next couple of weeks, once I have enough time to turn it into a quality article.\n\n1. Doing ML Mostly Means Preparing Data\n\nThis is a point I try not to think too much about, or it will tell me: you did not do your homework.\n\nWhen I started out, my internal monologue was something like: “I just want to do ML.” Whatever that meant; I had visions of plugging neural networks together, combining methods, and running large-scale training. While I did all of that at one point or another, I found that “doing ML” often means spending a lot of time just preparing the data so that you can eventually train a machine learning model. Model training, ironically, is often the shortest and last part of the whole process.\n\nThus, every time I finally get to the model training step, I mentally breathe a sigh of relief, because it means I’ve made it through the invisible part: preparing the data. There’s nothing “sellable” in merely preparing the data. In my experience, preparing the data is not noticeable in any way (as long as it’s done well enough).\n\nHere’s the usual pattern for it:\n\nYou have a project.\n\nYou get a real-world dataset. (If you work with a well-curated benchmark dataset, then you’re lucky!)\n\nYou want to train a model.\n\nBut first… data cleaning, fixing, merging, validating.\n\nLet me give you a personal example, one that I’ve told as a funny story (which it is now. Back then, it meant redoing a few days of machine learning work under time pressure…).\n\nI once worked on a project where I wanted to predict vegetation density (using the NDVI index) from ERA5 weather data. ERA5 is a massive gridded dataset, freely available from the European Centre for Medium-Range Weather Forecasts. I merged this dataset with NDVI satellite data from NOAA (basically, the American weather agency), carefully aligned the resolutions, and everything seemed fine—no shape mismatches, no errors were thrown.\n\nThen, I called the data preparation done and trained a Vision Transformer model on the combined dataset. A few days later, I visualized the results and… surprise! The model thought Earth was upside down. Literally—my input data was right-side up, but the target vegetation density was flipped at the equator.\n\nWhat had happened? A subtle bug in my resolution translation flipped the latitude orientation of the vegetation data. I hadn’t noticed it because I was spending a lot of time on data preparation already, and wanted to get to the “fun part” quickly.\n\nThis kind of mistake hones in an important point: real-world ML projects are data projects. Especially outside academic research, you’re not working with CIFAR or ImageNet. You’re working with messy, incomplete, partially labellel, multi-source datasets that require:\n\nCleaning\n\nAligning\n\nNormalizing\n\nDebugging\n\nVisual inspection\n\nAnd even more, that list is non-exhaustive. Then repeating all of the above.\n\nGetting the data right is the work. Everything else builds on that (sadly invisible) foundation.\n\n2. Writing Papers Is Like Preparing a Sales Pitch\n\nSome papers just read well. You might not be able to explain why, but they have a flow, a logic, a clarity that’s hard to ignore. That’s rarely by accident*. For me, it turned out that writing papers resembles crafting a very specific kind of sales pitch. You’re selling your idea, your approach, your insight to a skeptical audience.\n\nThis was a surprising realization for me.\n\nWhen I started out, I assumed most papers looked and felt the same. All of them were “scientific writing” to me. But over time, as I read more papers I began to notice the differences. It’s like that saying: to outsiders, all sheep look the same; to the shepherd, each one is distinct.\n\nFor example, compare these two papers that I came across recently:\n\nA machine learning paper in a top ML venue: https://arxiv.org/pdf/2206.06243\n\nA paper using ML, but published in a top operations management journal: https://arxiv.org/pdf/2304.11910\n\nBoth use machine learning. But they speak to different audiences, with different levels of abstraction, different narrative styles, and even different motivations. The first one assumes that technical novelty is central. The second one focuses on relevance for applications. Obviously, there also is the visual difference between the two.\n\nThe more papers you read, the more you realize: there’s not one way to write a “good” paper. There are many ways, and the way varies depending on the audience.\n\nAnd unless you’re one of those very rare brilliant minds (think Terence Tao or someone of that caliber), you’ll likely need support to write well. Especially when tailoring a paper for a specific conference or journal. In practice, that means working closely with a senior ML person who understands the field.\n\nCrafting a good paper is like preparing a sales pitch. You need to:\n\nFrame the problem the right way\n\nUnderstand your audience (i.e. target venue)\n\nEmphasize the parts that resonate most\n\nAnd polish until the message sticks\n\n3. Bug Fixing Is the Way Forward\n\nYears ago, I had that romantic idea of ML as exploring elegant models, inventing new activation functions, or crafting clever loss functions. That may be true for a small set of researchers. But for me, progress often looked like: “Why doesn’t this code run?”. Or, even more frustrating: “That code just ran a few seconds ago-why does it no longer run now?”\n\nLet’s say your project requires using Vision Transformers on environmental satellite data (i.e., the model side of Section 1 above). You have two options:\n\nImplement everything from scratch (not recommended unless you’re feeling particularly adventurous, or need to do it for course credits). Find an existing implementation and adapt it.\n\nIn 99% of the cases, option 2 is the obvious choice. But “just plug in your data” almost never works. You’ll run into:\n\nDifferent compute environments\n\nAssumptions about input shapes\n\nPreprocessing quirks (such as data normalization)\n\nHard-coded dependencies (of which I am guilty, too)\n\nQuickly, your day can become an endless series of debugging, backtracking, testing edge cases, modifying dataloaders, checking GPU memory**, and rerunning scripts. Then, slowly, things begin to work. Eventually, your model trains.\n\nBut it’s not fast. It’s bug fixing your way forward.\n\n4. I (Very Certainly) Won’t Make That Breakthrough\n\nYou’ve definitely heard of them. The Transformer paper. The GANs. Stable Diffusion. There’s a small part in my that thinks: maybe I’ll be the one to write the next transformative paper. And sure, someone has to. But statistically, it probably won’t be me. Or you, apologies. And that’s fine.\n\nThe works that cause a field to change rapidly are exceptional by definition. Those works being exceptional directly implies that most works, even good work, are barely recognized. Sometimes, I still hope that one of my projects would “blow up.” But, so far, most didn’t. Some didn’t even get published. But, hey, that’s not failure—it’s the baseline. If you expect every paper to be a home run, then you are on the fast lane to disappointment.\n\nClosing thoughts\n\nTo me, Machine learning often appears as a sleek, cutting-edge field—one where breakthroughs are just around the corner and where the “doing” means smart people make magic with GPUs and math. But in my day-to-day work, it’s rarely like that.\n\nMore often, my day-to-day work consists of:\n\nHandling messy datasets\n\nDebugging code pulled from GitHub\n\nRedrafting papers, over and over\n\nNot producing novel results, again\n\nAnd that’s okay.\n\nFootnotes\n\nThe previous article mentioned: https://towardsdatascience.com/lessons-learned-after-6-5-years-of-machine-learning/\n\n* If you are interested, my favorite paper is this one: https://arxiv.org/abs/2103.09762. I read it one year ago on a Friday afternoon.\n\n** To this day, I still get mail notifications about how clearing the GPU memory is impossible in TensorFlow. This 5-year old GitHub issue gives the details.",
         "2025-07-23T04:11:02",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/things-i-wish-i-had-known-before-starting-ml/",
         "2025-07-26T06:23:31.353113",
         "Ahh, the sea. vacation on the Mediterranean Sea, I found myself lying on the beach, staring into the waves. Lady Luck was having a good day: the sun glared down from a blue and cloudless sky, heating the sand and salty sea around me. For the first time in a while, I had downtime. There was nothing related to ML in the remote region where I was, where the rough roads would have scared away anybody who is used to the even pavements of western countries. Then, away from work and, partially, civilization, somewhere between zoning out and full-on daydreaming, my thoughts began to drift. In our day-to-day business, we are too, well, busy to spend time doing nothing. But nothing is strong word here: as my thoughts drifted, I first recalled recent events, then pondered about work, and then, eventually, arrived at machine learning. Maybe traces of my previous article—where I reflected on 6.5 years of “doing” ML—were still lingering in the back of my mind. Or maybe it was simply the complete absence of anything technical around me, where the sea was my only companion. Whatever the reason was, I mentally started rehearsing the years behind me. What had gone well? What had gone sideways? And—most importantly—what do I wish someone had told me at the beginning? This post is a collection of those things. It’s not meant to be a list of dumb mistakes that I urge others to avoid at all costs. Instead, it’s my attempt to write down the things that would have made my journey a bit smoother (but only a bit, uncertainty is necessary to make the future just that: the future). Parts of my list overlap with my previous post, and for good reason: some lessons are worth repeating, and reading again. Here’s Part 1 of that list. Part 2 is currently buried in my sandy, sea-water stained notebook. My plan is to follow up with it in the next couple of weeks, once I have enough time to turn it into a quality article. 1. Doing ML Mostly Means Preparing Data This is a point I try not to think too much about, or it will tell me: you did not do your homework. When I started out, my internal monologue was something like: “I just want to do ML.” Whatever that meant; I had visions of plugging neural networks together, combining methods, and running large-scale training. While I did all of that at one point or another, I found that “doing ML” often means spending a lot of time just preparing the data so that you can eventually train a machine learning model. Model training, ironically, is often the shortest and last part of the whole process. Thus, every time I finally get to the model training step, I mentally breathe a sigh of relief, because it means I’ve made it through the invisible part: preparing the data. There’s nothing “sellable” in merely preparing the data. In my experience, preparing the data is not noticeable in any way (as long as it’s done well enough). Here’s the usual pattern for it: You have a project. You get a real-world dataset. (If you work with a well-curated benchmark dataset, then you’re lucky!) You want to train a model. But first… data cleaning, fixing, merging, validating. Let me give you a personal example, one that I’ve told as a funny story (which it is now. Back then, it meant redoing a few days of machine learning work under time pressure…). I once worked on a project where I wanted to predict vegetation density (using the NDVI index) from ERA5 weather data. ERA5 is a massive gridded dataset, freely available from the European Centre for Medium-Range Weather Forecasts. I merged this dataset with NDVI satellite data from NOAA (basically, the American weather agency), carefully aligned the resolutions, and everything seemed fine—no shape mismatches, no errors were thrown. Then, I called the data preparation done and trained a Vision Transformer model on the combined dataset. A few days later, I visualized the results and… surprise! The model thought Earth was upside down. Literally—my input data was right-side up, but the target vegetation density was flipped at the equator. What had happened? A subtle bug in my resolution translation flipped the latitude orientation of the vegetation data. I hadn’t noticed it because I was spending a lot of time on data preparation already, and wanted to get to the “fun part” quickly. This kind of mistake hones in an important point: real-world ML projects are data projects. Especially outside academic research, you’re not working with CIFAR or ImageNet. You’re working with messy, incomplete, partially labellel, multi-source datasets that require: Cleaning Aligning Normalizing Debugging Visual inspection And even more, that list is non-exhaustive. Then repeating all of the above. Getting the data right is the work. Everything else builds on that (sadly invisible) foundation. 2. Writing Papers Is Like Preparing a Sales Pitch Some papers just read well. You might not be able to explain why, but they have a flow, a logic, a clarity that’s hard to ignore. That’s rarely by accident*. For me, it turned out that writing papers resembles crafting a very specific kind of sales pitch. You’re selling your idea, your approach, your insight to a skeptical audience. This was a surprising realization for me. When I started out, I assumed most papers looked and felt the same. All of them were “scientific writing” to me. But over time, as I read more papers I began to notice the differences. It’s like that saying: to outsiders, all sheep look the same; to the shepherd, each one is distinct. For example, compare these two papers that I came across recently: A machine learning paper in a top ML venue: https://arxiv.org/pdf/2206.06243 A paper using ML, but published in a top operations management journal: https://arxiv.org/pdf/2304.11910 Both use machine learning. But they speak to different audiences, with different levels of abstraction, different narrative styles, and even different motivations. The first one assumes that technical novelty is central. The second one focuses on relevance for applications. Obviously, there also is the visual difference between the two. The more papers you read, the more you realize: there’s not one way to write a “good” paper. There are many ways, and the way varies depending on the audience. And unless you’re one of those very rare brilliant minds (think Terence Tao or someone of that caliber), you’ll likely need support to write well. Especially when tailoring a paper for a specific conference or journal. In practice, that means working closely with a senior ML person who understands the field. Crafting a good paper is like preparing a sales pitch. You need to: Frame the problem the right way Understand your audience (i.e. target venue) Emphasize the parts that resonate most And polish until the message sticks 3. Bug Fixing Is the Way Forward Years ago, I had that romantic idea of ML as exploring elegant models, inventing new activation functions, or crafting clever loss functions. That may be true for a small set of researchers. But for me, progress often looked like: “Why doesn’t this code run?”. Or, even more frustrating: “That code just ran a few seconds ago-why does it no longer run now?” Let’s say your project requires using Vision Transformers on environmental satellite data (i.e., the model side of Section 1 above). You have two options: Implement everything from scratch (not recommended unless you’re feeling particularly adventurous, or need to do it for course credits). Find an existing implementation and adapt it. In 99% of the cases, option 2 is the obvious choice. But “just plug in your data” almost never works. You’ll run into: Different compute environments Assumptions about input shapes Preprocessing quirks (such as data normalization) Hard-coded dependencies (of which I am guilty, too) Quickly, your day can become an endless series of debugging, backtracking, testing edge cases, modifying dataloaders, checking GPU memory**, and rerunning scripts. Then, slowly, things begin to work. Eventually, your model trains. But it’s not fast. It’s bug fixing your way forward. 4. I (Very Certainly) Won’t Make That Breakthrough You’ve definitely heard of them. The Transformer paper. The GANs. Stable Diffusion. There’s a small part in my that thinks: maybe I’ll be the one to write the next transformative paper. And sure, someone has to. But statistically, it probably won’t be me. Or you, apologies. And that’s fine. The works that cause a field to change rapidly are exceptional by definition. Those works being exceptional directly implies that most works, even good work, are barely recognized. Sometimes, I still hope that one of my projects would “blow up.” But, so far, most didn’t. Some didn’t even get published. But, hey, that’s not failure—it’s the baseline. If you expect every paper to be a home run, then you are on the fast lane to disappointment. Closing thoughts To me, Machine learning often appears as a sleek, cutting-edge field—one where breakthroughs are just around the corner and where the “doing” means smart people make magic with GPUs and math. But in my day-to-day work, it’s rarely like that. More often, my day-to-day work consists of: Handling messy datasets Debugging code pulled from GitHub Redrafting papers, over and over Not producing novel results, again And that’s okay. Footnotes The previous article mentioned: https://towardsdatascience.com/lessons-learned-after-6-5-years-of-machine-learning/ * If you are interested, my favorite paper is this one: https://arxiv.org/abs/2103.09762. I read it one year ago on a Friday afternoon. ** To this day, I still get mail notifications about how clearing the GPU memory is impossible in TensorFlow. This 5-year old GitHub issue gives the details.",
         "en",
         "{'MISC': ['All of them were “scientific writing” to me', 'And sure', 'And that’', 'And unless you’re one of those very rare brilliant minds', 'Assumptions', 'Back then', 'Both', 'Bug Fixing Is the Way Forward Years ago', 'But for me', 'But over time', 'But they speak to different audiences', 'Cleaning Aligning Normalizing Debugging Visual inspection And even more', 'Closing thoughts To', 'Debugging', 'Doing ML Mostly Means Preparing Data This is', 'Emphasize the parts that resonate', 'Especially when tailoring', 'Everything else builds on that', 'Find an', 'For the first time in a while', 'Friday afternoon', 'Getting the data right is the work', 'GitHub', 'Here’s the usual pattern for it: You have a project', 'I', 'I called the data preparation done and trained', 'I first recalled', 'I found myself lying on the beach', 'I found that “doing ML” often means spending a lot of time just preparing the data so that you can eventually train', 'I had downtime', 'I had that romantic idea of ML', 'I had visions of plugging neural networks together', 'I have enough time to turn it into', 'I still get', 'I still hope that one of my projects would “blow up', 'I try not to think too much about', 'I visualized the results and… surprise!', 'If you expect every paper to be a home run', 'If you work with a well-curated benchmark dataset', 'In my experience', 'In our day-to-day business', 'It’', 'It’s like that saying: to outsiders', 'It’s not meant to be a list of dumb mistakes that I', 'Like Preparing', 'ML', 'Machine learning often appears as a sleek', 'Maybe traces of my previous article—', 'Model', 'My plan is to follow up with it in the next couple of weeks', 'Obviously', 'Parts of my list overlap with my previous post', 'Preprocessing quirks', 'Sales Pitch Some papers just read well', 'Stable Diffusion', 'TensorFlow', 'That may be true for a small set of researchers', 'That’', 'The GANs', 'The Transformer paper', 'The first one', 'The model thought Earth was upside down', 'The more papers you read', 'The works that cause', 'Then repeating all of the above', 'Then, away from work and', 'Then, slowly', 'There are many ways', 'There’', 'This kind of mistake hones in an important point', 'Those works being', 'Thus', 'To this day', 'What had gone sideways?', 'What had gone well?', 'What had happened?', 'Whatever that meant', 'Whatever the reason was', 'When I', 'While I did all of that at one point or another', 'Writing Papers Is', 'You get a real-world dataset', 'You have two options', 'You might not be able to', 'You need to: Frame the problem the right way Understand your audience', 'You want to train a model', 'You’ll run into', 'You’re selling your idea', 'You’re working with messy', 'a clarity that’s hard to ignore', 'all sheep look the same', 'and for good reason: some lessons are worth repeating', 'and rerunning', 'and running large', 'because it means I’ve made it through the invisible', 'busy to', 'by accident*. For me', 'checking GPU memory', 'combining methods', 'depending on the audience', 'each one is distinct', 'even good work', 'few days of machine learning work under time', 'field to', 'freely available from the European Centre for Medium-Range Weather Forecasts', 'heating the sand and salty sea around', 'https://towardsdatascience.com/lessons-learned-after-6-5-years-of-machine-learning/ * If you are interested', 'implementation and adapt it', 'is often the shortest and last part of the whole process', 'it', 'it probably won’t be me', 'it’', 'machine learning model', 'most didn’t. Some didn’t even get', 'my favorite', 'my thoughts began to drift', 'not recommended unless you’re feeling particularly adventurous', 'one that I’ve told as a funny story', 'paper for a specific', 'preparing the data', 'preparing the data is not noticeable in any way', 'redoing', 'rehearsing the years behind me', 'sea-water stained notebook', 'that means working closely with', 'the model side of Section 1 above', 'then you’re lucky!', 'to write well', 'using ML', 'using the NDVI index', 'vacation on the Mediterranean Sea', 'was flipped at the equator', 'we are too', 'well', 'what do I wish someone had told me at the beginning?', 'where the sea was my only', 'with different levels of abstraction', 'world ML projects are data projects', 'your insight to', 'you’ll likely need', 'you’re not working with CIFAR', '” But, so far'], 'PER': ['Here’', 'I mentally', 'I mentally breathe', 'Lady Luck was having a good day: the sun glared down from', 'More often', 'Terence Tao', 'This', 'carefully aligned the resolutions', 'elegant models', 'eventually', 'partially labellel', 'target venue', 'then pondered about work', 'then you are on the fast lane to disappointment', 'your approach'], 'ORG': ['American weather agency', 'ERA5', 'For', 'Handling', 'ImageNet', 'Instead', 'Very Certainly'], 'LOC': ['Crafting', 'Eventually', 'I', 'Literally', 'https://arxiv.org/abs/2103.09762', 'merging', 'the field', 'validating', 'your model']}",
         "[0.04180542752146721, -0.04239104688167572, 0.10090651363134384, 0.03745635226368904, 0.06955554336309433, -0.05040383338928223, 0.02198834903538227, -0.026652609929442406, 0.06819786131381989, -0.04329422861337662, -0.06332265585660934, 0.02211049571633339, -0.014349018223583698, -0.030326172709465027, -0.011663668788969517, -0.007525979075580835, -0.07087553292512894, -0.022560684010386467, -0.07121244817972183, 0.03487279266119003, -0.09729961305856705, 0.02924235723912716, -0.09142076969146729, 0.043372366577386856, -0.025517519563436508, 0.10825503617525101, 0.03433636575937271, -0.036108095198869705, -0.029219603165984154, 0.0008906121947802603, -0.010562029667198658, 0.10949364304542542, -0.018706616014242172, -0.010011008940637112, 0.07013826072216034, 0.06421560049057007, -0.03544292226433754, 0.008913527242839336, 0.022050030529499054, -0.021684197708964348, -0.020909171551465988, -0.083278588950634, 0.06321509182453156, 0.03956298157572746, -0.029105965048074722, -0.0137711176648736, 0.07699353247880936, -0.0687059536576271, -0.05007750913500786, 0.0001583784760441631, -0.11496030539274216, 0.015072949230670929, 0.0017265084898099303, -0.04510889947414398, -0.05498793348670006, 0.02882700227200985, 0.0477735698223114, 0.08011375367641449, 0.01938020810484886, -0.010293427854776382, -0.026158252730965614, -0.01369977742433548, -0.020628655329346657, -0.027860045433044434, 0.030741317197680473, 0.015968911349773407, 0.008170783519744873, 0.007378139533102512, -0.0002049193426501006, 0.02980189584195614, 0.011120647192001343, -0.035414960235357285, -0.06794349104166031, 0.016126707196235657, 0.04885241761803627, -0.00852375477552414, 0.016476904973387718, -0.11270054429769516, 0.09305522590875626, -0.048378270119428635, 0.04342348501086235, 0.07958512753248215, -0.03753681108355522, 0.03653603792190552, -0.04842352867126465, -0.057230301201343536, 0.03778427466750145, 0.06795347481966019, 0.1299753189086914, -0.015207896009087563, -0.013565612025558949, -0.1328454464673996, -0.11108454316854477, -0.011377102695405483, 0.08042189478874207, 0.03002779558300972, -0.07398094981908798, 0.08804485201835632, -0.020254911854863167, 0.0912860706448555, 0.018998851999640465, 0.06816210597753525, -0.007882604375481606, 0.0034214898478239775, 0.004565793089568615, 0.015462181530892849, -0.007526938803493977, 0.03448554500937462, -0.05893857032060623, -0.02790367417037487, -0.0871095284819603, -0.0054907347075641155, -0.08110419660806656, 0.03438630327582359, -0.015697991475462914, 0.027384649962186813, -0.01657811924815178, -0.03136809915304184, -0.0400054045021534, 0.06776740401983261, 0.026066385209560394, 0.04662737995386124, 0.026267996057868004, 0.031772464513778687, -0.034595005214214325, -0.025526035577058792, 0.0375986211001873, 1.739783618107811e-33, 0.06115260347723961, -0.05435933172702789, 0.017256565392017365, 0.07071484625339508, 0.03396868333220482, -0.020285381004214287, -0.06467806547880173, -0.016776835545897484, 0.05795290321111679, -0.005597453098744154, -0.015137511305510998, 0.0749289020895958, -0.016798965632915497, 0.025405462831258774, -0.01499754935503006, -0.01399874035269022, 0.010535180568695068, -0.06616944819688797, 0.01913071610033512, -0.0224419217556715, 0.043237339705228806, 0.020245777443051338, 0.005337161477655172, -0.11263248324394226, -0.034840382635593414, 0.00305371917784214, 0.016811467707157135, -0.008674979209899902, -0.0003896538109984249, 0.04204908385872841, -0.07114747166633606, 0.05486374720931053, -0.03176850453019142, -0.04095262289047241, -0.00577821210026741, 0.04424037039279938, -0.01573907770216465, -0.03071865811944008, 0.028077878057956696, -0.053411372005939484, -0.07155219465494156, 0.07401350885629654, 0.034300003200769424, -0.005676418077200651, -0.018654456362128258, 0.00921281985938549, 0.06454402208328247, -0.02981293760240078, -0.08537020534276962, 0.04278121143579483, -0.03022940084338188, -0.0005501832929439843, 0.018961191177368164, -0.07526830583810806, -0.06063489615917206, 0.02387593500316143, 0.04130278900265694, 0.03605097532272339, 0.0015470932703465223, 0.01677042804658413, 0.04783171787858009, 0.004204846918582916, 0.0028221493121236563, 0.02378981187939644, 0.028276219964027405, 0.07985807210206985, 0.013957653194665909, 0.039954740554094315, 0.03719848394393921, -0.05384373292326927, 0.020108023658394814, 0.022083548828959465, 0.03282883018255234, -0.020541682839393616, 0.06246037036180496, 0.022883139550685883, 0.008699029684066772, -0.066780686378479, -0.11386008560657501, -0.018860800191760063, 0.04934830591082573, 0.005375342443585396, -0.060713183134794235, -0.023762216791510582, 0.007800317835062742, 0.04109535366296768, 0.05480431392788887, -0.07144294679164886, -0.04134867712855339, 0.0050094472244381905, -0.07086779922246933, 0.041621722280979156, 0.08746337890625, -0.07273099571466446, -0.14507874846458435, -2.7188339447954857e-33, -0.04080699384212494, -0.07619140297174454, 0.03045426495373249, 0.019753947854042053, 0.003067773999646306, -0.05537265166640282, 0.02211649715900421, -0.01215827651321888, -0.0798095166683197, 0.052417512983083725, -0.019401373341679573, -0.0628884956240654, 0.048995960503816605, 0.04436482861638069, -0.04621086269617081, -0.032142411917448044, 0.017459917813539505, 0.05583091080188751, -0.053528036922216415, -0.01687587983906269, -0.020202115178108215, 0.02060975506901741, -0.02781219594180584, -0.02518174797296524, 0.02855287306010723, 0.06284428387880325, 0.04003003612160683, 0.04364572465419769, -0.06679561734199524, -0.03538624569773674, -0.03438960015773773, 0.0780649185180664, 0.004401970189064741, -0.035182561725378036, 0.011901906691491604, 0.04485630616545677, -0.029947737231850624, -0.03163527324795723, -0.04712037369608879, -0.07085756212472916, -0.05824746564030647, -0.028656698763370514, 0.05205272138118744, -0.04410190507769585, -0.07003986090421677, 0.02571573108434677, -0.026510946452617645, 0.0435718335211277, 0.045754574239254, -0.03435228392481804, 0.07138363271951675, 0.07199141383171082, -0.03801008313894272, -0.024039605632424355, 0.02617715857923031, 0.010095803998410702, -0.00647580623626709, -0.031151430681347847, -0.038537923246622086, 0.06357302516698837, -0.05581256374716759, -0.026216009631752968, -0.0534110926091671, -0.05987909808754921, 0.08043306320905685, -0.005960090551525354, 0.021432213485240936, 0.005892141256481409, -0.014766454696655273, 0.006622591521590948, 0.021619921550154686, 0.038097355514764786, -0.09870065748691559, -0.013346562162041664, 0.03002130798995495, -0.01958944834768772, -0.045190710574388504, -0.04064454883337021, -0.05192435905337334, -0.04159228503704071, -0.024014314636588097, -0.09765787422657013, -0.0017896476201713085, 0.02220938913524151, 0.01361637283116579, -0.007731182500720024, -0.04228287190198898, 0.0102991359308362, 0.002914880169555545, -0.06505919992923737, -0.06920844316482544, -0.021920952945947647, -0.1412305235862732, 0.03455158695578575, -0.04779364541172981, -5.973612360321567e-08, 0.01451852172613144, -0.030334142968058586, 0.03612888604402542, 0.10121384263038635, 0.05315687134861946, -0.03343304991722107, 0.025801919400691986, 0.07350083440542221, -0.040907856076955795, 0.035203345119953156, -0.027267655357718468, -0.12343069165945053, 0.03292228281497955, 0.03943399339914322, 0.05085868015885353, 0.039016421884298325, 0.09477093070745468, -0.03286096826195717, -0.053348831832408905, -0.05382607877254486, 0.15324507653713226, 0.017654825001955032, -0.07108629494905472, -0.003327321959659457, -0.026665233075618744, 0.01874198392033577, -0.03243950381875038, 0.11107199639081955, -0.03167414665222168, -0.023599473759531975, 0.057202648371458054, 0.022488348186016083, -0.051420051604509354, -0.061350017786026, -0.06014557182788849, -0.0726151168346405, 0.04028914123773575, 0.0036409327294677496, -0.029503140598535538, 0.03253156691789627, -0.01017200667411089, 0.02752174437046051, 0.03230828791856766, 0.06311862170696259, 0.046842943876981735, -0.012594735249876976, 0.024108560755848885, 0.011290455237030983, 0.0013268355978652835, 0.01669810712337494, 0.08480638265609741, 0.10149390250444412, 0.13674770295619965, 0.08671737462282181, 0.09097955375909805, 0.00449590478092432, 0.02388111874461174, 0.017022643238306046, -0.1239035502076149, 0.0524919256567955, 0.08579958230257034, -0.0004031393036711961, -0.16480493545532227, -0.0026994002982974052]",
         "0.221"
        ],
        [
         "43",
         "287",
         "\"La France était belle, je n'avais jamais vu ça de ma vie\", se remémore la première médaillée aux Jeux olympiques de Paris, Shirine Boukli",
         "La judokate avait ouvert le bal des 64 médailles tricolores (dont 16 titres) aux JO de Paris 2024. Un an après, elle se rappelle pour franceinfo: sport, ce moment si fort.",
         "La judokate avait ouvert le bal des 64 médailles tricolores (dont 16 titres) aux JO de Paris 2024. Un an après, elle se rappelle pour franceinfo: sport, ce moment si fort.\n\n\"Un moment unique, historique\". Fin de journée en ce samedi 27 juillet 2024. Le plublic de l'Arena Champ-de Mars explose de joie pour la première fois d'une longue série dans ces Jeux olympiques \"à la maison\". L'héroïne de l'instant se nomme Shirine Boukli, judokate française qui concourt dans la catégorie des -48 kg. Elle vient de décrocher la médaille de bronze, et la première tout court du contingent français, au bout d'une journée de compétition faite de hauts et de bas. \"J'ai ma première médaille olympique mais j’y crois pas, je ne comprends plus rien à ce qui m'arrive (rires). C'est un mélange d'émotions indescriptibles\", confiait-elle.\n\nIl y a un an jour pour jour, la cérémonie des Jeux de Paris enchantait la planète en mondovision. Shirine Boukli est revenue pour franceinfo: sport sur cette aventure olympique exceptionnelle. De l'eau a coulé sous les ponts pour la Gardoise de 26 ans, un nouveau titre européen dans la poche, elle se souvient de ce moment d'émotion intense. \"Les Jeux à domicile, ce n'est pas tous les jours et j'ai la chance de faire partie de cette génération chanceuse de l'avoir vécu et qui a marqué l'histoire\". Pour la jeune athlète, les souvenirs de cette belle journée et de celles qui ont suivi sont toujours bien présents. \"Avoir des souvenirs communs avec autant de monde, de faire partie d'une telle histoire, c'est dingue. J'espère en avoir assez profité, l'avoir vécu à fond\", sourit-elle.\n\nfranceinfo: sport : Qu'avez-vous retenu de ce samedi 27 juillet 2024, de cette médaille de bronze, la première de l'équipe de France dans les Jeux de Paris ?\n\nShirine Boukli : C’était un moment unique, historique. Les Jeux à domicile, ce n'est pas tous les jours et j'ai la chance de faire partie de cette génération chanceuse de l'avoir vécu et qui a marqué l'histoire. Je suis la première médaillée des jeux de Paris 2024. Il n’y en aura plus ici avant un moment. Et, voilà, c’est, c'est beau tout simplement.\n\nA-t-elle une saveur particulière cette médaille ?\n\nBien sûr, déjà, c'est ma première médaille olympique. Et les Jeux olympiques, c'est le Graal. J'étais partie pour gagner la plus belle, mais comme c'est une médaille à domicile, elle a une saveur différente. Elle est aussi belle, je crois.\n\nPour la première journée officielle des JO, Shirine Boukli a ouvert le compteur des médailles françaises avec une médaille de bronze remportée en judo, dans la catégorie des moins de 48 kg, à l'Arena Champ-de-Mars. (FEDERICO PESTELLINI / PANORAMIC)\n\nCette médaille de bronze représente tout mon parcours, toute mon histoire, le travail très dur que j'ai fourni pour l'obtenir. Les Jeux sont tous les quatre ans, j'ai dû me battre pour être la représentante française dans ma catégorie aussi, parce qu'il n'y a qu'une seule élue pour la compétition olympique. Le combat commence donc avant les Jeux pour accomplir un tel exploit. Elle signifie beaucoup pour moi, elle est vraiment forte en émotions.\n\nQu'est-ce que ça fait d'ouvrir le bal pour toute l'équipe de France olympique ?\n\nC'est un rôle que je connais bien (rires). Avec les Bleus du judo, aux championnats d'Europe ou du monde, en général, ma catégorie combat toujours le premier jour. Je suis habituée à ce que les autres me soutiennent en attendant leur compétition, ça me motive. Quand j'étais plus jeune en cadettes, je me souviens qu'on me disait que je devais lancer la dynamique de groupe, que j'avais aussi un rôle à jouer à ce niveau. Je dois apporter cette énergie pour mettre les autres dans le bain, leur donner envie de se dépasser.\n\nEt pour les Jeux à Paris, je me suis dit exactement la même chose, j'espère avoir servi d'exemple en ouvrant le compteur, d'avoir provoqué l'envie chez les autres sportifs français, de peut-être leur avoir donné un avant-goût de ce qu'ils pourraient vivre. Je pense que ma médaille a créé la bonne énergie pour tout le collectif équipe de France, tous sports confondus. Shirine Boukli à franceinfo: sport\n\nEn parlant avec Madeleine Malonga (-78 kg) et Romane Dicko (+ de 78 kg), elles me disaient qu'elles aiment regarder les compétitions avant de combattre, capter l'énergie. Moi, je n'ai jamais envie d'attendre, d'avoir ce stress pendant plusieurs jours. Je pense qu'on a des routines et des habitudes différentes qui nous correspondent. C'est pour moi, une motivation supplémentaire de lancer une belle dynamique pour tout le monde, d'ouvrir le bal, ça ne me met pas une pression supplémentaire. C'est cool en vrai. Je suis plus animée que stressée par ce rôle.\n\nQuel souvenir vous a-t-il particulièrement marquée lors de ces Jeux à domicile ?\n\nLe moment où je comprends que je suis médaillée, où je me bats, que l'arbitre va vérifier si mon action est valable. Là, c'est un moment extrêmement fort où je cherche dans les gradins les personnes que j'aime alors que je les ai esquivées toute la journée pour rester dans ma bulle. A partir de ce moment, je me reconnecte au reste du monde. Parce qu'avant, je ne suis pas un robot mais je suis tellement focus sur ma compétition que je ne capte pas grand-chose à ce qu'il se passe autour.\n\n(LUIS ROBAYO / AFP)\n\nMon quart de finale perdu un peu plus tôt dans la journée a aussi été un moment super fort. Avant de combattre en repêchages pour la médaille de bronze, il y a eu un break dans la compétition. J'ai pu aller voir mon entraîneur de club, Kylian Le Blouch, qui était en tribune. J'étais mal, le fait d'avoir perdu de cette manière (défaite sur ippon en quelques secondes), j'avais le sentiment de ne pas m'être exprimée. Je suis une compétitrice et si je ne faisais pas de nécessaire, je pouvais subir le repêchage et finir sans médaille. C'était ce qu'il aurait eu de pire. Le voir et discuter avec lui m'a remobilisée et permis de revenir dans ma compétition.\n\n#Paris2024 | La déception de Shirine Boukli. La Française chute en quarts de finale, battue par la Japonaise Natsumi Tsunoda.\n\n\n\nMais elle peut encore accrocher le bronze grâce au tournoi de repêchage, aujourd'hui à 16h.\n\n\n\nSuivez le direct : https://t.co/hHHwOiAOqk pic.twitter.com/vjZ4TW5t9F — francetvsport (@francetvsport) July 27, 2024\n\nEt puis la médaille par équipes. Même si on fait un sport individuel où on se bagarre seule, le collectif, c'est quelque chose, c'est une autre énergie. Toute la journée a été forte, la finale était folle, on en a tous pleuré. C'était sans doute plus fort qu'à Tokyo, trois ans avant, même si on avait battu les Japonais chez eux. Ils avaient soif de revanche, ils avaient même presque plus privilégié le par équipes que les individuels et on a gardé notre titre. C'était trop beau.\n\nComment s'est passée votre année post-olympique ? Avez-vous eu besoin de couper avec le judo ?\n\nJe pensais connaître l'après-Jeux vu que j'étais à Tokyo, mais je n'avais pas eu de médaille individuelle. J'avais donc soif de vengeance. Là, j'ai senti ce sentiment bizarre d'après-Jeux où tu as un peu moins envie. Il faut un temps d'adaptation, comme si la personne qui partage ta vie te quittait. Heureusement, j'étais bien suivie au niveau psychologique.\n\nCette année était très bizarre. Sur le plan objectif sportif, par exemple, même s'il y avait des envies, il fallait retrouver l'envie avec la passion, l'amour du sport, même si je sais que j'aime ce sport, retourner à une préparation pour un championnat, souffrir. Même si j'aime ça, ça n'a pas été simple. J'étais un peu rêveuse, pas toujours là. Mais je m'en suis rendue compte après coup. A la reprise, je ne comprenais pas pourquoi j'allais faire des séances techniques. C'était trop. J'ai eu besoin de me reconnecter à pourquoi j'aimais ce sport. Je suis donc aller m'entraîner avec des jeunes de 15-17 ans dans les poles et puis, j'ai repris le jujitsu brésilien. Je n'avais pas envie de retourner à des choses difficiles tout de suite.\n\nMa compétition de reprise a été le Grand Slam de Bercy en février, où je termine deuxième. Puis j'ai enchaîné sur les Europe, où j'ai conservé mon titre, puis une cinquième place aux Mondiaux. C'était difficile, il a fallu du temps pour réapprendre et réavancer. Je pense que la saison prochaine va être différente. Je l'espère en tout cas.\n\nLa ferveur du public français est-elle aussi exceptionnelle qu'on l'a dit ? Y pensez-vous encore souvent ?\n\nOui c'était complètement fou ! Le Palais éphémère était pourtant moins grand que Bercy où on participe au Grand Slam de Paris. Mais j'avais le sentiment d'avoir tout le monde au niveau de mes épaules. J'essayais vraiment de ne pas trop regarder autour de moi mais on sentait les énergies, limite sur le tapis. Tu sentais qu'il y avait du mouvement et des ondes qui te poussaient, justement, à donner le meilleur de toi-même.\n\nJe me souviens aussi du Club France, qui était une sacrée expérience. J'y étais le premier soir. Je ne m'attendais pas à une telle foule quand je suis arrivée sur scène, c'était fou ! Et puis, je suis allée voir d'autres épreuves à Paris, regarder les copains en compétition, tout le monde dans les rues ne parlait que des Jeux. On me reconnaissait, on venait me voir et me féliciter. C'était beau à voir, la France était belle, je n'avais jamais vu ça de ma vie. Avoir des souvenirs communs avec autant de monde, de faire partie d'une telle histoire, c'est dingue. J'espère en avoir assez profité, l'avoir vécu à fond.",
         "2025-07-26T04:30:02",
         "https://www.francetvinfo.fr/titres.rss",
         "https://www.franceinfo.fr/les-jeux-olympiques/judo/entretien-la-france-etait-belle-je-n-avais-jamais-vu-ca-de-ma-vie-se-rememore-la-premiere-medaillee-aux-jeux-olympiques-de-paris-shirine-boukli_7382995.html#xtor=RSS-3-[lestitres]",
         "2025-07-26T05:53:42.842444",
         "La judokate avait ouvert le bal des 64 médailles tricolores (dont 16 titres) aux JO de Paris 2024. Un an après, elle se rappelle pour franceinfo: sport, ce moment si fort. \"Un moment unique, historique\". Fin de journée en ce samedi 27 juillet 2024. Le plublic de l'Arena Champ-de Mars explose de joie pour la première fois d'une longue série dans ces Jeux olympiques \"à la maison\". L'héroïne de l'instant se nomme Shirine Boukli, judokate française qui concourt dans la catégorie des -48 kg. Elle vient de décrocher la médaille de bronze, et la première tout court du contingent français, au bout d'une journée de compétition faite de hauts et de bas. \"J'ai ma première médaille olympique mais j’y crois pas, je ne comprends plus rien à ce qui m'arrive (rires). C'est un mélange d'émotions indescriptibles\", confiait-elle. Il y a un an jour pour jour, la cérémonie des Jeux de Paris enchantait la planète en mondovision. Shirine Boukli est revenue pour franceinfo: sport sur cette aventure olympique exceptionnelle. De l'eau a coulé sous les ponts pour la Gardoise de 26 ans, un nouveau titre européen dans la poche, elle se souvient de ce moment d'émotion intense. \"Les Jeux à domicile, ce n'est pas tous les jours et j'ai la chance de faire partie de cette génération chanceuse de l'avoir vécu et qui a marqué l'histoire\". Pour la jeune athlète, les souvenirs de cette belle journée et de celles qui ont suivi sont toujours bien présents. \"Avoir des souvenirs communs avec autant de monde, de faire partie d'une telle histoire, c'est dingue. J'espère en avoir assez profité, l'avoir vécu à fond\", sourit-elle. franceinfo: sport : Qu'avez-vous retenu de ce samedi 27 juillet 2024, de cette médaille de bronze, la première de l'équipe de France dans les Jeux de Paris ? Shirine Boukli : C’était un moment unique, historique. Les Jeux à domicile, ce n'est pas tous les jours et j'ai la chance de faire partie de cette génération chanceuse de l'avoir vécu et qui a marqué l'histoire. Je suis la première médaillée des jeux de Paris 2024. Il n’y en aura plus ici avant un moment. Et, voilà, c’est, c'est beau tout simplement. A-t-elle une saveur particulière cette médaille ? Bien sûr, déjà, c'est ma première médaille olympique. Et les Jeux olympiques, c'est le Graal. J'étais partie pour gagner la plus belle, mais comme c'est une médaille à domicile, elle a une saveur différente. Elle est aussi belle, je crois. Pour la première journée officielle des JO, Shirine Boukli a ouvert le compteur des médailles françaises avec une médaille de bronze remportée en judo, dans la catégorie des moins de 48 kg, à l'Arena Champ-de-Mars. (FEDERICO PESTELLINI / PANORAMIC) Cette médaille de bronze représente tout mon parcours, toute mon histoire, le travail très dur que j'ai fourni pour l'obtenir. Les Jeux sont tous les quatre ans, j'ai dû me battre pour être la représentante française dans ma catégorie aussi, parce qu'il n'y a qu'une seule élue pour la compétition olympique. Le combat commence donc avant les Jeux pour accomplir un tel exploit. Elle signifie beaucoup pour moi, elle est vraiment forte en émotions. Qu'est-ce que ça fait d'ouvrir le bal pour toute l'équipe de France olympique ? C'est un rôle que je connais bien (rires). Avec les Bleus du judo, aux championnats d'Europe ou du monde, en général, ma catégorie combat toujours le premier jour. Je suis habituée à ce que les autres me soutiennent en attendant leur compétition, ça me motive. Quand j'étais plus jeune en cadettes, je me souviens qu'on me disait que je devais lancer la dynamique de groupe, que j'avais aussi un rôle à jouer à ce niveau. Je dois apporter cette énergie pour mettre les autres dans le bain, leur donner envie de se dépasser. Et pour les Jeux à Paris, je me suis dit exactement la même chose, j'espère avoir servi d'exemple en ouvrant le compteur, d'avoir provoqué l'envie chez les autres sportifs français, de peut-être leur avoir donné un avant-goût de ce qu'ils pourraient vivre. Je pense que ma médaille a créé la bonne énergie pour tout le collectif équipe de France, tous sports confondus. Shirine Boukli à franceinfo: sport En parlant avec Madeleine Malonga (-78 kg) et Romane Dicko (+ de 78 kg), elles me disaient qu'elles aiment regarder les compétitions avant de combattre, capter l'énergie. Moi, je n'ai jamais envie d'attendre, d'avoir ce stress pendant plusieurs jours. Je pense qu'on a des routines et des habitudes différentes qui nous correspondent. C'est pour moi, une motivation supplémentaire de lancer une belle dynamique pour tout le monde, d'ouvrir le bal, ça ne me met pas une pression supplémentaire. C'est cool en vrai. Je suis plus animée que stressée par ce rôle. Quel souvenir vous a-t-il particulièrement marquée lors de ces Jeux à domicile ? Le moment où je comprends que je suis médaillée, où je me bats, que l'arbitre va vérifier si mon action est valable. Là, c'est un moment extrêmement fort où je cherche dans les gradins les personnes que j'aime alors que je les ai esquivées toute la journée pour rester dans ma bulle. A partir de ce moment, je me reconnecte au reste du monde. Parce qu'avant, je ne suis pas un robot mais je suis tellement focus sur ma compétition que je ne capte pas grand-chose à ce qu'il se passe autour. (LUIS ROBAYO / AFP) Mon quart de finale perdu un peu plus tôt dans la journée a aussi été un moment super fort. Avant de combattre en repêchages pour la médaille de bronze, il y a eu un break dans la compétition. J'ai pu aller voir mon entraîneur de club, Kylian Le Blouch, qui était en tribune. J'étais mal, le fait d'avoir perdu de cette manière (défaite sur ippon en quelques secondes), j'avais le sentiment de ne pas m'être exprimée. Je suis une compétitrice et si je ne faisais pas de nécessaire, je pouvais subir le repêchage et finir sans médaille. C'était ce qu'il aurait eu de pire. Le voir et discuter avec lui m'a remobilisée et permis de revenir dans ma compétition. #Paris2024 | La déception de Shirine Boukli. La Française chute en quarts de finale, battue par la Japonaise Natsumi Tsunoda. Mais elle peut encore accrocher le bronze grâce au tournoi de repêchage, aujourd'hui à 16h. Suivez le direct : https://t.co/hHHwOiAOqk pic.twitter.com/vjZ4TW5t9F — francetvsport (@francetvsport) July 27, 2024 Et puis la médaille par équipes. Même si on fait un sport individuel où on se bagarre seule, le collectif, c'est quelque chose, c'est une autre énergie. Toute la journée a été forte, la finale était folle, on en a tous pleuré. C'était sans doute plus fort qu'à Tokyo, trois ans avant, même si on avait battu les Japonais chez eux. Ils avaient soif de revanche, ils avaient même presque plus privilégié le par équipes que les individuels et on a gardé notre titre. C'était trop beau. Comment s'est passée votre année post-olympique ? Avez-vous eu besoin de couper avec le judo ? Je pensais connaître l'après-Jeux vu que j'étais à Tokyo, mais je n'avais pas eu de médaille individuelle. J'avais donc soif de vengeance. Là, j'ai senti ce sentiment bizarre d'après-Jeux où tu as un peu moins envie. Il faut un temps d'adaptation, comme si la personne qui partage ta vie te quittait. Heureusement, j'étais bien suivie au niveau psychologique. Cette année était très bizarre. Sur le plan objectif sportif, par exemple, même s'il y avait des envies, il fallait retrouver l'envie avec la passion, l'amour du sport, même si je sais que j'aime ce sport, retourner à une préparation pour un championnat, souffrir. Même si j'aime ça, ça n'a pas été simple. J'étais un peu rêveuse, pas toujours là. Mais je m'en suis rendue compte après coup. A la reprise, je ne comprenais pas pourquoi j'allais faire des séances techniques. C'était trop. J'ai eu besoin de me reconnecter à pourquoi j'aimais ce sport. Je suis donc aller m'entraîner avec des jeunes de 15-17 ans dans les poles et puis, j'ai repris le jujitsu brésilien. Je n'avais pas envie de retourner à des choses difficiles tout de suite. Ma compétition de reprise a été le Grand Slam de Bercy en février, où je termine deuxième. Puis j'ai enchaîné sur les Europe, où j'ai conservé mon titre, puis une cinquième place aux Mondiaux. C'était difficile, il a fallu du temps pour réapprendre et réavancer. Je pense que la saison prochaine va être différente. Je l'espère en tout cas. La ferveur du public français est-elle aussi exceptionnelle qu'on l'a dit ? Y pensez-vous encore souvent ? Oui c'était complètement fou ! Le Palais éphémère était pourtant moins grand que Bercy où on participe au Grand Slam de Paris. Mais j'avais le sentiment d'avoir tout le monde au niveau de mes épaules. J'essayais vraiment de ne pas trop regarder autour de moi mais on sentait les énergies, limite sur le tapis. Tu sentais qu'il y avait du mouvement et des ondes qui te poussaient, justement, à donner le meilleur de toi-même. Je me souviens aussi du Club France, qui était une sacrée expérience. J'y étais le premier soir. Je ne m'attendais pas à une telle foule quand je suis arrivée sur scène, c'était fou ! Et puis, je suis allée voir d'autres épreuves à Paris, regarder les copains en compétition, tout le monde dans les rues ne parlait que des Jeux. On me reconnaissait, on venait me voir et me féliciter. C'était beau à voir, la France était belle, je n'avais jamais vu ça de ma vie. Avoir des souvenirs communs avec autant de monde, de faire partie d'une telle histoire, c'est dingue. J'espère en avoir assez profité, l'avoir vécu à fond.",
         "fr",
         "{'MISC': ['#Paris2024 |', 'Bleus du judo', 'Graal', 'Grand Slam', 'Grand Slam de Paris', 'JO', 'JO de Paris 2024', 'Japonaise Natsumi Tsunoda', 'Jeux', 'Jeux de Paris', 'Jeux olympiques', 'LUIS ROBAYO', 'Mondiaux', 'jeux de Paris 2024', 'ça'], 'ORG': ['AFP', 'Arena Champ-de', 'Club France', 'FEDERICO', 'franceinfo', 'franceinfo: sport'], 'PER': ['Kylian Le Blouch', 'Madeleine Malonga', 'Romane Dicko', 'Shirine Boukli'], 'LOC': ['@francetvsport', 'Arena Champ-de-Mars', 'Bercy', 'Europe', 'Française', 'Gardoise', 'Japonais', 'Palais', 'Paris', 'Tokyo', 'de France', 'la France']}",
         "[0.032988499850034714, 0.11697884649038315, -0.015376713126897812, -0.016162948682904243, -0.1171182170510292, 0.07259924709796906, 0.04376077651977539, 0.05507536977529526, 0.06304764747619629, -0.03452198952436447, -0.024826865643262863, -0.1159282848238945, 0.07512253522872925, -0.04980188235640526, 0.020100794732570648, -0.04621712863445282, 0.008098116144537926, 0.05938621610403061, -0.04515346139669418, 0.06347759813070297, 0.038182806223630905, -0.08681917190551758, 0.023743942379951477, 0.08370937407016754, -0.08514772355556488, -0.046518005430698395, -0.04208584502339363, 0.01894564740359783, -0.0547039657831192, -0.019998151808977127, -0.030189378187060356, -0.0036313077434897423, 0.008085500448942184, -0.012435282580554485, 0.019941240549087524, 0.00928445067256689, -0.03906787559390068, 0.005397594068199396, -0.04187300428748131, 0.11594786494970322, -0.045659374445676804, -0.021400591358542442, -0.07293502241373062, -0.003471071831882, 0.07472917437553406, -0.012161477468907833, 0.040134333074092865, 0.004128288943320513, -0.08079977333545685, -0.021817157045006752, -0.08431719243526459, 0.034527406096458435, 0.06646140664815903, -0.003777920501306653, 0.04903915897011757, -0.07889578491449356, -0.03571091592311859, -0.04769095033407211, 0.04080194607377052, -0.005672591272741556, -0.047940075397491455, 0.0807047113776207, 0.046883031725883484, -0.005277791526168585, -0.11744608730077744, -0.1324993371963501, 0.03021336905658245, -0.008834991604089737, 0.016404567286372185, 0.050142042338848114, 0.07145862281322479, -0.032584816217422485, -0.04132342338562012, 0.002210010541602969, 0.003370520193129778, 0.08381396532058716, 0.021916378289461136, 0.03232710063457489, -0.01060761883854866, -0.1182202622294426, 0.0445987693965435, -0.08622109889984131, 0.033654242753982544, 0.016391640529036522, -0.004122358281165361, 0.006926511414349079, 0.09289393573999405, 0.02939966879785061, 0.0501839853823185, -0.01173499133437872, 0.0017855793703347445, 0.0343860499560833, -0.1281924694776535, -0.004694100935012102, 0.09514813125133514, -0.05504767596721649, -0.06807366758584976, -0.04319140315055847, 0.046781692653894424, 0.03216947615146637, 0.0020229052752256393, -0.04608751833438873, 0.03457081690430641, 0.10079126805067062, 0.012881661765277386, 0.023948995396494865, 0.015600361861288548, 0.020774515345692635, -0.020181741565465927, -0.008138572797179222, -0.018799826502799988, -0.08950337767601013, -0.01629975065588951, -0.011182795278728008, -0.02109628915786743, 0.1274472326040268, -0.06346572935581207, -0.06552962958812714, -0.031976427882909775, 0.014809842221438885, 0.06383267045021057, -0.05534946918487549, -0.015430424362421036, -0.07130561769008636, 0.032098300755023956, 0.06454119831323624, 0.060155078768730164, 1.0987344227767983e-32, 0.0010974239557981491, -0.04559805989265442, 0.024363821372389793, -0.043076999485492706, -0.07707680016756058, -0.04434901475906372, -0.00714560691267252, -0.05828309804201126, 0.005419992841780186, -0.0436563566327095, -0.07805108278989792, 0.042276378720998764, -0.012633256614208221, -0.019050389528274536, 0.06746817380189896, -0.02474978193640709, 0.06474071741104126, -0.09793563932180405, 0.03296777978539467, 0.012381738051772118, 0.02863658219575882, 0.07458610832691193, 0.019499704241752625, 0.06163641810417175, -0.04345846548676491, 0.07079684734344482, 0.023462414741516113, -0.11083155125379562, -0.08630958199501038, 0.04995683953166008, -0.006661023944616318, -0.0884099006652832, 0.004022681154310703, 0.014679143205285072, -0.006014503072947264, -0.05225209519267082, -0.011753370054066181, 0.03724092245101929, 0.013493511825799942, 0.048272039741277695, 0.03176017850637436, -0.04465816169977188, 0.045896779745817184, -0.055964142084121704, 0.015485742129385471, 0.04579762741923332, 0.00035549403401091695, -0.008976202458143234, 0.0644109919667244, 0.048650193959474564, -0.023848701268434525, 0.09066379070281982, 0.02817467786371708, -0.03640257939696312, 0.014276224188506603, -0.006894396618008614, -0.03688580542802811, 0.004586219787597656, -0.05816785991191864, 0.05527857318520546, -0.035601578652858734, -0.01008132565766573, -0.009865372441709042, 0.04773934558033943, 0.0170889999717474, -0.06286781281232834, 0.0019753077067434788, 0.01628963090479374, 0.009799538180232048, -0.06111091747879982, -0.04997953772544861, 0.01849360205233097, 0.04105585813522339, -0.029636573046445847, 0.033884886652231216, 0.006034586112946272, 0.044200483709573746, -0.04560277238488197, -0.071900874376297, 0.02061445079743862, -0.015886971727013588, 0.017663607373833656, -0.050433993339538574, 0.025171251967549324, 0.022163284942507744, 0.006564814131706953, 0.023123499006032944, 0.054649583995342255, -0.03192468360066414, 0.08498542010784149, -0.03587502986192703, -0.020571528002619743, 0.01778019405901432, 0.0007886046078056097, -0.027342911809682846, -1.3170800005165427e-32, -0.01877651736140251, 0.055681489408016205, -0.03856324777007103, 0.12413588166236877, 0.031853217631578445, 0.04456726461648941, -0.03388581424951553, 0.1307392716407776, -0.06053714081645012, 0.01851331815123558, 0.025446677580475807, -0.06412749737501144, 0.03333215415477753, -0.011463604867458344, -0.03650745749473572, 0.03653498739004135, -0.07409106940031052, -0.021066050976514816, -0.06807337701320648, 0.042189471423625946, 0.06737514585256577, 0.008981923572719097, 0.010414197109639645, -0.05692882090806961, -0.012820699252188206, 0.08368190377950668, 0.014279810711741447, -0.007877219468355179, -0.08272676169872284, 0.03766043484210968, -0.03103794902563095, -0.003190217772498727, 0.0025662851985543966, 0.06086626276373863, 0.07543379068374634, 0.02023540437221527, 0.0942208468914032, -0.017182016745209694, -0.008615091443061829, 0.11177525669336319, -0.018957724794745445, -0.02547605335712433, 0.01900804042816162, 0.011620143428444862, 0.07086776942014694, -0.02085006982088089, -0.08080501854419708, -0.040866535156965256, 0.06952548772096634, -0.0883847326040268, 0.019388969987630844, 0.034413792192935944, -0.011606424115598202, -0.03705094754695892, 0.027127576991915703, -0.0945739820599556, -0.013932984322309494, -0.08451871573925018, -0.08909390866756439, 0.06249334290623665, 0.026102297008037567, 0.011933425441384315, -0.029473889619112015, -0.015525021590292454, -0.00931379571557045, -0.035052116960287094, -0.04273834824562073, -0.022004811093211174, -0.10057209432125092, -0.06762702763080597, 5.102360955788754e-05, 0.005320046097040176, -0.026481283828616142, 0.009980995208024979, -0.023755375295877457, 0.03175044804811478, -0.01930033229291439, 0.08514437824487686, 0.04847411438822746, 0.09893026202917099, -0.06716632097959518, 0.03476369008421898, -0.025102611631155014, -0.044760748744010925, 0.011715047061443329, 0.062168121337890625, -0.05195111408829689, 0.03513525053858757, 0.03350118175148964, -0.03875228017568588, 0.08000839501619339, 0.03825204446911812, 0.05222878232598305, -0.029849780723452568, -0.0016727864276617765, -6.831661636397257e-08, 0.01191436592489481, 0.0052170418202877045, -0.045256584882736206, 0.03730713203549385, -0.01227774377912283, -0.037910573184490204, -0.0649557039141655, -0.07310730218887329, -0.01556347031146288, 0.05680905655026436, 0.03968499228358269, 0.09797574579715729, -0.030329253524541855, -0.003977622836828232, -0.08942718058824539, 0.03850749880075455, -0.013741553761065006, -0.03464672341942787, -0.02755589596927166, -0.04354153946042061, 0.019323816522955894, -0.10169084370136261, -0.0531054325401783, -0.1094500869512558, -0.0938340425491333, -0.10222962498664856, -0.12550027668476105, -0.09983086585998535, -0.04593191295862198, -0.012745054438710213, 0.051040176302194595, -0.00927011575549841, -0.042438142001628876, -0.07835731655359268, -0.044978633522987366, -0.032101694494485855, 0.004559644497931004, 0.022154640406370163, -0.02227688580751419, 0.07316109538078308, 0.04895716905593872, -0.027758946642279625, -0.003914924804121256, -0.057740457355976105, 0.09055641293525696, -0.04047231748700142, -0.025647059082984924, -0.07156552374362946, -0.011711787432432175, -0.0002726242528297007, -0.05055678263306618, -0.023746613413095474, 0.016378089785575867, 0.0028121781069785357, -0.00771878007799387, 0.0707319974899292, -0.0016099121421575546, -0.022160926833748817, -0.0055300397798419, -0.009599920362234116, -0.02354065328836441, -0.031683847308158875, -0.03446578234434128, 0.02740224078297615]",
         "0.189"
        ],
        [
         "44",
         "577",
         "Multi-head Attention is a Fancy Addition Machine",
         "\"Attention is All you Need\" showed attention as a sequence of multiplicative and concat operations but... what if I told you they are additive? The post Multi-head Attention is a Fancy Addition Machine appeared first on Towards Data Science .",
         "is a relatively new sub-field in AI, focused on understanding how neural networks function by reverse-engineering their internal mechanisms and representations, aiming to translate them into human-understandable algorithms and concepts. This is in contrast to and further than traditional explainability techniques like SHAP and LIME.\n\nSHAP stands for SHapley Additive exPlanations. It computes the contribution of each feature to the prediction of the model, locally and globally, that is for a single example as well as across the whole dataset. This allows SHAP to be used to determine feature importance in general for the use case. LIME, meanwhile, works on a single example-prediction pair where it perturbs the example input and uses the perturbations and its outputs to approximate a simpler substitute of the black-box model. As such, both of these work at a feature level and give us some explanation and heuristic to gauge how each input into the model affects its prediction or output.\n\nOn the other hand, mechanistic interpretation understands things at a more granular level in that it is capable of providing a pathway of how the said feature is learnt by different neurons in different layers in the neural network, and how that learning evolves over the layers in the network. This makes it adept at tracing paths inside the network for a particular feature and also seeing how that feature affects the outcome.\n\nSHAP and LIME, then, answer the question “which feature contributes the most to the outcome?” whereas mechanistic interpretation answers the question “which neurons activate for which feature, and how does that feature evolve and affect the outcome of the network?“\n\nSince explainability in general is a problem with deeper networks, this sub-field majorly works with deeper models like the transformers. There are a few places where mechanistic interpretability looks at transformers differently than the traditional way, one of which is multi-head attention. As we will see, this difference is in reframing the multiplication and concatenation operations as defined in the “Attention is All You Need” paper as addition operations which opens a whole range of new possibilities.\n\nBut first, a recap of the Transformer architecture.\n\nTransformer Architecture\n\nImage by Author: Transformer Architecture\n\nThese are the sizes we work with:\n\nbatch_size B =1;\n\nsequence length S = 20;\n\nvocab_size V = 50,000;\n\nhidden_dims D = 512;\n\nheads H = 8\n\nThis means that the number of dimensions in the Q, K, V vectors is 512/8 (L) = 64. (In case you don’t remember, an analogy for understanding query, key and value: The idea is that for a token at a given position (K), based on its context (Q) we want to get alignment (reweighing) to the positions it’s relevant to (V).)\n\nThese are the steps upto the attention computation in a transformer. (The shape of tensors is assumed as an example for better understanding. Numbers in italic represent the dimension along which the matrix is multiplied.)\n\nStep Operation Input 1 Dims (Shape) Input 2 Dims (Shape) Output Dims (Shape) 1 N/A B x S x V\n\n(1 x 20 x 50,000) N/A B x S x V\n\n(1 x 20 x 50,000) 2 Get embeddings B x S x V\n\n(1 x 20 x 50,000) V x D\n\n(50,000 x 512) B x S x D\n\n(1 x 20 x 512) 3 Add positional embeddings B x S x D\n\n(1 x 20 x 512) N/A B x S x D\n\n(1 x 20 x 512) 4 Copy embeddings to Q, K, V B x S x D\n\n(1 x 20 x 512) N/A B x S x D\n\n(1 x 20 x 512) 5 Linear transform for each head H=8 B x S x D\n\n(1 x 20 x 512) D x L\n\n(512 x 64) BxHxSxL\n\n(1 x 1 x 20 x 64) 6 Scaled Dot Product (Q@K’) in each head BxHxSxL\n\n(1 x 1 x 20 x 64) (LxSxHxB)\n\n(64 x 20 x 1 x 1) BxHxSxS\n\n(1 x 1 x 20 x 20) 7 Scaled Dot Product (Attention calculation) Q@K’V in each head BxHxSxS\n\n(1 x 1 x 20 x 20) BxHxSxL\n\n(1 x 1 x 20 x 64) BxHxSxL\n\n(1 x 1 x 20 x 64) 8 Concat across all heads H=8 BxHxSxL\n\n(1 x 1 x 20 x 64) N/A B x S x D\n\n(1 x 20 x 512) 9 Linear projection B x S x D\n\n(1 x 20 x 512) D x D\n\n(512 x 512) B x S x D\n\n(1 x 20 x 512) Tabular view of shape transformations towards attention computation in the Transformer\n\nThe table explained in detail:\n\nWe start with one input sentence of a sequence length of 20 that is one-hot encoded to represent words in the vocabulary present in the sequence. Shape (B x S x V): (1 x 20 x 50,000) We multiply this input with the learnable embedding matrix Wₑ of shape (V x D) to get the embeddings. Shape (B x S x D): (1 x 20 x 512) Next a learnable positional encoding matrix of the same shape is added to the embeddings The resultant embeddings are then copied to the matrices Q, K and V. Q, K and V each are split and reshaped on the D dimension. Shape (B x S x D): (1 x 20 x 512) The matrices for Q, K and V are each fed to a linear transformation layer that multiplies them with learnable weight matrices each of shape (D x L) Wq, Wₖ and Wᵥ, respectively (one copy for each of the H=8 heads). Shape (B x H x S x L): (1 x 1 x 20 x 64) where H=1, as this is the resultant shape for each head. Next, we compute attention with Scaled Dot Product attention where Q and K (transposed) are multiplied first in each head. Shape (B x H x S x L) x (L x S x H x B) → (B x H x S x S): (1 x 1 x 20 x 20). There is a scaling and masking step next that I have skipped as that is not important in understanding what is the different way of looking at MHA. So, next we multiply QK with V for each head. Shape (B x H x S x S) x (B x H x S x L) → (B x H x S x L): (1 x 1 x 20 x 64) Concat: Here, we concatenate the results of attention from all the heads at the L dimension to get back a shape of (B x S x D) → (1 x 20 x 512) This output is once more linearly projected using yet another learnable weight matrix Wₒ of shape (D x D). Final shape we end with (B x S x D): (1 x 20 x 512)\n\nReimagining Multi-Head Attention\n\nNow, let’s see how the field of mechanistic interpretation looks at this, and we will also see why it is mathematically equivalent. On the right in the image above, you see the module that reimagines multi-head attention.\n\nInstead of concatenating the attention output, we proceed with the multiplication or linear projection “inside” the heads itself where now the shape of Wₒ is (L x D) which is multiplied with QK’V of shape (B x H x S x L) to get the result of shape (B x S x H x D): (1 x 20 x 1 x 512). Then, we sum over the H dimension to again end with the shape (B x S x D): (1 x 20 x 512).\n\nFrom the table above, the last two steps are what changes:\n\nStep Operation Input 1 Dims (Shape) Input 2 Dims (Shape) Output Dims (Shape) 8 Linear projection on L in each head H=8 BxHxSxL\n\n(1 x 1 x 20 x 64) L x D\n\n(64 x 512) BxSxHxD\n\n(1 x 20 x 1 x 512) 9 Sum over heads (H dimension) BxSxHxD\n\n(1 x 20 x 1 x 512) N/A B x S x D\n\n(1 x 20 x 512)\n\nSide note: This “summing over” is reminiscent of how summing over different channels happens in CNNs. In CNNs, each filter operates on the input, and then we sum the outputs across channels. Same here — each head can be seen as a channel, and the model learns a weight matrix to map each head’s contribution into the final output space.\n\nBut why is the project + sum mathematically equivalent to concat + project? In short, because the projection weights in the mechanistic perspective are just sliced versions of the weights in the traditional view (sliced across the D dimension and split to match each head).\n\nLet’s focus on the H and D dimensions before the multiplication with Wₒ. From image above, each head now has a vector of size 64 that is being multiplied with the weight matrix of shape (64 x 512). Let’s denote the result by R and head by h.\n\nTo get R₁₁, we have this equation:\n\nR₁,₁ = h₁,₁ x Wₒ₁,₁ + h₁,₂ x Wₒ₂,₁ + …. + h₁ₓ₆₄ x Wₒ₆₄,₁\n\nNow let’s say we had concatenated the heads to get an attention output shape of (1 x 512) and the weight matrix of shape (512, 512) then the equation would have been:\n\nR₁,₁ = h₁,₁ x Wₒ₁,₁ + h₁,₂ x Wₒ₂,₁ + …. + h₁ₓ₅₁₂ x Wₒ₅₁₂,₁\n\nSo, the part h₁ₓ₆₅ x Wₒ₆₅,₁ + … + h₁ₓ₅₁₂ x Wₒ₅₁₂,₁ would have been added. But this part being added is the part that is present in each of the other heads in modulo 64 fashion. Said another way, if there is no concatenation, Wₒ₆₅,₁ is the value behind Wₒ₁,₁ in the second head, Wₒ₁₂₉,₁ is the value behind Wₒ₁,₁ in the third head and so on if we imagine that the values for each head sit behind one another. Hence, even without concatenation, the “summing over the heads” operation results in the same values being added.\n\nIn conclusion, this insight lays the foundation of looking at transformers as purely additive models in that all the operations in a transformer take the initial embedding and add to it. This view opens up new possibilities like tracing features as they are learnt via additions through the layers (called circuit tracing) which is what mechanistic interpretability is about as I will show in my next articles.\n\nWe have shown that this view is mathematically equivalent to the vastly different view that multi-head attention, by splitting Q,K,V parallelizes and optimizes computation of attention. Read more about this in this blog here and the actual paper that introduces these points is here.",
         "2025-07-24T07:35:30",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/transformers-and-attention-are-just-fancy-addition-machines/",
         "2025-07-26T06:23:31.334052",
         "is a relatively new sub-field in AI, focused on understanding how neural networks function by reverse-engineering their internal mechanisms and representations, aiming to translate them into human-understandable algorithms and concepts. This is in contrast to and further than traditional explainability techniques like SHAP and LIME. SHAP stands for SHapley Additive exPlanations. It computes the contribution of each feature to the prediction of the model, locally and globally, that is for a single example as well as across the whole dataset. This allows SHAP to be used to determine feature importance in general for the use case. LIME, meanwhile, works on a single example-prediction pair where it perturbs the example input and uses the perturbations and its outputs to approximate a simpler substitute of the black-box model. As such, both of these work at a feature level and give us some explanation and heuristic to gauge how each input into the model affects its prediction or output. On the other hand, mechanistic interpretation understands things at a more granular level in that it is capable of providing a pathway of how the said feature is learnt by different neurons in different layers in the neural network, and how that learning evolves over the layers in the network. This makes it adept at tracing paths inside the network for a particular feature and also seeing how that feature affects the outcome. SHAP and LIME, then, answer the question “which feature contributes the most to the outcome?” whereas mechanistic interpretation answers the question “which neurons activate for which feature, and how does that feature evolve and affect the outcome of the network?“ Since explainability in general is a problem with deeper networks, this sub-field majorly works with deeper models like the transformers. There are a few places where mechanistic interpretability looks at transformers differently than the traditional way, one of which is multi-head attention. As we will see, this difference is in reframing the multiplication and concatenation operations as defined in the “Attention is All You Need” paper as addition operations which opens a whole range of new possibilities. But first, a recap of the Transformer architecture. Transformer Architecture Image by Author: Transformer Architecture These are the sizes we work with: batch_size B =1; sequence length S = 20; vocab_size V = 50,000; hidden_dims D = 512; heads H = 8 This means that the number of dimensions in the Q, K, V vectors is 512/8 (L) = 64. (In case you don’t remember, an analogy for understanding query, key and value: The idea is that for a token at a given position (K), based on its context (Q) we want to get alignment (reweighing) to the positions it’s relevant to (V).) These are the steps upto the attention computation in a transformer. (The shape of tensors is assumed as an example for better understanding. Numbers in italic represent the dimension along which the matrix is multiplied.) Step Operation Input 1 Dims (Shape) Input 2 Dims (Shape) Output Dims (Shape) 1 N/A B x S x V (1 x 20 x 50,000) N/A B x S x V (1 x 20 x 50,000) 2 Get embeddings B x S x V (1 x 20 x 50,000) V x D (50,000 x 512) B x S x D (1 x 20 x 512) 3 Add positional embeddings B x S x D (1 x 20 x 512) N/A B x S x D (1 x 20 x 512) 4 Copy embeddings to Q, K, V B x S x D (1 x 20 x 512) N/A B x S x D (1 x 20 x 512) 5 Linear transform for each head H=8 B x S x D (1 x 20 x 512) D x L (512 x 64) BxHxSxL (1 x 1 x 20 x 64) 6 Scaled Dot Product (Q@K’) in each head BxHxSxL (1 x 1 x 20 x 64) (LxSxHxB) (64 x 20 x 1 x 1) BxHxSxS (1 x 1 x 20 x 20) 7 Scaled Dot Product (Attention calculation) Q@K’V in each head BxHxSxS (1 x 1 x 20 x 20) BxHxSxL (1 x 1 x 20 x 64) BxHxSxL (1 x 1 x 20 x 64) 8 Concat across all heads H=8 BxHxSxL (1 x 1 x 20 x 64) N/A B x S x D (1 x 20 x 512) 9 Linear projection B x S x D (1 x 20 x 512) D x D (512 x 512) B x S x D (1 x 20 x 512) Tabular view of shape transformations towards attention computation in the Transformer The table explained in detail: We start with one input sentence of a sequence length of 20 that is one-hot encoded to represent words in the vocabulary present in the sequence. Shape (B x S x V): (1 x 20 x 50,000) We multiply this input with the learnable embedding matrix Wₑ of shape (V x D) to get the embeddings. Shape (B x S x D): (1 x 20 x 512) Next a learnable positional encoding matrix of the same shape is added to the embeddings The resultant embeddings are then copied to the matrices Q, K and V. Q, K and V each are split and reshaped on the D dimension. Shape (B x S x D): (1 x 20 x 512) The matrices for Q, K and V are each fed to a linear transformation layer that multiplies them with learnable weight matrices each of shape (D x L) Wq, Wₖ and Wᵥ, respectively (one copy for each of the H=8 heads). Shape (B x H x S x L): (1 x 1 x 20 x 64) where H=1, as this is the resultant shape for each head. Next, we compute attention with Scaled Dot Product attention where Q and K (transposed) are multiplied first in each head. Shape (B x H x S x L) x (L x S x H x B) → (B x H x S x S): (1 x 1 x 20 x 20). There is a scaling and masking step next that I have skipped as that is not important in understanding what is the different way of looking at MHA. So, next we multiply QK with V for each head. Shape (B x H x S x S) x (B x H x S x L) → (B x H x S x L): (1 x 1 x 20 x 64) Concat: Here, we concatenate the results of attention from all the heads at the L dimension to get back a shape of (B x S x D) → (1 x 20 x 512) This output is once more linearly projected using yet another learnable weight matrix Wₒ of shape (D x D). Final shape we end with (B x S x D): (1 x 20 x 512) Reimagining Multi-Head Attention Now, let’s see how the field of mechanistic interpretation looks at this, and we will also see why it is mathematically equivalent. On the right in the image above, you see the module that reimagines multi-head attention. Instead of concatenating the attention output, we proceed with the multiplication or linear projection “inside” the heads itself where now the shape of Wₒ is (L x D) which is multiplied with QK’V of shape (B x H x S x L) to get the result of shape (B x S x H x D): (1 x 20 x 1 x 512). Then, we sum over the H dimension to again end with the shape (B x S x D): (1 x 20 x 512). From the table above, the last two steps are what changes: Step Operation Input 1 Dims (Shape) Input 2 Dims (Shape) Output Dims (Shape) 8 Linear projection on L in each head H=8 BxHxSxL (1 x 1 x 20 x 64) L x D (64 x 512) BxSxHxD (1 x 20 x 1 x 512) 9 Sum over heads (H dimension) BxSxHxD (1 x 20 x 1 x 512) N/A B x S x D (1 x 20 x 512) Side note: This “summing over” is reminiscent of how summing over different channels happens in CNNs. In CNNs, each filter operates on the input, and then we sum the outputs across channels. Same here — each head can be seen as a channel, and the model learns a weight matrix to map each head’s contribution into the final output space. But why is the project + sum mathematically equivalent to concat + project? In short, because the projection weights in the mechanistic perspective are just sliced versions of the weights in the traditional view (sliced across the D dimension and split to match each head). Let’s focus on the H and D dimensions before the multiplication with Wₒ. From image above, each head now has a vector of size 64 that is being multiplied with the weight matrix of shape (64 x 512). Let’s denote the result by R and head by h. To get R₁₁, we have this equation: R₁,₁ = h₁,₁ x Wₒ₁,₁ + h₁,₂ x Wₒ₂,₁ + …. + h₁ₓ₆₄ x Wₒ₆₄,₁ Now let’s say we had concatenated the heads to get an attention output shape of (1 x 512) and the weight matrix of shape (512, 512) then the equation would have been: R₁,₁ = h₁,₁ x Wₒ₁,₁ + h₁,₂ x Wₒ₂,₁ + …. + h₁ₓ₅₁₂ x Wₒ₅₁₂,₁ So, the part h₁ₓ₆₅ x Wₒ₆₅,₁ + … + h₁ₓ₅₁₂ x Wₒ₅₁₂,₁ would have been added. But this part being added is the part that is present in each of the other heads in modulo 64 fashion. Said another way, if there is no concatenation, Wₒ₆₅,₁ is the value behind Wₒ₁,₁ in the second head, Wₒ₁₂₉,₁ is the value behind Wₒ₁,₁ in the third head and so on if we imagine that the values for each head sit behind one another. Hence, even without concatenation, the “summing over the heads” operation results in the same values being added. In conclusion, this insight lays the foundation of looking at transformers as purely additive models in that all the operations in a transformer take the initial embedding and add to it. This view opens up new possibilities like tracing features as they are learnt via additions through the layers (called circuit tracing) which is what mechanistic interpretability is about as I will show in my next articles. We have shown that this view is mathematically equivalent to the vastly different view that multi-head attention, by splitting Q,K,V parallelizes and optimizes computation of attention. Read more about this in this blog here and the actual paper that introduces these points is here.",
         "en",
         "{'LOC': ['B x H x S', 'B x H x S x L', 'B x H x S x L):', 'B x H x S x S', 'B x H x S x S):', 'B x S x D):', 'BxHxSxL', 'LIME', 'N', 'R₁,₁', 'Side', 'We', 'Wq', 'exPlanations', 'h₁,₁ x Wₒ₁,₁', 'h₁,₂', 'is', 'then'], 'MISC': ['Add', 'As such', 'As we will see', 'Attention calculation', 'B x S x D', 'B x S x D):', 'B x S x H x D):', 'B x S x V):', 'BxSxHxD', 'CNNs', 'Final shape we end with', 'From the table above', 'Get embeddings B x', 'H=1', 'Hence', 'Here, we concatenate the results of attention from all the heads at the L dimension to get back a shape of', 'In case you don’t remember', 'Input 2 Dims', 'Instead of concatenating the attention output', 'It computes the contribution of each feature to the prediction of the model', 'K', 'L in each head H=8', 'Let’', 'Let’s focus on the H and D dimensions before the multiplication', 'Linear', 'LxSxHxB', 'Q', 'Q) we want to get alignment', 'Q@K’V in each head BxHxSxS', 'Reimagining Multi-Head', 'SHAP to be used to', 'SHapley', 'Same here — each head can be seen as a channel', 'Since explainability in general is', 'So', 'Step Operation', 'Step Operation Input 1 Dims', 'Tabular view of shape transformations towards attention computation in the Transformer The', 'The idea is that for a token at a given position', 'The matrices for Q', 'The shape of tensors is', 'There are', 'There is a scaling and masking step next that I have skipped as that is not important in understanding what is the different way of looking at MHA', 'These are the steps upto the attention', 'This makes it adept at tracing paths inside the network for', 'This means that the number of dimensions in the Q', 'This “summing over” is reminiscent of how summing over different', 'V', 'V B x S x D', 'V vectors is 512/8', 'V x D', 'We have shown that this view is mathematically equivalent to the vastly', 'We start with one input', 'Wₑ of shape', 'Wₒ. From image above', 'Wₒ₁₂₉,₁ is the value behind Wₒ₁,₁ in the third head and so on if we imagine that the values for each head sit behind one another', 'Wₒ₂,₁', 'Wₒ₅₁₂,₁ would have been added.', 'Wₒ₆₄,₁ Now let’s say we had concatenated the heads to get an attention output shape of', 'Wₒ₆₅,₁', 'Wₒ₆₅,₁ is the value behind Wₒ₁,₁ in the second head', 'Wₖ and Wᵥ', 'additions through the layers', 'aiming to translate them into human-understandable algorithms and concepts', 'analogy for understanding query', 'and how does that feature evolve and affect the outcome of the network?', 'and the model learns', 'as well as across the whole dataset', 'by splitting Q', 'called circuit tracing) which is what mechanistic interpretability is about as I will show in my next articles', 'each head now has', 'embeddings are then copied to the matrices', 'for better understanding', 'input and uses the perturbations and its outputs', 'key and value', 'length S', 'length of 20 that is one-hot encoded to', 'let’s see how the field of mechanistic', 'mathematically equivalent to concat', 'matrix of the same shape is added to the embeddings', 'matrix to map each head’', 'of size 64 that is being multiplied with the weight matrix of shape', 'one copy for each of the', 'one of which is multi-head attention', 'operations which opens', 'problem with deeper networks', 'substitute of the black-box model', 'that is for', 'the D dimension and split to match each head', 'the dimension along which the matrix is multiplied', 'the most to the outcome', 'the “summing over the heads” operation results in the same values being added.', 'their internal mechanisms and representations', 'things at a more granular level in that it is capable of providing a pathway of how the said feature is learnt by different neurons in different layers in the neural network', 'this insight lays the foundation of looking at transformers as purely additive models in that all the operations in', 'way', 'we proceed with the multiplication or', 'weights in the mechanistic perspective', 'whereas mechanistic interpretation answers the question “', 'works with deeper models like the', 'x D', 'you see the module that reimagines'], 'ORG': ['BxHxSxS', 'K and V are each fed to', 'K and V each are split and reshaped on the D', 'K and V. Q', 'QK with V for each head', 'SHAP', 'SHAP and LIME', 'Scaled Dot Product', 'Shape', 'Transformer Architecture These are the sizes we work with: batch_size B', 'V parallelizes and optimizes', 'and how that learning evolves over the layers in the network'], 'PER': ['B x H x S', 'D x D', 'In CNNs', 'Read', 'Said another way', 'V x D', 'this difference is in reframing the multiplication and']}",
         "[-0.04685182869434357, -0.030672132968902588, 0.04316132143139839, 0.02015172876417637, 0.10618855059146881, 0.0071619125083088875, 0.020079711452126503, 0.013861839659512043, 0.06462975591421127, -0.026982149109244347, -0.0929289162158966, -0.03386100381612778, -0.01403528731316328, 0.005288270767778158, -0.09281190484762192, 0.004768037237226963, 0.07538428902626038, 0.02862687222659588, -0.13556553423404694, -0.09684271365404129, 0.03249096870422363, -0.05488947778940201, -0.0057488116435706615, -0.0010110579896718264, -0.00438248086720705, 0.035978127270936966, -0.029961690306663513, 0.08625324070453644, 0.04013613238930702, -0.05807362496852875, 0.05091651901602745, 0.02426052652299404, 0.00017281706095673144, 0.020210515707731247, -0.11872874945402145, 0.11790730059146881, -0.03255029767751694, 0.006288394331932068, -0.044876497238874435, -0.05153457447886467, -0.021109789609909058, 0.0043312544003129005, -0.04225308448076248, -0.03431551903486252, 0.09273874014616013, -0.01613580249249935, 0.07053421437740326, -0.05055294185876846, -0.03717297688126564, -0.05897209048271179, -0.09179559350013733, 0.034683194011449814, -0.02609136328101158, 0.045942649245262146, -0.02291278913617134, 0.008168763481080532, 0.019778989255428314, 0.043776918202638626, -0.027509693056344986, -0.06300466507673264, -0.0422818623483181, -0.03899763897061348, 0.03231482207775116, 0.006289181299507618, 0.11157072335481644, -0.03030787967145443, -0.021829869598150253, 0.0033214224968105555, 0.0024677368346601725, -0.03862685337662697, 0.041850488632917404, 0.0330975316464901, -0.08168439567089081, -0.02841983176767826, 0.04565839096903801, 0.06218907982110977, 0.05059495568275452, 0.08149226754903793, -0.010877711698412895, -0.039105258882045746, -0.05103011056780815, 0.02690221555531025, 0.01374384481459856, -0.008356715552508831, 0.028905803337693214, 0.013860180974006653, -0.008429046720266342, -0.0010694097727537155, -0.007645834237337112, 0.045441120862960815, -0.017007626593112946, -0.03975512832403183, -0.08061587065458298, -0.07008528709411621, 0.13123086094856262, 0.0315607413649559, -0.011107371188700199, -0.0653328001499176, -0.03877044841647148, 0.03538500517606735, -0.01834079623222351, 0.06576382368803024, 0.015287243761122227, -0.0782591924071312, 0.09979896247386932, -0.04372258111834526, 0.014474730007350445, -0.015767265111207962, 0.06351111084222794, -0.06881889700889587, 0.028267184272408485, 0.03122049942612648, -0.013561797328293324, -0.019853515550494194, 0.036600615829229355, 0.04454188048839569, -0.030828315764665604, 0.01927666924893856, -0.022008707746863365, 0.037128083407878876, -0.056531645357608795, -0.015527051873505116, 0.029011208564043045, 0.03086584247648716, -0.00905193667858839, -0.032673247158527374, -0.11387089639902115, 3.494394995425291e-33, -0.030547918751835823, 0.0016353314276784658, -0.035292934626340866, -0.01922662928700447, 0.07207711040973663, -0.05408177897334099, -0.04272233322262764, -0.0011406930861994624, 0.07994737476110458, 0.07894023507833481, -0.044307101517915726, 0.10286393761634827, -0.011872708797454834, 0.07340618222951889, 0.04688823223114014, 0.004802997224032879, -0.08422509580850601, 0.007282557897269726, -0.038560185581445694, -0.04146377742290497, 0.011359595693647861, 0.006812185514718294, 0.0036073673982173204, -0.06839550286531448, -0.017009777948260307, 0.014000044204294682, 0.0368390753865242, 0.02900056168437004, -0.0788445696234703, -0.008898221887648106, -0.045687317848205566, 0.04715205356478691, -0.034421369433403015, -0.038523897528648376, 0.039839837700128555, -0.019334709271788597, -0.004998014774173498, -0.07876532524824142, 0.05436868220567703, -0.06769032776355743, 0.036738764494657516, -0.042377326637506485, -0.03660505264997482, -0.03935577720403671, -0.026458432897925377, 0.00598281342536211, -0.019899757578969002, -0.04172361269593239, -0.08254608511924744, -0.06979084759950638, 0.023807911202311516, 0.03152252361178398, 0.046557698398828506, -0.09740156680345535, 0.0054122149012982845, -0.028944429010152817, 0.05394700542092323, -0.06655718386173248, -0.03233492001891136, 0.08910463005304337, 0.021311495453119278, 0.038757096976041794, 0.0434606708586216, 0.05320598557591438, -0.019384777173399925, 0.0063465666025877, -0.005106127820909023, 0.15426623821258545, 0.1223405972123146, 0.025035185739398003, -0.07124833762645721, 0.07084576785564423, -0.007752535864710808, -0.0686231255531311, 0.01900131069123745, -0.02675493434071541, -0.0013045256491750479, -0.0827985480427742, 0.06342525780200958, 0.06486109644174576, -0.08249440044164658, 0.06614571809768677, 0.011330044828355312, -0.004173746332526207, -0.11407877504825592, 0.03650425374507904, 0.04891941323876381, -0.0839892029762268, 0.030773861333727837, -0.052189163863658905, -0.09547226130962372, 0.0027680513449013233, 0.02571779116988182, -0.01505547109991312, -0.048187460750341415, -5.9747152589671805e-33, -0.0795748233795166, -0.027231160551309586, -0.07409286499023438, 0.0529470331966877, -0.028806444257497787, -0.058648016303777695, -0.04838578775525093, -0.014022055082023144, 0.01384301483631134, -0.019498059526085854, -0.01643560640513897, -0.002306760521605611, 0.01844470202922821, 0.007510303054004908, -0.0013157358625903726, -0.0025145928375422955, -0.08340495824813843, -0.028091469779610634, 0.05735650658607483, 0.0371101051568985, 0.01225312054157257, 0.08416775614023209, -0.08196861296892166, 0.015505338087677956, -0.04641687870025635, 0.024501705542206764, -0.03471924364566803, -0.010473962873220444, 0.018419403582811356, 0.012586468830704689, 0.02722315490245819, 0.03883642330765724, -0.07668375968933105, -0.03386992588639259, -0.015461967326700687, 0.01982472650706768, 0.042084310203790665, -0.01864265277981758, -0.005161477718502283, 0.01772906258702278, 0.09841974824666977, 0.01461536344140768, -0.011553776450455189, -0.04395109787583351, -0.05298995226621628, 0.018870599567890167, 0.019681185483932495, 0.09820301830768585, -0.004219905007630587, -0.01133345253765583, 0.12355663627386093, 0.02987489476799965, -0.01360963936895132, 0.034140512347221375, -0.02829197607934475, 0.05031504109501839, 0.060601748526096344, 0.028804071247577667, 7.09710075170733e-05, 0.06461784988641739, -0.0771738737821579, -0.03532274067401886, -0.012070167809724808, 0.05907175689935684, -0.09185846149921417, 0.04377351701259613, 0.023539848625659943, -0.05162655562162399, 0.06575340032577515, -0.05937635153532028, -0.009532039985060692, -0.08023440837860107, 0.03492950648069382, 0.04862023517489433, 0.011446363292634487, 0.016224032267928123, -0.010974659584462643, -0.03019508346915245, -0.007359777111560106, -0.014139428734779358, -0.0042519886046648026, -0.025907427072525024, -0.0235341414809227, 0.030614765360951424, 0.0200633741915226, -0.048696842044591904, -0.0794408768415451, 0.022651303559541702, 0.014859733171761036, -0.05803024023771286, -0.019879136234521866, 0.02871548943221569, -0.14341607689857483, 0.05500439181923866, -0.06817756593227386, -6.503208282993e-08, -0.03664397448301315, 0.020471908152103424, 0.07095330208539963, 0.021292157471179962, 0.0544840432703495, -0.04562787339091301, -0.027724338695406914, 0.02555706724524498, -0.06188017129898071, 0.028095761314034462, 0.060364797711372375, -0.021420281380414963, -0.07272014766931534, -0.07753454893827438, 0.024639155715703964, 0.13510604202747345, 0.0690809041261673, 0.035675786435604095, 0.01951001025736332, -0.03251872956752777, 0.028559165075421333, -0.028744006529450417, 0.012941144406795502, -0.015110118314623833, 0.07921991497278214, -0.06447761505842209, -0.1078408882021904, 0.0700739249587059, 0.038963645696640015, 0.0922095850110054, 0.04398614913225174, 0.04444411024451256, 0.08361385017633438, -0.04920649528503418, 0.09197935461997986, 0.07046908140182495, 0.007716289721429348, -0.0646146610379219, 0.02931460738182068, 0.024481793865561485, 0.0012048901990056038, 0.028108438476920128, -0.01519994530826807, -0.021233685314655304, -0.04260183498263359, -0.03009827621281147, 0.014059756882488728, -0.04978245124220848, -0.04447339475154877, 0.11419638246297836, -0.007470487151294947, 0.001598687143996358, 0.07848825305700302, 0.01759685017168522, 0.0493134930729866, 0.0081504937261343, -0.0002050199400400743, -0.08786744624376297, -0.0003256644413340837, 0.06691262125968933, 0.03508531674742699, 0.09472759813070297, 0.03746000677347183, -0.04950062930583954]",
         "0.14"
        ],
        [
         "45",
         "536",
         "Zuckerberg’s $15B bet: How Meta’s ‘Superintelligence Labs’ became Silicon Valley’s most expensive AI talent war",
         "Mark Zuckerberg has a history of making audacious bets that reshape entire industries – and losing spectacularly when they don’t pan out. After burning through US$46 billion on the metaverse with little to show for it, the Meta CEO is now doubling down with an even more ambitious wager: superintelligence AI. This time, however, the […] The post Zuckerberg’s $15B bet: How Meta’s ‘Superintelligence Labs’ became Silicon Valley’s most expensive AI talent war appeared first on AI News .",
         "Mark Zuckerberg has a history of making audacious bets that reshape entire industries – and losing spectacularly when they don’t pan out. After burning through US$46 billion on the metaverse with little to show for it, the Meta CEO is now doubling down with an even more ambitious wager: superintelligence AI.\n\nThis time, however, the stakes are higher, the competition more fierce, and the potential rewards more transformative than anything Meta has attempted before.\n\nWith nine-figure compensation packages and infrastructure investments that dwarf even the metaverse spending spree, Zuckerberg’s superintelligence AI gamble represents Silicon Valley’s most expensive talent war – one that could either cement Meta’s position as a tech giant or become another cautionary tale of visionary ambition meeting harsh reality.\n\nThe birth of Meta Superintelligence Labs\n\nThe formation of Meta Superintelligence Labs marks a shift for the social media giant. In an exclusive interview with The Information‘s TITV live-streaming programme, Zuckerberg told founder Jessica Lessin that “the most exciting thing this year is that we’re starting to see early glimpses of self-improvement with the models, which means that developing super intelligence is now in sight.”\n\nThe vision has driven the company to restructure its entire AI division, with the ambitious goal of delivering what Zuckerberg calls “personal super intelligence to everyone in the world.” The lab’s creation follows a period of internal struggles in Meta’s AI division, including management struggles, employee churn, and product releases that fell flat.\n\nRather than incrementally improving existing systems, Zuckerberg has opted for a complete overhaul, bringing in external leadership and re-imagining the company’s approach to AI development.\n\nAre we witnessing the most expensive talent war in tech history?\n\nCentral to Meta’s superintelligence AI ambitions is a talent acquisition strategy that has sent shockwaves through the industry. Zuckerberg has embarked on a spending spree to create the new lab, offering as much as nine-figure pay packages to hire top researchers from companies like OpenAI, Google, Apple and Anthropic.\n\nWhen The Information’s Lessin questioned reports of $100-200 million compensation packages, Zuckerberg acknowledged the competitive nature of the market, stating that “a lot of the specifics that have been reported aren’t accurate by themselves. But it is a very hot market… there’s a small number of researchers, who are the best, who are in demand by all of the different labs.”\n\nThe Meta AI talent acquisition strategy extends beyond financial incentives. Zuckerberg said having “basically the most compute per researcher is a strategic advantage, not just for doing the work, but for attracting the best people.” The approach reflects an understanding that in the superintelligence AI race, talent density matters more than team size.\n\nThe Alexandr Wang acquisition: A US$14.3b gamble\n\nThe centrepiece of Meta’s talent strategy was its acquisition of Scale AI leadership. In June, the company made a $14.3 billion investment in the AI startup, founded and led by Wang. Under the deal, Meta took a 49% stake in the company, and Wang and a team of top Scale employees joined Meta in leadership roles.\n\nAt just 28 years old, Alexandr Wang now serves as Meta’s chief AI officer, leading what the company has renamed “Meta Superintelligence Labs.” In the larger AI division, Wang has led a team of around a dozen newly-hired researchers, a handful of his deputies from Scale AI, and Nat Friedman, the former chief executive of GitHub.\n\nThe integration of Wang’s team as a re-imagining of how Meta approaches AI development. The group is working in an office space siloed from the rest of the company and next to Zuckerberg, highlighting the importance placed on the initiative.\n\nA philosophical shift: From open source to closed development\n\nPerhaps the most significant development emerging from Meta Superintelligence Labs is a potential abandonment of the company’s long-standing open-source philosophy. Last week, a small group of top members of the lab, including Wang, discussed abandoning the company’s most powerful open source AI model, called Behemoth, in favour of developing a closed model.\n\nThis represents a departure from Meta’s historical approach. For years, Meta has chosen to open source its AI models, making code public for other developers to build on. Meta executives have argued it is better for the technology to be built in public so that AI development will move faster and be accessible to more developers.\n\nThe shift reflects concerns about competitive positioning in the AI race. Meta had finished feeding data into its Behemoth model (training) but has delayed its release because of poor internal performance. The setback has prompted a serious reconsideration of the company’s approach.\n\nInfrastructure as a competitive advantage\n\nBeyond talent acquisition, Meta is making infrastructure investments to support its superintelligence ambitions. Zuckerberg revealed that the company is “building multiple, multi-gigawatt data centres” and pioneering new construction methods, including “weatherproof tents” to accelerate deployment.\n\nThe scale of these investments is staggering. Hyperion, one of Meta’s new data centres, “is going to scale up to five gigawatts over the coming years” and “the size of the site covers a significant portion of the footprint of Manhattan in terms of space.”\n\nThe infrastructure spending is enabled by Meta’s strong financial position, with Zuckerberg noting that “we can basically do this all funded from the cash flow of the company.”\n\nThe personal superintelligence vision\n\nWhat distinguishes Meta’s approach from competitors is its focus on “personal superintelligence” rather than centralised AI systems. During his interview with The Information’s Lessin, Zuckerberg explained that while other labs focus on “wanting to automate all of the economically productive work in society,” Meta’s vision centres on “what are the things that people care about in their own lives… relationships and culture and creativity and having fun and enjoying life.”\n\nThe vision extends to Meta’s hardware ambitions, particularly its AR glasses initiative. In the same TITV interview, Zuckerberg predicted that “if you don’t have AI glasses, you’re going to be at a cognitive disadvantage” and described future scenarios where AI companions could “observe what’s going on in your life and be able to follow up on things for you.”\n\nIndustry implications and competitive dynamics\n\nThe implications of Meta’s superintelligence push extend beyond the company. Meta’s AI talent acquisition strategy has created salary inflation in the industry, forcing competitors to match or exceed Meta’s compensation levels to retain their researchers.\n\nWhen asked about his interactions with competitors at Sun Valley, Zuckerberg acknowledged the competitive landscape, stating that “we’re not trying to target anyone individually. I want to make sure that I get to know all of the top researchers in the industry.”\n\nThe diplomatic approach masks what is fundamentally a zero-sum competition for a finite pool of top-tier superintelligence AI talent. The potential shift away from open-source development also signals a broader industry trend toward more proprietary approaches to AI development.\n\nConclusion: A defining moment for Meta\n\nMeta’s superintelligence initiative represents a re-imagining of the company’s future. After the costly metaverse experiment failed to deliver results, Zuckerberg is betting even bigger on AI, with investments that could exceed US$100 billion over the coming years.\n\nThe success or failure of Meta Superintelligence Labs will likely determine not just the company’s future but the trajectory of the broader AI industry. With some employees expecting “an exodus of AI talent who were not chosen to join Wang’s superintelligence team,” the stakes are high.\n\nWhether Meta’s AI talent acquisition campaign will yield the breakthrough technologies Zuckerberg envisions remains to be seen. What’s certain is that Silicon Valley’s most expensive talent war has begun.\n\nSee also: Apple loses key AI leader to Meta\n\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.\n\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.",
         "2025-07-17T15:43:07",
         "https://www.artificialintelligence-news.com/feed/",
         "https://www.artificialintelligence-news.com/news/meta-superintelligence-ai-lab-zuckerberg-talent-war/",
         "2025-07-26T05:53:46.642665",
         "Mark Zuckerberg has a history of making audacious bets that reshape entire industries – and losing spectacularly when they don’t pan out. After burning through US$46 billion on the metaverse with little to show for it, the Meta CEO is now doubling down with an even more ambitious wager: superintelligence AI. This time, however, the stakes are higher, the competition more fierce, and the potential rewards more transformative than anything Meta has attempted before. With nine-figure compensation packages and infrastructure investments that dwarf even the metaverse spending spree, Zuckerberg’s superintelligence AI gamble represents Silicon Valley’s most expensive talent war – one that could either cement Meta’s position as a tech giant or become another cautionary tale of visionary ambition meeting harsh reality. The birth of Meta Superintelligence Labs The formation of Meta Superintelligence Labs marks a shift for the social media giant. In an exclusive interview with The Information‘s TITV live-streaming programme, Zuckerberg told founder Jessica Lessin that “the most exciting thing this year is that we’re starting to see early glimpses of self-improvement with the models, which means that developing super intelligence is now in sight.” The vision has driven the company to restructure its entire AI division, with the ambitious goal of delivering what Zuckerberg calls “personal super intelligence to everyone in the world.” The lab’s creation follows a period of internal struggles in Meta’s AI division, including management struggles, employee churn, and product releases that fell flat. Rather than incrementally improving existing systems, Zuckerberg has opted for a complete overhaul, bringing in external leadership and re-imagining the company’s approach to AI development. Are we witnessing the most expensive talent war in tech history? Central to Meta’s superintelligence AI ambitions is a talent acquisition strategy that has sent shockwaves through the industry. Zuckerberg has embarked on a spending spree to create the new lab, offering as much as nine-figure pay packages to hire top researchers from companies like OpenAI, Google, Apple and Anthropic. When The Information’s Lessin questioned reports of $100-200 million compensation packages, Zuckerberg acknowledged the competitive nature of the market, stating that “a lot of the specifics that have been reported aren’t accurate by themselves. But it is a very hot market… there’s a small number of researchers, who are the best, who are in demand by all of the different labs.” The Meta AI talent acquisition strategy extends beyond financial incentives. Zuckerberg said having “basically the most compute per researcher is a strategic advantage, not just for doing the work, but for attracting the best people.” The approach reflects an understanding that in the superintelligence AI race, talent density matters more than team size. The Alexandr Wang acquisition: A US$14.3b gamble The centrepiece of Meta’s talent strategy was its acquisition of Scale AI leadership. In June, the company made a $14.3 billion investment in the AI startup, founded and led by Wang. Under the deal, Meta took a 49% stake in the company, and Wang and a team of top Scale employees joined Meta in leadership roles. At just 28 years old, Alexandr Wang now serves as Meta’s chief AI officer, leading what the company has renamed “Meta Superintelligence Labs.” In the larger AI division, Wang has led a team of around a dozen newly-hired researchers, a handful of his deputies from Scale AI, and Nat Friedman, the former chief executive of GitHub. The integration of Wang’s team as a re-imagining of how Meta approaches AI development. The group is working in an office space siloed from the rest of the company and next to Zuckerberg, highlighting the importance placed on the initiative. A philosophical shift: From open source to closed development Perhaps the most significant development emerging from Meta Superintelligence Labs is a potential abandonment of the company’s long-standing open-source philosophy. Last week, a small group of top members of the lab, including Wang, discussed abandoning the company’s most powerful open source AI model, called Behemoth, in favour of developing a closed model. This represents a departure from Meta’s historical approach. For years, Meta has chosen to open source its AI models, making code public for other developers to build on. Meta executives have argued it is better for the technology to be built in public so that AI development will move faster and be accessible to more developers. The shift reflects concerns about competitive positioning in the AI race. Meta had finished feeding data into its Behemoth model (training) but has delayed its release because of poor internal performance. The setback has prompted a serious reconsideration of the company’s approach. Infrastructure as a competitive advantage Beyond talent acquisition, Meta is making infrastructure investments to support its superintelligence ambitions. Zuckerberg revealed that the company is “building multiple, multi-gigawatt data centres” and pioneering new construction methods, including “weatherproof tents” to accelerate deployment. The scale of these investments is staggering. Hyperion, one of Meta’s new data centres, “is going to scale up to five gigawatts over the coming years” and “the size of the site covers a significant portion of the footprint of Manhattan in terms of space.” The infrastructure spending is enabled by Meta’s strong financial position, with Zuckerberg noting that “we can basically do this all funded from the cash flow of the company.” The personal superintelligence vision What distinguishes Meta’s approach from competitors is its focus on “personal superintelligence” rather than centralised AI systems. During his interview with The Information’s Lessin, Zuckerberg explained that while other labs focus on “wanting to automate all of the economically productive work in society,” Meta’s vision centres on “what are the things that people care about in their own lives… relationships and culture and creativity and having fun and enjoying life.” The vision extends to Meta’s hardware ambitions, particularly its AR glasses initiative. In the same TITV interview, Zuckerberg predicted that “if you don’t have AI glasses, you’re going to be at a cognitive disadvantage” and described future scenarios where AI companions could “observe what’s going on in your life and be able to follow up on things for you.” Industry implications and competitive dynamics The implications of Meta’s superintelligence push extend beyond the company. Meta’s AI talent acquisition strategy has created salary inflation in the industry, forcing competitors to match or exceed Meta’s compensation levels to retain their researchers. When asked about his interactions with competitors at Sun Valley, Zuckerberg acknowledged the competitive landscape, stating that “we’re not trying to target anyone individually. I want to make sure that I get to know all of the top researchers in the industry.” The diplomatic approach masks what is fundamentally a zero-sum competition for a finite pool of top-tier superintelligence AI talent. The potential shift away from open-source development also signals a broader industry trend toward more proprietary approaches to AI development. Conclusion: A defining moment for Meta Meta’s superintelligence initiative represents a re-imagining of the company’s future. After the costly metaverse experiment failed to deliver results, Zuckerberg is betting even bigger on AI, with investments that could exceed US$100 billion over the coming years. The success or failure of Meta Superintelligence Labs will likely determine not just the company’s future but the trajectory of the broader AI industry. With some employees expecting “an exodus of AI talent who were not chosen to join Wang’s superintelligence team,” the stakes are high. Whether Meta’s AI talent acquisition campaign will yield the breakthrough technologies Zuckerberg envisions remains to be seen. What’s certain is that Silicon Valley’s most expensive talent war has begun. See also: Apple loses key AI leader to Meta Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo. Explore other upcoming enterprise technology events and webinars powered by TechForge here.",
         "en",
         "{'PER': ['Alexandr Wang', 'Alexandr Wang now serves as Meta’', 'Jessica Lessin that “the most exciting thing this year is that we’re', 'Mark Zuckerberg has', 'Rather than incrementally improving', 'Wang has led', 'Zuckerberg acknowledged', 'Zuckerberg explained that while other labs focus on “wanting to automate all of the economically', 'Zuckerberg has embarked', 'Zuckerberg has opted for', 'Zuckerberg predicted that “if you don’t have AI glasses', 'Zuckerberg revealed that the company is “building multiple', 'Zuckerberg told', 'philosophical shift'], 'MISC': ['AI model', 'After burning through US$', 'After the costly metaverse experiment failed to deliver results', 'Are we witnessing the most expensive talent war in tech history', 'Beyond', 'BlockX', 'Central to Meta’', 'Check out AI & Big Data Expo taking place in Amsterdam', 'Cloud Expo', 'Conclusion:', 'Digital Transformation Week', 'During his interview with The Information’s Lessin', 'For years', 'From open source to closed development Perhaps the most significant development emerging from Meta Superintelligence Labs is', 'GitHub', 'I want to make sure that I get to know all of the top researchers in the industry', 'In June', 'Intelligent Automation', 'Last week', 'Manhattan in terms of space', 'Meta Superintelligence Labs', 'Meta Superintelligence Labs will likely', 'Meta had finished feeding data into its Behemoth model', 'Meta has attempted before', 'Meta has chosen to open source its AI', 'Meta is making infrastructure investments to support its superintelligence ambitions', 'Meta took', 'Meta’', 'See also', 'Silicon Valley’s most expensive talent war – one that could either cement', 'TechForge here', 'The', 'The birth of Meta', 'The centrepiece of Meta’', 'The diplomatic', 'The scale of these investments is staggering', 'This', 'This time', 'Wang’', 'What distinguishes Meta’', 'What’', 'Whether Meta’', 'With nine', 'With some employees expecting “an exodus of AI', 'Zuckerberg calls', 'Zuckerberg is betting even bigger on AI', 'Zuckerberg said having “basically the most compute per researcher is', 'as much as nine', 'bringing in external leadership and re-imagining the company’', 'but for attracting the best people', 'but the trajectory of the broader AI industry', 'called Behemoth', 'density matters more than team size', 'from Meta’', 'including Wang', 'not just for doing the work', 'one of Meta’', 'pay packages to hire top researchers from companies', 'serious reconsideration of the company’', 'small number of researchers', 'stating that “', 'stating that “we’re not trying to target anyone individually', 'that fell flat', 'the', 'to Meta’', 'war has begun', 'what’s going on in your life and be able to follow up on things for you', 'where AI', 'which means that developing super intelligence is now in sight', 'who are the best', 'will yield the breakthrough technologies Zuckerberg envisions remains to be seen', 'with Zuckerberg noting that “we can basically do this all funded from the cash flow of the company', 'with investments that could', 'work in society', 'you’re going to be at', '” In the', '” the stakes are high'], 'LOC': ['AI', 'California', 'Infrastructure', 'Zuckerberg’', 'and London', 'at Sun Valley'], 'ORG': ['Apple', 'Apple and Anthropic', 'Google', 'Hyperion', 'Industry implications and competitive dynamics The implications of Meta’', 'Meta', 'Meta AI', 'Meta in', 'and Nat Friedman', 'and Wang and a team of top Scale', 'the company made', '” The']}",
         "[-0.014195399358868599, -0.06238940730690956, -0.005858538672327995, 0.013392395339906216, 0.07509385049343109, -0.039673227816820145, 0.017987478524446487, 0.058079056441783905, -0.04359830170869827, -0.007215363439172506, -0.07117604464292526, 0.062211960554122925, -0.012719271704554558, 0.002302617533132434, -0.0555267408490181, -0.02706764079630375, 0.05015648156404495, -0.06408669054508209, -0.059351611882448196, -0.03618617355823517, 0.02187916822731495, -0.06018955260515213, 0.006276717409491539, -0.02720191329717636, 0.01847890205681324, 0.019577374681830406, -0.06499454379081726, -0.020640918985009193, -0.03430640324950218, 0.005756521597504616, -0.023709449917078018, 0.05357080325484276, 0.011831355281174183, -0.004673797637224197, -0.00045579223660752177, 0.04324236139655113, 0.047183044254779816, 0.07573486864566803, 0.053107112646102905, -0.0364857092499733, 0.03148758038878441, -0.10655756294727325, -0.04786497727036476, -0.012674158439040184, 0.014828776940703392, -0.008846724405884743, 0.04398605599999428, -0.0674445852637291, -0.006776024121791124, 0.0031693135388195515, -0.19336073100566864, -0.13000863790512085, 0.03224543109536171, 0.01188783161342144, -0.011440645903348923, 0.03963681682944298, 0.02875511348247528, -0.05125146731734276, 0.028667999431490898, 0.012056328356266022, -0.0035931081511080265, -0.10564323514699936, 0.03141479194164276, 0.008856208994984627, 0.11475546658039093, 0.025461969897150993, -0.033105138689279556, 0.005071185529232025, -0.05499675124883652, -0.009412837214767933, 0.12317359447479248, 0.03619404509663582, -0.06184186413884163, 0.03505454212427139, 0.07775118201971054, 0.0516582615673542, 0.016848474740982056, 0.052419669926166534, 0.15116246044635773, 0.016002776101231575, 0.09609032422304153, -0.02945329248905182, -0.006866650190204382, 0.025393152609467506, -0.06546682119369507, -0.03700338304042816, -0.01918724551796913, -0.004283424466848373, 0.09300953149795532, -0.008698994293808937, 0.006315289996564388, -0.044533632695674896, -0.015535444021224976, -0.00010794260742841288, -0.01240209024399519, 0.0247288029640913, -0.054273370653390884, -0.05373411998152733, -0.03517942875623703, 0.029187165200710297, 0.039926834404468536, -0.019643248990178108, 0.039325352758169174, -0.034211985766887665, 0.050215113908052444, -0.00034213639446534216, 0.04095247760415077, 0.07736673206090927, 0.024743536487221718, 0.031108692288398743, -0.030642975121736526, 0.012261476367712021, 0.011579901911318302, -0.03369094058871269, -0.003360909875482321, 0.039597008377313614, -0.038454942405223846, 0.12517134845256805, 0.03835282847285271, 0.0105219017714262, 0.09157320857048035, 0.09805238246917725, -0.03719770535826683, 0.01442210003733635, -0.0008244193741120398, 0.044941388070583344, -0.18649150431156158, 3.854139245789113e-33, -0.013776822946965694, 0.10931281000375748, 0.035360805690288544, 0.028904857113957405, 0.02469881810247898, 0.013410860672593117, 0.029469462111592293, 0.017880991101264954, -0.04932577908039093, -0.02046355791389942, -0.06343141943216324, 0.0405266098678112, -0.05801896005868912, 0.05321388319134712, 0.05015586316585541, -0.04224982112646103, -0.06874207407236099, -0.07633982598781586, 0.011040441691875458, -0.01970946602523327, 0.11705173552036285, -0.04068560153245926, -0.02703329175710678, -0.018324825912714005, 0.05122818052768707, 0.009469082579016685, -0.0028751539066433907, -0.04286159947514534, -0.03464702144265175, 0.05499863624572754, -0.05640978738665581, 0.07051241397857666, -0.03682507574558258, -0.008797070011496544, -0.019512994214892387, -0.038271911442279816, -0.00979954656213522, -0.07670410722494125, 0.029736777767539024, 0.00822803471237421, -0.056460343301296234, 0.081282839179039, -0.015152189880609512, -0.023515360429883003, -0.031227078288793564, -0.016644639894366264, 0.055733002722263336, 0.0011566905304789543, 0.03981820121407509, -0.037141427397727966, -0.05435639247298241, 0.015718482434749603, -0.012595479376614094, -0.06446336209774017, 0.0109274135902524, 0.02937788888812065, 0.03185379505157471, -0.014699140563607216, -0.036541424691677094, 0.011614993214607239, 0.02329137735068798, -0.006812126841396093, -0.07261817157268524, 0.1441839337348938, -0.07544425129890442, 0.052790362387895584, 0.07435984909534454, 0.06226547807455063, -0.01763308234512806, 0.08695855736732483, -0.0038459328934550285, -0.02490783855319023, -0.03190505504608154, -0.0895799770951271, -0.09432537853717804, -0.009977341629564762, -0.0036122226156294346, -0.0783000960946083, -0.017605764791369438, 0.02445843629539013, -0.017194785177707672, 0.007369399070739746, -0.005941559560596943, -0.03626229986548424, 0.036435216665267944, 0.006796824745833874, 0.006599484942853451, -0.020508533343672752, 0.09462476521730423, -0.02962845377624035, 0.0020080353133380413, -0.057323943823575974, 0.032424863427877426, 0.06058478727936745, -0.15472213923931122, -4.405993803223852e-33, -0.11942917853593826, 0.003061210038140416, 0.018520846962928772, 0.05455086752772331, 0.01268834713846445, -0.003124118084087968, 0.011296886950731277, -0.043862082064151764, -0.012102322652935982, 0.022663548588752747, -0.06472152471542358, 0.05528326705098152, 0.010261538438498974, 0.011488234624266624, -0.006705593783408403, -0.06250742077827454, 0.0352124460041523, -0.06324858218431473, 0.024632370099425316, -0.07297453284263611, 0.08265510201454163, 0.0827387347817421, -0.06922346353530884, 0.04978309944272041, -0.0027172714471817017, 0.004193713888525963, 0.03054223395884037, 0.047008953988552094, -0.017493536695837975, 0.09727801382541656, -0.024901101365685463, -0.0031548175029456615, -0.03752246871590614, -0.0240784902125597, 0.06412649154663086, 0.09772732853889465, 0.00835444312542677, -0.1114167645573616, -0.0013525853864848614, 0.02914746105670929, 0.012756510637700558, -0.009859364479780197, -0.061620865017175674, -0.025343332439661026, -0.015447857789695263, 0.019118651747703552, -0.031404245644807816, 0.02871781773865223, 0.04674733057618141, -0.06087741255760193, -0.0015474376268684864, 0.020594879984855652, -0.0823378786444664, -0.008933781646192074, -0.10719763487577438, -0.03571056202054024, -0.0188329815864563, 0.06929911673069, -0.014549840241670609, 0.03585057333111763, -0.009586757980287075, -0.024024013429880142, -0.01626574993133545, -0.013085535727441311, -0.044916000217199326, 0.047942038625478745, 0.0215988140553236, 0.016828926280140877, -0.06206498295068741, -0.028278900310397148, 0.05698652192950249, -0.006222082767635584, -0.04797103628516197, -0.06408272683620453, -0.08171497285366058, 0.13375113904476166, -0.06251370906829834, 0.06301110982894897, -0.07374947518110275, 0.03209039196372032, 0.04786212369799614, -0.015578634105622768, 0.07396990060806274, -0.007756014354526997, 0.04270211607217789, 0.036135170608758926, -0.01586015336215496, 0.04152829200029373, -0.07458686828613281, -0.001344276242889464, -0.08252881467342377, -0.053381338715553284, -0.061376433819532394, 0.08342339843511581, -0.049895960837602615, -4.993111701878661e-08, 0.012238004244863987, 0.03632398322224617, -0.017445974051952362, 0.008653690107166767, 0.07233244925737381, -0.04189205914735794, -0.04192284122109413, -0.018586289137601852, 0.06369840353727341, 0.0499948225915432, -0.04761091247200966, -0.023272329941391945, 0.018689263612031937, 0.09995684772729874, 0.08751431852579117, 0.03273451700806618, -0.015552068129181862, 0.007468043360859156, -0.02565283328294754, 0.02117781713604927, 0.05973173677921295, 0.03312858194112778, 0.03760503605008125, -0.07589765638113022, -0.030653156340122223, -0.07423902302980423, -0.003931176383048296, 0.01512227114289999, -0.00670779962092638, 0.09059885889291763, -0.0766221433877945, -0.01892896182835102, -0.005968139972537756, -0.03601760044693947, 0.03718472644686699, -0.011435781605541706, -0.036140862852334976, -0.019099468365311623, 0.03753381222486496, 0.03465186432003975, 0.03299384564161301, 0.038058649748563766, 0.012214620597660542, 0.0354495532810688, -0.006857134867459536, -0.04267042502760887, -0.11182691156864166, -0.017160402610898018, 0.0469893142580986, -0.02143210358917713, 0.02862793765962124, -0.0010708236368373036, -0.014473306946456432, 0.034769877791404724, 0.0643499493598938, 0.004371725954115391, -0.017828352749347687, 0.02905028685927391, -0.08433257043361664, 0.0553165003657341, 0.08664107322692871, -0.0962853655219078, 0.006345673929899931, -0.031200040131807327]",
         "0.204"
        ],
        [
         "46",
         "16",
         "Artist explores the toxic mining legacy of Zambia's 'black mountains'",
         "A major exhibition about the dangerous lives of the boys and young men who scour slag heaps in search of copper.",
         "Artist explores the toxic mining legacy of Zambia's 'black mountains'\n\n3 hours ago Share Save Penny Dale Lusaka Share Save\n\nStary Mwaba\n\nZambia's notorious \"black mountains\" - huge heaps of mining waste that scar the Copperbelt skyline - are deeply personal to Stary Mwaba, one of the country's leading visual artists. \"As kids, we used to call it 'mu danger' - meaning 'in the danger',\" Mwaba tells the BBC. \"The 'black mountain' was this place where you shouldn't go,\" says the painter, who was born and lived in the Copperbelt until he was 18. \"But we would sneak in anyway - to pick the wild fruits that somehow managed to grow there,\" the artist recalls. Nowadays, the young men heading to \"mu danger\" are looking for fragments of copper ore in the stony slag of these towering dumpsites - the toxic legacy of a century of industrial mining production in Zambia, one of the world's biggest copper and cobalt producers. They dig deep and meandering tunnels - and hew out rocks to sell to mostly Chinese buyers, who then extract copper. It is tough, dangerous, often illegal and sometimes fatal work. But it can also be lucrative - and, in a region where youth unemployment is about 45%, for some young people it is the only way that they can make ends meet.\n\nStary Mwaba Title: Mine shaft, just a T-shirt - the dangerous work is often the only way young people in the Copperbelt can make a living\n\nMwaba's latest work - on show at the Lusaka National Museum this month - tells the story of the young people who mine the black mountain in the town of Kitwe - and captures the rhythms of life among the residents of the Wusakile neighbourhood. They work for gang masters known as \"jerabos\", a corruption of \"jail boys\" - hinting at their perceived criminality. The artist has painted a series of large portraits, using old newspapers as a canvas. He cuts out articles that grab his attention - what he refers to as \"grand narratives\" - and sticks them on to a backing paper. He uses a soldering gun to burn away some of the words and create a series of perforations in the stories. Then he pours in paint to create the portraits, or what he calls the \"little narratives\". \"I take these grand narratives, and I create holes so that you can't make sense of the stories any more. I then impose images of people I know on to them - to show that little stories, the little narratives of ordinary people also count,\" Mwaba explains. \"They have stories that are important and are part of the bigger story.\"\n\nStary Mwaba Title: Mwenge - Mwaba held workshops in Kitwe and heard first-hand stories of hardship and survival\n\nThe portraits can be seen from both sides and, in characteristic Mwaba style, are brightly coloured. The artworks are coated with a transparent acrylic and the borders of newspaper held together with clear tape because they are very fragile - like the existence of the people Mwaba has painted. They live in the shadow of the black mountain - the site since the early 1930s of millions of tonnes of waste, full of toxic heavy metals - which wreaks havoc on people's health and the environment. One painting from his current work is entitled Jerabo and shows a miner preparing safety ropes that are tied around his waist as he lowers himself down narrow precarious tunnels, dug out by hand and prone to landslides.\n\nStary Mwaba Title: Jerabo - this young miner is depicted preparing a safety rope that will lower him into a tunnel\n\nEarlier this year, the entire water supply to Kitwe, home to about 700,000 people, was shut down after a catastrophic spill of waste from a nearby Chinese-owned copper mine into the streams that flow through neighbourhoods like Wusakile into one of Zambia's most important waterways, the Kafue River. Mwaba hears stories of hardship and survival during the drawing, photography and performance workshops that he and other artists have held over several years. Shofolo portrays a young man almost hugging his precious \"shofolo\" - the Zambian English, or Zamglish, word for shovel. Such tools are \"a personal lifeline\", Mwaba says.\n\nStary Mwaba Title: Shofolo - this is the name for shovel in Zambian English, essential for any young miner\n\nIpenga captures the tuba player of a local church group as he parades through the streets one Sunday morning. Most social lives in Wusakile revolve around either the church or the bar, Mwaba says.\n\nStary Mwaba Title: Ipenga - brass bands and gospel music are popular forms of entertainment\n\nBut the two young girls in Chimpelwa make their own fun on home-made swings. Strung up in the sturdy branches of a tree are yellow and blue heavy-duty cables - once high-voltage electrical cables, their copper wire innards have now been stripped out and sold as scrap metal.\n\nStary Mwaba Title: Chimpelwa - these young girls enjoy a swing made out of electrical cables once used in the mines\n\nMwaba comes from a family of miners - his great-grandfathers and one grandfather worked down the mines and his father above the ground. But the 49-year-old's interest in the impact of Zambia's mining as a subject for his paintings began almost accidentally in about 2011 - after he helped his daughter, Zoe, with a science project at the Chinese International School, which she attended in the capital, Lusaka. The task was to demonstrate how plants absorb minerals and water. He and Zoe went to the market and bought a Chinese cabbage. It is not indigenous but is now eaten in many Zambian homes. It has a white stem so is ideal to absorb the food dyes that Zoe decided to use to show how minerals would be similarly drawn into the plant. Mwaba remembers that the use of Chinese cabbage made the audience \"uneasy and so uncomfortable\".\n\nStary Mwaba Ten years ago Mwaba was inspired by his daughter's science project to use cabbages to explore the influence of Chinese mining companies in Zambia\n\nAt the time, the late Michael Sata was campaigning for the presidency - and tensions were high because of his vitriolic rhetoric against the Chinese, who are accused locally of dominating the Zambian economy and exploiting workers. So Mwaba turned the science project into a work of art - in which he explored the Chinese presence in Zambia's mining sector through three Chinese cabbage leaves, one dyed yellow to depict copper, one blue for cobalt and the third red for manganese. His Chinese Cabbage brought Mwaba much international acclaim, and he returned to Zambia in 2015, glowing with the success of an art residency and exhibition in Germany. He went to Kitwe, where he had spent some childhood years. But his focus changed from just exploring the Chinese presence in Zambia to trying to tell the story of the black mountain people. \"I went back to a place where I grew up and things had changed so much,\" the artist says, adding that he \"never, ever imagined that I would see the kind of the situation I see now - the poverty\". \"It was a very emotional space and I was sad,\" Mwaba says.\n\nStary Mwaba Title: Ba Bili - which means \"the two of us\" showing the joy of friendship in Wusakile\n\nMwaba had moved to Kasama in Northern Province in 1994, after his father suddenly died. Three years later Zambia's mines were privatised - leading to massive job losses and an unprecedented economic crisis in the Copperbelt. The black mountain - always a source of environmental and health problems - now became somewhere to earn money. \"The worst thing that happened is when the black mountain was super-profitable, most of these young people quit school.\" Unable to get a job anywhere else, Mwaba's cousin Ngolofwana joined a crew of jerabos. Every day he wakes up and risks his life just to stay afloat and feed his family. But even when the government has banned mining there, the dumpsite's wealth is tightly controlled by an aggressive hierarchy - with the top, sometimes very wealthy, jerabos often living up to their nickname. Frustrations further down the jerabo chain - of feeling exploited, giving up on education to fund someone else's lavish lifestyle, and having little say in their own futures - are reflected in the painting of one young man in a turquoise T-shirt standing with his hands confidently on his hips.\n\nStary Mwaba Title: Boss for a Day - reflects how the young miners feel exploited with little control over their futures\n\nBoss for a Day came out of a workshop in which Mwaba invited people to take their own photographs, striking a pose that reflected their hopes and dreams. And occasionally Mwaba's art may change the course of someone's life. Mwaba recalls a time where an older jerabo came to a workshop and said: \"Hey, I really like what you're doing. \"I think I may not understand it, but it's best for my young brother to be coming here because I don't want him to go through what I went through.\" Penny Dale is a freelance journalist, podcast and documentary-maker based in London\n\nMore BBC stories on Zambia:\n\nGetty Images/BBC",
         "2025-07-26T02:24:05",
         "https://feeds.bbci.co.uk/news/world/rss.xml",
         "https://www.bbc.com/news/articles/cvgewwvp00yo",
         "2025-07-26T05:41:35.671123",
         "Artist explores the toxic mining legacy of Zambia's 'black mountains' 3 hours ago Share Save Penny Dale Lusaka Share Save Stary Mwaba Zambia's notorious \"black mountains\" - huge heaps of mining waste that scar the Copperbelt skyline - are deeply personal to Stary Mwaba, one of the country's leading visual artists. \"As kids, we used to call it 'mu danger' - meaning 'in the danger',\" Mwaba tells the BBC. \"The 'black mountain' was this place where you shouldn't go,\" says the painter, who was born and lived in the Copperbelt until he was 18. \"But we would sneak in anyway - to pick the wild fruits that somehow managed to grow there,\" the artist recalls. Nowadays, the young men heading to \"mu danger\" are looking for fragments of copper ore in the stony slag of these towering dumpsites - the toxic legacy of a century of industrial mining production in Zambia, one of the world's biggest copper and cobalt producers. They dig deep and meandering tunnels - and hew out rocks to sell to mostly Chinese buyers, who then extract copper. It is tough, dangerous, often illegal and sometimes fatal work. But it can also be lucrative - and, in a region where youth unemployment is about 45%, for some young people it is the only way that they can make ends meet. Stary Mwaba Title: Mine shaft, just a T-shirt - the dangerous work is often the only way young people in the Copperbelt can make a living Mwaba's latest work - on show at the Lusaka National Museum this month - tells the story of the young people who mine the black mountain in the town of Kitwe - and captures the rhythms of life among the residents of the Wusakile neighbourhood. They work for gang masters known as \"jerabos\", a corruption of \"jail boys\" - hinting at their perceived criminality. The artist has painted a series of large portraits, using old newspapers as a canvas. He cuts out articles that grab his attention - what he refers to as \"grand narratives\" - and sticks them on to a backing paper. He uses a soldering gun to burn away some of the words and create a series of perforations in the stories. Then he pours in paint to create the portraits, or what he calls the \"little narratives\". \"I take these grand narratives, and I create holes so that you can't make sense of the stories any more. I then impose images of people I know on to them - to show that little stories, the little narratives of ordinary people also count,\" Mwaba explains. \"They have stories that are important and are part of the bigger story.\" Stary Mwaba Title: Mwenge - Mwaba held workshops in Kitwe and heard first-hand stories of hardship and survival The portraits can be seen from both sides and, in characteristic Mwaba style, are brightly coloured. The artworks are coated with a transparent acrylic and the borders of newspaper held together with clear tape because they are very fragile - like the existence of the people Mwaba has painted. They live in the shadow of the black mountain - the site since the early 1930s of millions of tonnes of waste, full of toxic heavy metals - which wreaks havoc on people's health and the environment. One painting from his current work is entitled Jerabo and shows a miner preparing safety ropes that are tied around his waist as he lowers himself down narrow precarious tunnels, dug out by hand and prone to landslides. Stary Mwaba Title: Jerabo - this young miner is depicted preparing a safety rope that will lower him into a tunnel Earlier this year, the entire water supply to Kitwe, home to about 700,000 people, was shut down after a catastrophic spill of waste from a nearby Chinese-owned copper mine into the streams that flow through neighbourhoods like Wusakile into one of Zambia's most important waterways, the Kafue River. Mwaba hears stories of hardship and survival during the drawing, photography and performance workshops that he and other artists have held over several years. Shofolo portrays a young man almost hugging his precious \"shofolo\" - the Zambian English, or Zamglish, word for shovel. Such tools are \"a personal lifeline\", Mwaba says. Stary Mwaba Title: Shofolo - this is the name for shovel in Zambian English, essential for any young miner Ipenga captures the tuba player of a local church group as he parades through the streets one Sunday morning. Most social lives in Wusakile revolve around either the church or the bar, Mwaba says. Stary Mwaba Title: Ipenga - brass bands and gospel music are popular forms of entertainment But the two young girls in Chimpelwa make their own fun on home-made swings. Strung up in the sturdy branches of a tree are yellow and blue heavy-duty cables - once high-voltage electrical cables, their copper wire innards have now been stripped out and sold as scrap metal. Stary Mwaba Title: Chimpelwa - these young girls enjoy a swing made out of electrical cables once used in the mines Mwaba comes from a family of miners - his great-grandfathers and one grandfather worked down the mines and his father above the ground. But the 49-year-old's interest in the impact of Zambia's mining as a subject for his paintings began almost accidentally in about 2011 - after he helped his daughter, Zoe, with a science project at the Chinese International School, which she attended in the capital, Lusaka. The task was to demonstrate how plants absorb minerals and water. He and Zoe went to the market and bought a Chinese cabbage. It is not indigenous but is now eaten in many Zambian homes. It has a white stem so is ideal to absorb the food dyes that Zoe decided to use to show how minerals would be similarly drawn into the plant. Mwaba remembers that the use of Chinese cabbage made the audience \"uneasy and so uncomfortable\". Stary Mwaba Ten years ago Mwaba was inspired by his daughter's science project to use cabbages to explore the influence of Chinese mining companies in Zambia At the time, the late Michael Sata was campaigning for the presidency - and tensions were high because of his vitriolic rhetoric against the Chinese, who are accused locally of dominating the Zambian economy and exploiting workers. So Mwaba turned the science project into a work of art - in which he explored the Chinese presence in Zambia's mining sector through three Chinese cabbage leaves, one dyed yellow to depict copper, one blue for cobalt and the third red for manganese. His Chinese Cabbage brought Mwaba much international acclaim, and he returned to Zambia in 2015, glowing with the success of an art residency and exhibition in Germany. He went to Kitwe, where he had spent some childhood years. But his focus changed from just exploring the Chinese presence in Zambia to trying to tell the story of the black mountain people. \"I went back to a place where I grew up and things had changed so much,\" the artist says, adding that he \"never, ever imagined that I would see the kind of the situation I see now - the poverty\". \"It was a very emotional space and I was sad,\" Mwaba says. Stary Mwaba Title: Ba Bili - which means \"the two of us\" showing the joy of friendship in Wusakile Mwaba had moved to Kasama in Northern Province in 1994, after his father suddenly died. Three years later Zambia's mines were privatised - leading to massive job losses and an unprecedented economic crisis in the Copperbelt. The black mountain - always a source of environmental and health problems - now became somewhere to earn money. \"The worst thing that happened is when the black mountain was super-profitable, most of these young people quit school.\" Unable to get a job anywhere else, Mwaba's cousin Ngolofwana joined a crew of jerabos. Every day he wakes up and risks his life just to stay afloat and feed his family. But even when the government has banned mining there, the dumpsite's wealth is tightly controlled by an aggressive hierarchy - with the top, sometimes very wealthy, jerabos often living up to their nickname. Frustrations further down the jerabo chain - of feeling exploited, giving up on education to fund someone else's lavish lifestyle, and having little say in their own futures - are reflected in the painting of one young man in a turquoise T-shirt standing with his hands confidently on his hips. Stary Mwaba Title: Boss for a Day - reflects how the young miners feel exploited with little control over their futures Boss for a Day came out of a workshop in which Mwaba invited people to take their own photographs, striking a pose that reflected their hopes and dreams. And occasionally Mwaba's art may change the course of someone's life. Mwaba recalls a time where an older jerabo came to a workshop and said: \"Hey, I really like what you're doing. \"I think I may not understand it, but it's best for my young brother to be coming here because I don't want him to go through what I went through.\" Penny Dale is a freelance journalist, podcast and documentary-maker based in London More BBC stories on Zambia: Getty Images/BBC",
         "en",
         "{'PER': ['I then', 'Mine shaft', 'Mwaba', 'Mwaba recalls', \"Mwaba'\", 'Ngolofwana', 'Penny Dale', 'Penny Dale Lusaka', 'Shofolo', 'depicted preparing', 'ever imagined that I would see the kind of the situation', 'feel exploited with little control over their futures Boss for a Day', 'striking'], 'MISC': ['Ba Bili', 'But even when the government has banned mining there', 'But his focus', 'Chimpelwa - these young girls enjoy a swing made out of electrical cables', 'Every day he wakes', 'Frustrations further down the jerabo', 'He and Zoe went to the market and bought', 'He cuts out articles', 'He uses a soldering gun to burn away some of the words and create', 'He went to Kitwe', 'His Chinese Cabbage brought Mwaba', \"I really like what you're doing\", 'I see now - the poverty', 'I think I may not understand it', 'Ipenga', 'It has a white stem so is ideal to absorb the food dyes that Zoe decided to use to show how minerals would be similarly drawn into the plant', 'It is not indigenous but is now eaten in many Zambian homes', 'It is tough', 'Jerabo and shows', 'Kitwe and heard first-hand stories of hardship and survival', 'Most social lives', 'Mwaba Title: Boss for a Day', 'Mwaba hears stories of hardship and survival during the drawing', 'Mwaba remembers that the use of Chinese cabbage made the audience', 'Mwaba says', 'Mwaba tells the BBC', \"Mwaba's latest work\", 'One painting from his', 'Share Save Stary', 'Stary Mwaba', 'Stary Mwaba Title', 'Strung up in the sturdy branches of a tree are yellow', 'Such tools are', 'The artist has painted', 'The artworks are coated with', 'The black mountain', 'The task was to demonstrate how plants absorb minerals and water', 'Then he pours in paint to create the portraits', 'They dig deep and meandering tunnels', 'They have stories that are important and are part of the bigger story', 'They live in the shadow of the black mountain', 'They work for gang masters known as', 'Three years', 'Wusakile', 'Wusakile Mwaba', 'Zambia', 'Zambia to trying to tell the story of the black mountain people', \"Zambia'\", \"Zambia's mining sector through three Chinese cabbage leaves\", 'Zambian English', 'Zamglish', 'Zoe, with a science project at the Chinese International School', 'adding that he \"never', \"and I create holes so that you can't make sense of the stories any more\", 'and he returned to Zambia', 'canvas', 'crisis in the Copperbelt', 'early 1930s of millions of tonnes of waste', \"giving up on education to fund someone else'\", 'glowing with the success of an art residency and exhibition in Germany', 'just a T-shirt', 'most of these young people', 'of dominating the Zambian economy and exploiting workers', 'often illegal and sometimes fatal work', 'one blue for cobalt and the third red for manganese', 'one dyed yellow', \"one of the country's leading visual artists\", \"one of the world's biggest copper and cobalt producers\", 'photography and performance workshops that he and other artists have held over several years', 'podcast and documentary-maker based in London More BBC stories on Zambia: Getty Images', 'preparing safety ropes that are tied around his waist as he lowers', 'safety rope that will lower him into a tunnel Earlier this year', 'show at the Lusaka National', 'that reflected their hopes and dreams', \"the dumpsite'\", 'the entire water supply to Kitwe', 'the influence of Chinese mining companies in Zambia At the time', 'the little narratives of ordinary people also count', 'the young men heading to \"mu danger', 'their copper wire innards have now been stripped out and sold as scrap metal', 'using old newspapers as', 'was shut down after', 'word for shovel', 'worked down the mines and his father above the ground'], 'ORG': ['As kids', 'BBC', \"Mwaba'\", 'Nowadays'], 'LOC': ['Chinese cabbage', 'Kafue River', 'Lusaka', 'who are']}",
         "[-0.09486982226371765, 0.06286510825157166, -0.05452287942171097, 0.07123619318008423, 0.06452751159667969, -0.004047587048262358, 0.010151036083698273, 0.031559813767671585, -0.06882373243570328, 0.001419076113961637, 0.02462947368621826, -0.10754290223121643, 0.049426399171352386, -0.0030051402281969786, -0.08593953400850296, 0.0272257998585701, 0.06729652732610703, -0.022301169112324715, -0.05988077446818352, 0.01815526932477951, 0.021886130794882774, 0.03830677643418312, 0.04498796910047531, -0.006905711255967617, -0.03907343000173569, 0.04630604758858681, -0.10725480318069458, 0.07587594538927078, 0.07565504312515259, -0.028035491704940796, 0.014262574724853039, 0.060540106147527695, -0.043209102004766464, 0.05152412876486778, 0.07393626868724823, 0.06423410773277283, -0.051026567816734314, 0.07144785672426224, -0.011753001250326633, -0.02267148531973362, -0.0011648182990029454, 0.013930640183389187, 0.045164790004491806, -0.08834362030029297, -0.021271102130413055, -0.061411578208208084, 0.08037535101175308, -0.07385348528623581, -0.047408558428287506, -0.0649513453245163, 0.0444740429520607, -0.010200186632573605, -0.05590786412358284, -0.008386469446122646, 0.06919807940721512, -0.12809453904628754, -0.010326026938855648, -0.0752582922577858, 0.018367385491728783, 0.006270937155932188, 0.006975258234888315, -0.01286357082426548, -0.03084062784910202, -0.0555264987051487, 0.10173283517360687, -0.04760349541902542, -0.051601581275463104, -0.012502018362283707, -0.021572940051555634, -0.00101807143073529, 0.04966156184673309, -0.07543410360813141, -0.089902862906456, -0.01698487624526024, -0.018881933763623238, 0.08637502789497375, 0.11870779097080231, -0.028641914948821068, -0.06262001395225525, -0.05977996811270714, 0.0004645726003218442, 0.06842218339443207, 0.0880478024482727, -0.07856830954551697, 0.04208318516612053, -0.002382896840572357, -0.06208006292581558, 0.003087989753112197, 0.0693216398358345, -0.08253151923418045, 0.06871446222066879, 0.039748385548591614, -0.013702558353543282, 0.14335212111473083, 0.06389466673135757, 0.024843785911798477, 0.021050533279776573, 0.02787424437701702, -0.0659114420413971, 0.020266912877559662, 0.05106126517057419, -0.006625475361943245, -0.029571305960416794, -0.0864337757229805, 0.003987737465649843, -0.05119430273771286, -0.0372425839304924, 0.13866311311721802, -0.052052393555641174, 0.022455230355262756, -0.008838199079036713, 0.03849415108561516, -0.061041057109832764, -0.0005906649748794734, 0.03323826938867569, 0.032814327627420425, -0.04493461176753044, -0.018875394016504288, -0.134356290102005, 0.04428236559033394, -0.05824242904782295, 0.03240343928337097, -0.06108331307768822, -0.05002664774656296, -0.02815827913582325, -0.034178659319877625, 0.04300940781831741, -3.523823496498127e-34, 0.06368622183799744, 0.005363266449421644, -0.05784371867775917, 0.0009167591924779117, 0.05906250700354576, 0.012238829396665096, -0.026702309027314186, -0.02232014387845993, 0.004462189041078091, 0.07352758198976517, -0.022607212886214256, 0.009088235907256603, -0.06410203129053116, 0.04168598726391792, -0.0010318560525774956, -0.033277831971645355, 0.014702805317938328, -0.1212131530046463, -0.03573989123106003, -0.06982709467411041, 0.014043498784303665, 0.007831891067326069, 0.008902541361749172, -0.035030558705329895, -0.003949866630136967, 0.04939396679401398, -0.05522650107741356, -0.06499695777893066, -0.009972489438951015, 0.02809353731572628, -0.03966105356812477, 0.018251774832606316, -0.023495102301239967, -0.05917995050549507, -0.037845298647880554, -0.0006749177118763328, -0.1292402744293213, 0.01364967506378889, -0.025390157476067543, -0.011054584756493568, -0.0007536857738159597, -0.042882148176431656, -0.061957597732543945, 0.06820224225521088, 0.05013039708137512, 0.08209877461194992, 0.016560500487685204, 0.006015527993440628, -0.11434290558099747, 0.016161732375621796, 0.007991082966327667, 0.026899117976427078, 0.04926189035177231, 0.06360991299152374, -0.017805783078074455, 0.0024932415690273046, 0.05143940821290016, -0.06985747069120407, 0.048611484467983246, -0.032326966524124146, 0.04823578521609306, 0.02488977275788784, -0.034834735095500946, 0.11196061968803406, -0.00011988670303253457, -0.09383629262447357, 0.045485518872737885, 0.055778197944164276, -0.012591807171702385, -0.027313634753227234, -0.048662420362234116, -0.00039972635568119586, -0.001635319204069674, -0.04797789081931114, 0.0037351164501160383, -0.043901536613702774, -0.04264698177576065, 0.014049391262233257, 0.05035841092467308, 0.04458172619342804, -0.0319395549595356, 0.06286042928695679, -0.004595620092004538, -0.020057998597621918, -0.06763538718223572, 0.014845709316432476, -0.003773067146539688, -0.06270711123943329, 0.01998557709157467, -0.03197616711258888, -0.06554701179265976, -0.033410124480724335, 0.013741857372224331, -0.05624379217624664, -0.01677202247083187, -1.1439382049744632e-33, 0.03197643160820007, 0.0036992633249610662, 0.03596644848585129, 0.030811328440904617, 0.013881443999707699, -0.10841577500104904, -0.02129977196455002, -0.011773576959967613, -0.00541128683835268, 0.02197384461760521, -0.010102925822138786, -0.03938974812626839, 0.015939464792609215, 0.010048973374068737, 0.08310922980308533, -0.038027599453926086, -0.017039937898516655, 0.13538989424705505, -0.04324261099100113, -0.03777390718460083, -0.010190973058342934, 0.014218238182365894, -0.11825022846460342, -0.05263859033584595, -0.05332325026392937, 0.03931193798780441, -0.054389432072639465, -0.07434629648923874, 0.05561026185750961, 0.057620517909526825, -0.051281511783599854, 0.14467753469944, -0.01919890195131302, 0.0029670498333871365, -0.0367911197245121, -0.006304881069809198, 0.035498932003974915, -0.04330641031265259, -0.03124973736703396, -0.031038247048854828, 0.11408782750368118, 0.0924617350101471, -0.019236627966165543, 0.06972220540046692, -0.06172109395265579, 0.02088950201869011, 0.027673952281475067, 0.01732001081109047, -0.02595951221883297, 0.04024824872612953, 0.12666882574558258, 0.07315511256456375, 0.027024291455745697, -0.0007784924819134176, 0.05884656682610512, -0.009631192311644554, -0.00050181127153337, -0.046697139739990234, -0.08016572147607803, 0.017161579802632332, -0.021145207807421684, 0.033999767154455185, -0.10218583792448044, 0.011869560927152634, 0.0031709775794297457, 0.07757667452096939, 0.03441189229488373, 0.04340018704533577, 0.0026329304091632366, -0.012009186670184135, 0.05529692396521568, -0.024915989488363266, -0.024499189108610153, -0.1016911119222641, 0.02431468293070793, -0.034998271614313126, -0.032506879419088364, 0.060562290251255035, 0.053109221160411835, -0.06973402947187424, 0.02263767644762993, -0.05360462889075279, 0.12632940709590912, 0.04907240346074104, 0.06444807350635529, 0.040629658848047256, -0.03303688392043114, -0.0052619134075939655, 0.02623656950891018, -0.045621734112501144, -0.032257258892059326, -0.10768508911132812, -0.012464849278330803, 0.05068923905491829, 0.02101242169737816, -4.693003319289346e-08, -0.03564610704779625, 0.03896455094218254, 0.01439489796757698, -0.009323017671704292, 0.039766374975442886, 0.025276655331254005, 0.015804419293999672, 0.04563569277524948, 0.04635707288980484, 0.1324567198753357, -0.024650216102600098, -0.012855077162384987, -0.013971060514450073, -0.013748050667345524, -0.07656900584697723, 0.07241642475128174, 0.0399787612259388, -0.03535688295960426, 0.021686630323529243, -0.04146863892674446, 0.015972131863236427, 0.01631484366953373, 0.09601272642612457, -0.009242155589163303, -0.01302624773234129, 0.006659828592091799, -0.0436544306576252, 0.008208023384213448, 0.020515961572527885, 0.026056306436657906, -0.009552134200930595, 0.020354336127638817, 0.01917576603591442, 0.05928950756788254, 0.014449624344706535, -0.015189161524176598, 0.04602200165390968, -0.07101434469223022, -0.05759763717651367, -0.011512870900332928, -0.056621432304382324, -0.019763849675655365, 0.09135238826274872, -0.016649913042783737, -0.012848792597651482, -0.0038913018070161343, -0.03848961368203163, 0.05013183504343033, 0.01903422363102436, -0.0011359897907823324, -0.03466492518782616, -0.015293972566723824, 0.07224481552839279, 0.025853188708424568, 0.03374044597148895, -0.00445449398830533, 0.008702357299625874, 0.0065956744365394115, -0.016641970723867416, 0.014768007211387157, 0.032276056706905365, -0.055432599037885666, -0.029486119747161865, -0.03740100562572479]",
         "0.194"
        ],
        [
         "47",
         "557",
         "Productivité : trois conseils pour tirer profit de l'IA sur le travail de vos effectifs",
         "Selon une étude, 80 % des professionnels pensent que l'intelligence artificielle aura un impact significatif sur leur boulot au cours de l'année à venir. Voici comment préparer votre personnel.",
         "Mihaela Rosu/Getty Images\n\nRecevez une sélection de conseils stratégiques et d'astuces concrètes chaque semaine dans votre boîte mail avec notre newsletter Guides pratiques. En savoir plus sur l’utilisation des données personnelles\n\nSi vous pensez que l'IA a déjà irrévocablement changé votre rôle, n'en restez pas là. Le plein impact de l'IA sur les le travail des professionnels se fera sentir dans les mois et les années à venir.\n\nC'est l'avis de Kirsty Roth, responsable des opérations et de la technologie chez Thomson Reuters, spécialiste des services d'information aux entreprises, qui s'est penchée sur l'étude récemment publiée par son entreprise sur l'utilisation de l'IA dans les entreprises modernes.\n\nL'enquête Future of Professionals Survey, qui a interrogé 2 275 professionnels et cadres supérieurs de plus de 50 pays, a révélé que 80 % des personnes interrogées pensent que l'IA aura un impact important, voire transformationnel, sur leur travail au cours des cinq prochaines années. Près des deux cinquièmes (38 %) s'attendent à voir ces changements dans leur organisation cette année.\n\n\"Il s'agit de personnes qui ont un travail quotidien normal\", a-t-elle déclaré. \"Nous ne parlons pas seulement d'ingénieurs ou de techniciens. Il s'agit de professionnels de tous les secteurs d'activité qui utilisent déjà l'IA.\"\n\nKirsty Roth a réfléchi au rythme du changement et a suggéré que les taux d'adoption de l'IA sont beaucoup plus rapides que lors des vagues de transformation numérique précédentes, telles que celles du commerce électronique ou du cloud computing.\n\nL'enquête a révélé que plus de la moitié (55 %) des professionnels ont connu des changements importants dans leur travail au cours de l'année écoulée ou prévoient des changements majeurs au cours de l'année à venir.\n\nToutefois, Mme Roth a déclaré à ZDNET que ces taux d'adoption de l'IA ne sont qu'un début, et que les professionnels et leurs boss devraient s'attendre à d'autres changements.\n\n\"L'impact sera énorme\", a-t-elle déclaré. \"De plus, nous n'en avons pas encore vu tous les effets. L'IA n'en est qu'à ses débuts.\"\n\nMme Roth, qui est en charge de la transformation basée sur l'IA dans sa propre entreprise, a déclaré que les chefs d'entreprise devraient se concentrer sur trois domaines lorsqu'ils se préparent au changement.\n\nÉtape 1 : rendez l'IA accessible\n\nSelon Mme Roth, les chefs d'entreprise doivent veiller à ce que leur personnel ait accès aux meilleurs outils possibles en fonction de leur domaine d'activité.\n\nL'étude de Thomson Reuters indique que près de la moitié (46 %) des organisations ont investi dans une nouvelle technologie alimentée par l'IA au cours de l'année écoulée, et que 30 % des professionnels utilisent régulièrement l'IA pour commencer ou modifier leur travail.\n\nSelon Mme Roth, les entreprises qui ne recherchent pas les outils adaptés à tel ou tel rôle spécifique ne seront pas en mesure de récolter les fruits de l'IA.\n\n\"Assurez-vous que tous les membres de votre entreprise ont accès à l'IA et l'utilisent\", a-t-elle déclaré.\n\n\"De nombreuses personnes parlent des opportunités de revenus ou d'efficacité offertes par les technologies émergentes. Je pense qu'il est essentiel de reconnaître que les professionnels qui n'utilisent pas l'IA se retrouveront rapidement dans l'incapacité de faire leur travail.\"\n\nLes répondants à l'enquête qui ont déclaré que leurs dirigeants donnaient l'exemple étaient 1,7 fois plus susceptibles de voir les avantages de l'IA que ceux qui ont déclaré que leurs dirigeants ne le faisaient pas.\n\nSelon Mme Roth, tous les membres de l'organisation doivent s'informer des utilisations de l'IA et de son impact potentiel : \"Nous avons tous le devoir de rester à la pointe de ces changements, sinon nous ne serons plus employés à l'avenir.\"\n\nÉtape 2 : partagez les meilleures pratiques\n\nAlors que plus de la moitié (53 %) des répondants à l'enquête ont déclaré qu'ils pensaient que leur organisation bénéficiait déjà de certains avantages de l'IA, près d'un tiers (30 %) ont affirmé que leur entreprise avançait trop lentement dans l'adoption de l'IA.\n\nL'étude suggère que la recherche d'un retour sur investissement de l'IA doit être un effort de collaboration entre les dirigeants, les utilisateurs et le personnel de soutien.\n\n\"Trouvez un bon moyen de partager les meilleures pratiques\", a déclaré Mme Roth. \"En règle générale, il y a des personnes créatives et compétentes dans certains secteurs de l'entreprise qui trouvent des moyens astucieux d'utiliser l'IA dans des cas d'utilisation plus avancés.\"\n\nToutefois, elle a mis en garde les autres chefs d'entreprise contre l'inutilité de ces bonnes idées si elles sont enfermées dans des zones confinées. \"Il faut partager ces idées et s'assurer que les gens comprennent ce qui fonctionne et ce qui ne fonctionne pas.\"\n\nÉtape 3 : parlez à vos pairs\n\nKirsty Roth a également encouragé les chefs d'entreprise et les professionnels à regarder au-delà du pare-feu.\n\nL'étude a révélé que les organisations qui disposent d'une stratégie visible en matière d'IA ont presque quatre fois plus de chances de bénéficier de l'IA que celles qui n'ont pas de plans d'adoption significatifs.\n\nElle a ajouté que les chefs d'entreprise et les responsables du numérique qui communiquent avec leurs pairs du secteur au sujet de leur stratégie en matière d'IA obtiendront des informations précieuses.\n\n\"Je parle tout le temps à mes pairs dans différents types d'entreprises pour savoir ce qu'ils font et ce qui fonctionne pour eux. Vous obtiendrez énormément d'informations de ce type\".\n\nSelon Mme Roth, la bonne nouvelle est que ses conversations avec d'autres DSI suggèrent que le potentiel de l'IA est largement reconnu.\n\n\"Ils ont juste besoin de s'assurer qu'ils ont le soutien de la direction pour mener à bien leurs changements, et d'une poignée de personnes compétentes pour les aider à réfléchir aux cas d'utilisation qui vont fonctionner et à la manière de mettre en œuvre la transformation.\n\nSuivez et tracez les avantages de l'IA\n\nL'étude de Thomson Reuters suggère que les entreprises qui encouragent, favorisent et développent un intérêt professionnel naissant pour l'IA bénéficient d'avantages significatifs.\n\nLes répondants à l'enquête ont prédit que l'IA leur ferait gagner cinq heures par semaine ou environ 240 heures au cours de l'année à venir, pour une valeur annuelle moyenne de 19 000 dollars par professionnel.\n\nToutefois, il n'est pas facile de prouver que votre organisation obtient ce type de résultats.\n\nMme Roth a déclaré que, d'après son expérience, de nombreuses entreprises ont du mal à comprendre où les gens passent leurs journées de travail et comment l'IA peut les aider à gagner du temps.\n\nC'est un problème quand l'une des affirmations souvent répétées à propos de l'IA est qu'elle aide les gens à réduire la charge administrative et à se concentrer sur des tâches dites à plus forte valeur ajoutée.\n\n\"Ce que nous découvrons, c'est que si vous posez la question aux gens, ils ne sont pas très doués pour deviner comment l'IA leur fait gagner du temps\", a-t-elle déclaré.\n\nSelon Mme Roth, les chefs d'entreprise qui veillent à ce que leurs effectifs ne soit pas laissés pour compte à mesure que la transformation de l'IA s'accélère trouvent des moyens de suivre et de tracer les avantages.\n\n\"Il faut s'assurer que l'utilisation est claire. Par exemple, lorsque nous avons commencé, nous nous sommes simplement demandé si les gens utilisaient les outils. C'était une question de haut niveau\", a-t-elle déclaré.\n\n\"Aujourd'hui, nous sommes beaucoup plus précis et nous demandons : \"Les gens utilisent-ils les outils tous les jours ? Font-ils partie intégrante de leur méthode de travail ? Les utilisent-ils pendant un certain temps au cours de la journée ?\" Pour réussir, il faut avoir une idée beaucoup plus précise de la manière dont les outils d'IA sont utilisés dans le flux de travail quotidien d'une personne, plutôt que de se contenter de résumer une réunion.\"\n\nKirsty Roth a donné un exemple tiré de sa propre société. Les ingénieurs qui utilisent l'IA pour accélérer leur temps de codage ont exponentiellement plus de temps pour se concentrer sur des tâches de plus grande valeur, qui, selon elle, comprennent le développement de nouvelles idées et de nouveaux modèles d'entreprise.\n\n\"Ce que nous commençons à voir chez nos meilleurs ingénieurs, c'est que certaines tâches simples, comme le codage et les tests, sont réduites de manière significative\", a-t-elle déclaré.\n\n\"Ils ont donc plus de temps pour réfléchir à la suite des événements. Qu'est-ce que je veux construire après cela ? Et qu'est-ce que mon client veut que je mette dans le produit qui va suivre ? Un tel changement dans l'allocation de leur temps est un grand avantage\".\n\nSource : \"ZDNet.com\"",
         "2025-07-21T04:07:54",
         "https://www.zdnet.fr/feeds/rss/actualites/",
         "https://www.zdnet.fr/pratique/productivite-trois-conseils-pour-tirer-profit-de-lia-sur-le-travail-de-vos-effectifs-479195.htm#xtor=RSS-1",
         "2025-07-26T06:23:31.221617",
         "Mihaela Rosu/Getty Images Recevez une sélection de conseils stratégiques et d'astuces concrètes chaque semaine dans votre boîte mail avec notre newsletter Guides pratiques. En savoir plus sur l’utilisation des données personnelles Si vous pensez que l'IA a déjà irrévocablement changé votre rôle, n'en restez pas là. Le plein impact de l'IA sur les le travail des professionnels se fera sentir dans les mois et les années à venir. C'est l'avis de Kirsty Roth, responsable des opérations et de la technologie chez Thomson Reuters, spécialiste des services d'information aux entreprises, qui s'est penchée sur l'étude récemment publiée par son entreprise sur l'utilisation de l'IA dans les entreprises modernes. L'enquête Future of Professionals Survey, qui a interrogé 2 275 professionnels et cadres supérieurs de plus de 50 pays, a révélé que 80 % des personnes interrogées pensent que l'IA aura un impact important, voire transformationnel, sur leur travail au cours des cinq prochaines années. Près des deux cinquièmes (38 %) s'attendent à voir ces changements dans leur organisation cette année. \"Il s'agit de personnes qui ont un travail quotidien normal\", a-t-elle déclaré. \"Nous ne parlons pas seulement d'ingénieurs ou de techniciens. Il s'agit de professionnels de tous les secteurs d'activité qui utilisent déjà l'IA.\" Kirsty Roth a réfléchi au rythme du changement et a suggéré que les taux d'adoption de l'IA sont beaucoup plus rapides que lors des vagues de transformation numérique précédentes, telles que celles du commerce électronique ou du cloud computing. L'enquête a révélé que plus de la moitié (55 %) des professionnels ont connu des changements importants dans leur travail au cours de l'année écoulée ou prévoient des changements majeurs au cours de l'année à venir. Toutefois, Mme Roth a déclaré à ZDNET que ces taux d'adoption de l'IA ne sont qu'un début, et que les professionnels et leurs boss devraient s'attendre à d'autres changements. \"L'impact sera énorme\", a-t-elle déclaré. \"De plus, nous n'en avons pas encore vu tous les effets. L'IA n'en est qu'à ses débuts.\" Mme Roth, qui est en charge de la transformation basée sur l'IA dans sa propre entreprise, a déclaré que les chefs d'entreprise devraient se concentrer sur trois domaines lorsqu'ils se préparent au changement. Étape 1 : rendez l'IA accessible Selon Mme Roth, les chefs d'entreprise doivent veiller à ce que leur personnel ait accès aux meilleurs outils possibles en fonction de leur domaine d'activité. L'étude de Thomson Reuters indique que près de la moitié (46 %) des organisations ont investi dans une nouvelle technologie alimentée par l'IA au cours de l'année écoulée, et que 30 % des professionnels utilisent régulièrement l'IA pour commencer ou modifier leur travail. Selon Mme Roth, les entreprises qui ne recherchent pas les outils adaptés à tel ou tel rôle spécifique ne seront pas en mesure de récolter les fruits de l'IA. \"Assurez-vous que tous les membres de votre entreprise ont accès à l'IA et l'utilisent\", a-t-elle déclaré. \"De nombreuses personnes parlent des opportunités de revenus ou d'efficacité offertes par les technologies émergentes. Je pense qu'il est essentiel de reconnaître que les professionnels qui n'utilisent pas l'IA se retrouveront rapidement dans l'incapacité de faire leur travail.\" Les répondants à l'enquête qui ont déclaré que leurs dirigeants donnaient l'exemple étaient 1,7 fois plus susceptibles de voir les avantages de l'IA que ceux qui ont déclaré que leurs dirigeants ne le faisaient pas. Selon Mme Roth, tous les membres de l'organisation doivent s'informer des utilisations de l'IA et de son impact potentiel : \"Nous avons tous le devoir de rester à la pointe de ces changements, sinon nous ne serons plus employés à l'avenir.\" Étape 2 : partagez les meilleures pratiques Alors que plus de la moitié (53 %) des répondants à l'enquête ont déclaré qu'ils pensaient que leur organisation bénéficiait déjà de certains avantages de l'IA, près d'un tiers (30 %) ont affirmé que leur entreprise avançait trop lentement dans l'adoption de l'IA. L'étude suggère que la recherche d'un retour sur investissement de l'IA doit être un effort de collaboration entre les dirigeants, les utilisateurs et le personnel de soutien. \"Trouvez un bon moyen de partager les meilleures pratiques\", a déclaré Mme Roth. \"En règle générale, il y a des personnes créatives et compétentes dans certains secteurs de l'entreprise qui trouvent des moyens astucieux d'utiliser l'IA dans des cas d'utilisation plus avancés.\" Toutefois, elle a mis en garde les autres chefs d'entreprise contre l'inutilité de ces bonnes idées si elles sont enfermées dans des zones confinées. \"Il faut partager ces idées et s'assurer que les gens comprennent ce qui fonctionne et ce qui ne fonctionne pas.\" Étape 3 : parlez à vos pairs Kirsty Roth a également encouragé les chefs d'entreprise et les professionnels à regarder au-delà du pare-feu. L'étude a révélé que les organisations qui disposent d'une stratégie visible en matière d'IA ont presque quatre fois plus de chances de bénéficier de l'IA que celles qui n'ont pas de plans d'adoption significatifs. Elle a ajouté que les chefs d'entreprise et les responsables du numérique qui communiquent avec leurs pairs du secteur au sujet de leur stratégie en matière d'IA obtiendront des informations précieuses. \"Je parle tout le temps à mes pairs dans différents types d'entreprises pour savoir ce qu'ils font et ce qui fonctionne pour eux. Vous obtiendrez énormément d'informations de ce type\". Selon Mme Roth, la bonne nouvelle est que ses conversations avec d'autres DSI suggèrent que le potentiel de l'IA est largement reconnu. \"Ils ont juste besoin de s'assurer qu'ils ont le soutien de la direction pour mener à bien leurs changements, et d'une poignée de personnes compétentes pour les aider à réfléchir aux cas d'utilisation qui vont fonctionner et à la manière de mettre en œuvre la transformation. Suivez et tracez les avantages de l'IA L'étude de Thomson Reuters suggère que les entreprises qui encouragent, favorisent et développent un intérêt professionnel naissant pour l'IA bénéficient d'avantages significatifs. Les répondants à l'enquête ont prédit que l'IA leur ferait gagner cinq heures par semaine ou environ 240 heures au cours de l'année à venir, pour une valeur annuelle moyenne de 19 000 dollars par professionnel. Toutefois, il n'est pas facile de prouver que votre organisation obtient ce type de résultats. Mme Roth a déclaré que, d'après son expérience, de nombreuses entreprises ont du mal à comprendre où les gens passent leurs journées de travail et comment l'IA peut les aider à gagner du temps. C'est un problème quand l'une des affirmations souvent répétées à propos de l'IA est qu'elle aide les gens à réduire la charge administrative et à se concentrer sur des tâches dites à plus forte valeur ajoutée. \"Ce que nous découvrons, c'est que si vous posez la question aux gens, ils ne sont pas très doués pour deviner comment l'IA leur fait gagner du temps\", a-t-elle déclaré. Selon Mme Roth, les chefs d'entreprise qui veillent à ce que leurs effectifs ne soit pas laissés pour compte à mesure que la transformation de l'IA s'accélère trouvent des moyens de suivre et de tracer les avantages. \"Il faut s'assurer que l'utilisation est claire. Par exemple, lorsque nous avons commencé, nous nous sommes simplement demandé si les gens utilisaient les outils. C'était une question de haut niveau\", a-t-elle déclaré. \"Aujourd'hui, nous sommes beaucoup plus précis et nous demandons : \"Les gens utilisent-ils les outils tous les jours ? Font-ils partie intégrante de leur méthode de travail ? Les utilisent-ils pendant un certain temps au cours de la journée ?\" Pour réussir, il faut avoir une idée beaucoup plus précise de la manière dont les outils d'IA sont utilisés dans le flux de travail quotidien d'une personne, plutôt que de se contenter de résumer une réunion.\" Kirsty Roth a donné un exemple tiré de sa propre société. Les ingénieurs qui utilisent l'IA pour accélérer leur temps de codage ont exponentiellement plus de temps pour se concentrer sur des tâches de plus grande valeur, qui, selon elle, comprennent le développement de nouvelles idées et de nouveaux modèles d'entreprise. \"Ce que nous commençons à voir chez nos meilleurs ingénieurs, c'est que certaines tâches simples, comme le codage et les tests, sont réduites de manière significative\", a-t-elle déclaré. \"Ils ont donc plus de temps pour réfléchir à la suite des événements. Qu'est-ce que je veux construire après cela ? Et qu'est-ce que mon client veut que je mette dans le produit qui va suivre ? Un tel changement dans l'allocation de leur temps est un grand avantage\". Source : \"ZDNet.com\"",
         "fr",
         "{'PER': ['Assurez', 'Kirsty Roth', 'Mihaela Rosu/Getty', 'Mme Roth'], 'MISC': ['Future of Professionals Survey', 'Guides pratiques', 'Si', 'cloud computing'], 'ORG': [\"L'impact\", 'Thomson Reuters'], 'LOC': ['ZDNET', 'ZDNet.com']}",
         "[-0.06620419770479202, 0.024559546262025833, -0.05699286609888077, -0.011964244768023491, -0.015658708289265633, 0.04260692000389099, 0.026683615520596504, 0.07613921910524368, 0.021812815219163895, 0.016293169930577278, -0.02515484392642975, -0.019621824845671654, 0.0451800562441349, 0.03281080350279808, -0.01929786428809166, -0.05726033076643944, -0.030212948098778725, -0.019768573343753815, -0.018775513395667076, 0.08858945965766907, -0.04425595700740814, -0.10251765698194504, 0.006823436357080936, -0.014977929182350636, 0.01701219193637371, -0.05197066068649292, -0.05788232386112213, -0.017293747514486313, -0.059345223009586334, -0.06126697361469269, -0.0072870259173214436, 0.08260094374418259, 0.04505298286676407, 0.002713856752961874, 0.03304050862789154, -0.0019944426603615284, 0.02894648350775242, -0.014055467210710049, 0.014361116103827953, 0.09071194380521774, -0.08037418872117996, -0.04647412523627281, -0.1101757138967514, -0.0797041580080986, 0.02259623073041439, -0.04056979715824127, 0.09280731528997421, 0.012337756343185902, -0.09301334619522095, 0.03506780043244362, -0.11161337792873383, -0.02383580431342125, 0.11630454659461975, -0.015107687562704086, -0.020119626075029373, -0.07083196938037872, -0.014820032753050327, 0.004446983337402344, 0.020478643476963043, 0.0145777752622962, -0.023332687094807625, -0.030780047178268433, -0.0606033019721508, -0.01235551480203867, -0.007181723602116108, -0.032659851014614105, -0.02635570615530014, -0.03340723738074303, -0.03702670708298683, -0.08313260972499847, -0.006418909877538681, -0.03772008791565895, -0.02507012151181698, 0.002419926691800356, 0.08156156539916992, 0.001032415428198874, -0.015712078660726547, 0.039687857031822205, -0.006607969757169485, -0.1872764229774475, 0.1189277172088623, -0.022555671632289886, -0.029373297467827797, 0.030375655740499496, -0.027101440355181694, -0.030871106311678886, 0.002820233115926385, 0.017085392028093338, 0.0754890963435173, -0.011148329824209213, 0.012622729875147343, 0.014882517047226429, -0.04544984921813011, -0.0013064396334812045, 0.052168864756822586, -0.007833251729607582, -0.038670849055051804, -0.048246655613183975, 0.01981367915868759, 0.02745760977268219, 0.026086725294589996, 0.015221299603581429, 0.0340917743742466, 0.019115304574370384, -0.08081568032503128, -0.041402459144592285, -0.031148018315434456, 0.006250114645808935, -0.08473464846611023, 0.03354023024439812, -0.034978292882442474, 0.04095771163702011, -0.08710099011659622, -0.08692055940628052, 0.0317930169403553, -0.040636468678712845, -0.029083041474223137, 0.019093161448836327, 0.020716480910778046, -0.011182677000761032, 0.028200644999742508, 0.0606519877910614, -0.07538789510726929, -0.07489271461963654, 0.017098024487495422, 0.0022324896417558193, -0.0004609273455571383, 1.0641571829789638e-32, -0.0018347466830164194, 0.08113843947649002, -0.04446263238787651, 0.053886573761701584, 0.02172667719423771, -0.002380630001425743, -0.06156076863408089, 0.05622576177120209, 0.03771969676017761, -0.060165200382471085, -0.053950291126966476, 0.1553071290254593, 0.029700033366680145, 0.029691876843571663, 0.04175688698887825, 0.03404581919312477, 0.061107341200113297, 0.03137454017996788, 0.04219115525484085, 0.026511946693062782, -0.06994733214378357, 0.02128329873085022, 0.029589403420686722, 0.08795086294412613, 0.09794259071350098, 0.008929806761443615, 0.03919520229101181, -0.028923649340867996, -0.07170676440000534, 0.042793501168489456, 0.10493316501379013, 0.001095498213544488, -0.030368294566869736, -0.0312507189810276, 0.011194386519491673, -0.02551463432610035, -0.017831139266490936, 0.00616005714982748, 0.012916004285216331, 0.01248401589691639, -0.03725869208574295, 0.03902479633688927, 0.04642188176512718, 0.06751477718353271, -0.035637084394693375, 0.06057986244559288, 0.045377906411886215, 0.02094339206814766, 0.08963119983673096, -0.016711492091417313, 0.006930673960596323, -0.024754371494054794, -0.06367790699005127, 0.004430152475833893, 0.03549083694815636, -0.060030046850442886, -0.019091617316007614, -0.07449812442064285, -0.045624881982803345, -0.031116770580410957, -0.016770655289292336, 0.006810956634581089, -0.006524479016661644, -0.009785017929971218, -0.04221770167350769, -0.029192833229899406, -0.04503213241696358, 0.017938746139407158, 0.09495875984430313, 0.010767307132482529, -0.07546614855527878, 0.03945399820804596, 0.06542225182056427, -0.014823240227997303, -0.008693213574588299, 0.03587138280272484, -0.07048419117927551, 0.0011682093609124422, -0.0020226079504936934, 0.09285152703523636, -0.050250329077243805, 0.0030147130601108074, -0.01525223720818758, -0.07139959186315536, 0.08784501254558563, 0.011495963670313358, 0.09297638386487961, 0.020061885938048363, 0.029819386079907417, 0.06328652799129486, -0.0354868546128273, -0.005929959937930107, -0.044010013341903687, 0.06901571899652481, 0.020561181008815765, -1.33851029108959e-32, -0.04273290932178497, 0.0018376386724412441, -0.093942791223526, 0.0316869355738163, -0.03617912903428078, 0.01648825779557228, 0.031141135841608047, 0.013959899544715881, 0.028335396200418472, -0.05430179834365845, -0.005729396361857653, -0.0786416158080101, -0.03154439851641655, 0.006270209327340126, -0.08793556690216064, 0.031090091913938522, -0.12186487764120102, -0.10551249980926514, -0.048055458813905716, 0.00492229126393795, -0.01255789678543806, 0.025261612609028816, 0.03537311777472496, 0.0426449328660965, 0.027645861729979515, 0.005887589417397976, -0.02479318156838417, 0.02986755594611168, -0.0334489606320858, -0.03883549943566322, -0.00877394713461399, -0.08563490211963654, 0.00026867800625041127, 0.11108998954296112, 0.013297272846102715, -0.009386352263391018, 0.06488955765962601, -0.001151425763964653, 0.01730543188750744, 0.0410117581486702, 0.06883875280618668, 0.001344324555248022, -0.03377354145050049, -0.03321529179811478, -0.001278554555028677, -0.07752816379070282, -0.078123539686203, -0.1374925971031189, 0.04795791581273079, -0.1023080125451088, 0.06826025992631912, 0.0024668467231094837, -0.017620695754885674, 0.025347519665956497, -0.027715150266885757, -0.004601757507771254, -0.07083866745233536, -0.03358560428023338, -0.07736863195896149, 0.055621031671762466, 0.07546279579401016, 0.1288173645734787, 0.02603423222899437, 0.033839546144008636, 0.06714662909507751, -0.08444473147392273, 0.02021331526339054, -0.03443494066596031, -0.041279762983322144, -0.03058057278394699, 0.059501830488443375, -0.05251052975654602, 0.0539519265294075, -0.04147019982337952, -0.0249932873994112, 0.011939761228859425, -0.014973302371799946, 0.04298178851604462, -0.018323538824915886, 0.12390182912349701, -0.11288256198167801, -0.02734534442424774, -0.03013071045279503, 0.021949918940663338, -0.01901923678815365, 0.06063110753893852, 0.03432467207312584, -0.000825833179987967, 0.027176115661859512, -0.06565660983324051, 0.04614308848977089, -0.010573669336736202, -0.000920425052754581, 0.012701209634542465, 0.017226239666342735, -7.825975956166076e-08, -0.005493832286447287, -0.0589442104101181, -0.07408352941274643, 0.04507696256041527, 0.03683203086256981, -0.11178067326545715, -0.04429097846150398, 0.018787050619721413, -0.024594739079475403, 0.08606576919555664, 0.01441998966038227, 0.017343195155262947, -0.07675785571336746, -0.028037864714860916, 0.04062788188457489, -0.03898686170578003, -0.04465741664171219, 0.007422254886478186, -0.024550380185246468, -0.07753258943557739, 0.11892114579677582, -0.05356829613447189, -0.037280503660440445, -0.040813274681568146, -0.038574427366256714, -0.005649082828313112, -0.07560310512781143, -0.1079293042421341, -0.029504641890525818, 0.013854099437594414, -0.04535564407706261, -0.05159953609108925, 0.03773631528019905, -0.0626010075211525, 0.008712956681847572, -0.06761394441127777, 0.025411101058125496, -0.03353862836956978, -0.03266217187047005, 0.09061261266469955, 0.13872788846492767, -0.06537824124097824, -0.04607401788234711, 0.03504490479826927, 0.049494605511426926, -0.0617155022919178, -0.03623063489794731, 0.015576263889670372, 0.051366936415433884, -0.011392959393560886, 0.01455868873745203, 0.023556334897875786, 0.03288104757666588, 0.09624528139829636, -0.06938805431127548, -0.007513430900871754, 0.01851140707731247, -0.05102476477622986, -0.031883854418992996, 0.05336732044816017, 0.005811113864183426, -0.032200925052165985, -0.02781345136463642, 0.0029704661574214697]",
         "0.18"
        ],
        [
         "48",
         "583",
         "From Rules to Relationships: How Machines Are Learning to Understand Each Other",
         "Using knowledge graphs to handle the unexpected in semantic communication The post From Rules to Relationships: How Machines Are Learning to Understand Each Other appeared first on Towards Data Science .",
         "Communication systems have evolved from simple bit transmission to intelligent information sharing. Traditional systems focus on moving raw data from point A to point B as reliably as possible. Now, with the explosion of machine-to-machine communication in IoT devices, autonomous systems, and smart infrastructure, we’re hitting a fundamental bottleneck.\n\nModern networks are drowning in unnecessary data. But machines don’t need every bit of information that traditional systems transmit.\n\nLet’s take a look at the following security monitoring interaction:\n\nSecurity Camera: Spots someone walking around in a restricted area during off-hours and captures a high-resolution video frame of size 5 MB\n\nTraditional System: Sends the entire 5MB frame with every single bit\n\nCentral Monitoring: Analyzes frame and determines: “Unauthorized person detected in Zone A”\n\nIn this interaction, the monitoring system primarily cares about the security alert rather than the person’s clothing details, facial features, or background. But traditional communication gives equal importance to every pixel, transmitting millions of irrelevant bits along with the few that matter for decision-making.\n\nSemantic communication emerged as a paradigm shift that transmits meaning rather than bits. Instead of sending the entire 5MB video frame, a semantic communication system would extract and transmit only: “zone_A, unauthorized_person, threat_level_high” while requiring just a tiny fraction of data, while preserving all decision-relevant information.\n\nThe receiving system gets exactly what it needs to make the right decision by deploying security personnel to Zone A for an unauthorized intrusion.\n\nEarly systems relied on Semantic Knowledge Bases (SKBs) to reduce bandwidth usage without losing the actual meaning of the message.\n\nBut SKB-based systems have limitations. They work well in controlled environments but fail when encountering unknown scenarios. This limitation sparked the development of knowledge graph-based semantic communication that promises to solve unknown situations through relational reasoning.\n\nWhy does SKBs-based semantic communication fail?\n\nSKB systems have a critical weakness. To understand it, we first need to see how they process information.\n\nIn our security monitoring example, both the camera and monitoring station maintain a shared knowledge base K = {k m ∈ Rd} {m∈M} where each k m represents semantic attributes for category m. When a security camera captures a video frame x, the semantic encoder S_α(·) extracts features s ∈ Rd.\n\nInstead of transmitting “s” directly, the system finds the closest match using cosine similarity:\n\nImage Source: SKB Paper[1]\n\nwhere D(s, k m ) represents the cosine similarity between s and k m .\n\nIn our example, the camera sees someone in a restricted area and extracts features like “human shape, no uniform, nighttime movement.” It compares these against its knowledge base and finds the best match is “unauthorized_person” at index v in the knowledge base. Instead of sending all the feature details, it just transmits “v.”\n\nThis simple approach significantly reduces bandwidth usage while preserving all the information the monitoring system needs to make decisions.\n\nWhere does this break down?\n\nThe system works great until something unexpected shows up. What happens when the camera spots something that’s not in its knowledge base?\n\nLet’s look at the following example:\n\nSecurity Camera: Spots a maintenance worker in work clothes carrying tools during off-hours.\n\nSKB System: Only knows “unauthorized_person,” “authorized_person,” “vehicle,” “animal”\n\nSystem Decision: Confidently classifies worker as “unauthorized_person” with high threat level\n\nResult: False alarm — security team gets dispatched to stop legitimate maintenance work\n\nThe math behind this might seem simple, but it’s actually quite problematic. The system always picks the “best” match, even when all the options are terrible. It’s like being forced to choose an answer on a multiple-choice test when none of the choices make sense. You still have to pick something, and the system has no way to say it doesn’t know.\n\nThese problems get worse in real deployments. For example, if your training data didn’t include shadows, the system starts calling them “intruders.” Train without winter clothing examples, and it thinks heavy coats are “suspicious gear.” The system never admits uncertainty. It always sounds confident, even when it’s completely wrong.\n\nHow do Knowledge Graphs Fix this?\n\nKnowledge graph based semantic communication solves SKB limitations by encoding relationships between nodes rather than just isolated categories. Instead of asking “which category does this match?” it asks “how does this relate to what I already know?”\n\nLet’s walk through our maintenance worker example to see the difference:\n\nStep 1: Detection and Feature Extraction\n\nThe camera detects the same features as before, such as “human shape, work clothes, carrying tools, off-hours timing”\n\nStep 2: Relationship Mapping\n\nInstead of forcing these features into a single category, the knowledge graph maps them to multiple connected nodes.\n\nHuman shape → triggers “human” node\n\nWork clothes + tools → triggers “work_tools” and “maintenance_equipment” nodes\n\nOff-hours timing → triggers “unusual_access_time” node\n\nStep 3: Relationship Traversal\n\nTo track connections between nodes, the system uses following formula:\n\nImage source: Knowledge Graph Paper [2]\n\nwhere “z v ” denotes the updated representation of node v, and the sum aggregates information from all neighboring nodes u. Each node picks up its meaning from the neighbors it’s connected to.\n\nwork_tools → indicates → maintenance_activity\n\nmaintenance_activity → performed_by → maintenance_worker\n\nmaintenance_worker → is_a → authorized_personnel (conditional)\n\noff_hours_access + authorized_personnel → requires → verification\n\nStep 4: Contextual Reasoning\n\nThe knowledge graph combines these relationship paths: “This appears to be a maintenance activity by potentially authorized personnel, but the timing requires verification before determining threat level.”\n\nFinal classification is made using the following formula:\n\nImage source: Knowledge Graph Paper [2]\n\nwhere ŷ is the predicted category, φ(y) is the knowledge graph embedding for category y, and ŝ is the received semantic information. This leads to “verify before alarm” instead of SKB’s forced “unauthorized person” classification.\n\nThe Key Difference\n\nThe difference from the maintenance worker example is that the SKB system sees “human in restricted area during off-hours” and is forced to pick from its existing categories. In our example, the system chose “unauthorized_person” because it’s the closest match.\n\nA knowledge graph-based system takes a completely different approach. It sees the same person but starts connecting the dots. A person carrying work tools suggests a maintenance activity, which typically serves a legitimate purpose. But happening during off-hours means it needs verification first. The system generates a smart response — “verify before alarm.” Even though the system was not trained for this scenario, it was able to reason using relation graphs.\n\nEvaluation\n\nKnowledge graph systems showed significant improvements over SKB-based systems, showing 70–80% better accuracy in both familiar and unfamiliar environments. The system worked well even when the signal quality wasn’t great, which proved it could actually function in real-world situations where communication is noisy.\n\nThat said, knowledge graph systems have their own limitations. Graph building requires domain expertise and significant computing power. Our testing was limited to a specific dataset with predetermined categories, so we’re not sure how it would it perform in a large-scale real-world deployment. These systems need more testing before they can completely replace the SKB-based systems.\n\nConclusion\n\nSKB systems were great when everything was predictable, but failed in an unfamiliar environment. Knowledge graphs solve this problem by truly understanding how nodes connect to each other. This allows the system to reason through unfamiliar environment by these connections, rather than needing explicit training for every possible situation. They are harder and more expensive to build, but they are suitable for real-world scenarios.\n\nReferences\n\n[1] https://arxiv.org/pdf/2405.05738\n\n[2] https://arxiv.org/pdf/2507.02291",
         "2025-07-23T00:15:39",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/from-rules-to-relationships-how-machines-are-learning-to-understand-each-other/",
         "2025-07-26T06:23:31.369474",
         "Communication systems have evolved from simple bit transmission to intelligent information sharing. Traditional systems focus on moving raw data from point A to point B as reliably as possible. Now, with the explosion of machine-to-machine communication in IoT devices, autonomous systems, and smart infrastructure, we’re hitting a fundamental bottleneck. Modern networks are drowning in unnecessary data. But machines don’t need every bit of information that traditional systems transmit. Let’s take a look at the following security monitoring interaction: Security Camera: Spots someone walking around in a restricted area during off-hours and captures a high-resolution video frame of size 5 MB Traditional System: Sends the entire 5MB frame with every single bit Central Monitoring: Analyzes frame and determines: “Unauthorized person detected in Zone A” In this interaction, the monitoring system primarily cares about the security alert rather than the person’s clothing details, facial features, or background. But traditional communication gives equal importance to every pixel, transmitting millions of irrelevant bits along with the few that matter for decision-making. Semantic communication emerged as a paradigm shift that transmits meaning rather than bits. Instead of sending the entire 5MB video frame, a semantic communication system would extract and transmit only: “zone_A, unauthorized_person, threat_level_high” while requiring just a tiny fraction of data, while preserving all decision-relevant information. The receiving system gets exactly what it needs to make the right decision by deploying security personnel to Zone A for an unauthorized intrusion. Early systems relied on Semantic Knowledge Bases (SKBs) to reduce bandwidth usage without losing the actual meaning of the message. But SKB-based systems have limitations. They work well in controlled environments but fail when encountering unknown scenarios. This limitation sparked the development of knowledge graph-based semantic communication that promises to solve unknown situations through relational reasoning. Why does SKBs-based semantic communication fail? SKB systems have a critical weakness. To understand it, we first need to see how they process information. In our security monitoring example, both the camera and monitoring station maintain a shared knowledge base K = {k m ∈ Rd} {m∈M} where each k m represents semantic attributes for category m. When a security camera captures a video frame x, the semantic encoder S_α(·) extracts features s ∈ Rd. Instead of transmitting “s” directly, the system finds the closest match using cosine similarity: Image Source: SKB Paper[1] where D(s, k m ) represents the cosine similarity between s and k m . In our example, the camera sees someone in a restricted area and extracts features like “human shape, no uniform, nighttime movement.” It compares these against its knowledge base and finds the best match is “unauthorized_person” at index v in the knowledge base. Instead of sending all the feature details, it just transmits “v.” This simple approach significantly reduces bandwidth usage while preserving all the information the monitoring system needs to make decisions. Where does this break down? The system works great until something unexpected shows up. What happens when the camera spots something that’s not in its knowledge base? Let’s look at the following example: Security Camera: Spots a maintenance worker in work clothes carrying tools during off-hours. SKB System: Only knows “unauthorized_person,” “authorized_person,” “vehicle,” “animal” System Decision: Confidently classifies worker as “unauthorized_person” with high threat level Result: False alarm — security team gets dispatched to stop legitimate maintenance work The math behind this might seem simple, but it’s actually quite problematic. The system always picks the “best” match, even when all the options are terrible. It’s like being forced to choose an answer on a multiple-choice test when none of the choices make sense. You still have to pick something, and the system has no way to say it doesn’t know. These problems get worse in real deployments. For example, if your training data didn’t include shadows, the system starts calling them “intruders.” Train without winter clothing examples, and it thinks heavy coats are “suspicious gear.” The system never admits uncertainty. It always sounds confident, even when it’s completely wrong. How do Knowledge Graphs Fix this? Knowledge graph based semantic communication solves SKB limitations by encoding relationships between nodes rather than just isolated categories. Instead of asking “which category does this match?” it asks “how does this relate to what I already know?” Let’s walk through our maintenance worker example to see the difference: Step 1: Detection and Feature Extraction The camera detects the same features as before, such as “human shape, work clothes, carrying tools, off-hours timing” Step 2: Relationship Mapping Instead of forcing these features into a single category, the knowledge graph maps them to multiple connected nodes. Human shape → triggers “human” node Work clothes + tools → triggers “work_tools” and “maintenance_equipment” nodes Off-hours timing → triggers “unusual_access_time” node Step 3: Relationship Traversal To track connections between nodes, the system uses following formula: Image source: Knowledge Graph Paper [2] where “z v ” denotes the updated representation of node v, and the sum aggregates information from all neighboring nodes u. Each node picks up its meaning from the neighbors it’s connected to. work_tools → indicates → maintenance_activity maintenance_activity → performed_by → maintenance_worker maintenance_worker → is_a → authorized_personnel (conditional) off_hours_access + authorized_personnel → requires → verification Step 4: Contextual Reasoning The knowledge graph combines these relationship paths: “This appears to be a maintenance activity by potentially authorized personnel, but the timing requires verification before determining threat level.” Final classification is made using the following formula: Image source: Knowledge Graph Paper [2] where ŷ is the predicted category, φ(y) is the knowledge graph embedding for category y, and ŝ is the received semantic information. This leads to “verify before alarm” instead of SKB’s forced “unauthorized person” classification. The Key Difference The difference from the maintenance worker example is that the SKB system sees “human in restricted area during off-hours” and is forced to pick from its existing categories. In our example, the system chose “unauthorized_person” because it’s the closest match. A knowledge graph-based system takes a completely different approach. It sees the same person but starts connecting the dots. A person carrying work tools suggests a maintenance activity, which typically serves a legitimate purpose. But happening during off-hours means it needs verification first. The system generates a smart response — “verify before alarm.” Even though the system was not trained for this scenario, it was able to reason using relation graphs. Evaluation Knowledge graph systems showed significant improvements over SKB-based systems, showing 70–80% better accuracy in both familiar and unfamiliar environments. The system worked well even when the signal quality wasn’t great, which proved it could actually function in real-world situations where communication is noisy. That said, knowledge graph systems have their own limitations. Graph building requires domain expertise and significant computing power. Our testing was limited to a specific dataset with predetermined categories, so we’re not sure how it would it perform in a large-scale real-world deployment. These systems need more testing before they can completely replace the SKB-based systems. Conclusion SKB systems were great when everything was predictable, but failed in an unfamiliar environment. Knowledge graphs solve this problem by truly understanding how nodes connect to each other. This allows the system to reason through unfamiliar environment by these connections, rather than needing explicit training for every possible situation. They are harder and more expensive to build, but they are suitable for real-world scenarios. References [1] https://arxiv.org/pdf/2405.05738 [2] https://arxiv.org/pdf/2507.02291",
         "en",
         "{'LOC': ['B', 'K', 'https://arxiv.org/pdf/2507.02291', 'problematic', 'the SKB-based systems', 'the cosine similarity between s', '∈ Rd'], 'MISC': ['Analyzes frame and determines: “', 'But happening during off', 'Central Monitoring', 'Conclusion SKB systems', 'Confidently classifies worker as “unauthorized_person” with high threat level Result: False alarm — security team gets dispatched to stop legitimate maintenance work The math behind this might seem simple', 'Contextual Reasoning The knowledge graph combines these relationship paths', 'Detection and Feature', 'How do Knowledge Graphs Fix this?', 'Human shape → triggers “human', 'Image', 'Image Source: SKB Paper[1', 'In our security monitoring', 'Instead of sending all the feature details', 'Instead of sending the entire', 'Instead of transmitting “s” directly', 'IoT', 'It always sounds confident', 'It sees the same person but starts connecting the dots', 'It’s like being forced to choose an answer', 'Knowledge Graph Paper', 'Let’s', 'Let’s look at the following', 'Let’s take', 'MB frame with every single', 'MB video frame', 'Modern networks are drowning in unnecessary data', 'Now', 'Off-hours timing → triggers “', 'Our testing was limited to a specific dataset with predetermined categories', 'SKB System:', 'Security Camera: Spots a maintenance worker in work clothes carrying tools during off-hours', 'Security Camera: Spots someone walking around in', 'Sends the entire', 'Step 1:', 'Step 2:', 'Step 3: Relationship Traversal To', 'Step 4', 'System Decision', 'The Key Difference The difference from the maintenance worker', 'The receiving system gets', 'The system always picks the “best” match', 'The system generates', 'The system worked well even when the', 'These problems get worse in real deployments', 'They are harder and more expensive to build', 'They work well in controlled environments', 'This allows the system to reason through unfamiliar environment by these connections', 'To understand it', 'What happens when the', 'When a security', 'Where does this break down?', 'Why does SKBs', 'Work clothes', 'You still have to pick something, and the system has no way to say it doesn’t know', 'along with the few that matter for decision-making', 'and smart infrastructure', 'and the sum aggregates information from all neighboring nodes u.', 'between nodes rather than just', 'both the camera and monitoring', 'carrying tools', 'equal importance to every pixel', 'even when it’', 'is_a → authorized_personnel', 'it’', 'look at the following security monitoring interaction', 'match using cosine similarity', 'shadows', 'something that’s not in its knowledge base', 'such as “human shape', 'the camera sees someone in', 'the monitoring system primarily cares about the security alert rather than the person’s clothing details', 'the system chose', 'the system starts calling them “intruders', 'the system uses following formula: Image source: Knowledge Graph Paper', 'to see the difference', 'we’re hitting', 'when none of the choices make sense', 'which proved it could actually function in real-world situations where communication is noisy', 'with the explosion of machine-to-machine', 'work_tools', '” Even though the system was not trained for this scenario', '” “animal', '” “vehicle'], 'ORG': ['Early systems relied on Semantic Knowledge Bases', 'For', 'In our example', 'Instead of asking “which category does this match', 'SKB', 'SKB systems', 'Semantic', 'These systems need', 'Train without winter clothing examples', 'and it thinks heavy coats are “suspicious gear'], 'PER': ['maintenance_worker maintenance_worker', 'while preserving all decision-relevant information']}",
         "[0.10219932347536087, 0.021808171644806862, -0.0117257758975029, -0.06910116970539093, 0.1542743593454361, -0.05741773173213005, 0.06395423412322998, -0.040475767105817795, 0.07591831684112549, 0.0604737251996994, -0.015291492454707623, -0.03259335830807686, 0.014201391488313675, 0.021152786910533905, 0.019324297085404396, -0.04170457646250725, 0.16305240988731384, -0.06237560883164406, -0.08397410809993744, 0.016338065266609192, 0.0034483959898352623, -0.049445729702711105, 0.041772592812776566, -0.01889495737850666, -0.040810681879520416, 0.017556488513946533, -0.002948155626654625, -0.01629016362130642, 0.01058154832571745, -0.03942275419831276, 0.036914631724357605, 0.04467587172985077, 0.040172308683395386, 0.05133961886167526, -0.056226715445518494, -0.06562542170286179, 0.1074981763958931, -0.03716711327433586, -0.06526700407266617, -0.04574931785464287, -0.07125479727983475, -0.04694145545363426, 0.003919202368706465, 0.03601653873920441, -0.028744041919708252, 0.06815291196107864, 0.06859724968671799, -0.03727308660745621, -0.0850973129272461, -0.09927086532115936, -0.07859179377555847, 0.04140773415565491, 0.019678443670272827, 0.028984224423766136, -0.044370003044605255, -0.03536165505647659, -0.06315859407186508, 0.010823952034115791, -0.000968694977927953, 0.008594869635999203, -0.07988616079092026, 0.010682044550776482, 0.026498032733798027, 0.03262696787714958, -0.045191556215286255, 0.042614735662937164, 0.021042825654149055, 0.014113106764853, 0.05942855030298233, 0.006434983108192682, -0.0501796193420887, 0.016977444291114807, -0.018352946266531944, -0.001686945091933012, -0.03261842951178551, -0.044584766030311584, 0.033161312341690063, -0.03544885292649269, -0.02363598719239235, -0.10095168650150299, 0.058853164315223694, -0.00031473374110646546, 0.07896112650632858, 0.0502166785299778, 0.026308970525860786, -0.03188489377498627, -0.06302610784769058, 0.007057469803839922, 0.012608302757143974, -0.04550836607813835, -0.11373144388198853, -0.05057624354958534, 0.046097926795482635, 0.002899270039051771, 0.07898896187543869, -0.03884793072938919, -0.05614442378282547, -0.09698645770549774, -0.002240941161289811, 0.01418943703174591, 0.03233535587787628, -0.015396722592413425, -0.0131410863250494, -0.01901945471763611, 0.06379767507314682, -0.001808608416467905, -0.025667794048786163, 0.0014229767257347703, 0.03579277545213699, 0.09930947422981262, -0.00324495998211205, 0.060349542647600174, -0.05938135087490082, -0.0578819215297699, 0.008158175274729729, 0.032084859907627106, -0.06912146508693695, 0.0462258942425251, 0.01551150344312191, 0.016366222873330116, 0.008632857352495193, -0.04812188446521759, -0.014437058009207249, -0.0080269118770957, -0.0009686594712547958, -0.020232785493135452, 0.04182835668325424, 7.720873913547287e-33, -0.047030456364154816, 0.06595764309167862, -0.05741969868540764, 0.04836691915988922, 0.04609205946326256, 0.08364736288785934, 0.023847371339797974, 0.02317923866212368, 0.04335394129157066, 0.04929936304688454, -0.045710451900959015, -0.013815267942845821, 0.05069591477513313, 0.006246527191251516, 0.10469096899032593, 0.08889241516590118, -0.058701466768980026, -0.028205521404743195, -0.003814724273979664, 0.0599958561360836, 0.058081939816474915, -0.0007781550521031022, -0.003580937860533595, 0.06798399239778519, 0.002249745652079582, -0.05726400017738342, 0.024841904640197754, -0.04638730362057686, 0.09400080889463425, -0.018492113798856735, -0.09622441232204437, 0.024720575660467148, 0.08285658806562424, 0.006773045286536217, 0.10310734808444977, -0.05018612742424011, 0.040929004549980164, -0.039070241153240204, -0.011280442588031292, -0.057723503559827805, 0.0010184902930632234, 0.0034317681565880775, -0.08633013069629669, -0.05307857692241669, 0.007127704564481974, 0.0009031490189954638, 0.01358279213309288, 0.05635320767760277, -0.15556956827640533, 0.010288277640938759, 0.06312103569507599, 0.002762890886515379, 0.009454510174691677, -0.01844767853617668, -0.07850468903779984, 0.004222703631967306, 0.03091440349817276, -0.04560083895921707, 0.003229477908462286, 0.0663209781050682, -0.05218471959233284, -0.019139409065246582, 0.08867950737476349, 0.012787639163434505, 0.022270355373620987, -0.0428260900080204, 0.05819566920399666, 0.08836321532726288, -0.023839173838496208, 0.017701007425785065, -0.04459962248802185, 0.025001995265483856, 0.017608556896448135, -0.032468218356370926, 0.03092988021671772, 0.050880298018455505, -0.02419212833046913, 0.011297960765659809, -0.04803895205259323, 0.10837969928979874, -0.02865380421280861, -0.023523125797510147, 0.04447123408317566, 0.002906276611611247, 0.008214873261749744, 0.012139531783759594, -0.031697385013103485, -0.022631986066699028, -0.08027993142604828, 0.025071339681744576, 0.010645599104464054, -0.014072922058403492, 0.05561934784054756, 0.03847799077630043, -0.06604672968387604, -7.836317744373605e-33, -0.0018140894826501608, 0.02494044229388237, -0.07056007534265518, 0.02671516314148903, -0.07030151784420013, -0.08109896630048752, 0.08746031671762466, 0.034168243408203125, 0.028294043615460396, 0.02041367068886757, -0.04041362926363945, -0.08454650640487671, 0.02189851738512516, -0.02507585659623146, -0.006375136785209179, -0.02918367274105549, -0.004007413052022457, 0.00667573930695653, -0.045729875564575195, 0.028198054060339928, 0.0133918896317482, 0.08916320651769638, -0.11749120056629181, -0.043367110192775726, -0.003350336803123355, 0.08805500715970993, -0.07420172542333603, 0.05206793546676636, -0.022280169650912285, -0.040828168392181396, -0.012920147739350796, -0.057784419506788254, 0.037801310420036316, -0.053949300199747086, 0.001109381322748959, 0.014384549111127853, 0.08164888620376587, 0.048508066684007645, -0.08273399621248245, 0.054100099951028824, -0.04421473294496536, 0.04358401522040367, -0.06886831670999527, 0.02107073925435543, -0.010828432627022266, -0.026755256578326225, -0.09501005709171295, 0.013761968351900578, -0.08695949614048004, -0.020034804940223694, 0.07034110277891159, 0.018539011478424072, -0.012310303747653961, -0.025553876534104347, -0.029976416379213333, 0.03225891292095184, -0.01593993417918682, 0.057504117488861084, -0.009649651125073433, 0.11253190040588379, 0.04608842357993126, -0.03904193267226219, -0.028304938226938248, 0.04055745527148247, 0.08220091462135315, 0.09613285958766937, 0.013871366158127785, 0.013530821539461613, -0.0471634715795517, 0.025896506384015083, 0.04839860647916794, 0.017476022243499756, 0.006874438840895891, 0.03331158310174942, 0.11089255660772324, 0.051869720220565796, 0.019122382625937462, -0.05752558261156082, -0.022166302427649498, 0.03980952128767967, -0.07690687477588654, -0.03718499839305878, 0.045565977692604065, -0.0031363535672426224, 0.04096117988228798, 0.04368045553565025, -0.0018620563205331564, -0.07851006835699081, -0.006978181656450033, -0.01292438991367817, -0.059149015694856644, -0.04906538873910904, -0.04682750999927521, 0.014602341689169407, -0.004332630429416895, -6.22467908328872e-08, -0.07907320559024811, -0.026517514139413834, -0.04917954280972481, -0.0655742734670639, 0.033131446689367294, -0.0019485127413645387, 0.0012327900622040033, -0.0340949110686779, 0.006044556852430105, -0.03373085707426071, 0.03452664241194725, -0.030808312818408012, -0.0691765770316124, -0.00985661894083023, 0.012775239534676075, 0.03577481955289841, 0.01902845688164234, -0.1816977709531784, -0.021281661465764046, 0.03339460492134094, 0.049694400280714035, -0.08335815370082855, -0.0765979215502739, 0.01079430989921093, 0.07886123657226562, 0.0032898338977247477, -0.00133007753174752, 0.007182740606367588, 0.04229782521724701, 0.017892073839902878, -0.06145770102739334, -0.07512488961219788, 0.04778623208403587, 0.06972675025463104, -0.024366315454244614, 0.02051164023578167, 0.017237653955817223, -0.10725665837526321, 0.03931206092238426, -0.00037188679561950266, -0.012797382660210133, -0.05986899510025978, 2.9169725166866556e-05, 0.0025473558343946934, -0.027746044099330902, 0.040822189301252365, -0.05913197621703148, 0.00032212844234891236, -0.015067268162965775, 0.025179335847496986, 0.00101819122210145, 0.0038755338173359632, 0.015345603227615356, 0.1453666388988495, 0.02641686238348484, -0.07768047600984573, 0.09693514555692673, -0.08738820999860764, 0.01824870891869068, 0.07114158570766449, 0.0513610914349556, 0.05831236392259598, -0.04495306313037872, -0.026030516251921654]",
         "0.216"
        ],
        [
         "49",
         "572",
         "How Do Grayscale Images Affect Visual Anomaly Detection?",
         "A practical exploration focusing on performance and speed The post How Do Grayscale Images Affect Visual Anomaly Detection? appeared first on Towards Data Science .",
         "Introduction: Why grayscale images might affect anomaly detection. Anomaly detection, grayscale images: Quick recap on the two main subjects discussed in this article. Experiment setting: What and how we compare. Performance results: How grayscale images affect model performance. Speed results: How grayscale images affect inference speed. Conclusion\n\n1. Introduction\n\nIn this article, we’ll explore how grayscale images affect the performance of anomaly detection models and examine how this choice influences inference speed.\n\nIn computer vision, it’s well established that fine-tuning pre-trained classification models on grayscale images can lead to degraded performance. But what about anomaly detection models? These models do not require fine-tuning, but they use pre-trained classification models such as WideResNet or EfficientNet as feature extractors. This raises an important question: do these feature extractors produce less relevant features when applied to a grayscale image?\n\nImage taken from the VisA dataset (CC-BY-4.0) and processed using Anomalib library\n\nThis question is not just academic, but one with real-world implications for anyone working on automating industrial visual inspection in manufacturing. For example, you might find yourself wondering if a color camera is necessary or if a cheaper grayscale one will be sufficient. Or you could have concerns regarding the inference speed and want to use any opportunity to increase it.\n\n2. Anomaly detection, grayscale images\n\nIf you are already familiar with both anomaly detection in computer vision and the basics of digital image representation, feel free to skip this section. Otherwise, it provides a brief overview and links for further exploration.\n\nAnomaly detection\n\nIn computer vision, anomaly detection is a fast-evolving field within deep learning that focuses on identifying unusual patterns in images. Typically, these models are trained using only images without defects, allowing the model to learn what “normal” looks like. During inference, the model can detect images that deviate from this learned representation as abnormal. Such anomalies often correspond to various defects that may appear in a production environment but were not seen during training. For a more detailed introduction, see this link.\n\nGrayscale images\n\nFor humans, color and grayscale images look quite similar (aside from the lack of color). But for computers, an image is an array of numbers, so it becomes a little bit more complicated. A grayscale image is a two-dimensional array of numbers, typically ranging from 0 to 255, where each value represents the intensity of a pixel, with 0 being black and 255 being white.\n\nIn contrast, color images are typically composed of three such separate grayscale images (called channels) stacked together to form a three-dimensional array. Each channel (red, green, and blue) describes the intensity of the respective color, and its combination creates a color image. You can learn more about this here.\n\n3. Experiment setting\n\nModels\n\nWe will use four state-of-the-art anomaly detection models: PatchCore, Reverse Distillation, FastFlow, and GLASS. These models represent different types of anomaly detection algorithms and, at the same time, they are widely used in practical applications due to fast training and inference speed. The first three models use the implementation from the Anomalib library, for GLASS we employ the official implementation.\n\nImage by author\n\nDataset\n\nFor our experiments, we use the VisA dataset with 12 categories of objects, which provides a variety of images and has no color-dependent defects.\n\nImage taken from the VisA dataset (CC-BY-4.0)\n\nMetrics\n\nWe will use image-level AUROC to see if the whole image was classified correctly without the need to select a particular threshold, and pixel-level AUPRO, which shows how good we are at localizing defective areas in the image. Speed will be evaluated using the frames-per-second (FPS) metric. For all metrics, higher values correspond to better results.\n\nGrayscale conversion\n\nTo make an image grayscale, we will use torchvision transforms.\n\nImage by author\n\nFor one channel, we also modify feature extractors using the in_chans parameter in the timm library.\n\nImage by author\n\nThe code for adapting Anomalib to use one channel is available here.\n\n\n\n4. Performance results\n\nRGB\n\nThese are regular images with red, blue, and green channels.\n\nImage by author\n\nGrayscale, three channels\n\nImages were converted to grayscale using torchvision transform Grayscale with three channels.\n\nImage by author\n\nGrayscale, one channel\n\nImages were converted to grayscale using the same torchvision transform Grayscale with one channel.\n\nImage by author\n\nComparison\n\nWe can see that PatchCore and Reverse Distillation have close results across all three experiments for both image and pixel-level metrics. FastFlow becomes somewhat worse, and GLASS becomes noticeably worse. Results are averaged across the 12 categories of objects in the VisA dataset.\n\nWhat about results per category of objects? Maybe some of them perform worse than others, and some better, causing the average results to appear the same? Here is the visualization of results for PatchCore across all three experiments showing that results are quite stable within categories as well.\n\nImage by author\n\nThe same visualization for GLASS shows that some categories can be slightly better while some can be strongly worse. However, this is not necessarily caused by grayscale transformation only; some of it can be regular result fluctuations due to how the model is trained. Averaged results show a clear tendency that for this model, RGB images produce the best result, grayscale with three channels somewhat worse, and grayscale with one channel the worst result.\n\nImage by author\n\nBonus\n\nHow do results change per category? It is possible that some categories are simply better suited for RGB or grayscale images, even if there are no color-dependent defects.\n\nHere is the visualization of the difference between RGB and grayscale with one channel for all the models. We can see that only pipe_fryum category becomes slightly (or strongly) worse for every model. The rest of the categories become worse or better, depending on the model.\n\nImage by author\n\nExtra bonus\n\nIf you are interested in how this pipe_fryum looks, here are a couple of examples with GLASS model predictions.\n\nImages taken from the VisA dataset (CC-BY-4.0) and processed using GLASS and Anomalib library\n\n5. Speed results\n\nThe number of channels affects only the first layer of the model, the rest remains unchanged. The speed improvement seems to be negligible, highlighting how the first layer feature extraction is just a small part of the calculations performed by the models. GLASS shows a somewhat noticeable improvement, but at the same time, it shows the worst metrics decline, so it requires caution if you want to speed it up by switching to one channel.\n\nImage by author\n\n6. Conclusion\n\nSo how does using grayscale images affect visual anomaly detection? It depends, but RGB seems to be the safer bet. The impact varies depending on the model and data. PatchCore and Reverse Distillation generally handle grayscale inputs well, but you need to be more careful with FastFlow and especially GLASS, which shows some speed improvement but also the most significant drop in performance metrics. If you want to use grayscale input, you need to test and compare it with RGB on your specific data.\n\nThe jupyter notebook with the Anomalib code: link.\n\nFollow author on LinkedIn for more on industrial visual anomaly detection.\n\nReferences\n\n1. C. Hughes, Transfer Learning on Greyscale Images: How to Fine-Tune Pretrained Models (2022), towardsdatascience.com\n\n2. S. Wehkamp, A practical guide to image-based anomaly detection using Anomalib (2022), blog.ml6.eu\n\n3. A. Baitieva, Y. Bouaouni, A. Briot, D. Ameln, S. Khalfaoui, and S. Akcay. Beyond Academic Benchmarks: Critical Analysis and Best Practices for Visual Industrial Anomaly Detection (2025), CVPR Workshop on Visual Anomaly and Novelty Detection (VAND)\n\n4. Y. Zou, J. Jeong, L. Pemula, D. Zhang, and O. Dabeer, SPot-the-Difference Self-Supervised Pre-training for Anomaly Detection and Segmentation (2022), ECCV\n\n5. S. Akcay, D. Ameln, A. Vaidya, B. Lakshmanan, N. Ahuja, and U. Genc, Anomalib (2022), ICIP",
         "2025-07-24T19:53:07",
         "https://towardsdatascience.com/feed",
         "https://towardsdatascience.com/how-do-grayscale-images-affect-visual-anomaly-detection/",
         "2025-07-26T06:23:31.303423",
         "Introduction: Why grayscale images might affect anomaly detection. Anomaly detection, grayscale images: Quick recap on the two main subjects discussed in this article. Experiment setting: What and how we compare. Performance results: How grayscale images affect model performance. Speed results: How grayscale images affect inference speed. Conclusion 1. Introduction In this article, we’ll explore how grayscale images affect the performance of anomaly detection models and examine how this choice influences inference speed. In computer vision, it’s well established that fine-tuning pre-trained classification models on grayscale images can lead to degraded performance. But what about anomaly detection models? These models do not require fine-tuning, but they use pre-trained classification models such as WideResNet or EfficientNet as feature extractors. This raises an important question: do these feature extractors produce less relevant features when applied to a grayscale image? Image taken from the VisA dataset (CC-BY-4.0) and processed using Anomalib library This question is not just academic, but one with real-world implications for anyone working on automating industrial visual inspection in manufacturing. For example, you might find yourself wondering if a color camera is necessary or if a cheaper grayscale one will be sufficient. Or you could have concerns regarding the inference speed and want to use any opportunity to increase it. 2. Anomaly detection, grayscale images If you are already familiar with both anomaly detection in computer vision and the basics of digital image representation, feel free to skip this section. Otherwise, it provides a brief overview and links for further exploration. Anomaly detection In computer vision, anomaly detection is a fast-evolving field within deep learning that focuses on identifying unusual patterns in images. Typically, these models are trained using only images without defects, allowing the model to learn what “normal” looks like. During inference, the model can detect images that deviate from this learned representation as abnormal. Such anomalies often correspond to various defects that may appear in a production environment but were not seen during training. For a more detailed introduction, see this link. Grayscale images For humans, color and grayscale images look quite similar (aside from the lack of color). But for computers, an image is an array of numbers, so it becomes a little bit more complicated. A grayscale image is a two-dimensional array of numbers, typically ranging from 0 to 255, where each value represents the intensity of a pixel, with 0 being black and 255 being white. In contrast, color images are typically composed of three such separate grayscale images (called channels) stacked together to form a three-dimensional array. Each channel (red, green, and blue) describes the intensity of the respective color, and its combination creates a color image. You can learn more about this here. 3. Experiment setting Models We will use four state-of-the-art anomaly detection models: PatchCore, Reverse Distillation, FastFlow, and GLASS. These models represent different types of anomaly detection algorithms and, at the same time, they are widely used in practical applications due to fast training and inference speed. The first three models use the implementation from the Anomalib library, for GLASS we employ the official implementation. Image by author Dataset For our experiments, we use the VisA dataset with 12 categories of objects, which provides a variety of images and has no color-dependent defects. Image taken from the VisA dataset (CC-BY-4.0) Metrics We will use image-level AUROC to see if the whole image was classified correctly without the need to select a particular threshold, and pixel-level AUPRO, which shows how good we are at localizing defective areas in the image. Speed will be evaluated using the frames-per-second (FPS) metric. For all metrics, higher values correspond to better results. Grayscale conversion To make an image grayscale, we will use torchvision transforms. Image by author For one channel, we also modify feature extractors using the in_chans parameter in the timm library. Image by author The code for adapting Anomalib to use one channel is available here. 4. Performance results RGB These are regular images with red, blue, and green channels. Image by author Grayscale, three channels Images were converted to grayscale using torchvision transform Grayscale with three channels. Image by author Grayscale, one channel Images were converted to grayscale using the same torchvision transform Grayscale with one channel. Image by author Comparison We can see that PatchCore and Reverse Distillation have close results across all three experiments for both image and pixel-level metrics. FastFlow becomes somewhat worse, and GLASS becomes noticeably worse. Results are averaged across the 12 categories of objects in the VisA dataset. What about results per category of objects? Maybe some of them perform worse than others, and some better, causing the average results to appear the same? Here is the visualization of results for PatchCore across all three experiments showing that results are quite stable within categories as well. Image by author The same visualization for GLASS shows that some categories can be slightly better while some can be strongly worse. However, this is not necessarily caused by grayscale transformation only; some of it can be regular result fluctuations due to how the model is trained. Averaged results show a clear tendency that for this model, RGB images produce the best result, grayscale with three channels somewhat worse, and grayscale with one channel the worst result. Image by author Bonus How do results change per category? It is possible that some categories are simply better suited for RGB or grayscale images, even if there are no color-dependent defects. Here is the visualization of the difference between RGB and grayscale with one channel for all the models. We can see that only pipe_fryum category becomes slightly (or strongly) worse for every model. The rest of the categories become worse or better, depending on the model. Image by author Extra bonus If you are interested in how this pipe_fryum looks, here are a couple of examples with GLASS model predictions. Images taken from the VisA dataset (CC-BY-4.0) and processed using GLASS and Anomalib library 5. Speed results The number of channels affects only the first layer of the model, the rest remains unchanged. The speed improvement seems to be negligible, highlighting how the first layer feature extraction is just a small part of the calculations performed by the models. GLASS shows a somewhat noticeable improvement, but at the same time, it shows the worst metrics decline, so it requires caution if you want to speed it up by switching to one channel. Image by author 6. Conclusion So how does using grayscale images affect visual anomaly detection? It depends, but RGB seems to be the safer bet. The impact varies depending on the model and data. PatchCore and Reverse Distillation generally handle grayscale inputs well, but you need to be more careful with FastFlow and especially GLASS, which shows some speed improvement but also the most significant drop in performance metrics. If you want to use grayscale input, you need to test and compare it with RGB on your specific data. The jupyter notebook with the Anomalib code: link. Follow author on LinkedIn for more on industrial visual anomaly detection. References 1. C. Hughes, Transfer Learning on Greyscale Images: How to Fine-Tune Pretrained Models (2022), towardsdatascience.com 2. S. Wehkamp, A practical guide to image-based anomaly detection using Anomalib (2022), blog.ml6.eu 3. A. Baitieva, Y. Bouaouni, A. Briot, D. Ameln, S. Khalfaoui, and S. Akcay. Beyond Academic Benchmarks: Critical Analysis and Best Practices for Visual Industrial Anomaly Detection (2025), CVPR Workshop on Visual Anomaly and Novelty Detection (VAND) 4. Y. Zou, J. Jeong, L. Pemula, D. Zhang, and O. Dabeer, SPot-the-Difference Self-Supervised Pre-training for Anomaly Detection and Segmentation (2022), ECCV 5. S. Akcay, D. Ameln, A. Vaidya, B. Lakshmanan, N. Ahuja, and U. Genc, Anomalib (2022), ICIP",
         "en",
         "{'MISC': ['A practical guide to image', 'AUPRO', 'AUROC to see if the whole image was classified correctly without the need to select', 'Beyond Academic Benchmarks: Critical Analysis and Best Practices for Visual Industrial', 'CVPR Workshop', 'Conclusion 1', 'Dataset For our experiments', 'Each channel', 'FastFlow', 'Follow author on LinkedIn for more on industrial visual anomaly detection', 'For all metrics', 'GLASS shows a somewhat noticeable', 'Grayscale', 'Grayscale images For humans', 'Here is the visualization of the difference between RGB and grayscale with one channel for all the models', 'How grayscale images affect inference speed', 'How grayscale images affect model performance', 'How to Fine-Tune Pretrained Models', 'If you', 'If you are already familiar with both anomaly detection in computer vision and the basics of digital image representation', 'If you want to use grayscale input', 'Image by author', 'Image by author 6', 'Image by author Grayscale', 'Image by author The same visualization', 'Image taken from the VisA dataset', 'Images taken from the VisA dataset', 'Images were converted to grayscale using the same torchvision', 'Images were converted to grayscale using torchvision', 'Introduction In this article', 'It depends', 'It is possible that some categories are simply better suited for RGB or grayscale images', 'Maybe some of them perform worse than others', 'Metrics We will', 'Models We will', 'Otherwise', 'PatchCore', 'PatchCore and Reverse Distillation generally handle grayscale inputs', 'Performance results RGB These are regular images with red', 'Quick recap on the two main subjects', 'RGB images produce the best result', 'RGB seems to be the safer bet', 'Reverse Distillation', 'Speed results The number of', 'Speed results:', 'Speed will be evaluated using the frames', 'Such anomalies often correspond to various defects that may appear in', 'The', 'The first three models', 'The speed', 'These models do not require fine', 'Transfer Learning on Greyscale Images', 'VAND', 'Visual Anomaly and Novelty', 'We can see that only pipe_fryum category becomes slightly', 'What about results per category of objects', 'What and how we', 'Why grayscale images might affect anomaly detection', 'You can learn more about this here', 'allowing the model to learn what “normal', 'and GLASS', 'and blue', 'and green', 'and pixel-level', 'and processed using Anomalib', 'and processed using GLASS and Anomalib', 'blue', 'but also the most significant drop in performance metrics', 'but you need to be more careful with FastFlow and especially GLASS', 'depending on the model', 'depending on the model and data', 'feel free to skip this section', 'for GLASS we', 'highlighting how the first layer feature extraction is just a small part of the calculations', 'it shows the worst metrics', 'it’s well established that fine-tuning pre-trained', 'link', 'notebook with the Anomalib', 'one with real-world implications for anyone working on automating industrial visual inspection in manufacturing', 'see this link', 'somewhat worse, and grayscale with one channel the worst result', 'the', 'the average results to appear the same?', 'the implementation from the Anomalib library', 'the inference speed and want to use any opportunity to increase it', 'the intensity of a pixel', 'the intensity of the respective', 'the model can', 'these models are trained using only images without defects', 'threshold', 'to better results', 'to fast training and inference speed', 'to how the model is trained', 'using the in_chans parameter in the timm library', 'we also', 'well', 'we’ll explore how grayscale images affect', 'which shows how good we are at localizing', 'which shows some speed', 'with 0 being black and 255 being white', 'with GLASS model', 'you need to test and'], 'PER': ['A. Baitieva', 'A. Briot', 'A. Vaidya', 'Averaged results show', 'B. Lakshmanan', 'C. Hughes', 'D. Ameln', 'D. Zhang', 'J. Jeong', 'L. Pemula', 'N. Ahuja', 'Performance', 'S. Akcay', 'S. Khalfaoui', 'S. Wehkamp', 'This', 'Y. Bouaouni', 'Y. Zou', 'and O. Dabeer', 'and S. Akcay', 'anomaly detection is a fast-evolving field within deep learning that focuses', 'even if there are no color-dependent defects', 'here are', 'we will', 'you could have', 'you might find yourself wondering if'], 'ORG': ['EfficientNet', 'For', 'ICIP', 'The impact', 'These', 'green', 'red'], 'LOC': ['Anomalib', 'CC-BY-4.0', 'ECCV 5', 'However', 'SPot-the-Difference Self-Supervised Pre-training for Anomaly Detection and', 'Typically', 'and U. Genc', 'blog.ml6.eu', 'four state-of-the-art anomaly detection models']}",
         "[-0.00011230720701860264, 0.01848524436354637, 0.10176438093185425, 0.031659021973609924, 0.14342716336250305, -0.03642277047038078, 0.05603059381246567, -0.05078502744436264, 0.006580681074410677, -0.0800156369805336, -0.019612740725278854, -0.024481771513819695, 0.002736964961513877, 0.058997441083192825, -0.06820208579301834, -0.03691592067480087, 0.10776837170124054, 0.040723640471696854, -0.14680957794189453, -0.06676241755485535, -0.03469197824597359, -0.037580981850624084, -0.03492703661322594, -0.060499515384435654, -0.10012144595384598, -0.042366281151771545, 0.0026933688204735518, -0.01890341006219387, -0.009444279596209526, -0.07678931206464767, -0.07713962346315384, -0.002370530506595969, 0.017077066004276276, 0.05474645644426346, 0.030960693955421448, -0.021305127069354057, 0.030956396833062172, 0.04641559347510338, -0.011651490814983845, -0.04689981788396835, -0.0061143552884459496, -0.060309797525405884, -0.01565326377749443, 0.026796959340572357, 0.02194156125187874, 0.008485614322125912, 0.053477417677640915, -0.04786332696676254, -0.026868876069784164, -0.08359028398990631, -0.06195526942610741, -0.051431261003017426, -0.020418057218194008, -0.011413068510591984, -0.008532799780368805, -0.021856315433979034, 0.02657065913081169, -0.06032741069793701, 0.005417173728346825, -0.005304532125592232, -0.0158387441188097, -0.041835274547338486, -0.047946251928806305, -0.0030383055564016104, 0.00827514287084341, 0.03013521246612072, 0.04536942392587662, -0.09948191791772842, 0.036927543580532074, -0.047363173216581345, -0.014132042415440083, 0.060640014708042145, -0.03273319453001022, -0.026901686564087868, -0.02178545668721199, 0.011775339022278786, 0.04374292865395546, 0.01080036535859108, 0.03495286777615547, -0.1355321854352951, 0.026186492294073105, 0.03049120306968689, 0.06473569571971893, -0.03624854236841202, 0.12246202677488327, 0.029664000496268272, -0.06838212162256241, 0.04271584376692772, -0.03595620021224022, 0.005794164724647999, 0.004384421743452549, -0.017894789576530457, -0.04786403477191925, -0.03184570372104645, 0.12512055039405823, 0.009427132084965706, 0.014222431927919388, -0.047457143664360046, 0.024020325392484665, 0.0036692405119538307, 0.048860516399145126, -0.010022439993917942, 0.0009587146923877299, 0.05942415073513985, 0.05894968658685684, -0.01422208733856678, 0.07219401746988297, 0.030544424429535866, 0.12247375398874283, -0.01663092151284218, 0.026710836216807365, 0.06572776287794113, -0.06244075298309326, -0.006337560713291168, -0.007829119451344013, 0.015134974382817745, 0.022301727905869484, 0.032700493931770325, -0.13324537873268127, 0.0031414770055562258, -0.02449990063905716, -0.0014259327435865998, -0.03823674097657204, -0.011400667019188404, 0.024591170251369476, -0.023467769846320152, -0.12015365809202194, 5.8878223492124124e-33, -0.021371016278862953, -0.011800993233919144, -0.05407891422510147, -0.021964972838759422, -0.00225407094694674, -0.0320051871240139, -0.04259838908910751, 0.0431358776986599, 0.06598915159702301, 0.058259591460227966, -0.09266480058431625, 0.0073091560043394566, -0.021036643534898758, 0.09329034388065338, 0.031600020825862885, 0.07867318391799927, -0.022680411115288734, 0.030085859820246696, -0.03546668589115143, 0.034449268132448196, -0.015003454871475697, -0.10104470700025558, -0.012975230813026428, 0.009527953341603279, -0.0024961724411696196, -0.02064099907875061, 0.00045985550968907773, 0.011508234776556492, -0.00405495660379529, 0.021968791261315346, -0.09656364470720291, 0.030780456960201263, 0.01777839846909046, 0.0511804074048996, -0.03332756087183952, -0.03226357325911522, -0.048642728477716446, -0.0031387025956064463, 0.04849301651120186, -0.008837295696139336, -0.05609111860394478, 0.034336429089307785, -0.01159752905368805, -0.012506792321801186, 0.006127398926764727, 0.013035408221185207, 0.042098041623830795, 0.020373307168483734, -0.08910410106182098, -0.00804736278951168, 0.020647959783673286, 0.02936335653066635, 0.013079569675028324, -0.06310857832431793, -0.025321731343865395, 0.043923426419496536, 0.10308974236249924, -0.027267862111330032, -0.02342529594898224, -0.018379421904683113, -0.016321389004588127, 0.036609940230846405, -0.011421550065279007, 0.05457865074276924, 0.03801827132701874, 0.0021730843000113964, 0.027205929160118103, 0.06771405786275864, -0.08161824196577072, 0.05866051837801933, -1.2579310350702144e-05, -0.002052747644484043, -0.027234282344579697, -0.07529125362634659, 0.06164077669382095, 0.0282132551074028, 0.03961576148867607, 0.018428584560751915, 0.016401682049036026, 0.04138090834021568, -0.030339522287249565, 0.006562800612300634, 0.04617859795689583, -0.09145589917898178, -0.0593256838619709, 0.044150158762931824, 0.049148622900247574, -0.016461795195937157, 0.040823645889759064, -0.02790466509759426, 0.02313876897096634, 0.07220971584320068, -0.07711390405893326, 0.018021203577518463, -0.04148360714316368, -5.2573518316206326e-33, 0.055212412029504776, -0.013385453261435032, -0.0877884030342102, 0.032220300287008286, -0.031506218016147614, -0.010301916860044003, 0.03237537294626236, 0.023897171020507812, -0.011541010811924934, -0.08925345540046692, 0.00441425247117877, 0.020157508552074432, -0.058791473507881165, -0.0144652109593153, -0.016352754086256027, -0.02520282007753849, -0.02740590274333954, 0.03197282925248146, -0.00781277660280466, 0.06356709450483322, 0.02137701027095318, 0.026922274380922318, -0.03442760556936264, -0.03487334027886391, -0.08862818032503128, 0.09922424703836441, -0.08552505075931549, 0.04005192965269089, -0.07357717305421829, -0.056809719651937485, -0.06846502423286438, 0.05892940238118172, 0.05712132155895233, -0.009560258127748966, 0.06554580479860306, 0.04159596189856529, 0.05994263291358948, -0.04280053451657295, 0.044799916446208954, 0.05557170510292053, 0.049723848700523376, 0.09325654804706573, -0.024651100859045982, 0.07728128880262375, -0.0479920469224453, -0.051627159118652344, 0.024371743202209473, -0.0039902860298752785, -0.014401237480342388, 0.025063149631023407, 0.02353646047413349, 0.06017278507351875, -0.03108956292271614, 0.045735884457826614, -0.06268232315778732, 0.059106700122356415, -0.03886296600103378, -0.024543730542063713, 0.03377818688750267, 0.15788714587688446, -0.06178593263030052, 0.0065190354362130165, -0.05240894854068756, 0.009697437286376953, -0.016866708174347878, -0.03460152447223663, -0.02408427745103836, -0.015324319712817669, 0.036506008356809616, 0.021903295069932938, 0.002953913761302829, -0.02718740701675415, -0.05552688613533974, 0.025065423920750618, -0.08824232220649719, -0.04453318938612938, 0.0934087336063385, -0.0697304829955101, -0.017081476747989655, -0.002566099399700761, -0.015383975580334663, -0.04984984174370766, 0.04152803122997284, 0.0893472358584404, 0.01075640320777893, 0.11222083121538162, 0.028158390894532204, -0.06549113988876343, 0.06694483011960983, -0.05505562201142311, -0.013820336200296879, 0.013911528512835503, -0.031197287142276764, 0.05237583816051483, 0.023733200505375862, -5.0175096077964554e-08, -0.07347721606492996, 0.07143792510032654, 0.03880910202860832, -0.03248288109898567, 0.03800509124994278, -0.03589324280619621, -0.04069133847951889, 0.14421826601028442, -0.04464560002088547, -0.011612454429268837, 0.03589459881186485, -0.062124308198690414, -0.07075930386781693, 0.01712077297270298, 0.06096476688981056, 0.04680626094341278, 0.07880697399377823, 0.005898503120988607, -0.03018060512840748, 0.0042702024802565575, -0.011080215685069561, -0.02071968838572502, 0.04354439303278923, -0.008967551402747631, -0.03073444962501526, -0.09725973010063171, 0.002813316648826003, 0.07441570609807968, 0.08336324244737625, -0.008980159647762775, -0.07076467573642731, 0.0867873877286911, 0.035906605422496796, 0.04930543899536133, 0.1136641725897789, 0.007206407841295004, -0.05088600888848305, -0.03291367366909981, -0.024075914174318314, -0.016706638038158417, -0.027146797627210617, 0.07310517877340317, -0.04794212803244591, 0.009278161451220512, -0.022268135100603104, -0.1127016693353653, -0.014089246280491352, -0.09531261771917343, 0.016066880896687508, 0.06698045134544373, 0.07771366089582443, 0.018115680664777756, 0.018134232610464096, 0.1236066073179245, 0.014810415916144848, -0.031209800392389297, 0.07534615695476532, -0.05524099990725517, 0.04184534028172493, 0.09714847058057785, 0.0822422057390213, -0.06210894510149956, -0.03252195939421654, -0.07634053379297256]",
         "0.188"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 200
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>published</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>created_at</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>language</th>\n",
       "      <th>entities</th>\n",
       "      <th>embedding</th>\n",
       "      <th>quality_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>Top 10 AI Content Generator &amp; Writer Tools in ...</td>\n",
       "      <td>Are you looking for a way to create content th...</td>\n",
       "      <td>Top 10 AI Content Generator &amp; Writer Tools in ...</td>\n",
       "      <td>2022-11-15T08:58:00</td>\n",
       "      <td>https://feeds.feedburner.com/TechCrunch/</td>\n",
       "      <td>https://techncruncher.blogspot.com/2022/11/top...</td>\n",
       "      <td>2025-07-26T05:41:35.784294</td>\n",
       "      <td>Top 10 AI Content Generator &amp; Writer Tools in ...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'MISC': ['10 writing tools that used AI to cr...</td>\n",
       "      <td>[-0.11071627587080002, -0.041722897440195084, ...</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569</td>\n",
       "      <td>How I Fine-Tuned Granite-Vision 2B to Beat a 9...</td>\n",
       "      <td>A hands-on journey exploring fine-tuning techn...</td>\n",
       "      <td>or vision-language models is a powerful techni...</td>\n",
       "      <td>2025-07-25T19:29:01</td>\n",
       "      <td>https://towardsdatascience.com/feed</td>\n",
       "      <td>https://towardsdatascience.com/how-i-fine-tune...</td>\n",
       "      <td>2025-07-26T06:23:31.282901</td>\n",
       "      <td>or vision-language models is a powerful techni...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'PER': ['Ada Lovelace', 'Despite', 'Eli Schwa...</td>\n",
       "      <td>[-0.06249945983290672, -0.03206057474017143, -...</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>586</td>\n",
       "      <td>When LLMs Try to Reason: Experiments in Text a...</td>\n",
       "      <td>Can large language models learn to reason abst...</td>\n",
       "      <td>models learn to reason abstractly from just a ...</td>\n",
       "      <td>2025-07-22T19:35:25</td>\n",
       "      <td>https://towardsdatascience.com/feed</td>\n",
       "      <td>https://towardsdatascience.com/when-llms-try-t...</td>\n",
       "      <td>2025-07-26T06:23:31.390578</td>\n",
       "      <td>models learn to reason abstractly from just a ...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'MISC': ['# Black '#', '# Here is an extracte...</td>\n",
       "      <td>[0.004933114629238844, -0.06849845498800278, 0...</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>263</td>\n",
       "      <td>\"On n'a fait que du Tetris\" : on vous raconte ...</td>\n",
       "      <td>Vous pensiez tout savoir du spectacle mis en s...</td>\n",
       "      <td>Vous pensiez tout savoir du spectacle mis en s...</td>\n",
       "      <td>2025-07-26T05:00:37</td>\n",
       "      <td>https://www.francetvinfo.fr/titres.rss</td>\n",
       "      <td>https://www.franceinfo.fr/les-jeux-olympiques/...</td>\n",
       "      <td>2025-07-26T05:53:42.336454</td>\n",
       "      <td>Vous pensiez tout savoir du spectacle mis en s...</td>\n",
       "      <td>fr</td>\n",
       "      <td>{'PER': ['Alexandre Boyon', 'Alexis Decalonne'...</td>\n",
       "      <td>[-0.0072211455553770065, 0.07925660908222198, ...</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>578</td>\n",
       "      <td>How Not to Mislead with Your Data-Driven Story</td>\n",
       "      <td>Data storytelling can enlighten—but it can als...</td>\n",
       "      <td>is everywhere. There are countless books, arti...</td>\n",
       "      <td>2025-07-23T19:10:41</td>\n",
       "      <td>https://towardsdatascience.com/feed</td>\n",
       "      <td>https://towardsdatascience.com/how-not-to-misl...</td>\n",
       "      <td>2025-07-26T06:23:31.338091</td>\n",
       "      <td>is everywhere. There are countless books, arti...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'MISC': ['A clean', 'AI chatbots distort and ...</td>\n",
       "      <td>[0.05727158114314079, 0.09395787864923477, 0.0...</td>\n",
       "      <td>0.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>14</td>\n",
       "      <td>​​What is inside the GHF food aid box being di...</td>\n",
       "      <td>BBC Verify examines the meals handed out to Ga...</td>\n",
       "      <td>​​What is inside the GHF food aid box being di...</td>\n",
       "      <td>2025-07-25T23:41:52</td>\n",
       "      <td>https://feeds.bbci.co.uk/news/world/rss.xml</td>\n",
       "      <td>https://www.bbc.com/news/articles/cd787er1qz4o</td>\n",
       "      <td>2025-07-26T05:41:35.648879</td>\n",
       "      <td>​​What is inside the GHF food aid box being di...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'MISC': ['Dr Andrew Seal', 'GHF', 'He added t...</td>\n",
       "      <td>[-0.012845661491155624, 0.027754053473472595, ...</td>\n",
       "      <td>0.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>527</td>\n",
       "      <td>Alibaba’s new Qwen reasoning AI model sets ope...</td>\n",
       "      <td>The Qwen team from Alibaba have just released ...</td>\n",
       "      <td>The Qwen team from Alibaba have just released ...</td>\n",
       "      <td>2025-07-25T12:43:07</td>\n",
       "      <td>https://www.artificialintelligence-news.com/feed/</td>\n",
       "      <td>https://www.artificialintelligence-news.com/ne...</td>\n",
       "      <td>2025-07-26T05:53:46.540024</td>\n",
       "      <td>The Qwen team from Alibaba have just released ...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'MISC': ['AI model from the Qwen team with', ...</td>\n",
       "      <td>[-0.06894423812627792, -0.08636637032032013, -...</td>\n",
       "      <td>0.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>472</td>\n",
       "      <td>Plus de 20 000 suppressions de postes chez Int...</td>\n",
       "      <td>Intel taille dans le vif. Moins de cinq mois a...</td>\n",
       "      <td>Intel taille dans le vif. Moins de cinq mois a...</td>\n",
       "      <td>2025-07-25T12:46:24</td>\n",
       "      <td>https://www.01net.com/rss/actualites/</td>\n",
       "      <td>https://www.01net.com/actualites/plus-de-20-00...</td>\n",
       "      <td>2025-07-26T05:53:45.935827</td>\n",
       "      <td>Intel taille dans le vif. Moins de cinq mois a...</td>\n",
       "      <td>fr</td>\n",
       "      <td>{'ORG': ['CNBC', 'Intel', 'Lip-Bu Tan', 'Micro...</td>\n",
       "      <td>[-0.02674338035285473, 0.021592628210783005, 0...</td>\n",
       "      <td>0.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>309</td>\n",
       "      <td>Centrafrique: la pression se renforce sur le g...</td>\n",
       "      <td>En Centrafrique, la pression s'accentue sur le...</td>\n",
       "      <td>En Centrafrique, la pression s'accentue sur le...</td>\n",
       "      <td>2025-07-25T23:05:15</td>\n",
       "      <td>https://www.rfi.fr/fr/rss</td>\n",
       "      <td>https://www.rfi.fr/fr/afrique/20250725-centraf...</td>\n",
       "      <td>2025-07-26T05:53:43.541609</td>\n",
       "      <td>En Centrafrique, la pression s'accentue sur le...</td>\n",
       "      <td>fr</td>\n",
       "      <td>{'LOC': ['Bangui', 'Cameroun', 'Centrafrique',...</td>\n",
       "      <td>[-0.06552132964134216, 0.03700387477874756, -0...</td>\n",
       "      <td>0.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>289</td>\n",
       "      <td>Taiwan votes to decide whether to oust lawmake...</td>\n",
       "      <td>Taiwanese were voting Saturday to determine wh...</td>\n",
       "      <td>Taiwan votes to decide whether to oust lawmake...</td>\n",
       "      <td>2025-07-26T05:39:06</td>\n",
       "      <td>https://www.npr.org/rss/rss.php?id=1001</td>\n",
       "      <td>https://www.npr.org/2025/07/26/g-s1-79686/taiw...</td>\n",
       "      <td>2025-07-26T05:53:42.977959</td>\n",
       "      <td>Taiwan votes to decide whether to oust lawmake...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'LOC': ['Outside', 'Taipei', 'Taiwan', 'at le...</td>\n",
       "      <td>[0.004105429630726576, 0.021461015567183495, 0...</td>\n",
       "      <td>0.243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0     26  Top 10 AI Content Generator & Writer Tools in ...   \n",
       "1    569  How I Fine-Tuned Granite-Vision 2B to Beat a 9...   \n",
       "2    586  When LLMs Try to Reason: Experiments in Text a...   \n",
       "3    263  \"On n'a fait que du Tetris\" : on vous raconte ...   \n",
       "4    578     How Not to Mislead with Your Data-Driven Story   \n",
       "..   ...                                                ...   \n",
       "195   14  ​​What is inside the GHF food aid box being di...   \n",
       "196  527  Alibaba’s new Qwen reasoning AI model sets ope...   \n",
       "197  472  Plus de 20 000 suppressions de postes chez Int...   \n",
       "198  309  Centrafrique: la pression se renforce sur le g...   \n",
       "199  289  Taiwan votes to decide whether to oust lawmake...   \n",
       "\n",
       "                                               summary  \\\n",
       "0    Are you looking for a way to create content th...   \n",
       "1    A hands-on journey exploring fine-tuning techn...   \n",
       "2    Can large language models learn to reason abst...   \n",
       "3    Vous pensiez tout savoir du spectacle mis en s...   \n",
       "4    Data storytelling can enlighten—but it can als...   \n",
       "..                                                 ...   \n",
       "195  BBC Verify examines the meals handed out to Ga...   \n",
       "196  The Qwen team from Alibaba have just released ...   \n",
       "197  Intel taille dans le vif. Moins de cinq mois a...   \n",
       "198  En Centrafrique, la pression s'accentue sur le...   \n",
       "199  Taiwanese were voting Saturday to determine wh...   \n",
       "\n",
       "                                                  text            published  \\\n",
       "0    Top 10 AI Content Generator & Writer Tools in ...  2022-11-15T08:58:00   \n",
       "1    or vision-language models is a powerful techni...  2025-07-25T19:29:01   \n",
       "2    models learn to reason abstractly from just a ...  2025-07-22T19:35:25   \n",
       "3    Vous pensiez tout savoir du spectacle mis en s...  2025-07-26T05:00:37   \n",
       "4    is everywhere. There are countless books, arti...  2025-07-23T19:10:41   \n",
       "..                                                 ...                  ...   \n",
       "195  ​​What is inside the GHF food aid box being di...  2025-07-25T23:41:52   \n",
       "196  The Qwen team from Alibaba have just released ...  2025-07-25T12:43:07   \n",
       "197  Intel taille dans le vif. Moins de cinq mois a...  2025-07-25T12:46:24   \n",
       "198  En Centrafrique, la pression s'accentue sur le...  2025-07-25T23:05:15   \n",
       "199  Taiwan votes to decide whether to oust lawmake...  2025-07-26T05:39:06   \n",
       "\n",
       "                                                source  \\\n",
       "0             https://feeds.feedburner.com/TechCrunch/   \n",
       "1                  https://towardsdatascience.com/feed   \n",
       "2                  https://towardsdatascience.com/feed   \n",
       "3               https://www.francetvinfo.fr/titres.rss   \n",
       "4                  https://towardsdatascience.com/feed   \n",
       "..                                                 ...   \n",
       "195        https://feeds.bbci.co.uk/news/world/rss.xml   \n",
       "196  https://www.artificialintelligence-news.com/feed/   \n",
       "197              https://www.01net.com/rss/actualites/   \n",
       "198                          https://www.rfi.fr/fr/rss   \n",
       "199            https://www.npr.org/rss/rss.php?id=1001   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://techncruncher.blogspot.com/2022/11/top...   \n",
       "1    https://towardsdatascience.com/how-i-fine-tune...   \n",
       "2    https://towardsdatascience.com/when-llms-try-t...   \n",
       "3    https://www.franceinfo.fr/les-jeux-olympiques/...   \n",
       "4    https://towardsdatascience.com/how-not-to-misl...   \n",
       "..                                                 ...   \n",
       "195     https://www.bbc.com/news/articles/cd787er1qz4o   \n",
       "196  https://www.artificialintelligence-news.com/ne...   \n",
       "197  https://www.01net.com/actualites/plus-de-20-00...   \n",
       "198  https://www.rfi.fr/fr/afrique/20250725-centraf...   \n",
       "199  https://www.npr.org/2025/07/26/g-s1-79686/taiw...   \n",
       "\n",
       "                     created_at  \\\n",
       "0    2025-07-26T05:41:35.784294   \n",
       "1    2025-07-26T06:23:31.282901   \n",
       "2    2025-07-26T06:23:31.390578   \n",
       "3    2025-07-26T05:53:42.336454   \n",
       "4    2025-07-26T06:23:31.338091   \n",
       "..                          ...   \n",
       "195  2025-07-26T05:41:35.648879   \n",
       "196  2025-07-26T05:53:46.540024   \n",
       "197  2025-07-26T05:53:45.935827   \n",
       "198  2025-07-26T05:53:43.541609   \n",
       "199  2025-07-26T05:53:42.977959   \n",
       "\n",
       "                                          cleaned_text language  \\\n",
       "0    Top 10 AI Content Generator & Writer Tools in ...       en   \n",
       "1    or vision-language models is a powerful techni...       en   \n",
       "2    models learn to reason abstractly from just a ...       en   \n",
       "3    Vous pensiez tout savoir du spectacle mis en s...       fr   \n",
       "4    is everywhere. There are countless books, arti...       en   \n",
       "..                                                 ...      ...   \n",
       "195  ​​What is inside the GHF food aid box being di...       en   \n",
       "196  The Qwen team from Alibaba have just released ...       en   \n",
       "197  Intel taille dans le vif. Moins de cinq mois a...       fr   \n",
       "198  En Centrafrique, la pression s'accentue sur le...       fr   \n",
       "199  Taiwan votes to decide whether to oust lawmake...       en   \n",
       "\n",
       "                                              entities  \\\n",
       "0    {'MISC': ['10 writing tools that used AI to cr...   \n",
       "1    {'PER': ['Ada Lovelace', 'Despite', 'Eli Schwa...   \n",
       "2    {'MISC': ['# Black '#', '# Here is an extracte...   \n",
       "3    {'PER': ['Alexandre Boyon', 'Alexis Decalonne'...   \n",
       "4    {'MISC': ['A clean', 'AI chatbots distort and ...   \n",
       "..                                                 ...   \n",
       "195  {'MISC': ['Dr Andrew Seal', 'GHF', 'He added t...   \n",
       "196  {'MISC': ['AI model from the Qwen team with', ...   \n",
       "197  {'ORG': ['CNBC', 'Intel', 'Lip-Bu Tan', 'Micro...   \n",
       "198  {'LOC': ['Bangui', 'Cameroun', 'Centrafrique',...   \n",
       "199  {'LOC': ['Outside', 'Taipei', 'Taiwan', 'at le...   \n",
       "\n",
       "                                             embedding  quality_score  \n",
       "0    [-0.11071627587080002, -0.041722897440195084, ...          0.142  \n",
       "1    [-0.06249945983290672, -0.03206057474017143, -...          0.146  \n",
       "2    [0.004933114629238844, -0.06849845498800278, 0...          0.153  \n",
       "3    [-0.0072211455553770065, 0.07925660908222198, ...          0.179  \n",
       "4    [0.05727158114314079, 0.09395787864923477, 0.0...          0.194  \n",
       "..                                                 ...            ...  \n",
       "195  [-0.012845661491155624, 0.027754053473472595, ...          0.243  \n",
       "196  [-0.06894423812627792, -0.08636637032032013, -...          0.243  \n",
       "197  [-0.02674338035285473, 0.021592628210783005, 0...          0.256  \n",
       "198  [-0.06552132964134216, 0.03700387477874756, -0...          0.249  \n",
       "199  [0.004105429630726576, 0.021461015567183495, 0...          0.243  \n",
       "\n",
       "[200 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9949d9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Harmonisation: cleaned_text → text_cleaned\n",
      "   Toutes les colonnes essentielles présentes\n",
      "   Structure: 200 articles, 14 colonnes\n"
     ]
    }
   ],
   "source": [
    "# Harmonisation text_cleaned vs cleaned_text\n",
    "if 'cleaned_text' in df.columns and 'text_cleaned' not in df.columns:\n",
    "    df['text_cleaned'] = df['cleaned_text']\n",
    "    print(\"   Harmonisation: cleaned_text → text_cleaned\")\n",
    "elif 'text' in df.columns and 'text_cleaned' not in df.columns:\n",
    "    df['text_cleaned'] = df['text']\n",
    "    print(\"   Création: text → text_cleaned\")\n",
    "\n",
    "# Vérification des colonnes essentielles\n",
    "required_columns = ['title', 'text', 'source']\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    print(f\"   Colonnes manquantes: {missing_columns}\")\n",
    "else:\n",
    "    print(\"   Toutes les colonnes essentielles présentes\")\n",
    "\n",
    "print(f\"   Structure: {len(df)} articles, {len(df.columns)} colonnes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "586148c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détection des colonnes d'enrichissement déjà présentes\n",
    "enrichment_columns = {\n",
    "    'language': 'language' in df.columns and df['language'].notna().sum() > 0,\n",
    "    'entities': 'entities' in df.columns and df['entities'].notna().sum() > 0,\n",
    "    'quality_score': 'quality_score' in df.columns and df['quality_score'].notna().sum() > 0,\n",
    "    'embedding': 'embedding' in df.columns and df['embedding'].notna().sum() > 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb77985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   language: Présent (200 articles)\n",
      "   entities: Présent (200 articles)\n",
      "   quality_score: Présent (200 articles)\n",
      "   embedding: Présent (200 articles)\n",
      "\n",
      "MODE DÉTECTÉ: Preprocessing complémentaire avancé\n",
      "   → Focus: Déduplication, biais, corpus calibration, métriques avancées\n"
     ]
    }
   ],
   "source": [
    "for col, present in enrichment_columns.items():\n",
    "    status = \"Présent\" if present else \"Absent\"\n",
    "    count = df[col].notna().sum() if present else 0\n",
    "    print(f\"   {col}: {status} ({count} articles)\")\n",
    "\n",
    "# Adaptation de la stratégie\n",
    "if enrichment_columns['language'] and enrichment_columns['entities']:\n",
    "    print(f\"\\nMODE DÉTECTÉ: Preprocessing complémentaire avancé\")\n",
    "    print(f\"   → Focus: Déduplication, biais, corpus calibration, métriques avancées\")\n",
    "    SKIP_BASIC_ENRICHMENT = True\n",
    "else:\n",
    "    print(f\"\\nMODE DÉTECTÉ: Preprocessing complet depuis zéro\")\n",
    "    print(f\"   → Pipeline: Enrichissement + Analyses avancées\")\n",
    "    SKIP_BASIC_ENRICHMENT = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45f12352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Textes déjà nettoyés détectés\n",
      "   Filtrage longueur minimum (100 chars): 200 → 200 articles\n"
     ]
    }
   ],
   "source": [
    "def clean_text_advanced(text):\n",
    "    \"\"\"Nettoyage robuste et avancé du texte\"\"\"\n",
    "    if pd.isna(text) or not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Correction encodage\n",
    "    text = ftfy.fix_text(text)\n",
    "    # Suppression HTML résiduel\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    # Normalisation Unicode\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    # Suppression caractères de contrôle\n",
    "    text = re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', '', text)\n",
    "    # Normalisation espaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Suppression URLs et emails\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    # Suppression patterns RSS spécifiques\n",
    "    text = re.sub(r'#xtor=RSS-\\d+.*', '', text)\n",
    "    text = re.sub(r'\\[.*?\\]$', '', text)  # Crédits en fin d'article\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Application du nettoyage si nécessaire\n",
    "if 'text_cleaned' not in df.columns or df['text_cleaned'].isna().any():\n",
    "    print(\"   Application du nettoyage avancé...\")\n",
    "    df['text_cleaned'] = df['text'].apply(clean_text_advanced)\n",
    "    print(f\"      {len(df)} textes nettoyés\")\n",
    "else:\n",
    "    print(\"   Textes déjà nettoyés détectés\")\n",
    "\n",
    "# Filtrage des articles trop courts ou vides\n",
    "min_length = 100  # caractères minimum\n",
    "df_clean = df[df['text_cleaned'].str.len() >= min_length].copy()\n",
    "print(f\"   Filtrage longueur minimum ({min_length} chars): {len(df)} → {len(df_clean)} articles\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eccbd9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Langues déjà détectées, validation des données...\n",
      "   Focus français: 130 articles sélectionnés\n"
     ]
    }
   ],
   "source": [
    "if not enrichment_columns['language'] or not SKIP_BASIC_ENRICHMENT:\n",
    "    print(\"   Détection de langue en cours...\")\n",
    "    def detect_language_robust(text):\n",
    "        \"\"\"Détection de langue avec fallback\"\"\"\n",
    "        if not text or len(text) < 50:\n",
    "            return 'unknown', 0.0\n",
    "        \n",
    "        try:\n",
    "            # langdetect avec probabilités\n",
    "            langs = detect_langs(text)\n",
    "            primary_lang = langs[0]\n",
    "            return primary_lang.lang, primary_lang.prob\n",
    "        except LangDetectException:\n",
    "            # Fallback: détection basique\n",
    "            try:\n",
    "                return detect(text), 0.5\n",
    "            except:\n",
    "                return 'unknown', 0.0\n",
    "\n",
    "    # Application de la détection\n",
    "    language_results = df_clean['text_cleaned'].apply(detect_language_robust)\n",
    "    df_clean['language'] = [result[0] for result in language_results]\n",
    "    df_clean['language_confidence'] = [result[1] for result in language_results]\n",
    "    \n",
    "    print(f\"   Détection de langue terminée\")\n",
    "else:\n",
    "    print(\"   Langues déjà détectées, validation des données...\")\n",
    "    if 'language_confidence' not in df_clean.columns:\n",
    "        df_clean['language_confidence'] = df_clean['language'].apply(lambda x: 0.9 if x == 'fr' else 0.7)\n",
    "\n",
    "# Sélection intelligente selon la distribution\n",
    "lang_counts = df_clean['language'].value_counts()\n",
    "if lang_counts.get('fr', 0) > len(df_clean) * 0.3:  # Si >30% en français\n",
    "    df_filtered = df_clean[df_clean['language'] == 'fr'].copy()\n",
    "    print(f\"   Focus français: {len(df_filtered)} articles sélectionnés\")\n",
    "else:\n",
    "    # Garder top 2 langues si pas assez de français\n",
    "    top_langs = lang_counts.head(2).index.tolist()\n",
    "    df_filtered = df_clean[df_clean['language'].isin(top_langs)].copy()\n",
    "    print(f\"   Multi-langues: {len(df_filtered)} articles ({top_langs})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68357aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Chargement du modèle sentence-transformers...\n",
      "      Modèle all-MiniLM-L6-v2 chargé avec succès\n"
     ]
    }
   ],
   "source": [
    "# Chargement du modèle d'embeddings avec gestion d'erreur\n",
    "print(\"   Chargement du modèle sentence-transformers...\")\n",
    "try:\n",
    "    embeddings_model = SentenceTransformer(EMBEDDINGS_MODEL)\n",
    "    print(f\"      Modèle {EMBEDDINGS_MODEL} chargé avec succès\")\n",
    "except OSError as e:\n",
    "    if \"pagination\" in str(e) or \"1455\" in str(e):\n",
    "        print(f\"      Erreur mémoire détectée, utilisation d'un modèle plus léger...\")\n",
    "        # Fallback vers un modèle encore plus petit\n",
    "        EMBEDDINGS_MODEL_FALLBACK = \"all-MiniLM-L6-v2\"\n",
    "        embeddings_model = SentenceTransformer(EMBEDDINGS_MODEL_FALLBACK)\n",
    "        print(f\"      Modèle fallback {EMBEDDINGS_MODEL_FALLBACK} chargé\")\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "def deduplicate_semantic(df, threshold=0.85):\n",
    "    \"\"\"Déduplication sémantique avancée avec FAISS et correction du type\"\"\"\n",
    "    print(f\"   Génération des embeddings pour {len(df)} articles...\")\n",
    "    \n",
    "    # Utilisation des embeddings existants ou génération\n",
    "    if 'embedding' in df.columns and df['embedding'].notna().sum() > 0:\n",
    "        print(\"      Utilisation des embeddings existants\")\n",
    "        embeddings = []\n",
    "        for idx, emb in df['embedding'].items():\n",
    "            if isinstance(emb, (list, np.ndarray)) and len(emb) > 0:\n",
    "                embeddings.append(np.array(emb, dtype=np.float32))  # CORRECTION: forcer float32\n",
    "            else:\n",
    "                # Génération pour les embeddings manquants\n",
    "                text = df.loc[idx, 'text_cleaned']\n",
    "                new_emb = embeddings_model.encode(text)\n",
    "                embeddings.append(np.array(new_emb, dtype=np.float32))  # CORRECTION: forcer float32\n",
    "        embeddings = np.array(embeddings, dtype=np.float32)  # CORRECTION: forcer float32\n",
    "    else:\n",
    "        print(\"      Génération des embeddings...\")\n",
    "        texts = df['text_cleaned'].tolist()\n",
    "        embeddings = embeddings_model.encode(texts, show_progress_bar=True)\n",
    "        embeddings = np.array(embeddings, dtype=np.float32)  # CORRECTION: forcer float32\n",
    "\n",
    "    # Configuration FAISS\n",
    "    print(\"   Configuration de l'index FAISS...\")\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "\n",
    "    # CORRECTION: Normalisation avec vérification du type et copie\n",
    "    embeddings_normalized = embeddings.copy()  # Créer une copie\n",
    "    if not embeddings_normalized.flags['C_CONTIGUOUS']:\n",
    "        embeddings_normalized = np.ascontiguousarray(embeddings_normalized)  # Assurer la contiguïté\n",
    "\n",
    "    faiss.normalize_L2(embeddings_normalized)  # Normaliser la copie\n",
    "    index.add(embeddings_normalized)\n",
    "    \n",
    "    # Recherche des doublons\n",
    "    print(\"   Recherche des doublons sémantiques...\")\n",
    "    similarities, indices = index.search(embeddings_normalized, k=5)\n",
    "    \n",
    "    to_remove = set()\n",
    "    duplicate_pairs = []\n",
    "    \n",
    "    for i, (sim_scores, sim_indices) in enumerate(zip(similarities, indices)):\n",
    "        for j, (score, idx) in enumerate(zip(sim_scores, sim_indices)):\n",
    "            if j > 0 and score > threshold and idx not in to_remove and i not in to_remove:\n",
    "                # Garde le plus récent ou le mieux noté\n",
    "                if df.iloc[i].get('quality_score', 0) >= df.iloc[idx].get('quality_score', 0):\n",
    "                    to_remove.add(idx)\n",
    "                else:\n",
    "                    to_remove.add(i)\n",
    "                \n",
    "                duplicate_pairs.append((i, idx, score))\n",
    "    \n",
    "    # Suppression des doublons\n",
    "    df_dedup = df.drop(df.index[list(to_remove)]).copy()\n",
    "    \n",
    "    print(f\"   Résultats déduplication:\")\n",
    "    print(f\"      Articles originaux: {len(df)}\")\n",
    "    print(f\"      Doublons détectés: {len(to_remove)}\")\n",
    "    print(f\"      Articles finaux: {len(df_dedup)}\")\n",
    "    print(f\"      Taux de déduplication: {len(to_remove)/len(df)*100:.1f}%\")\n",
    "\n",
    "    return df_dedup, embeddings_normalized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdcb16bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Génération des embeddings pour 130 articles...\n",
      "      Utilisation des embeddings existants\n",
      "   Configuration de l'index FAISS...\n",
      "   Recherche des doublons sémantiques...\n",
      "   Résultats déduplication:\n",
      "      Articles originaux: 130\n",
      "      Doublons détectés: 2\n",
      "      Articles finaux: 128\n",
      "      Taux de déduplication: 1.5%\n"
     ]
    }
   ],
   "source": [
    "# Application de la déduplication\n",
    "df_clean_dedup, article_embeddings = deduplicate_semantic(df_filtered, SIMILARITY_THRESHOLD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65ac4cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Conversion et amélioration des entités existantes...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not enrichment_columns['entities'] or not SKIP_BASIC_ENRICHMENT:\n",
    "    print(\"   Extraction complète des entités avec spaCy...\")\n",
    "    \n",
    "    # Chargement du modèle spaCy français\n",
    "    print(f\"      Chargement du modèle spaCy: {NLP_MODEL}\")\n",
    "    try:\n",
    "        nlp = spacy.load(NLP_MODEL)\n",
    "    except OSError:\n",
    "        print(f\"      Modèle {NLP_MODEL} non trouvé. Installation...\")\n",
    "        import subprocess\n",
    "        subprocess.run(f\"python -m spacy download {NLP_MODEL}\", shell=True)\n",
    "        nlp = spacy.load(NLP_MODEL)\n",
    "\n",
    "    def extract_entities_advanced(text, nlp_model):\n",
    "        \"\"\"Extraction d'entités avec enrichissements\"\"\"\n",
    "        if not text or len(text) < 50:\n",
    "            return {\n",
    "                'persons': [], 'organizations': [], 'locations': [],\n",
    "                'dates': [], 'money': [], 'misc': []\n",
    "            }\n",
    "        \n",
    "        # Traitement avec spaCy (limiter la longueur pour performance)\n",
    "        doc = nlp_model(text[:8000])  # Premier 8k caractères\n",
    "        \n",
    "        entities = {\n",
    "            'persons': [],\n",
    "            'organizations': [],\n",
    "            'locations': [],\n",
    "            'dates': [],\n",
    "            'money': [],\n",
    "            'misc': []\n",
    "        }\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            entity_text = ent.text.strip()\n",
    "            if len(entity_text) < 2:  # Ignorer entités trop courtes\n",
    "                continue\n",
    "                \n",
    "            if ent.label_ in ['PERSON']:\n",
    "                entities['persons'].append(entity_text)\n",
    "            elif ent.label_ in ['ORG']:\n",
    "                entities['organizations'].append(entity_text)\n",
    "            elif ent.label_ in ['GPE', 'LOC']:\n",
    "                entities['locations'].append(entity_text)\n",
    "            elif ent.label_ in ['DATE', 'TIME']:\n",
    "                entities['dates'].append(entity_text)\n",
    "            elif ent.label_ in ['MONEY']:\n",
    "                entities['money'].append(entity_text)\n",
    "            else:\n",
    "                entities['misc'].append(entity_text)\n",
    "        \n",
    "        # Déduplication et nettoyage\n",
    "        for key in entities:\n",
    "            entities[key] = list(set(entities[key]))  # Suppression doublons\n",
    "            entities[key] = [e for e in entities[key] if len(e) > 1]  # Filtrage longueur\n",
    "        \n",
    "        return entities\n",
    "\n",
    "    # Application de l'extraction d'entités\n",
    "    entities_results = []\n",
    "    for text in tqdm(df_clean_dedup['text_cleaned'], desc=\"Extraction NER\"):\n",
    "        entities = extract_entities_advanced(text, nlp)\n",
    "        entities_results.append(entities)\n",
    "\n",
    "    # Ajout des résultats au DataFrame\n",
    "    df_clean_dedup['entities_advanced'] = entities_results\n",
    "    \n",
    "    print(f\"      Extraction NER terminée\")\n",
    "else:\n",
    "    print(\"   Conversion et amélioration des entités existantes...\")\n",
    "    def convert_and_improve_entities(existing_entities):\n",
    "        \"\"\"CONVERSION du format existant + amélioration\"\"\"\n",
    "        if not existing_entities or not isinstance(existing_entities, dict):\n",
    "            return {\n",
    "                'persons': [], 'organizations': [], 'locations': [],\n",
    "                'dates': [], 'money': [], 'misc': []\n",
    "            }\n",
    "        \n",
    "        # CONVERSION DES FORMATS\n",
    "        converted = {\n",
    "            'persons': [],\n",
    "            'organizations': [],\n",
    "            'locations': [],\n",
    "            'dates': [],\n",
    "            'money': [],\n",
    "            'misc': []\n",
    "        }\n",
    "        \n",
    "        # Mapping des anciens noms vers les nouveaux\n",
    "        field_mapping = {\n",
    "            'PER': 'persons',           # PER → persons\n",
    "            'PERSON': 'persons',        # PERSON → persons  \n",
    "            'ORG': 'organizations',     # ORG → organizations\n",
    "            'LOC': 'locations',         # LOC → locations\n",
    "            'GPE': 'locations',         # GPE → locations (entités géopolitiques)\n",
    "            'MISC': 'misc',             # MISC → misc\n",
    "            'DATE': 'dates',            # DATE → dates\n",
    "            'TIME': 'dates',            # TIME → dates\n",
    "            'MONEY': 'money'            # MONEY → money\n",
    "        }\n",
    "        \n",
    "        # Conversion avec mapping\n",
    "        for old_key, entity_list in existing_entities.items():\n",
    "            if old_key in field_mapping:\n",
    "                new_key = field_mapping[old_key]\n",
    "                if isinstance(entity_list, list):\n",
    "                    # Nettoyage des entités\n",
    "                    cleaned = [str(e).strip() for e in entity_list if e and len(str(e)) > 1]\n",
    "                    # Déduplication case-insensitive\n",
    "                    seen = set()\n",
    "                    for entity in cleaned:\n",
    "                        if entity.lower() not in seen:\n",
    "                            converted[new_key].append(entity)\n",
    "                            seen.add(entity.lower())\n",
    "        \n",
    "        return converted\n",
    "\n",
    "    # Application de la conversion\n",
    "    df_clean_dedup['entities_advanced'] = df_clean_dedup['entities'].apply(convert_and_improve_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5af3391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Résumé entités: 23.1 entités/article en moyenne\n"
     ]
    }
   ],
   "source": [
    "# Création de colonnes métriques enrichies\n",
    "df_clean_dedup['persons_count'] = df_clean_dedup['entities_advanced'].apply(lambda x: len(x.get('persons', [])))\n",
    "df_clean_dedup['organizations_count'] = df_clean_dedup['entities_advanced'].apply(lambda x: len(x.get('organizations', [])))\n",
    "df_clean_dedup['locations_count'] = df_clean_dedup['entities_advanced'].apply(lambda x: len(x.get('locations', [])))\n",
    "df_clean_dedup['entities_total'] = (df_clean_dedup['persons_count'] + \n",
    "                                   df_clean_dedup['organizations_count'] +\n",
    "                                   df_clean_dedup['locations_count'])\n",
    "\n",
    "print(f\"   Résumé entités: {df_clean_dedup['entities_total'].mean():.1f} entités/article en moyenne\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27fd3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Téléchargement des ressources NLTK si nécessaire\n",
    "try:\n",
    "    import ssl\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "except:\n",
    "    pass\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "def segment_text_advanced(text):\n",
    "    \"\"\"Segmentation en phrases avec analyse sémantique avancée\"\"\"\n",
    "    if not text or len(text) < 100:\n",
    "        return {\n",
    "            'sentences': [],\n",
    "            'sentence_count': 0,\n",
    "            'avg_sentence_length': 0,\n",
    "            'paragraphs': [],\n",
    "            'paragraph_count': 0,\n",
    "            'text_complexity': 0,\n",
    "            'readability_score': 0\n",
    "        }\n",
    "    \n",
    "    # Segmentation en phrases (multi-langue)\n",
    "    sentences = sent_tokenize(text[:5000], language='french')  # Limiter pour performance\n",
    "    \n",
    "    # Segmentation en paragraphes\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip() and len(p) > 20]\n",
    "\n",
    "    # Métriques avancées\n",
    "    sentence_lengths = [len(s.split()) for s in sentences]\n",
    "    avg_sentence_length = np.mean(sentence_lengths) if sentence_lengths else 0\n",
    "    \n",
    "    # Score de complexité basé sur la longueur des phrases\n",
    "    complexity = 0\n",
    "    if sentence_lengths:\n",
    "        variance = np.var(sentence_lengths)\n",
    "        long_sentences = sum(1 for length in sentence_lengths if length > 20)\n",
    "        complexity = min((variance / 100) + (long_sentences / len(sentences)), 1.0)\n",
    "\n",
    "    # Score de lisibilité approximatif (Flesch-like)\n",
    "    if sentence_lengths and avg_sentence_length > 0:\n",
    "        readability = max(0, min(1, 1 - (avg_sentence_length - 10) / 20))\n",
    "    else:\n",
    "        readability = 0.5\n",
    "\n",
    "    return {\n",
    "        'sentences': sentences[:50],  # Limiter pour stockage\n",
    "        'sentence_count': len(sentences),\n",
    "        'avg_sentence_length': avg_sentence_length,\n",
    "        'paragraphs': paragraphs[:20],  # Limiter pour stockage\n",
    "        'paragraph_count': len(paragraphs),\n",
    "        'text_complexity': complexity,\n",
    "        'readability_score': readability\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59dbaa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Segmentation  en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmentation: 100%|██████████| 128/128 [00:00<00:00, 801.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# Application de la segmentation\n",
    "print(\"   Segmentation  en cours...\")\n",
    "segmentation_results = []\n",
    "for text in tqdm(df_clean_dedup['text_cleaned'], desc=\"Segmentation\"):\n",
    "    segments = segment_text_advanced(text)\n",
    "    segmentation_results.append(segments)\n",
    "\n",
    "df_clean_dedup['segmentation'] = segmentation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faa53e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Résumé segmentation: 29.7 phrases/article\n"
     ]
    }
   ],
   "source": [
    "# Extraction des métriques de segmentation\n",
    "df_clean_dedup['sentence_count'] = df_clean_dedup['segmentation'].apply(lambda x: x['sentence_count'])\n",
    "df_clean_dedup['paragraph_count'] = df_clean_dedup['segmentation'].apply(lambda x: x['paragraph_count'])\n",
    "df_clean_dedup['avg_sentence_length'] = df_clean_dedup['segmentation'].apply(lambda x: x['avg_sentence_length'])\n",
    "df_clean_dedup['text_complexity'] = df_clean_dedup['segmentation'].apply(lambda x: x['text_complexity'])\n",
    "df_clean_dedup['readability_score'] = df_clean_dedup['segmentation'].apply(lambda x: x['readability_score'])\n",
    "\n",
    "print(f\"   Résumé segmentation: {df_clean_dedup['sentence_count'].mean():.1f} phrases/article\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7000f07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Analyse temporelle...\n"
     ]
    }
   ],
   "source": [
    "# Conversion et nettoyage des dates\n",
    "print(\"   Analyse temporelle...\")\n",
    "df_clean_dedup['published_clean'] = pd.to_datetime(df_clean_dedup['published'], errors='coerce')\n",
    "\n",
    "# Extraction des composants temporels\n",
    "df_clean_dedup['hour'] = df_clean_dedup['published_clean'].dt.hour\n",
    "df_clean_dedup['day_of_week'] = df_clean_dedup['published_clean'].dt.day_name()\n",
    "df_clean_dedup['month'] = df_clean_dedup['published_clean'].dt.month\n",
    "df_clean_dedup['date_only'] = df_clean_dedup['published_clean'].dt.date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceae490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Biais temporel détecté: 0.81 (horaire), 0.50 (quotidien)\n"
     ]
    }
   ],
   "source": [
    "# Analyse des biais temporels\n",
    "valid_dates = df_clean_dedup[df_clean_dedup['published_clean'].notna()]\n",
    "if len(valid_dates) > 0:\n",
    "    # Distribution horaire\n",
    "    hour_dist = valid_dates['hour'].value_counts().head(3)\n",
    "    # Distribution par jour\n",
    "    day_dist = valid_dates['day_of_week'].value_counts().head(3)\n",
    "    \n",
    "    # Calcul du score de biais temporel\n",
    "    hour_entropy = -sum((p := hour_dist / len(valid_dates)) * np.log2(p + 1e-10))\n",
    "    day_entropy = -sum((p := day_dist / len(valid_dates)) * np.log2(p + 1e-10))\n",
    "    \n",
    "    # Normalisation (entropie max = log2(24) pour heures, log2(7) pour jours)\n",
    "    hour_bias = 1 - (hour_entropy / np.log2(24))  # 0 = uniforme, 1 = très biaisé\n",
    "    day_bias = 1 - (day_entropy / np.log2(7))\n",
    "    \n",
    "    print(f\"      Biais temporel détecté: {hour_bias:.2f} (horaire), {day_bias:.2f} (quotidien)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d483b311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Analyse géographique...\n",
      "      Biais géographique détecté: -0.57\n"
     ]
    }
   ],
   "source": [
    "# Analyse géographique via entités lieux\n",
    "print(\"   Analyse géographique...\")\n",
    "all_locations = []\n",
    "location_counts_by_article = []\n",
    "for entities in df_clean_dedup['entities_advanced']:\n",
    "    article_locations = entities.get('locations', [])\n",
    "    location_counts_by_article.append(len(article_locations))\n",
    "    all_locations.extend(article_locations)\n",
    "\n",
    "location_distribution = Counter(all_locations)\n",
    "df_clean_dedup['locations_count'] = location_counts_by_article\n",
    "\n",
    "if location_distribution:\n",
    "    # Score de biais géographique\n",
    "    if len(location_distribution) > 1:\n",
    "        geo_probs = np.array(list(location_distribution.values())) / len(all_locations)\n",
    "        geo_entropy = -sum(geo_probs * np.log2(geo_probs + 1e-10))\n",
    "        max_entropy = np.log2(min(len(location_distribution), 50))  # Entropie max théorique\n",
    "        geo_bias = 1 - (geo_entropy / max_entropy) if max_entropy > 0 else 0\n",
    "        print(f\"      Biais géographique détecté: {geo_bias:.2f}\")\n",
    "    else:\n",
    "        geo_bias = 1.0  # Maximum bias if only one location\n",
    "        print(f\"      Biais géographique maximal détecté\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06de1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des scores de biais au DataFrame\n",
    "df_clean_dedup['temporal_bias_hour'] = hour_bias if 'hour_bias' in locals() else 0\n",
    "df_clean_dedup['temporal_bias_day'] = day_bias if 'day_bias' in locals() else 0\n",
    "df_clean_dedup['geographic_bias'] = geo_bias if 'geo_bias' in locals() else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d2504fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_advanced_quality_score(row):\n",
    "    \"\"\"Calcul d'un score de qualité multi-dimensionnel\"\"\"\n",
    "    scores = {}\n",
    "    \n",
    "    # 1. Score de longueur (0-1)\n",
    "    text_len = len(str(row.get('text_cleaned', '')))\n",
    "    scores['length'] = min(text_len / 2000, 1.0)  # Optimal à 2000 caractères\n",
    "    \n",
    "    # 2. Score d'entités (0-1)\n",
    "    entities_count = row.get('entities_total', 0)\n",
    "    scores['entities'] = min(entities_count / 10, 1.0)  # Optimal à 10 entités\n",
    "    \n",
    "    # 3. Score de lisibilité (0-1)\n",
    "    scores['readability'] = row.get('readability_score', 0.5)\n",
    "    \n",
    "    # 4. Score de complexité inversé (0-1)\n",
    "    complexity = row.get('text_complexity', 0.5)\n",
    "    scores['complexity'] = 1 - complexity  # Moins complexe = meilleur\n",
    "    \n",
    "    # 5. Score de structure (0-1)\n",
    "    sentence_count = row.get('sentence_count', 0)\n",
    "    paragraph_count = row.get('paragraph_count', 0)\n",
    "    if sentence_count > 0 and paragraph_count > 0:\n",
    "        structure_ratio = min(sentence_count / paragraph_count, 10) / 10  # Ratio phrases/paragraphes\n",
    "        scores['structure'] = structure_ratio\n",
    "    else:\n",
    "        scores['structure'] = 0.1\n",
    "        \n",
    "    # 6. Score de langue (0-1)\n",
    "    lang_confidence = row.get('language_confidence', 0.5)\n",
    "    scores['language'] = lang_confidence\n",
    "    \n",
    "    # Score global pondéré\n",
    "    weights = {\n",
    "        'length': 0.2,\n",
    "        'entities': 0.25, \n",
    "        'readability': 0.2,\n",
    "        'complexity': 0.15,\n",
    "        'structure': 0.1,\n",
    "        'language': 0.1\n",
    "    }\n",
    "    \n",
    "    final_score = sum(scores[key] * weights[key] for key in scores)\n",
    "    \n",
    "    return {\n",
    "        'quality_score_advanced': final_score,\n",
    "        'quality_breakdown': scores\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e0eeab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Calcul des scores de qualité...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qualité: 100%|██████████| 128/128 [00:00<00:00, 7533.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score qualité moyen: 0.681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Application du calcul de qualité\n",
    "print(\"   Calcul des scores de qualité...\")\n",
    "quality_results = []\n",
    "for _, row in tqdm(df_clean_dedup.iterrows(), total=len(df_clean_dedup), desc=\"Qualité\"):\n",
    "    quality_result = calculate_advanced_quality_score(row)\n",
    "    quality_results.append(quality_result)\n",
    "\n",
    "# Ajout des résultats\n",
    "df_clean_dedup['quality_score_advanced'] = [r['quality_score_advanced'] for r in quality_results]\n",
    "df_clean_dedup['quality_breakdown'] = [r['quality_breakdown'] for r in quality_results]\n",
    "\n",
    "print(f\"   Score qualité moyen: {df_clean_dedup['quality_score_advanced'].mean():.3f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5686e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stratified_calibration_corpus(df, n_samples=300):\n",
    "    \"\"\"Création d'un corpus stratifié pour calibration\"\"\"\n",
    "    \n",
    "    # Définition des strates multi-dimensionnelles\n",
    "    print(\"   Définition des strates...\")\n",
    "    \n",
    "    # 1. Strate par qualité (3 niveaux)\n",
    "    quality_tertiles = df['quality_score_advanced'].quantile([0.33, 0.67])\n",
    "    df['quality_stratum'] = pd.cut(df['quality_score_advanced'], \n",
    "                                  bins=[0, quality_tertiles[0.33], quality_tertiles[0.67], 1],\n",
    "                                  labels=['low', 'medium', 'high'])\n",
    "    \n",
    "    # 2. Strate par longueur (3 niveaux)\n",
    "    df['text_length'] = df['text_cleaned'].str.len()\n",
    "    length_tertiles = df['text_length'].quantile([0.33, 0.67])\n",
    "    df['length_stratum'] = pd.cut(df['text_length'],\n",
    "                                 bins=[0, length_tertiles[0.33], length_tertiles[0.67], float('inf')],\n",
    "                                 labels=['short', 'medium', 'long'])\n",
    "    \n",
    "    # 3. Strate par richesse en entités (3 niveaux)\n",
    "    if df['entities_total'].max() > 0:\n",
    "        entity_tertiles = df['entities_total'].quantile([0.33, 0.67])\n",
    "        df['entity_stratum'] = pd.cut(df['entities_total'],\n",
    "                                     bins=[-1, entity_tertiles[0.33], entity_tertiles[0.67], float('inf')],\n",
    "                                     labels=['sparse', 'moderate', 'rich'])\n",
    "    else:\n",
    "        df['entity_stratum'] = 'sparse'\n",
    "        \n",
    "    # 4. Strate par source (top sources + autres)\n",
    "    source_counts = df['source'].value_counts()\n",
    "    top_sources = source_counts.head(5).index.tolist()\n",
    "    df['source_stratum'] = df['source'].apply(lambda x: x if x in top_sources else 'other')\n",
    "    \n",
    "    # Échantillonnage stratifié proportionnel\n",
    "    print(\"   Échantillonnage stratifié...\")\n",
    "    \n",
    "    # Groupement par strates multiples\n",
    "    strata_cols = ['quality_stratum', 'length_stratum', 'entity_stratum', 'source_stratum']\n",
    "    grouped = df.groupby(strata_cols, group_keys=False)\n",
    "    \n",
    "    # Calcul des tailles d'échantillon par strate\n",
    "    strata_sizes = grouped.size()\n",
    "    total_size = len(df)\n",
    "    \n",
    "    sample_dfs = []\n",
    "    remaining_samples = n_samples\n",
    "    \n",
    "    for stratum, group in grouped:\n",
    "        if remaining_samples <= 0:\n",
    "            break\n",
    "            \n",
    "        # Taille proportionnelle de l'échantillon pour cette strate\n",
    "        stratum_size = len(group)\n",
    "        proportion = stratum_size / total_size\n",
    "        target_sample_size = max(1, int(proportion * n_samples))\n",
    "        \n",
    "        # Ajustement si on dépasse le nombre d'échantillons restants\n",
    "        actual_sample_size = min(target_sample_size, remaining_samples, stratum_size)\n",
    "        \n",
    "        if actual_sample_size > 0:\n",
    "            # Échantillonnage au sein de la strate\n",
    "            if len(group) >= actual_sample_size:\n",
    "                # Tri par score de qualité pour prendre les meilleurs\n",
    "                group_sorted = group.sort_values('quality_score_advanced', ascending=False)\n",
    "                stratum_sample = group_sorted.head(actual_sample_size)\n",
    "                sample_dfs.append(stratum_sample)\n",
    "                remaining_samples -= actual_sample_size\n",
    "                \n",
    "    # Combinaison des échantillons de toutes les strates\n",
    "    if sample_dfs:\n",
    "        calibration_corpus = pd.concat(sample_dfs, ignore_index=True)\n",
    "    else:\n",
    "        # Fallback: échantillonnage simple par qualité\n",
    "        calibration_corpus = df.nlargest(n_samples, 'quality_score_advanced')\n",
    "        \n",
    "    # Complément aléatoire si nécessaire\n",
    "    if len(calibration_corpus) < n_samples:\n",
    "        remaining_df = df[~df.index.isin(calibration_corpus.index)]\n",
    "        if len(remaining_df) > 0:\n",
    "            additional_samples = min(n_samples - len(calibration_corpus), len(remaining_df))\n",
    "            additional = remaining_df.sample(n=additional_samples, random_state=42)\n",
    "            calibration_corpus = pd.concat([calibration_corpus, additional], ignore_index=True)\n",
    "            \n",
    "    return calibration_corpus.head(n_samples)  # S'assurer qu'on ne dépasse pas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50d1e9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Définition des strates...\n",
      "   Échantillonnage stratifié...\n",
      "   CORPUS DE CALIBRATION CRÉÉ:\n",
      "      Taille finale: 186 articles\n",
      "      Score qualité moyen: 0.679\n"
     ]
    }
   ],
   "source": [
    "# Création du corpus de calibration\n",
    "calibration_corpus = create_stratified_calibration_corpus(df_clean_dedup, n_samples=300)\n",
    "\n",
    "print(f\"   CORPUS DE CALIBRATION CRÉÉ:\")\n",
    "print(f\"      Taille finale: {len(calibration_corpus)} articles\")\n",
    "print(f\"      Score qualité moyen: {calibration_corpus['quality_score_advanced'].mean():.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec826d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métriques de qualité finales\n",
    "quality_metrics = {\n",
    "    'source_file': str(source_file.name),\n",
    "    'enriched_mode': ENRICHED_MODE,\n",
    "    'total_articles_input': len(articles_data),\n",
    "    'articles_after_deduplication': len(df_clean_dedup),\n",
    "    'calibration_corpus_size': len(calibration_corpus),\n",
    "    'deduplication_rate': ((len(df) - len(df_clean_dedup)) / len(df)) if len(df) > 0 else 0,\n",
    "    'avg_quality_score': df_clean_dedup['quality_score_advanced'].mean(),\n",
    "    'language_distribution': df_clean_dedup['language'].value_counts().to_dict(),\n",
    "    'entities_avg_per_article': df_clean_dedup['entities_total'].mean(),\n",
    "    'temporal_bias_detected': df_clean_dedup['temporal_bias_hour'].iloc[0] if len(df_clean_dedup) > 0 else 0,\n",
    "    'geographic_bias_detected': df_clean_dedup['geographic_bias'].iloc[0] if len(df_clean_dedup) > 0 else 0,\n",
    "    'processing_timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfaa244f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset principal sauvegardé: C:\\Users\\beedi.goua_square-ma\\Desktop\\Gheb\\projet perso\\InsightDetector\\insight-detector\\data\\processed\\articles_preprocessed_advanced.pkl\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du DataFrame principal (format optimisé)\n",
    "output_file = PROCESSED_DIR / \"articles_preprocessed_advanced.pkl\"\n",
    "df_clean_dedup.to_pickle(output_file)\n",
    "print(f\"   Dataset principal sauvegardé: {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e3705eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Corpus de calibration sauvegardé: C:\\Users\\beedi.goua_square-ma\\Desktop\\Gheb\\projet perso\\InsightDetector\\insight-detector\\data\\processed\\calibration_corpus_stratified.pkl\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du corpus de calibration\n",
    "calibration_file = PROCESSED_DIR / \"calibration_corpus_stratified.pkl\"\n",
    "calibration_corpus.to_pickle(calibration_file)\n",
    "print(f\"   Corpus de calibration sauvegardé: {calibration_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "335f8dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Métriques sauvegardées: C:\\Users\\beedi.goua_square-ma\\Desktop\\Gheb\\projet perso\\InsightDetector\\insight-detector\\data\\processed\\advanced_preprocessing_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde des métriques\n",
    "metrics_file = PROCESSED_DIR / \"advanced_preprocessing_metrics.json\"\n",
    "with open(metrics_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(quality_metrics, f, indent=2, ensure_ascii=False, default=str)\n",
    "print(f\"   Métriques sauvegardées: {metrics_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "874023e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Export CSV résumé: C:\\Users\\beedi.goua_square-ma\\Desktop\\Gheb\\projet perso\\InsightDetector\\insight-detector\\data\\processed\\articles_preprocessed_summary.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Export CSV léger pour analyse externe\n",
    "csv_file = PROCESSED_DIR / \"articles_preprocessed_summary.csv\"\n",
    "df_export = df_clean_dedup[[\n",
    "    'title', 'source', 'published', 'language', 'quality_score_advanced',\n",
    "    'entities_total', 'sentence_count', 'readability_score', 'text_complexity'\n",
    "]].copy()\n",
    "df_export.to_csv(csv_file, index=False, encoding='utf-8')\n",
    "print(f\"   Export CSV résumé: {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8a73751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Corpus calibration JSON: C:\\Users\\beedi.goua_square-ma\\Desktop\\Gheb\\projet perso\\InsightDetector\\insight-detector\\data\\processed\\calibration_corpus_300.json\n"
     ]
    }
   ],
   "source": [
    "# Export JSON du corpus de calibration (pour Phase 3)\n",
    "calibration_json = PROCESSED_DIR / \"calibration_corpus_300.json\"\n",
    "calibration_export = calibration_corpus[[\n",
    "    'id', 'title', 'text_cleaned', 'source', 'published', 'language',\n",
    "    'quality_score_advanced', 'entities_advanced'\n",
    "]].to_dict('records')\n",
    "\n",
    "with open(calibration_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(calibration_export, f, ensure_ascii=False, indent=2, default=str)\n",
    "print(f\"   Corpus calibration JSON: {calibration_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "818971e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RÉSULTATS FINAUX:\n",
      "   Source: enriched_articles.json\n",
      "   Mode: Enrichissement complémentaire\n",
      "   Articles traités: 200\n",
      "   Articles finaux: 128\n",
      "   Corpus de calibration: 186\n",
      "   Taux de déduplication: 36.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"RÉSULTATS FINAUX:\")\n",
    "print(f\"   Source: {quality_metrics['source_file']}\")\n",
    "print(f\"   Mode: {'Enrichissement complémentaire' if ENRICHED_MODE else 'Pipeline complet'}\")\n",
    "print(f\"   Articles traités: {quality_metrics['total_articles_input']}\")\n",
    "print(f\"   Articles finaux: {quality_metrics['articles_after_deduplication']}\")\n",
    "print(f\"   Corpus de calibration: {quality_metrics['calibration_corpus_size']}\")\n",
    "print(f\"   Taux de déduplication: {quality_metrics['deduplication_rate']:.1%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e394572c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MÉTRIQUES DE QUALITÉ:\n",
      "   Score qualité moyen: 0.681\n",
      "   Entités par article: 23.1\n",
      "   Biais temporel détecté: 0.81\n",
      "   Biais géographique: -0.57\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nMÉTRIQUES DE QUALITÉ:\")\n",
    "print(f\"   Score qualité moyen: {quality_metrics['avg_quality_score']:.3f}\")\n",
    "print(f\"   Entités par article: {quality_metrics['entities_avg_per_article']:.1f}\")\n",
    "print(f\"   Biais temporel détecté: {quality_metrics['temporal_bias_detected']:.2f}\")\n",
    "print(f\"   Biais géographique: {quality_metrics['geographic_bias_detected']:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8e744e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FICHIERS GÉNÉRÉS:\n",
      "   1. articles_preprocessed_advanced.pkl - Dataset principal avec preprocessing avancé\n",
      "   2. calibration_corpus_stratified.pkl - Corpus stratifié pour calibration\n",
      "   3. advanced_preprocessing_metrics.json - Métriques détaillées\n",
      "   4. articles_preprocessed_summary.csv - Export CSV pour analyse\n",
      "   5. calibration_corpus_300.json - Corpus JSON pour Phase 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFICHIERS GÉNÉRÉS:\")\n",
    "print(f\"   1. {output_file.name} - Dataset principal avec preprocessing avancé\")\n",
    "print(f\"   2. {calibration_file.name} - Corpus stratifié pour calibration\")\n",
    "print(f\"   3. {metrics_file.name} - Métriques détaillées\")\n",
    "print(f\"   4. {csv_file.name} - Export CSV pour analyse\")\n",
    "print(f\"   5. {calibration_json.name} - Corpus JSON pour Phase 3\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9d909fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VARIABLES DISPONIBLES POUR EXPORT:\n",
      "   - df_clean_dedup: DataFrame principal preprocessé\n",
      "   - calibration_corpus: Corpus de calibration\n",
      "   - quality_metrics: Métriques de qualité\n",
      "   - PROCESSED_DIR: Répertoire des données traitées\n"
     ]
    }
   ],
   "source": [
    "# Variables exportées pour les autres notebooks\n",
    "print(f\"\\nVARIABLES DISPONIBLES POUR EXPORT:\")\n",
    "print(f\"   - df_clean_dedup: DataFrame principal preprocessé\")\n",
    "print(f\"   - calibration_corpus: Corpus de calibration\")\n",
    "print(f\"   - quality_metrics: Métriques de qualité\")\n",
    "print(f\"   - PROCESSED_DIR: Répertoire des données traitées\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d777d251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Variables sauvegardées: preprocessing_variables.pkl\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde des variables principales pour les autres notebooks\n",
    "import pickle\n",
    "variables_export = {\n",
    "    'df_clean_dedup': df_clean_dedup,\n",
    "    'calibration_corpus': calibration_corpus,\n",
    "    'quality_metrics': quality_metrics,\n",
    "    'PROCESSED_DIR': PROCESSED_DIR\n",
    "}\n",
    "with open(PROCESSED_DIR / 'preprocessing_variables.pkl', 'wb') as f:\n",
    "    pickle.dump(variables_export, f)\n",
    "print(f\"   Variables sauvegardées: preprocessing_variables.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
