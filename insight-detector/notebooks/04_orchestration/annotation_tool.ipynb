{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outil d'Annotation Manuelle des Résumés\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Chemins\n",
    "BASE_DIR = Path().resolve().parent.parent\n",
    "RESULTS_DIR = BASE_DIR / \"data\" / \"results\"\n",
    "ANNOTATIONS_DIR = RESULTS_DIR / \"human_annotations\"\n",
    "ANNOTATIONS_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les résumés générés\n",
    "with open(RESULTS_DIR / \"all_summaries_and_scores.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "summaries = data[\"summaries\"]\n",
    "evaluations = data[\"evaluations\"]\n",
    "\n",
    "print(f\"Nombre total de résumés : {len(summaries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnotationInterface:\n",
    "    def __init__(self, summaries_data, evaluations_data, sample_size=25):\n",
    "        self.summaries = summaries_data\n",
    "        self.evaluations = evaluations_data\n",
    "        self.sample_size = sample_size\n",
    "        self.current_index = 0\n",
    "        self.annotations = []\n",
    "        \n",
    "        # Sélection stratifiée : mix scores élevés/moyens/faibles\n",
    "        self.selected_indices = self._stratified_sample()\n",
    "        \n",
    "        # Widgets\n",
    "        self.setup_widgets()\n",
    "        \n",
    "    def _stratified_sample(self):\n",
    "        \"\"\"Échantillonnage stratifié basé sur les scores composites\"\"\"\n",
    "        scores = [(i, eval_data.get('Score composite', 0.5)) \n",
    "                 for i, eval_data in enumerate(self.evaluations)]\n",
    "        scores.sort(key=lambda x: x[1])\n",
    "        \n",
    "        # Prendre 1/3 de chaque catégorie\n",
    "        n_per_group = self.sample_size // 3\n",
    "        low_scores = scores[:len(scores)//3][:n_per_group]\n",
    "        mid_scores = scores[len(scores)//3:2*len(scores)//3][:n_per_group]\n",
    "        high_scores = scores[2*len(scores)//3:][:n_per_group]\n",
    "        \n",
    "        selected = [x[0] for x in low_scores + mid_scores + high_scores]\n",
    "        random.shuffle(selected)\n",
    "        return selected\n",
    "    \n",
    "    def setup_widgets(self):\n",
    "        # Critères d'évaluation\n",
    "        self.factuality_slider = widgets.IntSlider(\n",
    "            value=3, min=1, max=5, description='Factualité:', \n",
    "            tooltip='1=Très incorrecte, 5=Parfaitement correcte'\n",
    "        )\n",
    "        \n",
    "        self.coherence_slider = widgets.IntSlider(\n",
    "            value=3, min=1, max=5, description='Cohérence:',\n",
    "            tooltip='1=Incohérente, 5=Très cohérente'\n",
    "        )\n",
    "        \n",
    "        self.readability_slider = widgets.IntSlider(\n",
    "            value=3, min=1, max=5, description='Lisibilité:',\n",
    "            tooltip='1=Très difficile, 5=Très facile à lire'\n",
    "        )\n",
    "        \n",
    "        self.completeness_slider = widgets.IntSlider(\n",
    "            value=3, min=1, max=5, description='Complétude:',\n",
    "            tooltip='1=Manque beaucoup, 5=Très complet'\n",
    "        )\n",
    "        \n",
    "        self.overall_slider = widgets.IntSlider(\n",
    "            value=3, min=1, max=5, description='Global:',\n",
    "            tooltip='1=Très mauvais, 5=Excellent résumé'\n",
    "        )\n",
    "        \n",
    "        # Zone de commentaires\n",
    "        self.comments_text = widgets.Textarea(\n",
    "            placeholder='Commentaires optionnels (erreurs spécifiques, suggestions...)'\n",
    "        )\n",
    "        \n",
    "        # Boutons\n",
    "        self.prev_button = widgets.Button(description='Précédent', disabled=True)\n",
    "        self.next_button = widgets.Button(description='Suivant ')\n",
    "        self.save_button = widgets.Button(description=' Sauvegarder', button_style='success')\n",
    "        \n",
    "        # Events\n",
    "        self.prev_button.on_click(self.prev_summary)\n",
    "        self.next_button.on_click(self.next_summary)\n",
    "        self.save_button.on_click(self.save_annotation)\n",
    "        \n",
    "        # Progress\n",
    "        self.progress = widgets.IntProgress(\n",
    "            value=0, min=0, max=len(self.selected_indices),\n",
    "            description='Progrès:'\n",
    "        )\n",
    "        \n",
    "    def display_current_summary(self):\n",
    "        if self.current_index >= len(self.selected_indices):\n",
    "            display(HTML(\"<h3> Annotation terminée ! Merci !</h3>\"))\n",
    "            return\n",
    "            \n",
    "        idx = self.selected_indices[self.current_index]\n",
    "        summary_data = self.summaries[idx]\n",
    "        eval_data = self.evaluations[idx]\n",
    "        \n",
    "        # Affichage du résumé et texte source\n",
    "        html_content = f\"\"\"\n",
    "        <div style='border: 2px solid #e1e5e9; padding: 15px; margin: 10px 0; border-radius: 8px;'>\n",
    "            <h4> Article #{self.current_index + 1}/{len(self.selected_indices)} (ID: {summary_data['summary_id']})</h4>\n",
    "            \n",
    "            <div style='background: #f8f9fa; padding: 10px; margin: 10px 0; border-radius: 5px;'>\n",
    "                <strong> Résumé généré :</strong><br>\n",
    "                {summary_data['ensemble_summary']['summary']}\n",
    "            </div>\n",
    "            \n",
    "            <div style='background: #e8f4fd; padding: 10px; margin: 10px 0; border-radius: 5px; max-height: 300px; overflow-y: auto;'>\n",
    "                <strong> Article original (extrait) :</strong><br>\n",
    "                {summary_data.get('source_text', 'Non disponible')[:1000]}...\n",
    "            </div>\n",
    "            \n",
    "            <div style='background: #fff3cd; padding: 8px; margin: 10px 0; border-radius: 5px;'>\n",
    "                <strong> Scores automatiques :</strong> \n",
    "                Factualité: {eval_data.get('Factualité', 'N/A'):.3f} | \n",
    "                Cohérence: {eval_data.get('Cohérence', 'N/A'):.3f} | \n",
    "                Score global: {eval_data.get('Score composite', 'N/A'):.3f}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        display(HTML(html_content))\n",
    "        \n",
    "        # Widgets d'annotation\n",
    "        display(widgets.VBox([\n",
    "            self.progress,\n",
    "            widgets.HTML(\"<h4> Votre évaluation :</h4>\"),\n",
    "            self.factuality_slider,\n",
    "            self.coherence_slider, \n",
    "            self.readability_slider,\n",
    "            self.completeness_slider,\n",
    "            self.overall_slider,\n",
    "            self.comments_text,\n",
    "            widgets.HBox([self.prev_button, self.next_button, self.save_button])\n",
    "        ]))\n",
    "        \n",
    "        # Mise à jour des boutons\n",
    "        self.prev_button.disabled = (self.current_index == 0)\n",
    "        self.next_button.disabled = (self.current_index >= len(self.selected_indices) - 1)\n",
    "        self.progress.value = self.current_index\n",
    "        \n",
    "    def save_annotation(self, button):\n",
    "        idx = self.selected_indices[self.current_index]\n",
    "        \n",
    "        annotation = {\n",
    "            'summary_id': self.summaries[idx]['summary_id'],\n",
    "            'original_index': idx,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'human_scores': {\n",
    "                'factuality': self.factuality_slider.value,\n",
    "                'coherence': self.coherence_slider.value,\n",
    "                'readability': self.readability_slider.value,\n",
    "                'completeness': self.completeness_slider.value,\n",
    "                'overall': self.overall_slider.value\n",
    "            },\n",
    "            'comments': self.comments_text.value,\n",
    "            'automatic_scores': {\n",
    "                'factuality': self.evaluations[idx].get('Factualité'),\n",
    "                'coherence': self.evaluations[idx].get('Cohérence'),\n",
    "                'composite': self.evaluations[idx].get('Score composite')\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.annotations.append(annotation)\n",
    "        \n",
    "        # Sauvegarde immédiate\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = ANNOTATIONS_DIR / f\"annotations_{timestamp}.json\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.annotations, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "        print(f\" Annotation {self.current_index + 1} sauvegardée !\")\n",
    "        \n",
    "    def next_summary(self, button):\n",
    "        if self.current_index < len(self.selected_indices) - 1:\n",
    "            self.current_index += 1\n",
    "            self.display_current_summary()\n",
    "            \n",
    "    def prev_summary(self, button):\n",
    "        if self.current_index > 0:\n",
    "            self.current_index -= 1\n",
    "            self.display_current_summary()\n",
    "\n",
    "# Initialiser l'interface\n",
    "annotation_tool = AnnotationInterface(summaries, evaluations, sample_size=25)\n",
    "annotation_tool.display_current_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des annotations collectées\n",
    "def analyze_annotations():\n",
    "    annotation_files = list(ANNOTATIONS_DIR.glob(\"annotations_*.json\"))\n",
    "    if not annotation_files:\n",
    "        print(\"Aucune annotation trouvée.\")\n",
    "        return\n",
    "        \n",
    "    # Charger la dernière annotation\n",
    "    latest_file = max(annotation_files, key=lambda x: x.stat().st_mtime)\n",
    "    with open(latest_file, 'r', encoding='utf-8') as f:\n",
    "        annotations = json.load(f)\n",
    "    \n",
    "    if not annotations:\n",
    "        print(\"Aucune annotation dans le fichier.\")\n",
    "        return\n",
    "        \n",
    "    # Créer DataFrame pour analyse\n",
    "    df_annotations = pd.DataFrame([\n",
    "        {\n",
    "            'summary_id': ann['summary_id'],\n",
    "            'human_factuality': ann['human_scores']['factuality'],\n",
    "            'human_coherence': ann['human_scores']['coherence'],\n",
    "            'human_readability': ann['human_scores']['readability'],\n",
    "            'human_overall': ann['human_scores']['overall'],\n",
    "            'auto_factuality': ann['automatic_scores']['factuality'],\n",
    "            'auto_coherence': ann['automatic_scores']['coherence'],\n",
    "            'auto_composite': ann['automatic_scores']['composite'],\n",
    "            'comments': ann['comments']\n",
    "        }\n",
    "        for ann in annotations\n",
    "    ])\n",
    "    \n",
    "    print(f\" Analyse de {len(df_annotations)} annotations\")\n",
    "    print(\"\\n=== MOYENNES SCORES HUMAINS ===\")\n",
    "    human_cols = ['human_factuality', 'human_coherence', 'human_readability', 'human_overall']\n",
    "    print(df_annotations[human_cols].mean())\n",
    "    \n",
    "    print(\"\\n=== CORRÉLATIONS HUMAIN vs AUTOMATIQUE ===\")\n",
    "    correlations = {\n",
    "        'Factualité': df_annotations[['human_factuality', 'auto_factuality']].corr().iloc[0,1],\n",
    "        'Cohérence': df_annotations[['human_coherence', 'auto_coherence']].corr().iloc[0,1],\n",
    "        'Global': df_annotations[['human_overall', 'auto_composite']].corr().iloc[0,1]\n",
    "    }\n",
    "    \n",
    "    for metric, corr in correlations.items():\n",
    "        print(f\"{metric}: {corr:.3f}\")\n",
    "        \n",
    "    return df_annotations\n",
    "\n",
    "# Lancer l'analyse si des annotations existent\n",
    "df_human = analyze_annotations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
